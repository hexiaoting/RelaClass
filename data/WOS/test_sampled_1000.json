{"id": "0", "token": "Agitation associated with dementia is frequently reported clinically but has received little attention in preclinical models of dementia. The current study used a 7PA2 CM intracerebroventricular injection model of Alzheimer's disease (AD) to assess acute memory impairment, and a bilateral intrahippocampal (IH) injection model of AD (aggregated A beta(1-42) injections) and a bilateral IH injection model of dementia with Lewy bodies (aggregated NAC(61-95) injections) to assess chronic memory impairment in the rat. An alternating-lever cyclic-ratio schedule of operant responding was used for data collection, where incorrect lever perseverations measured executive function (memory) and running response rates (RRR) measured behavioral output (agitation). The results indicate that bilateral IH injections of A beta(1-42) and bilateral IH injections of NAC(61-95) decreased memory function and increased RRRs, whereas intracerebroventricular injections of 7PA2 CM decreased memory function but did not increase RRRs. These findings show that using the aggregated peptide IH injection models of dementia to induce chronic neurotoxicity, memory decline was accompanied by elevated behavioral output. This demonstrates that IH peptide injection models of dementia provide a preclinical screen for pharmacological interventions used in the treatment of increased behavioral output (agitation), which also establish detrimental side effects on memory. (C) 2017 Wolters Kluwer Health, Inc. All rights reserved.", "labels": [5, 32]}
{"id": "120", "token": "Objective: This exploratory study provided a proof of concept of a new procedure using multivariate electroencephalographic (EEG) topographic markers of cortical connectivity to discriminate normal elderly (Nold) and Alzheimer's disease (AD) individuals. Method: The new procedure was tested on an existing database formed by resting state eyes-closed EEG data (19 exploring electrodes of 10-20 system referenced to linked-ear reference electrodes) recorded in 42 AD patients with dementia (age: 65.9 years +/- 8.5 standard deviation, SD) and 42 Nold non-consanguineous caregivers (age: 70.6 years +/- 8.5 SD). In this procedure, spectral EEG coherence estimated reciprocal functional connectivity while non-normalized directed transfer function (NDTF) estimated effective connectivity. Principal component analysis and computation of Mahalanobis distance integrated and combined these EEG topographic markers of cortical connectivity. The area under receiver operating curve (AUC) indexed the classification accuracy. Results: A good classification of Nold and AD individuals was obtained by combining the EEG markers derived from NDTF and coherence (AUC = 86%, sensitivity = 0.85, specificity = 0.70). Conclusion: These encouraging results motivate a cross-validation study of the new procedure in ageand education-matched Nold, stable and progressing mild cognitive impairment individuals, and de novo AD patients with dementia. Significance: If cross- validated, the new procedure will provide cheap, broadly available, repeatable over time, and entirely non-invasive EEG topographic markers reflecting abnormal cortical connectivity in AD patients diagnosed by direct or indirect measurement of cerebral amyloid beta and hyperphosphorylated tau peptides. (C) 2016 International Federation of Clinical Neurophysiology. Published by Elsevier Ireland Ltd. All rights reserved.", "labels": [5, 32]}
{"id": "292", "token": "Chronic cerebral hypoperfusion (CCH) has been recognized as an important cause of both vascular dementia and Alzheimer's disease (AD), the two most prominent neurodegenerative diseases causing memory impairment in the elderly. However, an effective therapy for CCH-induced memory impairment has not yet been established. Grape seed polyphenol extract (GSPE) has powerful antioxidant properties and protects neurons and glia during ischemic injury, but its potential use in the prevention of CCH-induced memory impairment has not yet been investigated. Here, CCH-related memory impairment was modeled in rats using permanent bilateral occlusion of the common carotid artery. A Morris water maze task was used to evaluate memory, the levels of acetylcholinesterase, choline acetyltransferase, acetylcholine were used to evaluate cholinergic function, and oxidative stress was assessed by measuring the enzyme activity of superoxide dismutase, glutathione peroxidase, malonic dialdehyde, and catalase. We found that oral administration of GSPE for 1 month can rescue memory deficits. We also found that GSPE restores cholinergic neuronal function and represses oxidative damage in the hippocampus of CCH rats. We propose that GSPE protects memory in CCH rats by reducing ischemia-induced oxidative stress and cholinergic dysfunction. These findings provide a novel application of GSPE in CCH-related memory impairments. Copyright (C) 2017 Wolters Kluwer Health, Inc. All rights reserved.", "labels": [5, 32]}
{"id": "393", "token": "The anterior temporal lobes (ATLs) have been consistently associated with semantic processing which, in turn, has a key role in reading aloud single words. This study aimed to investigate (1) the reading abilities in patients with the semantic variant of primary progressive aphasia (svPPA), and (2) the relationship between gray matter (GM) volume of the left ATL and word reading performance using voxel-based morphometry (VBM). Three groups of participants (svPPA, Alzheimer's Disease, AD and healthy elderly adults) performed a reading task with exception words, regular words and pseudowords, along with a structural magnetic resonance imaging scan. For exception words, the svPPA group had a lower accuracy and a greater number of regularization errors as compared to the control groups of healthy participants and AD patients. Similarly, for regular words, svPPA patients had a lower accuracy in comparison with AD patients, and a greater number of errors related to complex orthography-to-phonology mappings (OPM) in comparison to both control groups. VBM analyses revealed that GM volume of the left ATL was associated with the number of regularization errors. Also, GM volume of the left lateral ATL was associated with the number of errors with complex OPM during regular word reading. Our results suggest that the left ATL might play a role in the reading of exception words, in accordance with its role in semantic processing. Results further support the involvement of the left lateral ATL in combinatorial processes, including the integration of semantic and phonological information, for both exception and regular words.", "labels": [5, 32]}
{"id": "455", "token": "Biomarkers of brain amyloidosis and neurodegeneration/synaptic dysfunction are featured in recent diagnostic criteria for Alzheimer's disease. Several gaps in our knowledge, however, need to be filled before they can be adopted clinically. The aim of this article is to describe a roadmap, developed by a multidisciplinary task force, to rationally implement biomarkers for Italian Memory Clinics. This roadmap is based on a framework comprising 5 sequential phases: identification of leads for potentially useful biomarkers; development of clinical assays for clinical disease; evaluation of detection of early stages; definition of operating characteristics in relevant populations; and estimation of reducing disease-associated mortality, morbidity, and disability. The roadmap was devised by identifying current evidence of validity, still missing evidence, and action needed to collect this missing evidence. With appropriate adaptation to local, country-specific circumstances, the roadmap can be translated to other countries. (C) 2016 Elsevier Inc. All rights reserved.", "labels": [5, 32]}
{"id": "589", "token": "Background In the central nervous system (CNS), G proteincoupled receptors (GPCRs) are the most fruitful targets for neuropsychopharmacological drug development. Rhodopsin (class A) is the most studied class of GPCR and includes orphan receptors for which the endogenous ligand is not known or is unclear. Characterization of orphan GPCRs has proven to be challenging, and the production pace of GPCR-based drugs has been incredibly slow. Objective Determination of the functions of these receptors may provide unexpected insight into physiological and neuropathological processes. Advances in various methods and techniques to investigate orphan receptors including in situ hybridization and knockdown/knockout (KD/KO) showed extensive expression of these receptors in the mammalian brain and unmasked their physiological and neuropathological roles. Due to these rapid progress and development, orphan GPCRs are rising as a new and promising class of drug targets for neurodegenerative diseases and psychiatric disorders. Conclusion This review presents a neuropsychopharmacological perspective of 26 orphan receptors of rhodopsin (class A) family, namely GPR3, GPR6, GPR12, GPR17, GPR26, GPR35, GPR39, GPR48, GPR49, GPR50, GPR52, GPR55, GPR61, GPR62, GPR63, GPR68, GPR75, GPR78, GPR83, GPR84, GPR85, GPR88, GPR153, GPR162, GPR171, and TAAR6. We discussed the expression of these receptors in mammalian brain and their physiological roles. Furthermore, we have briefly highlighted their roles in neurodegenerative diseases and psychiatric disorders including Alzheimer's disease, Parkinson's disease, neuroinflammation, inflammatory pain, bipolar and schizophrenic disorders, epilepsy, anxiety, and depression.", "labels": [5, 32]}
{"id": "653", "token": "In Alzheimer's disease, the microtubule-associated protein tau forms intracellular neurofibrillary tangles (NFTs). A critical step in the formation of NFTs is the conversion of soluble tau into insoluble filaments. Accordingly, a current therapeutic strategy in clinical trials is aimed at preventing tau aggregation. Here, we assessed altenusin, a bioactive polyphenolic compound, for its potential to inhibit tau aggregation. Altenusin inhibits aggregation of tau protein into paired helical filaments in vitro. This was associated with stabilization of, tau dimers and other oligomers into globular structures as revealed by atomic force microscopy. Moreover, altenusin reduced tau phosphorylation in cells expressing pathogenic tau, and prevented neuritic tau pathology induced by incubation of primary neurons with tau fibrils. However, treatment of tau transgenic mice did not improve neuropathology and functional deficits. Taken together, altenusin prevents tau fibrillization in vitro and induced tau pathology in neurons.", "labels": [5, 32]}
{"id": "720", "token": "Deficiencies of the retrograde transport mediated by the retromer complex have been described in Alzheimer's disease (AD). Genetic manipulation of retromer modulates brain amyloidosis in Tg2576 mice. However, whether the complex is altered during the development of the AD-like phenotype remains unknown. In this study we assayed the expression levels of the vacuolar sorting protein 35 (VPS35), VPS26, VPS29, and its cargo proteins, cation independent mannose 6-phosphate receptor, sortilin-related receptor in brains of Tg2576 and controls at the ages of 3, 8, and 14 months. While cortex showed an age-dependent decrease in all but VPS29, levels of the same proteins in the cerebellum were unchanged at any age. Neuronal cells expressing human amyloid beta precursor protein Swedish mutant had also reduced retromer complex levels. However, incubation with a pharmacological chaperone dose-dependently restored these levels together with a reduction in amyloid beta. Our study is the first to show that in a transgenic mouse model of AD the changes in the expression levels of the retromer complex are age and region dependent, and that the complex is a viable therapeutic target since its deficiency can be restored pharmacologically by a retromer chaperone. (C) 2016 Elsevier Inc. All rights reserved.", "labels": [5, 32]}
{"id": "850", "token": "Although Alzheimer's disease criteria promote the use of biomarkers, their maturity in clinical routine still needs to be assessed. In the light of the oncology framework, we conducted a literature review on measures used to assess delayed recall impairment due to medial temporal lobe dysfunction (i. e., free and cued word list recall tests). Ample evidence is available for phases 1 (rationale for use), 2 (discriminative ability), and 3 (early detection ability) for many of the tests in routine use. Evidence about phase 4 (performance in real world) and phase 5 (quantify impact and costs) is yet to come. Administration procedures have been standardized and cutoff scores are well validated in large Alzheimer's disease and mild cognitive impaired series. Some aspects (e. g., different task formats), however, hamper the comparability of results among different populations and the reproducibility between laboratories. No definite guideline for their use can thus be proposed at the moment. Accordingly, the maturity of such markers is not yet sufficient and requires future investigation to promote the proper use of memory measures in clinical settings. (C) 2016 Elsevier Inc. All rights reserved.", "labels": [5, 32]}
{"id": "950", "token": "Caffeine is adjudged world's most consumed pharmacologically active food component. With reports of the potential cognitive enhancing properties of caffeine, we sought to investigate if caffeine can influence the anticholinesterase and antioxidant properties of donepezil-a selective acetylcholinesterase (AChE) inhibitor used in the management of Alzheimer's disease (AD). In vitro, we investigated the effect of donepezil (DON), caffeine (CAF) and their various combinations on the activity of AChE in rat brain homogenate, as well as determined their antioxidant properties. In vivo, two rat groups were administered single oral dose of DON (5 mg/kg) and CAF (5 mg/kg) separately, while three groups, each received 5 mg/kg DON plus either 5, 50 or 100 mg/kg CAF for three hours, after which the rats were sacrificed and brain isolated. Results show that CAF concentration dependently and synergistically increased the anticholinesterase properties of DON in vitro. Also, CAF produced a significant influence on investigated in vitro antioxidant properties of DON. Furthermore, rats administered 5 mg/kg CAF and DON produced no significant difference in AChE activity compared to rats administered DON alone. However, co-administration of either 50 or 100 mg/kg CAF with DON lead to higher AChE activity compared to both control and DON groups. In addition, DON, CAF and their various combinations augmented brain antioxidant status in treated rats. We conclude that while low caffeine consumption may improve the antioxidant properties of donepezil without having a significant influence on its anticholinesterase effect, moderate-high caffeine consumption could also improve the antioxidant properties of donepezil but reduce its anticholinesterase effect; nevertheless, a comprehensive clinical trial is essential to fully explore these possibilities in human AD condition.", "labels": [5, 32]}
{"id": "1124", "token": "Introduction: Amyloid imaging has been integrated into diagnostic criteria for Alzheimer's disease (AD). How amyloid tracers binding differ for different tracer structures and amyloid-beta aggregates in autosomal dominant AD (ADAD) and sporadic AD is unclear. Methods: Binding properties of different amyloid tracers were examined in brain homogenates from six ADAD with APPswe, PS1 M146V, and PS1 E Delta 9 mutations, 13 sporadic AD, and 14 control cases. Results: H-3-PIB, H-3-florbetaben, H-3-AZD2184, and BTA-1 shared a high-and a varying low-affinity binding site in the frontal cortex of sporadic AD. AZD2184 detected another binding site (affinity 33 nM) in the frontal cortex of ADAD. The H-3-AZD2184 and H-3-PIB binding were significantly higher in the striatum of ADAD compared to sporadic AD and control. Polyphenol resveratrol showed strongest inhibition on H-3-AZD84 binding followed by H-3-florbetaben and minimal on H-3-PIB. Discussion: This study implies amyloid tracers of different structures detect different sites on amyloid-beta fibrils or conformations. (C) 2016 the Alzheimer's Association. Published by Elsevier Inc. All rights reserved.", "labels": [5, 32]}
{"id": "1168", "token": "Introduction: Dementia is a heterogeneous neurodegenerative disease, whose etiology results from a complex interplay between environmental and genetic factors. Methods: We searched PubMed to identify meta-analyses of observational studies that examined associations between nongenetic factors and dementia. We estimated the summary effect size using random-effects and fixed-effects model, the 95% CI, and the 95% prediction interval. We assessed the between-study heterogeneity (I-square), evidence of small-study effects, and excess significance. Results: A total of 76 unique associations were examined. By applying standardized criteria, seven associations presented convincing evidence. These associations pertained to benzodiazepines use, depression at any age, late-life depression, and frequency of social contacts for all types of dementia; late-life depression for Alzheimer's disease; and type 2 diabetes mellitus for vascular dementia and Alzheimer's disease. Discussion: Several risk factors present substantial evidence for association with dementia and should be assessed as potential targets for interventions, but these associations may not necessarily be causal. (C) 2016 the Alzheimer's Association. Published by Elsevier Inc. All rights reserved.", "labels": [5, 32]}
{"id": "1295", "token": "Background: The aims of this study were (1) to describe and compare the performance of illiterate and low-educated older adults, without evidence of cognitive impairment, on different versions of the Boston Naming Test (BNT) original, Brazilian adapted, abbreviated 30-item (even and odd) and 15-item from the CERAD (Consortium to Establish a Registry for Alzheimer's Disease) battery; (2) to compare performance on the original versus adapted versions of the BNT. Methods: A total of 180 healthy older adults (60 years or older) were stratified according to educational level (0, 1-2, and 3-4 years), and age (60-69, 70-79, and 80 years). The protocol comprised the following instruments: Mini-Mental State Examination (MMSE), Brief Cognitive Screening Battery (BCSB), Functional Activities Questionnaire (FAQ), Geriatric Depression Scale (GDS), and the BNT. Results: The illiterate participants had poorer performance than the educated participants. The performance of the two educated groups was similar on all versions of the BNT. A higher number of correct responses were observed on the adapted BNT than on the original BNT in all three education groups. Conclusions: The adapted BNT appears to be the most suitable for use in the low-educated Brazilian population. The present study provided normative data for low-educated elderly on several different versions of the BNT, which may be helpful in diagnosing naming deficits among elderly in these strata of the population.", "labels": [5, 32]}
{"id": "1541", "token": "Proteolytic processing of amyloid precursor protein (APP) C-terminal fragments (CTFs) by gamma-secretase underlies the pathogenesis of Alzheimer's disease (AD). An RNA interference screen using APP-CTF [99-residue CTF (C99)]- and Notch-specific gamma-secretase interaction assays identified a unique ErbB2-centered signaling network that was predicted to preferentially govern the proteostasis of APP-C99. Consistently, significantly elevated levels of ErbB2 were confirmed in the hippocampus of human AD brains. We then found that ErbB2 effectively suppressed autophagic flux by physically dissociating Beclin-1 from the Vps34-Vps15 complex independent of its kinase activity. Down-regulation of ErbB2 by CL-387,785 decreased the levels of C99 and secreted amyloid-beta in cellular, zebrafish, and mouse models of AD, through the activation of autophagy. Oral administration of an ErbB2-targeted CL-387,785 for 3 wk significantly improves the cognitive functions of APP/presenilin-1 (PS1) transgenic mice. This work unveils a noncanonical function of ErbB2 in modulating autophagy and establishes ErbB2 as a therapeutic target for AD.", "labels": [5, 32]}
{"id": "1842", "token": "Introduction: Rapid cognitive decline (RCD) occurs in dementia due to Alzheimer's disease (AD). Methods: Literature review, consensus meetings, and a retrospective chart review of patients with probable AD were conducted. Results: Literature review showed that RCD definitions varied. Mini-Mental State Examination scores <20 at treatment onset, vascular risk factors, age= 3 points/year) is more common in moderate (43.2%) than in mild patients (20.1%; P<.001). Rapid and slow decliners had similar age, gender, and education levels at baseline. Discussion: RCD is sufficiently common to interfere with randomized clinical trials. We propose a 6-month prerandomization determination of the decline rate or use of an RCD risk score to ensure balanced allocation among treatment groups. (C) 2017 the Alzheimer's Association. Published by Elsevier Inc. All rights reserved.", "labels": [5, 32]}
{"id": "1969", "token": "Introduction: There are scarce studies of time series that analysed the short-term association between emergency hospital admissions due to Alzheimer's disease (AD) and environmental factors. The objective is to analyse the effect of heat waves, noise and air pollutants on urgent hospital admissions due to AD in Madrid. Methods: Longitudinal ecological time series study was performed. The dependent variable was the emergency AD hospital admissions occurred in Madrid during the period 2001-2009. Independent variables were: Daily mean concentrations (mu g/m(3)) of air pollutants (PM2.5 and PM10; O3 and NO2); maximum daily temperature (degrees C) and daily and night noise levels (dB(A)). Relative Risk (RR) for an increment in interquartile range, and Attributable Risk (AR) values were calculated through GLM with Poisson link. Results: Our findings indicated that only PM2.5 concentrations at lag 2 with a RR: 1.38 (95% CI: 1.15-1.65); AR 27.5% (95% CI: 13.0-39.4); and heat wave days at lag 3 with a RR: 1.30 (95% CI: 1.12-1.52); AR 23.1% (95% CI: 10.7-34.2) were associated with AD hospital admissions. Conclusion: A reduction in AD patients' exposure levels to PM2.5 and special care of such patients during heat wave periods could result in a decrease in both emergency AD admissions and the related health care costs. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [5, 32]}
{"id": "2123", "token": "Increased incidence of neuronal nuclear indentations is a well-known feature of the striatum of Huntington's disease (HD) brains and, in Alzheimer's disease (AD), neuronal nuclear indentations have recently been reported to correlate with neurotoxicity caused by improper cytoskeletal/nucleoskeletal coupling. Initial detection of rod-shaped tau immunostaining in nuclei of cortical and striatal neurons of HD brains and in hippocampal neurons of early Braak stage AD led us to coin the term tau nuclear rods (TNRs). Although TNRs traverse nuclear space, they in fact occupy narrow cytoplasmic extensions that fill indentations of the nuclear envelope and we will here refer to this histological hallmark as Tau-immunopositive nuclear indentations (TNIs). We reasoned that TNI formation is likely secondary to tau alterations as TNI detection in HD correlates with an increase in total tau, particularly of the isoforms with four tubulin binding repeats (4R-tau). Here we analyze transgenic mice that overexpress human 4R-tau with a frontotemporal lobar degeneration-tau point mutation (P301S mice) to explore whether tau alteration is sufficient for TNI formation. Immunohistochemistry with various tau antibodies, immunoelectron microscopy and double tau-immunofluorescence/DAPI-nuclear counterstaining confirmed that excess 4R-tau in P301S mice is sufficient for the detection of abundant TNIs that fill nuclear indentations. Interestingly, this does not correlate with an increase in the number of nuclear indentations, thus suggesting that excess total tau or an isoform imbalance in favor of 4R-tau facilitates tau detection inside preexisting nuclear indentations but does not induce formation of the latter. In summary, here we demonstrate that tau alteration is sufficient for TNI detection and our results suggest that the neuropathological finding of TNIs becomes a possible indicator of increased total tau and/or increased 4R/3R-tau ratio in the affected neurons apart from being an efficient way to monitor pathology-associated nuclear indentations.", "labels": [5, 32]}
{"id": "2159", "token": "A novel series of feruloyl-donepezil hybrid compounds were designed, synthesized and evaluated as multitarget drug candidates for the treatment of Alzheimer's Disease (AD). In vitro results revealed potent acetylcholinesterase (AChE) inhibitory activity for some of these compounds and all of them showed moderate antioxidant properties. Compounds 12a, 12b and 12c were the most potent AChE inhibitors, highlighting 12a with IC50 = 0.46 mu M. In addition, these three most promising compounds exhibited significant in vivo anti-inflammatory activity in the mice paw edema, pleurisy and formalin-induced hyperalgesy models, in vitro metal chelator activity for Cu2+ and Fe2+, and neuroprotection of human neuronal cells against oxidative damage. Molecular docking studies corroborated the in vitro inhibitory mode of interaction of these active compounds on AChE. Based on these data, compound 12a was identified as a novel promising drug prototype candidate for the treatment of AD with innovative structural feature and multitarget effects. (C) 2017 Elsevier Masson SAS. All rights reserved.", "labels": [5, 32]}
{"id": "2237", "token": "Amyloid plaques and neurofibrillary tangles (NFTs) in the brain are the neuropathological hallmarks of Alzheimer's disease (AD). Amyloid plaques are composed of beta-amyloid peptides (A beta), while NFTs contain hyperphosphorylated tau proteins. Patients with familial AD who have mutations in the amyloid precursor protein (APP) gene have either increased production of A beta or generate more aggregation-prone forms of A beta. The findings of familial AD mutations in the APP gene suggest that A beta plays a central role in the pathophysiology of AD. A beta 42, composed of 42 amino acid residues, aggregates readily and is considered to form amyloid plaque. However, the processes of plaque formation are still not well known. It is generally thought that A beta is secreted into the extracellular space and aggregates to form amyloid plaques. A beta as extracellular aggregates and amyloid plaques are thought to be toxic to the surrounding neurons. The intraneuronal accumulation of A beta has more recently been demonstrated and is reported to be involved in synaptic dysfunction, cognitive impairment, and the formation of amyloid plaques in AD. We herein provide an overview of the process of the intraneuronal accumulation of A beta and plaque formation, and discuss its implications for the pathology, early diagnosis, and therapy of AD.", "labels": [5, 32]}
{"id": "2439", "token": "The combined supplementation of medium-chain triglycerides (MCTs), L-leucine-rich amino acids, and cholecalciferol (vitamin D-3) increase muscle strength and function in frail elderly individuals. However, their effects on cognition are unknown. We enrolled 38 elderly nursing home residents (mean age +/- SD, 86.6 +/- 4.8 y) in a 3-mo randomized, controlled, parallel group trial. The participants were randomly allocated to 3 groups: the first group received a L-leucine (1.2 g)- and cholecalciferol (20 mu g)-enriched supplement with 6 g of MCT (LD+MCT); the second group received the same supplement with 6 g of long-chain triglycerides (LD+LCT); and the third group did not receive any supplements (control). Cognition was assessed at baseline and after the 3-mo intervention. The difference in changes among the groups was assessed with ANCOVA, adjusting for age and the baseline value as covariates. After 3 mo, the Mini-Mental State Examination (MMSE) score in the LD+MCT group increased by 10.6% (from 16.6 to 18.4 points, p<0.05). After 3 mo, the Nishimura geriatric rating scale for mental status (NM scale) score in the LD+MCT group increased by 30.6% (from 24.6 to 32.2 points, p<0.001), whereas that in the LD+LCT and control groups decreased by 11.2% (from 31.2 to 27.7 points, p<0.05) and 26.1% (from 27.2 to 20.1 points, p<0.001), respectively. The combined supplementation of MCTs (6 g), L-leucine-rich amino acids, and cholecalciferol may improve cognitive function in frail elderly individuals.", "labels": [5, 32]}
{"id": "2489", "token": "Alzheimer's disease is characterized by the deposition of amyloid-beta as extracellular plaques and hyperphosphorylated tau as intracellular neurofibrillary tangles. Tau pathology characterizes not only Alzheimer's disease, but also many other tauopathies, presenting tau as an attractive therapeutic target. Passive tau immunotherapy has been previously explored; however, because only a small fraction of peripherally delivered antibodies crosses the blood-brain barrier, enters the brain and engages with tau that forms intracellular aggregates, more efficient ways of antibody delivery and neuronal uptake are warranted. In the brain, tau exists as multiple isoforms. Here, we investigated the efficacy of a novel 2N tau isoform-specific single chain antibody fragment, RN2N, delivered by passive immunization in the P301L human tau transgenic pR5 mouse model. We demonstrate that, in treated mice, RN2N reduces anxiety-like behaviour and phosphorylation of tau at distinct sites. When administration of RN2N was combined with focused ultrasound in a scanning mode (scanning ultrasound), RN2N delivery into the brain and uptake by neurons were markedly increased, and efficacy was significantly enhanced. Our study provides evidence that scanning ultrasound is a viable tool to enhance the delivery of biologics across the blood-brain barrier and improve therapeutic outcomes and further presents single-chain antibodies as an alternative to full-length antibodies.", "labels": [5, 32]}
{"id": "2633", "token": "Protein misfolding and aggregation has been implicated as the cause of more than 20 diseases in humans such as Alzheimer's and Parkinson's and systemic amyloidosis. Retardation of A beta-42 aggregation is considered as a promising and challenging strategy for developing effective therapeutics against Alzheimer's disease. Herein, we demonstrated the effect of vitamin B12 (VB) on inhibiting amyloid formation by employing ThT fluorescence assay, circular dichroism, ANS fluorescence assay, dynamic light scattering measurements and transmission electron microscopy and cell viability assay. Our results demonstrate that vitamin B12 (VB), inhibits A beta-42 aggregation in a concentration dependent manner. Further VB also provide protection against amyloid induced cytotoxicity in human neuronal cell line. This study points towards a promising strategy to combat A beta-42 aggregation and may have broader implication for targeting other neurological disorders whose distinct hallmark is also amyloid formation. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [5, 32]}
{"id": "2782", "token": "Alzheimer's disease (AD) is a neurodegenerative disorder that is the most common cause of dementia in the elderly, and intracellular neurofibrillary tangles (NFTs) are one of the pathological features of AD. Recent studies have suggested long noncoding RNAs (lncRNAs) play important roles in AD. Competing endogenous RNAs (ceRNAs) is a mechanism that has recently been proposed, in which IncRNAs compete for common miRNA-binding sites with mRNAs. However, the roles of IncRNAs and ceRNA in AD NFTs is limited. In this study, we constructed a global triple network based on ceRNA theory, then an AD NFT lncRNA mRNA network (NFTLMN) was generated. By analyzing the NFTLMN, three IncRNAs (AP000265.1, KB-1460A1.5 and RP11-145M9.4), which are highly related with AD NFTs were identified. To further explore the cross-talk between mRNAs and IncRNAs, a clustering module analysis was performed on the NFTLMN and two AD NFT related modules were identified. Our study provides a better understanding of the molecular basis of AD NFTs and may offer novel treatment strategies for AD. (C) 2016 Published by Elsevier Inc.", "labels": [5, 32]}
{"id": "2816", "token": "Brain-derived neurotrophic factor (BDNF) plays pivotal roles in neuronal function. The cleaved-mature-form of BDNF (mBDNF), predominantly expressed in adult brains, critically determines its effects. However, insufficient proteolytic processing under pathology may lead to the precursor form of BDNF (proBDNF) and thereby increased neuronal apoptosis and synaptic weakening. Previous findings in our lab showed that cognitive stimulation (CS) delayed memory decline in Tg2576 mouse model of Alzheimer's disease (AD), an effect that was tightly associated with augmented levels of mBDNF. In view of this association, the present study explored whether altered cleavage of BDNF could be involved in AD-related traits triggered by excessive amyloid-beta (A beta) pathology and whether this process could be therapeutically targeted. Ala pathology, both in AD patient samples and experimental models, triggered the upregulation of plasminogen-activator inhibitor-1 (PAI-1) via JNK/c-Jun. This led to inhibition of plasmin-regulated conversion of mBDNF. Pharmacological inhibition of PAI-1 with PAl039 sufficiently reverted Ap-induced tau hyperphosphorylation and neurotoxicity. Chronic treatment of 15 old-month Tg2576 mice with oral administration of PAI-039 resulted in improved BDNF maturation and cognitive function without inducing significant changes in amyloid burden. In conclusion, upregulation of PAI-1 may be a critical mechanism underlying insufficient neurotrophic support and increased neurodegeneration associated with AD. Thus, targeting BDNF maturation through pharmacological inhibition of PAI-1 might become a potential treatment for AD. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [5, 32]}
{"id": "2836", "token": "The hippocampus is one of the most interesting and studied brain regions because of its involvement in memory functions and its vulnerability in pathological conditions, such as neurodegenerative processes. In the recent years, the increasing availability of Magnetic Resonance Imaging (MRI) scanners that operate at ultra-high field (UHF), that is, with static magnetic field strength 7T, has opened new research perspectives. Compared to conventional high-field scanners, these systems can provide new contrasts, increased signal-to-noise ratio and higher spatial resolution, thus they may improve the visualization of very small structures of the brain, such as the hippocampal subfields. Studying the morphometry of the hippocampus is crucial in neuroimaging research because changes in volume and thickness of hippocampal subregions may be relevant in the early assessment of pathological cognitive decline and Alzheimer's Disease (AD). The present review provides an overview of the manual, semi-automated and fully automated methods that allow the assessment of hippocampal subfield morphometry at UHF MRI, focusing on the different hippocampal segmentation produced. (c) 2017 Wiley Periodicals, Inc.", "labels": [5, 32]}
{"id": "2899", "token": "AimsBoth amyloid deposition and neuroinflammation appear in the early course of Alzheimer's disease (AD). However, the progression of neuroinflammation and its relationship with amyloid deposition and behavioral changes have not been fully elucidated. A better understanding the role of neuroinflammation in AD might extend our current knowledge to therapeutic intervention possibilities. MethodsThis study systematically characterized changes in behavioral abnormalities in APP/PS1 transgenic mice. Brain pathology measures were performed in post-mortem brain tissues of mice from 2 to 22months. ResultsAPP/PS1 mice exhibited significant memory deficits from 5months old, which were aggravated at the later stage of life. However, the degree of memory impairments reached a plateau at 12months. An early appearance of amyloid plaques was at 3months with a linear increase throughout the disease course. CD11b-positive microglia and glial fibrillary acidic protein-(GFAP) positive astrocytes were first detected at 3months with a close association with amyloid plaques. Yet, the rate of changes in glial activation slowed down from 12months despite the steady increase in A. ConclusionThese findings provided evidence that neuroinflammation might be involved in the development and progression of cognitive deficits in APP/PS1 mice, suggesting novel intervention and prevention strategies for AD.", "labels": [5, 32]}
{"id": "3077", "token": "Mitochondrial dysfunction is implicated in the pathological mechanism of Alzheimer's disease (AD). Amyloid beta-protein (A beta), which plays a central role in AD pathogenesis, is reported to accumulate within mitochondria. However, a question remains as to whether A beta is generated locally from amyloid precursor protein (APP) within mitochondria. We investigated this issue by analyzing the expression patterns of APP, APP-processing secretases, and APP metabolites in mitochondria separated from human neuroblastoma SH-SY5Y cells and those expressing Swedish mutant APR APP, BACE1, and PEN-2 protein levels were significantly lower in crude mitochondria than microsome fractions while those of ADAM10 and the other gamma-secretase complex components (presenilin 1, nicastrin, and APH-1) were comparable between fractions. The crude mitochondrial fraction containing substantial levels of cathepsin D, a lysosomal marker, was further separated via iodixanol gradient centrifugation to obtain mitochondria- and lysosome-enriched fractions. Mature APP, BACE1, and all gamma-secretase complex components (in particular, presenilin 1 and PEN -2) were scarcely present in the mitochondria-enriched fraction, compared to the lysosome-enriched fraction. Moreover, expression of the beta-C-terminal fragment (beta-CTF) of APP was markedly low in the mitochondria-enriched fraction. Additionally, immunocytochemical analysis showed very little co-localization between presenilin 1 and Tom20, a marker protein of mitochondria. In view of the particularly low expression levels of BACE1, gamma-secretase complex proteins, and beta-CTF in mitochondria, we propose that it is unlikely that A beta generation from APP occurs locally within this organelle. (C) 2017 Elsevier Inc. All rights reserved.", "labels": [5, 32]}
{"id": "3275", "token": "Introduction: Brain imaging with F-18 fluorodeoxyglucose (F-18-FDG) positron emission tomography or Tc-99m hexamethylpropyleneamine oxime (Tc-99m-HMPAO) SPECT is widely used for the evaluation of Alzheimer's dementia (AD); we aim to assess superiority of one method over the other. Methods: Twenty four patients with clinical diagnosis of Alzheimer disease underwent F-18-FDG PET and Tc-99m-HMPAO SPECT in order to assess the zones of hypo metabolism & hypoperfusion specific for Alzheimer's disease. Results: F-18-FDG PET showed specific zones of hypometabolism in 19 patients (79.1%) while SPECT was positive in 15 cases (62.5%) with statistically significant difference (P=0.027). Conclusion: F-18-FDG PET was significantly superior to HMPAO SPECT and F-18-FDG PET could replace the classic role of perfusion SPECT in diagnosis of Alzheimer's disease.", "labels": [5, 32]}
{"id": "3341", "token": "Our understanding of B cells as merely antibody producers is slowly changing. Alone or in concert with antibody, they control outcomes of seemingly different diseases such as cancer, rheumatoid arthritis, diabetes, and multiple sclerosis. While their role in activation of effector immune cells is beneficial in cancer but bad in autoimmune diseases, their immunosuppressive and regulatory subsets (Bregs) inhibit autoimmune and anticancer responses. These pathogenic and suppressive functions are not static and appear to be regulated by the nature and strength of inflammation. Although aging increases inflammation and changes the composition and function of B cells, surprisingly, little is known whether the change affects aging-associated neurodegenerative disease, such as Alzheimer's disease (AD). Here, by analyzing B cells in cancer and autoimmune and neuroinflammatory diseases, we elucidate their potential importance in AD and other aging-associated neuroinflammatory diseases.", "labels": [5, 32]}
{"id": "3490", "token": "Introduction: We examined the association between decreased cerebral blood flow (CBF) and cognitive impairment in Alzheimer's disease (AD), mild cognitive impairment (MCI), and subjective cognitive decline (SCD). Methods: We included 161 AD, 95 MCI, and 143 SCD patients from the Amsterdam Dementia Cohort. We used 3-T pseudo-continuous arterial spin labeling to estimate whole-brain and regional partial volume-corrected CBF. Neuropsychological tests covered global cognition and five cognitive domains. Associations were investigated using linear regression analyses. Results: In the whole sample, reduced overall and regional CBF was associated with impairment in all cognitive domains. We found significant interactions between diagnosis and CBF for language and between diagnosis and parietal CBF for global cognition and executive functioning. Stratification showed that decreased CBF was associated with worse performance in AD patients but not in MCI or SCD. Discussion: Our results suggest that CBF may have potential as a functional marker of disease severity. (C) 2016 the Alzheimer's Association. Published by Elsevier Inc. All rights reserved.", "labels": [5, 32]}
{"id": "1", "token": "This study was designed to investigate the effects of two instructional approaches (4C-ID versus conventional) on learners' knowledge-acquisition and learning transfer of the electrical circuits content in Physics. Participants were 129 9th graders from a secondary school in Lisbon, M = 14.3 years, SD = 0.54. The participants were divided in two groups: an experimental group constituted three intact classes (n = 78); and a control group constituted two intact classes (n = 51). The experimental group was taught using a digital learning environment designed with the 4C-ID model principles while the control group learned the same contents through a conventional method. We assessed the students' performance (knowledge-acquisition and transfer), the perceived cognitive load, and the instructional efficiency. Results indicated that the experimental group performed significantly better than the control group on a knowledge-acquisition test and in a learning transfer test. They also perceived a less cognitive load in the transfer test and the learning environment developed with the 4C-ID model proved to be more instructional efficient than the conventional method.", "labels": [1, 13]}
{"id": "176", "token": "Stationary modes and their possible bifurcations in nonautonomous electrical circuits with nonlinear resistive elements, the voltage-current characteristic of which cannot be satisfied to known conditions of convergence, are investigated. The main result of this article is description of current modes in a single and three-phase circuit with asymmetric voltage-current characteristics. The most interesting result of investigation of these transient and steady current modes in nonlinear electrical circuits is the possibility of the quasi-periodical process with low-frequency component, values and significance of which can be modulated by modification of amplitude of external high-frequency three-phase voltage.", "labels": [1, 13]}
{"id": "243", "token": "In this work we study the localization properties of the disordered classical dual transmission lines, when the values of capacitances {C-j} and inductances {4} fluctuate in phase in the form C-j= C-0+b sin(2 pi x(j)) and L-j= L-0+b sin(2 pi x(j)), where b is the fluctuation amplitude. {x(j)} is a disordered long-range correlated sequence obtained using the Fourier filtering method which depends on the correlation exponent alpha. To obtain the transition point in the thermodynamic limit, we study the critical behavior of the participation number D. To do so, we calculate the linear relationship between In(D) versus In(N), the relative fluctuation eta(D) and the Binder cumulant BD. The critical value obtained with these three methods is totally coincident between them. In addition, we calculate the critical behavior of the normalized localization length Lambda(b) as a function of the system size N. With these data we build the phase diagram (b,alpha) which separates the extended states from the localized states. A final result of our work is the disappearance of the conduction bands when we introduce a finite number of impurities in random sites. This process can serve as a mechanism of secure communication, since a little alteration of the original sequence of capacitances and inductances, can destroy the band of extended states. (C) 2013 Elsevier BY. All rights reserved.", "labels": [1, 13]}
{"id": "345", "token": "Thin Sn-O-Te films with a thickness of 60 nm have been deposited by co-evaporation of Sn and TeO2 on alumina substrates with interdigitated silver-palladium electrodes. During the co-evaporation a chemical reaction between the two substances takes place, resulting in the formation of a Sn-oxide matrix and finely dispersed phases of Te, Sn, TeO2 or SnTe, depending on the atomic ratio of Sn to Te (R-Sn/Te). To study the morphology and structure as well as to determine the atomic ratio R-Sn/Te of the films, electron microscopy techniques (TEM, SAED) and analytical methods (EDS in SEM) have been applied. The electrical properties of the sensors studied have been investigated in the frequency range of 20 Hz - 5 MHz using a Precision Impedance Analyzer. The measurements have been taken on samples placed in a controlled humidity and temperature chamber. The characteristics of the resistance R, capacitance C, impedance z and phase theta as functions of relative humidity RH%, the frequency dependences of R, C, z and center dot, the Nyquist plots and equivalent electrical circuits of the sensors have been obtained. As a result, the relation between the type of water adsorption, impedance spectra and the properties of the films as humidity sensors are presented in this paper.", "labels": [1, 13]}
{"id": "457", "token": "The paper is devoted to the study of the Aubin/Lipschitz-like property and the isolated calmness of a particular non-monotone generalized equation arising in electronics. The variational and non-smooth analysis is applied in the theory of non-regular electrical circuits involving electronic devices like ideal diodes, practical diodes, DIACs, silicon controlled rectifiers (SCR), and transistors. We also discuss the relationship of our results to the ones using classical techniques from (smooth) analysis and provide a simulation for several simple electrical circuits which are chosen in order to cover the most common non-smooth elements in electronics. The simulations of the electrical circuits discussed in this paper are performed by using Xcos (a component of Scilab).", "labels": [1, 13]}
{"id": "597", "token": "Building physical computing projects can enable learners to integrate computing into a range of interests and disciplines. However, the electronic portion of these projects can be difficult. Students are learning new concepts as well as how to work with new tools. This influx of information can be difficult for students to retain in their working memory as they construct their circuits. In this paper, we introduce BitBlox, a set of modular, solderless Breadboards for prototyping circuits. BitBlox attempts to decrease the cognitive load on the user by reducing the complexity found in the standard Breadboard by bringing visibility to the underlying connections within its modules. We present a comparative classroom study integrating the Breadboard and BitBlox into two different high school classes. Our qualitative analysis focuses on student errors, strategies, and collaborative practices, highlighting important dynamics for designing hardware tools.", "labels": [1, 13]}
{"id": "750", "token": "It is well known that optimizing network topology by switching on and off transmission lines improves the efficiency of power delivery in electrical networks. In fact, the USA Energy Policy Act of 2005 (Section 1223) states that the United States should encourage, as appropriate, the deployment of advanced transmission technologies including optimized transmission line configurations. As such, many authors have studied the problem of determining an optimal set of transmission lines to switch off to minimize the cost of meeting a given power demand under the direct current (DC) model of power flow. This problem is known in the literature as the Direct-Current Optimal Transmission Switching Problem (DC-OTS). Most research on DC-OTS has focused on heuristic algorithms for generating quality solutions or on the application of DC-OTS to crucial operational and strategic problems such as contingency correction, real-time dispatch, and transmission expansion. The mathematical theory of the DC-OTS problem is less well developed. In this work, we formally establish that DC-OTS is NP-Hard, even if the power network is a series-parallel graph with at most one load/demand pair. Inspired by Kirchoff's Voltage Law, we provide a cycle-based formulation for DC-OTS, and we use the new formulation to build a cycle-induced relaxation. We characterize the convex hull of the cycle-induced relaxation; this characterization provides strong valid inequalities that can be used in a cutting-plane approach to solve the DC-OTS. We give details of a practical implementation, and we show promising computational results on standard benchmark instances.", "labels": [1, 13]}
{"id": "835", "token": "The software support for simulation of electrical circuits has been developed for more than sixty years. Currently, the standard tools for simulation of analogous circuits are the simulators based on the open source package Simulation Program with Integrated Circuit Emphasis generally known as SPICE (Biolek 2003). There are many different applications that provide graphical interface and extended functionalities on the basis of SPICE or, at least, using SPICE models of electronic devices. The author of this paper performed a simulation of a circuit that acts as an electronic diode in Multisim and provides a comparison of the simulation results with the results obtained from measurements on the real circuit.", "labels": [1, 13]}
{"id": "922", "token": "In the paper, firstly, the insulation aging and insulation cut or crack fault models of DC feeder cable were established; then according to the characteristics of electrical and loads of DC feeder cable, the Rail-Voltage law and different DC current law were purposed in the orbital theory, and the feasibility of purposed law were discussed from engineering view. The results of analysis show that the Rail-Voltage law could not be carried out in real project, because there were lots of interferences and could not be separated; and the different DC current law meets the real projection request and could be carried out. Lastly, simulation tests were done to investigate the effectiveness of different DC current law to detect the cable faults in the Laboratory. The results of experiment show that the different DC current law had great limitations on detecting insulation cut or crack fault of DC feeder cable, and the effectiveness was impacted by the environment especially soil moisture. Another law should be found to living detect the insulation cut or crack fault of EPR DC cable.", "labels": [1, 13]}
{"id": "1081", "token": "The purpose of this study is to propose a novel differential protection scheme for DC-AC converters. The current differential relay is widely used to protect transformers, generators, busbars and transmission lines. However, it cannot be applied to a DC-AC inverter, which is used in an AC-DC transmission line system. This paper presents a novel differential protection scheme for DC-AC converters, using Tellegen's Theorem. Tellegen's Theorem is a simple theorem of electric power proved from Kirchhoff's current law and Kirchhoff's voltage law. Under the theorem, we define three kinds of electric power as power flow. The proposed technique is evaluated using simulation studies based on an ideal inverter circuit which transforms DC to AC. The test results show the validity of the proposed protection.", "labels": [1, 13]}
{"id": "1176", "token": "Complex-reluctance bridges are electromagnetic devices that are shown to be able to detect both the angle of strain in steel and changes in the magnitude of applied strain with some sensitivity. Evidence is presented that they can also detect the magnitude of residual strain. Further research is suggested in this area. The residual strain detection technique is simple to use and easy to understand. Two new terms are introduced for complex-reluctance circuits: impermance, to parallel the impedance in alternating current electrical circuits; and reductance, to parallel reactance in alternating current electrical circuits.", "labels": [1, 13]}
{"id": "1261", "token": "The aim of this paper was to generate nanotopological structure on the power set of vertices of simple digraphs using new definition neighbourhood of vertices on out linked of digraphs. Based on the neighbourhood we define the approximations of the subgraphs of a graph. A new nanotopological graph reduction to symbolic circuit analysis is developed in this paper. By means of structural equivalence on nanotopology induced by graph we have framed an algorithm for detecting patent infringement suit.", "labels": [1, 13]}
{"id": "1524", "token": "In the report are discussed the laboratory test results of SPAD detectors with InGaAs / InP avalanche photodiodes, operating in Geiger mode. Device operating in synchronous mode with the dead timer setting for proper working conditions of photodiodes. The report materials will showing the functional block diagram of the detector, real operating signals in the receiver path and clock circuits and main results of measurements. The input signal of the synchronous detector is the clock, which determines the time positions of expected photons arrival. Increasing the clock speed 1-300 MHz or getting more time positions of the time grid, we provide increased capacity for time position code of signals, when QKD information transmitted over the nets. At the same time, the maximum attainable speed of photon reception is limited by diode dead time. Diode quantum noise are minimized by inclusion of a special time interval -dead time 0.1-10 usec, after each received and registered a photon. The lowest attainable value of the dead time is determined as a compromise between transients in electrical circuits, passive avalanche quenching' circuit and thermal transients cooling crystal diode, after each avalanche pass though photodiode. Achievable time and speed parameters are discussed with specific examples of detectors.", "labels": [1, 13]}
{"id": "1652", "token": "A common approach to model memristive systems is to include empirical window functions to describe edge effects and nonlinearities in the change of the memristance. We demonstrate that under quite general conditions, each window function can be associated with a sigmoidal curve relating the normalised time-dependent memristance to the time integral of the input. Conversely, this explicit relation allows us to derive window functions suitable for the mesoscopic modelling of memristive systems from a variety of well-known sigmoidals. Such sigmoidal curves are defined in terms of measured variables and can thus be extracted from input and output signals of a device and then transformed to its corresponding window. We also introduce a new generalised window function that allows the flexible modelling of asymmetric edge effects in a simple manner. Copyright (C) 2016 John Wiley & Sons, Ltd.", "labels": [1, 13]}
{"id": "1712", "token": "It has been stated that roughly 50% of electrical incidents involve workers whose primary function is not electrical in nature. It also encouraged all to address electrical safety for all workers and not just workers whose job responsibilities involve working on or near energized electrical circuits. In this paper, a program which includes specific briefings to non-electrical workers as well as to workers who may need to perform their normal activities in proximity to energized electrical conductors is presented. The program uses a targeted approach to specific areas such as welding, excavating, rigging, chart reading, switching, cord and plug equipment and several other general areas to point out hazards that may exist and how to avoid them. The site experience over the years supports the assertion that about half of the electrical incidents involve non-electrical workers and this prompted us to develop specific briefings to enhance the knowledge of the non-electrical worker regarding safe electrical practices. The promotion of May is Electrical Safety Month and the development of informative presentations which are delivered to the general site population as well as electrical workers have greatly improved the hazards awareness status of the general worker on site.", "labels": [1, 13]}
{"id": "1779", "token": "In an ADS injector I, there are five superconducting magnets in each cryomodule. Each superconducting magnet contains a solenoid magnet, a horizontal dipole corrector (HDC), and a vertical dipole corrector (VDC). Six current leads will be required to power the electrical circuits, from room temperature to the 2.1 K liquid helium bath: two leads carry 100 A current for the solenoid magnet while the other four carry 12 A for the HDC and the VDC. This paper presents the principle of current lead optimization, which includes the cooling methods, the choice of material and structure, and the issues for current lead integration.", "labels": [1, 13]}
{"id": "1977", "token": "In power electronics, the pulse width modulation (PWM) inverter is one of the families of electrical circuits that converts the electrical supply from one level to another using semiconductor-based electronic switches. The important characteristic of these types of circuits is that the switches are operated only in one of two states: ON or OFF. The continuous conduction operations of these transitions cause switching power losses, which lead to power loss in PWM inverter. The purpose of the switch is to assist the process of transferring power from source to load. So, these power losses affect the performance and efficiency of the load. To overcome these problems, in this paper, asymmetric space vector pulse width modulation (ASVPWM) technique is proposed. In the proposed ASVM, the additional voltage sectors' switching states are determined by state transition matrix. Subsequently, using the proposed technique, the speed of the induction motor (IM) is controlled. The error speed and change of error speed of an IM are calculated using a fuzzy logic controller (FLC). The output of FLC is applied to the ASVPWM inverter and the stability of the IM is improved. Then, the switching loss and harmonics effect of the proposed ASVPWM inverter are analyzed.", "labels": [1, 13]}
{"id": "2082", "token": "Multiferroic Tb1-xAlxMnO3 (x=0, 0.1, 0.2) was prepared using the standard solid-state reaction. The dielectric properties of these samples were investigated over wide ranges of frequencies and temperatures (T >= 300 K) by means of complex impedance spectroscopy. The isovalent substitution of Al3+ for Tb3+ distinctly influences the structural and dielectric properties of the parent TbMnO3. The conductivity data of the undoped and Al-doped samples fit well to Jonscher's law sigma(ac)(omega)=sigma(dc)+A omega(n). The resulting fitting parameters indicated that the hopping process occured between neighboring sites. The conductivity in the dc regime followed an Arrhenius relation with activation energies of 0.26 and 0.12 eV for undoped and Al-doped (x=0.1) samples, respectively. In turn, the ac conductivity was well described by the small polaron hopping model, with energies of 0.2 and 0.14 eV for undoped and Al-doped (x=0.1) samples, respectively. The real part of the dielectric permittivity (epsilon') increased with increasing temperature and lowering frequency. The value of epsilon' also increased with the Al doping. The occurrence of a non-Debye-type relaxation was verified for the studied samples. The relaxation dynamics of charge carriers in the samples was examined within the electric modulus formalism, which allowed determining the most probable relaxation time and the respective activation energy for the dielectric relaxation. In the temperature range 300-425 K, the activation energy for the dielectric relaxation was calculated as 0.25 eV and 0.16 eV for undoped and Al-doped (x=0.1) samples, respectively. The imperfect overlapping of the reduced plots of the modulus curves on a single master curve, particularly at higher frequencies, for all the temperatures and Al concentrations considered, suggests that the behavior of the dynamic processes is slightly temperature- and Al-content-dependent. Finally, the impedance spectra, characterized by the appearance of semicircle arcs, were well modeled in terms of equivalent electrical circuits. (C) 2014 Elsevier Ltd and Techna Group S.r.l. All rights reserved.", "labels": [1, 13]}
{"id": "2132", "token": "The purpose of this paper is to determine physical electrical circuits, in both impedance and admittance forms, that match fractional-order integrators and differentiators, namely 1/s(q) and s(q). Then, using these idealized infinite-dimensional circuits, the energy storage and loss expressions for them are determined, carefully relating the associated infinite dimensional state variables to physically meaningful quantities. The resulting realizations and energy expressions allow a variety of implementations for understanding the transient behavior of fractional-order systems.", "labels": [1, 13]}
{"id": "2282", "token": "A simplified method for measuring the fluidic resistance (R-fluidic) of microfluidic channels is presented, in which the electrical resistance (R-elec) of a channel filled with a conductivity standard solution can be measured and directly correlated to R-fluidic using a simple equation. Although a slight correction factor could be applied in this system to improve accuracy, results showed that a standard voltage meter could be used without calibration to determine R-fluidic to within 12% error. Results accurate to within 2% were obtained when a geometric correction factor was applied using these particular channels. When compared to standard flow rate measurements, such as meniscus tracking in outlet tubing, this approach provided a more straightforward alternative and resulted in lower measurement error. The method was validated using 9 different fluidic resistance values (from similar to 40 to 600 kPa s mm(-3)) and over 30 separately fabricated microfluidic devices. Furthermore, since the method is analogous to resistance measurements with a voltage meter in electrical circuits, dynamic R-fluidic measurements were possible in more complex microfluidic designs. Microchannel R-elec was shown to dynamically mimic pressure waveforms applied to a membrane in a variable microfluidic resistor. The variable resistor was then used to dynamically control aqueous-in-oil droplet sizes and spacing, providing a unique and convenient control system for droplet-generating devices. This conductivity-based method for fluidic resistance measurement is thus a useful tool for static or real-time characterization of microfluidic systems. (C) 2012 Elsevier B.V. All rights reserved.", "labels": [1, 13]}
{"id": "2355", "token": "Multi-slice methods allow us to approximate the 3D phenomena without carrying out a full 3D analysis, e. g. in skewed radial flux electrical machines. The idea is to divide a 3D machine into several 2D FEM models, only connected by electrical circuits. Here we show how the multi-slice method is perfect for parallel computation; the computation efficiency is close to that of 2D models in modern parallel hardware. The results are shown to match with 3D computation and experimental results.", "labels": [1, 13]}
{"id": "2401", "token": "We have developed a small, lightweight, single operator fuel cell vehicle with a 20 W fuel cell and a 5.8 L hydrogen gas tank for university education purposes, named the pico FCY. The frame for the vehicle was fabricated using thin rectangular aluminum rods. A 90 W DC motor and a reduction gear system were used to actuate the system. The control system was designed using a PIC microcomputer which controls the drive motor speed, the drive current, and purging of the non-active gas from the fuel cell. Students are able to study the design of mechanical systems, electrical circuits, and microcomputer programming during the development of their pico FCYs. There is also the added benefit of focusing student interest on environmental consciousness while working on this project. In this paper, we will discuss the designs of the pico FCV, and will provide the running experimental results with varied gear ratios.", "labels": [1, 13]}
{"id": "2511", "token": "This essay reinterprets Frank Norris's novel McTeague: A Story of San Francisco (1899) as a depiction of the annihilating effects of entropy on human and material systems. Focusing on McTeague's lengthy and underanalyzed conclusion, in which McTeague flees into the heart of Death Valley, I argue that Norris's descriptions of the desert identify an irresistible and destructive force guiding the disintegration of individuals, relationships, and ultimately the Earth itself. Drawing. on the record of cultural anxieties surrounding the laws of thermodynamics in the nineteenth century, the essay demonstrates how McTeague exemplifies an apocalyptic posthumanism with implications far more disruptive to human exceptionalism than those of traditional biological determinism. The essay also interprets social, biological, and material systems in the novel as attempting, unsuccessfully, to resist entropic decline by channeling and diversifying forces through systems resembling electrical circuits. In this context, gold is read as the current or currency subtending California's economic and social worlds, but also that which drives them to greater and greater states of entropic disorder and eventual collapse.", "labels": [1, 13]}
{"id": "2599", "token": "Absolutely secure communication should be implemented only through the 'one-time pad' proposed by Shannon, requires that physical random numbers with rates matched with the associated communication systems be used as secret keys. With the wide application of the WDM technology in optical communication, the single channel rate of the current digital communication system has exceeded 10 Gb/s and developed towards 100 Gb/s. To ensure the absolute security of such a large capacity communication, a large number of real-time, and secure random numbers are needed. Secure random numbers are commonly produced through utilizing physical random phenomena, called physical random number generators. However, conventional physical random number generators are limited by the low bandwidth of the applied entropy sources such as thermal noise, photon-counting and chaotic electrical circuits, and thus have typical low bit rates of the order of Mb/s. In recent years, chaotic lasers attracted wide attention due to their generation of secure, reliable and high-speed random number sequences, and so due to their coherent merits such as high bandwidth, large amplitude fluctuation and ease of integration. There have been lots of schemes based on laser chaos for high-speed random number generation, but most of them execute the random number extractions from the associated laser chaos in the electrical domain and thus their generation rates are faced with the well-known 'electrical bottleneck'. On the other hand, all-optical random number generation (AO-RNG) methods are all signal processes in the optical domain, so they can efficiently overcome this rate limitation and have a great potential in generating ultrafast random numbers of several dozens or hundreds of Gb/s. However, there is no experimental report on its realization of AO-RNG. One of the obstacles in the way for the AO-RNG achievement is to implement the fast and real-time all-optical sampling of the entropy signals (i.e., laser chaos). In this paper, we present a principal experimental demonstration of the feasibility in the all-optical sampling of the chaotic light signal through constructing a TOAD-based all-optical sampler with a polarization-independent semiconductor optical amplifier (SOA). Specifically, we experimentally generate chaotic laser signals using an optical feedback semiconductor laser and finally complete a 5 GSa/s real-time and high-fidelity all-optical sampling of the chaotic laser with a bandwidth of 6.4 GHz. Further experimental results show that whether the optical sampling period is proportional to the external cavity feedback time or not has a great effect on the weak periodic suppression of the chaotic signal: only when both of them are out of proportion, can the weak periodicity of the original chaotic signal be effectively eliminated; and this is favorable for the generation of high-quality physical random numbers. To the best of our knowledge, it is the first time to realize all-optical sampling of chaotic signal in experiments.", "labels": [1, 13]}
{"id": "2677", "token": "In this paper, we study the well-posedness and stability analysis of set-valued Lur'e dynamical systems in infinite-dimensional Hilbert spaces. The existence and uniqueness results are established under the so-called passivity condition. Our approach uses a regularization procedure for the term involving the maximal monotone operator. The Lyapunov stability as well as the invariance properties are considered in detail. In addition, we give some sufficient conditions ensuring the robust stability of the system in finite-dimensional spaces. The theoretical developments are illustrated by means of two examples dealing with nonregular electrical circuits and an other one in partial differential equations. Our methodology is based on tools from set-valued and variational analysis.", "labels": [1, 13]}
{"id": "2845", "token": "This paper proposes a novel inerter-based electromagnetic device and investigates its performance as a vehicle suspension strut. The inerter-based electromagnetic device is obtained by placing the flywheel employed in an existing inerter prototype into a constant magnetic field. During rotation of the flywheel, the flywheel is doing the magnetic line cutting motion, which makes the flywheel perform as a Faraday generator. The influences of different types of loads on the behaviour of the inerter-based electromagnetic device are analyzed, and it is shown that the resistive, capacitive and inductive loads can contribute to the damping, the inertance, and the stiffness of the whole device, respectively. Moreover, the proposed device can also be used to realize higher-order mechanical admittances by using electrical circuits. The performance of the device as a suspension strut is also studied. Numerical simulations show that the proposed device can not only provide improvements on the suspension performance (ride comfort and road holding) compared with the conventional strut, but also generate an amount of electric energy that can be utilized by other parts of the vehicle.", "labels": [1, 13]}
{"id": "2961", "token": "The use of convex relaxations has lately gained considerable interest in Power Systems. These relaxations play a major role in providing quality guarantees for non-convex optimization problems. For the Optimal Power Flow (OPF) problem, the semidefinite programming (SDP) relaxation is known to produce tight lower bounds. Unfortunately, SDP solvers still suffer from a lack of scalability. In this work, we introduce an exact reformulation of the SDP relaxation, formed by a set of polynomial constraints defined in the space of real variables. The new constraints can be seen as cuts, strengthening weaker second-order cone relaxations, and can be generated in a lazy iterative fashion. The new formulation can be handled by standard nonlinear programming solvers, enjoying better stability and computational efficiency. This new approach benefits from recent results on tree-decomposition methods, reducing the dimension of the underlying SDP matrices. As a side result, we present a formulation of Kirchhoff's Voltage Law in the SDP space and reveal the existing link between these cycle constraints and the original SDP relaxation for three dimensional matrices. Preliminary results show a significant gain in computational efficiency compared to a standard SDP solver approach.", "labels": [1, 13]}
{"id": "3208", "token": "We are assessing the effect of our new freshman electrical engineering course sequence on follow-on courses. One of our assessments is a survey distributed to sophomores in electrical circuits and juniors in microelectronics courses. Roughly one half of freshman year is spent on programming in MATLAB and C, and problem solving using these programming tools. Our observation is that students consider programming important and have reasonably good confidence (self-efficacy) that they can solve problems using MATLAB and C. However, when asked about frequency of use for these tools students report using them somewhere between once a week and once a month. There is a significant number of students who report almost no usage at all. Results are consistent across sophomore and junior years with a slight up-tick in frequency of use for juniors. We are hypothesizing that students do not view MATLAB and C as tools for problem solving but as yet another item to acquire in their studies. Our plan is to change instruction in sophomore courses so that more problem-solving which requires programming will be introduced. The existing survey will be used to measure future improvement.", "labels": [1, 13]}
{"id": "3297", "token": "The stellarator fusion experiment Wendelstein 7-X (W7-X) is presently under assembly at the Greifswald branch of the Max Planck Institute for Plasma Physics, Germany. The W7-X superconducting magnet system basically consists of 50 nonplanar and 20 planar coils, including the interconnecting bus bars, and the support structure. The seven electrical circuits with 10 coils each in a series are supplied by 14 current leads (CLs) operating between the cryogenic and ambient temperature environments. A special feature of these feedthroughs is their upside-down orientation to save space in the vicinity of the machine. Basic electrical CL requirements are maximal steady-state currents of 18.2 kA and voltage strengths of 13 kV to ground. A W7-X CL consists of a copper conductor that also acts as a heat exchanger at the warm end side, in its continuation of a high-temperature superconductor part, and at the cold end side of a copper bar with integrated Nb3Sn rods. All components are fully contained within a CL vacuum chamber that is separated from the main W7-X cryostat vacuum. The high-voltage (HV) electrical insulation is built up of a glass tape epoxy resin system. Mechanical support of the CLs is achieved by a warm and cold glass fiber reinforced plastic flange. There are three He cooling circuits: 1) one for the bus bar and contact cooling; 2) one for the cold end of the CL (both at about 5 K); and 3) one for the CLs heat exchanger (entrance temperature about 50 K). After intensive tests of two prototypes, the series production has been established and completed. The CLs were tested at room temperature (HV, helium leaks, instrumentation, etc.) and with electrical currents up to the maximum current at cryogenic temperatures. This paper gives an overview of the basic CL design requirements and layout as well as on the fabrication and acceptance tests. Furthermore, a description of the assembly progress is given.", "labels": [1, 13]}
{"id": "3451", "token": "Two-dimensional (2D) boron nitride (BN) nanosheets, the rising material stars, have unique properties and amazing functionalities. The concise history of diverse synthesis routes of BN nanosheets is briefly summarized here; and the recent development towards mass production of BN nanosheets, i.e. chemical blowing technique relying on blowing molten polymer precursors into large polymeric bubbles and subsequent annealing into BN bubbles/nanosheets, is focused on. The abundant BN nanosheets enable their applications, especially in the representative polymeric composites with BN nanosheet additives, as particularly highlighted in this review. The highly thermoconductive insulating BN-filled composites are thus envisaged as high-performance packaging materials for electrical circuits.", "labels": [1, 13]}
{"id": "2", "token": "Automatic detection of brain tumors in single-spectral magnetic resonance images is a challenging task. Existing techniques suffer from inadequate performance, dependence on initial assumptions, and, sometimes, the need for manual interference. The research reported in this paper seeks to reduce some of these shortcomings, and to remove others, achieving satisfactory performance at reasonable computational costs. The success of the system described here is explained by the synergy of the following aspects: (1) a broad choice of high-level features to characterize the image's texture, (2) an efficient mechanism to eliminate less useful features (3) a machine-learning technique to induce a classifier that signals the presence of a tumor-affected tissue, and (4) an improved version of the skippy greedy snake algorithm to outline the tumor's contours. The paper describes the system and reports experiments with synthetic as well as real data. (C) 2017 Elsevier Ltd. All rights reserved.", "labels": [0, 8]}
{"id": "43", "token": "Metastasis accounts for the high mortality rate associated with colorectal cancer (CRC), but metastasis regulators are not fully understood. To identify a novel gene involved in tumor metastasis, we used oligonucleotide microarrays, transcriptome distance analyses, and machine learning algorithms to determine links between primary and metastatic colorectal cancers. Aminopeptidase A (APA; also known as ENPEP) was selected as our focus because its relationship with colorectal cancer requires clarification. Higher APA mRNA levels were observed in patients in advanced stages of cancer, suggesting a correlation between ENPEP and degree of malignancy. Our data also indicate that APA overexpression in CRC cells induced cell migration, invasion, anchorage-independent capability, and mesenchyme-like characteristics (e.g., EMT markers). We also observed TWIST induction in APA-overexpressing SW480 cells and TWIST down-regulation in HT29 cells knocked down with APA. Both APA silencing and impaired APA activity were found to reduce migratory capacity, cancer anchorage, stemness properties, and drug resistance in vitro and in vivo. We therefore suggest that APA enzymatic activity affects tumor initiation and cancer malignancy in a TWIST-dependent manner. Results from RT-qPCR and the immunohistochemical staining of specimens taken from CRC patients indicate a significant correlation between APA and TWIST. According to data from SurvExpress analyses of TWIST1 and APA mRNA expression profiles, high APA and TWIST expression are positively correlated with poor CRC prognosis. APA may act as a prognostic factor and/or therapeutic target for CRC metastasis and recurrence.", "labels": [0, 8]}
{"id": "191", "token": "In this paper, we propose a robust methodology to assess the value of microblogging data to forecast stock market variables: returns, volatility and trading volume of diverse indices and portfolios. The methodology uses sentiment and attention indicators extracted from microblogs (a large Twitter dataset is adopted) and survey indices (AAII and II, USMC and Sentix), diverse forms to daily aggregate these indicators, usage of a Kalman Filter to merge microblog and survey sources, a realistic rolling windows evaluation, several Machine Learning methods and the Diebold-Mariano test to validate if the sentiment and attention based predictions are valuable when compared with an autoregressive baseline. We found that Twitter sentiment and posting volume were relevant for the forecasting of returns of S&P 500 index, portfolios of lower market capitalization and some industries. Additionally, KF sentiment was informative for the forecasting of returns. Moreover, Twitter and KF sentiment indicators were useful for the prediction of some survey sentiment indicators. These results confirm the usefulness of microblogging data for financial expert systems, allowing to predict stock market behavior and providing a valuable alternative for existing survey measures with advantages (e.g., fast and cheap creation, daily frequency). (c) 2016 Elsevier Ltd. All rights reserved.", "labels": [0, 8]}
{"id": "261", "token": "Data-driven models can be used as an efficient proxy to model complex concepts in engineering. It is common engineering practice to optimize some controllable input parameters in a model to increase efficiency of operations. Machine Learning can be used to predict the rate of penetration (ROP) during drilling to a great accuracy as shown by Hegde, Wallace, and Gray (2015). This paper illustrates the use of machine learning to predict and increase ROP effectively. The machine learning model is first used to predict ROP with input parameters such as weight on bit (WOB), rotations per minute of the drill bit (RPM), and flow rate of the drilling mud. The input parameters are then modified to increase ROP. This process has been applied to field drilling data from a vertical well consisting of different rocks and formations. The procedure can be used to determine the maximum achievable ROP in each formation, and map out operational guidelines for drilling of pad wells. A post drilling analysis can be conducted for pad wells to cut costs and save time while drilling. This model is very innovative because only surface measured parameters are used, without a priori requirements for geological, laboratory, or drilling data. Published by Elsevier B.V.", "labels": [0, 8]}
{"id": "331", "token": "Sparse representation-based classifier (SRC) and kernel sparse representation-based classifier (KSRC) are founded on combining pattern recognition and compressive sensing methods and provide acceptable results in many machine learning problems. Nevertheless, these classifiers suffer from some shortcomings. For instance, SRC's accuracy drops against samples from same directional classes or KSRC's output declines when data is not normally distributed in kernel space. This paper introduces nonparametric kernel sparse representation-based classifier (NKSRC) as a generalized framework for SRC and KSRC. First, it applies kernel on samples to overcome data directionality and then employs nonparametric discriminant analysis (NDA) to reduce data dimensionality in kernel space alleviating concern about data distribution type. The experimental results of NKSRC demonstrate its superiority over SRC and KSRC-LDA and its equal or superior performance with respect to KSRC-PCA on some synthetic, four well-known face recognition and several UCI datasets. (C) 2017 Published by Elsevier B.V.", "labels": [0, 8]}
{"id": "707", "token": "Innovation scholars have long recognized entrepreneurship is imitative', whereas the commercialization of novelty is innovative'. Thus they are highly distinctive skill-sets. Entrepreneurship, first, involves optimizing market sentiment for pure profit sometimes to the point of catastrophe and even fraudulence in many markets. These include: payment protection insurance (PPI) to flash crashes', automotive emission defeat devices', corporate bribery settlements, social media hacking', fake news' and a litany of other infractions and catastrophes. Innovation, by contrast, is more explorative and team-reliant. Even if patenting betrays the hope for commercialization on markets, patented innovation frequently fails. Some academic innovators even profess a preference for prizes over profits. Second, this means that collective bonding' among entrepreneurs, in the form of claimed entrepreneurial ecosystems', is often based on a single customer platform or as a supplier of a highly specialist type of imitative' service from identikit pizza chains to me-too' smartphone apps. Through the latter, fused with artificial intelligence some interactive machine-learning services have long-existed as postsocial' algorithms serving customers of, for example, investment banks in stock and currency markets. Finally, entrepreneurship is fundamentally competitive, individualistic and non-solidaristic, whereas open innovation' was born from the practices of open science' and the collegiate tradition of research. Accordingly, entrepreneurial ecosystems' can display more closure than RIS set-ups. This special issue explores aspects of these ecosystem platforms and their implications for emergent forms of urban and regional evolution in the near and nearly present future.", "labels": [0, 8]}
{"id": "833", "token": "Background and objective: To safely select the proper therapy for Ventricullar Fibrillation (VF) is essential to distinct it correctly from Ventricular Tachycardia (VT) and other rhythms. Provided that the required therapy would not be the same, an erroneous detection might lead to serious injuries to the patient or even cause Ventricular Fibrillation (VF). The main novelty of this paper is the use of time-frequency (t-f) representation images as the direct input to the classifier. We hypothesize that this method allow to improve classification results as it allows to eliminate the typical feature selection and extraction stage, and its corresponding loss of information. Methods: The standard AHA and MIT-BIH databases were used for evaluation and comparison with other authors. Previous to t-f Pseudo Wigner-Ville (PWV) calculation, only a basic preprocessing for denoising and signal alignment is necessary. In order to check the validity of the method independently of the classifier, four different classifiers are used: Logistic Regression with L2 Regularization (L2 RLR), Adaptive Neural Network Classifier (ANNC), Support Vector Machine (SSVM), and Bagging classifier (BAGG). Results: The main classification results for VF detection (including flutter episodes) are 95.56% sensitivity and 98.8% specificity, 88.80% sensitivity and 99.5% specificity for ventricular tachycardia (VT), 98.98% sensitivity and 97.7% specificity for normal sinus, and 96.87% sensitivity and 99.55% specificity for other rhythms. Conclusion: Results shows that using t-f data representations to feed classifiers provide superior performance values than the feature selection strategies used in previous works. It opens the door to be used in any other detection applications. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [0, 8]}
{"id": "897", "token": "Dimensionality reduction is a challenging task for high-dimensional data processing in machine learning and data mining. It can help to reduce computation time, save storage space and improve the performance of learning algorithms. As an effective dimension reduction technique, unsupervised feature selection aims at finding a subset of features to retain the most relevant information. In this paper, we propose a novel unsupervised feature selection method, called Robust Unsupervised Feature Selection via Matrix Factorization (RUFSM), in which robust discriminative feature selection and robust clustering are performed simultaneously under l(2),(1)-norm while the local manifold structures of data are preserved. The advantages of this work are three-fold. Firstly, both the latent orthogonal cluster centers and the sparse representation of the projected data points based on matrix factorization are predicted for selecting robust discriminative features. Secondly, the feature selection and the clustering are performed simultaneously to guarantee an overall optimum. Thirdly, an efficient iterative update algorithm, which is based on Alternating Direction Method of Multipliers (ADMM), is used for RUFSM optimization. Compared with several state-of-the-art unsupervised feature selection methods, the proposed algorithm comes with better clustering performance for almost all datasets we have experimented with here. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [0, 8]}
{"id": "954", "token": "The requirements concerning the technical availability as part of the overall equipment effectiveness increase constantly in production nowadays. Unplanned downtimes have to be prevented via efficient methods. Predictive, condition-based maintenance represents a valuable approach for fulfilling these demands, but precise models for state estimation are missing. From the manufacturers' point of view the challenge consists in wear models with the capability of specifying the correct component's state as well as providing reliable failure forecasts. Unfortunately, nowadays creation of wear models is based on specific stress tests or design of experiments from the manufacturer. The integration of the production phase or even data feedback and user knowledge does not take place. New potential is promised by cross-cutting technologies from ICT like cloud technologies-in general virtual platform concepts-or approaches of machine learning as enabling technologies. The objective of this paper is to adopt existing algorithms to the new application of condition monitoring in order to evaluate the applicability for automated training of robust wear models. In that context the most commonly used algorithms are described and the reader gets an impression what challenges have to be met when dealing with machine learning. A selection of about ten algorithms with 45 variants is evaluated for four different features within a packaging machine. In the outlook the embedding of the trained model in a cloud architecture is presented.", "labels": [0, 8]}
{"id": "1084", "token": "We present here a vision of individualized Knowledge Graphs (iKGs) in cardiovascular medicine: a modern informatics platform of exchange and inquiry that comprehensively integrates biological knowledge with medical histories and health outcomes of individual patients. We envision that this could transform how clinicians and scientists together discover, communicate, and apply new knowledge.", "labels": [0, 8]}
{"id": "1204", "token": "Heterogeneous computing, combining devices with different architectures such as CPUs and GPUs, is rising in popularity and promises increased performance combined with reduced energy consumption. OpenCL has been proposed as a standard for programming such systems and offers functional portability. However, it suffers from poor performance portability, because applications must be retuned for every new device. In this paper, we use machine learning-based auto-tuning to address this problem. Benchmarks are run on a random subset of the tuning parameter spaces, and the results are used to build a machine learning-based performance model. The model can then be used to find interesting subspaces for further search. We evaluate our method using five image processing benchmarks, with tuning parameter space sizes up to 2.3 M, using different input sizes, on several devices, including an Intel i7 4771 (Haswell) CPU, an Nvidia Tesla K40 GPU, and an AMD Radeon HD 7970 GPU. We compare different machine learning algorithms for the performance model. Our model achieves a mean relative error as low as 3.8% and is able to find solutions on average only 0.29% slower than the best configuration in some cases, evaluating less than 1.1% of the search space. The source code of our framework is available at https://github.com/acelster/ML-autotuning.", "labels": [0, 8]}
{"id": "1407", "token": "We investigate semisupervised learning (SL) and pool-based active learning (AL) of a classifier for domains with label-scarce (LS) and unknown categories, i.e., defined categories for which there are initially no labeled examples. This scenario manifests, e.g., when a category is rare, or expensive to label. There are several learning issues when there are unknown categories: 1) it is a priori unknown which subset of (possibly many) measured features are needed to discriminate unknown from common classes and 2) label scarcity suggests that overtraining is a concern. Our classifier exploits the inductive bias that an unknown class consists of the subset of the unlabeled pool's samples that are atypical (relative to the common classes) with respect to certain key (albeit a priori unknown) features and feature interactions. Accordingly, we treat negative log-p-values on raw features as nonnegatively weighted derived feature inputs to our class posterior, with zero weights identifying irrelevant features. Through a hierarchical class posterior, our model accommodates multiple common classes, multiple LS classes, and unknown classes. For learning, we propose a novel semisupervised objective customized for the LS/unknown category scenarios. While several works minimize class decision uncertainty on unlabeled samples, we instead preserve this uncertainty [ maximum entropy (maxEnt)] to avoid overtraining. Our experiments on a variety of UCI Machine learning (ML) domains show: 1) the use of p-value features coupled with weight constraints leads to sparse solutions and gives significant improvement over the use of raw features and 2) for LS SL and AL, unlabeled samples are helpful, and should be used to preserve decision uncertainty (maxEnt), rather than to minimize it, especially during the early stages of AL. Our AL system, leveraging a novel sample-selection scheme, discovers unknown classes and discriminates LS classes from common ones, with sparing use of oracle labeling.", "labels": [0, 8]}
{"id": "1485", "token": "There has been significant recent interest in sensing systems and 'smart environments', with a number of longitudinal studies in this area. Typically the goal of these studies is to develop methods to predict, at any one moment of time, the activity or activities that the resident(s) of the home are engaged in, which may in turn be used for determining normal or abnormal patterns of behaviour (e.g. in a health-care setting). Classification algorithms, such as Conditional Random Field (CRFs), typically consider sensor activations as features but these are often treated as if they were independent, which in general they are not. Our hypothesis is that learning patterns based on combinations of sensors will be more powerful than single sensors alone. The exhaustive approach to take all possible combinations of sensors and learn classifier Weights for each combination is clearly computationally prohibitive. We show that through the application of signal processing and information theoretic techniques we can learn about the sensor topology in the home (i.e. learn an adjacency matrix) which enables us to determine the combinations of sensors that will be useful for classification ahead of time. As a result we can achieve classification performance better than that of the exhaustive approach, whilst only incurring a small cost in terms of computational resources. We demonstrate our results on several datasets, showing that our method is robust in terms of variations in the layout and the number of residents in the house. Furthermore, we have incorporated the adjacency matrix into the CRF learning framework and have shown that it can improve performance over multiple baselines.", "labels": [0, 8]}
{"id": "1581", "token": "Oscillometric measurement is widely used to estimate systolic blood pressure (SBP) and diastolic blood pressure (DBP). In this paper, we propose a deep belief network (DBN)-deep neural network (DNN) to learn about the complex nonlinear relationship between the artificial feature vectors obtained from the oscillometric wave and the reference nurse blood pressures using the DBN-DNN-based-regression model. Our DBN-DNN is a powerful generative network for feature extraction and can address to stick in local minima through a special pretraining phase. Therefore, this model provides an alternative way for replacing a popular shallow model. Based on this, we apply the DBN-DNN-based regression model to estimate the SBP and DBP. However, there are a small amount of data samples, which is not enough to train the DBN-DNN without the overfitting problem. For this reason, we use the parametric bootstrap-based artificial features, which are used as training samples to efficiently learn the complex nonlinear functions between the feature vectors obtained and the reference nurse blood pressures. As far as we know, this is one of the first studies using the DBN-DNN-based regression model for BP estimation when a small training sample is available. Our DBN-DNN-based regression model provides a lower standard deviation of error, mean error, and mean absolute error for the SBP and DBP as compared with the conventional methods.", "labels": [0, 8]}
{"id": "1696", "token": "Ranking items is an essential problem in recommendation systems. Since comparing two items is the simplest type of queries in order to measure the relevance of items, the problem of aggregating pairwise comparisons to obtain a global ranking has been widely studied. Furthermore, ranking with pairwise comparisons has recently received a lot of attention in crowdsourcing systems where binary comparative queries can be used effectively to make assessments faster for precise rankings. In order to learn a ranking based on a training set of queries and their labels obtained from annotators, machine learning algorithms are generally used to find the appropriate ranking model which describes the data set the best. In this paper, we propose a probabilistic model for learning multiple latent rankings by using pairwise comparisons. Our novel model can capture multiple hidden rankings underlying the pairwise comparisons. Based on the model, we develop an efficient inference algorithm to learn multiple latent rankings as well as an effective inference algorithm for active learning to update the model parameters in crowdsourcing systems whenever new pairwise comparisons are supplied. The performance study with synthetic and real-life data sets confirms the effectiveness of our model and inference algorithms.", "labels": [0, 8]}
{"id": "1799", "token": "Aims: A normal tissue complication probability (NTCP) model of severe acute mucositis would be highly useful to guide clinical decision making and inform radiotherapy planning. We aimed to improve upon our previous model by using a novel oral mucosal surface organ at risk (OAR) in place of an oral cavity OAR. Materials and methods: Predictive models of severe acute mucositis were generated using radiotherapy dose to the oral cavity OAR or mucosal surface OAR and clinical data. Penalised logistic regression and random forest classification (RFC) models were generated for both OARs and compared. Internal validation was carried out with 100-iteration stratified shuffle split cross-validation, using multiple metrics to assess different aspects of model performance. Associations between treatment covariates and severe mucositis were explored using RFC feature importance. Results: Penalised logistic regression and RFC models using the oral cavity OAR performed at least as well as the models using mucosal surface OAR. Associations between dose metrics and severe mucositis were similar between the mucosal surface and oral cavity models. The volumes of oral cavity or mucosal surface receiving intermediate and high doses were most strongly associated with severe mucositis. Conclusions: The simpler oral cavity OAR should be preferred over the mucosal surface OAR for NTCP modelling of severe mucositis. We recommend minimising the volume of mucosa receiving intermediate and high doses, where possible. (C) 2016 The Royal College of Radiologists. Published by Elsevier Ltd.", "labels": [0, 8]}
{"id": "1883", "token": "Background: Brain networks in fMRI are typically identified using spatial independent component analysis (ICA), yet other mathematical constraints provide alternate biologically-plausible frameworks for generating brain networks. Non-negative matrix factorization (NMF) would suppress negative BOLD signal by enforcing positivity. Spatial sparse coding algorithms (L1 Regularized Learning and K-SVD) would impose local specialization and a discouragement of multitasking, where the total observed activity in a single voxel originates from a restricted number of possible brain networks. New method: The assumptions of independence, positivity, and sparsity to encode task-related brain networks are compared; the resulting brain networks within scan for different constraints are used as basis functions to encode observed functional activity. These encodings are then decoded using machine learning, by using the time series weights to predict within scan whether a subject is viewing a video, listening to an audio cue, or at rest, in 304 fMRI scans from 51 subjects. Results and comparison with existing method: The sparse coding algorithm of L1 Regularized Learning outperformed 4 variations of ICA (p < 0.001) for predicting the task being performed within each scan using artifact-cleaned components. The NMF algorithms, which suppressed negative BOLD signal, had the poorest accuracy compared to the ICA and sparse coding algorithms. Holding constant the effect of the extraction algorithm, encodings using sparser spatial networks (containing more zero-valued voxels) had higher classification accuracy (p < 0.001). Lower classification accuracy occurred when the extracted spatial maps contained more CSF regions (p < 0.001). Conclusion: The success of sparse coding algorithms suggests that algorithms which enforce sparsity, discourage multitasking, and promote local specialization may capture better the underlying source processes than those which allow inexhaustible local processes such as ICA. Negative BOLD signal may capture task-related activations. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [0, 8]}
{"id": "1934", "token": "In many research and application areas, such as information retrieval and machine learning, we often encounter dealing with a probability distribution that is mixed by one distribution that is relevant to our task in hand and the other that is irrelevant and that we want to get rid of. Thus, it is an essential problem to separate the irrelevant distribution from the mixture distribution. This article is focused on the application in Information Retrieval, where relevance feedback is a widely used technique to build a refined query model based on a set of feedback documents. However, in practice, the relevance feedback set, even provided by users explicitly or implicitly, is often a mixture of relevant and irrelevant documents. Consequently, the resultant query model (typically a term distribution) is often a mixture rather than a true relevance term distribution, leading to a negative impact on the retrieval performance. To tackle this problem, we recently proposed a Distribution Separation Method (DSM), which aims to approximate the true relevance distribution by separating a seed irrelevance distribution from the mixture one. While it achieved a promising performance in an empirical evaluation with simulated explicit irrelevance feedback data, it has not been deployed in the scenario where one should automatically obtain the irrelevance feedback data. In this article, we propose a substantial extension of the basic DSM from two perspectives: developing a further regularization framework and deploying DSM in the automatic irrelevance feedback scenario. Specifically, in order to avoid the output distribution of DSM drifting away from the true relevance distribution when the quality of seed irrelevant distribution (as the input to DSM) is not guaranteed, we propose a DSM regularization framework to constrain the estimation for the relevance distribution. This regularization framework includes three algorithms, each corresponding to a regularization strategy incorporated in the objective function of DSM. In addition, we exploit DSM in automatic (i.e., pseudo) irrelevance feedback, by automatically detecting the seed irrelevant documents via three different document reranking methods. We have carried out extensive experiments based on various TREC datasets, in order to systematically evaluate the proposed methods. The experimental results demonstrate the effectiveness of our proposed approaches in comparison with various strong baselines.", "labels": [0, 8]}
{"id": "2271", "token": "Screening alcohol use disorder (AUD) patients has been challenging due to the subjectivity involved in the process. Hence, robust and objective methods are needed to automate the screening of AUD patients. In this paper, a machine learning method is proposed that utilized resting-state electroencephalography (EEG)-derived features as input data to classify the AUD patients and healthy controls and to perform automatic screening of AUD patients. In this context, the EEG data were recorded during 5 min of eyes closed and 5 min of eyes open conditions. For this purpose, 30 AUD patients and 15 aged-matched healthy controls were recruited. After preprocessing the EEG data, EEG features such as inter-hemispheric coherences and spectral power for EEG delta, theta, alpha, beta and gamma bands were computed involving 19 scalp locations. The selection of most discriminant features was performed with a rank-based feature selection method assigning a weight value to each feature according to a criterion, i.e., receiver operating characteristics curve. For example, a feature with large weight was considered more relevant to the target labels than a feature with less weight. Therefore, a reduced set of most discriminant features was identified and further be utilized during classification of AUD patients and healthy controls. As results, the inter-hemispheric coherences between the brain regions were found significantly different between the study groups and provided high classification efficiency (Accuracy = 80.8, sensitivity = 82.5, and specificity = 80, F-Measure = 0.78). In addition, the power computed in different EEG bands were found significant and provided an overall classification efficiency as (Accuracy = 86.6, sensitivity = 95, specificity = 82.5, and F-Measure = 0.88). Further, the integration of these EEG feature resulted into even higher results (Accuracy = 89.3 %, sensitivity = 88.5 %, specificity = 91 %, and F-Measure = 0.90). Based on the results, it is concluded that the EEG data (integration of the theta, beta, and gamma power and inter-hemispheric coherence) could be utilized as objective markers to screen the AUD patients and healthy controls.", "labels": [0, 8]}
{"id": "2467", "token": "Higher-level cognition depends on the ability to learn models of the world. We can characterize this at the computational level as a structure-learning problem with the goal of best identifying the prevailing causal relationships among a set of relata. However, the computational cost of performing exact Bayesian inference over causal models grows rapidly as the number of relata increases. This implies that the cognitive processes underlying causal learning must be substantially approximate. A powerful class of approximations that focuses on the sequential absorption of successive inputs is captured by the Neurath's ship metaphor in philosophy of science, where theory change is cast as a stochastic and gradual process shaped as much by people's limited willingness to abandon their current theory when considering alternatives as by the ground truth they hope to approach. Inspired by this metaphor and by algorithms for approximating Bayesian inference in machine learning, we propose an algorithmic-level model of causal structure learning under which learners represent only a single global hypothesis that they update locally as they gather evidence. We propose a related scheme for understanding how, under these limitations, learners choose informative interventions that manipulate the causal system to help elucidate its workings. We find support for our approach in the analysis of 3 experiments.", "labels": [0, 8]}
{"id": "2591", "token": "Sleep impairment significantly alters human brain structure and cognitive function, but available evidence suggests that adults in developed nations are sleeping less. A growing body of research has sought to use sleep to forecast cognitive performance by modeling the relationship between the two, but has generally focused on vigilance rather than other cognitive constructs affected by sleep, such as reaction time, executive function, and working memory. Previous modeling efforts have also utilized subjective, self-reported sleep durations and were restricted to laboratory environments. In the current effort, we addressed these limitations by employing wearable systems and mobile applications to gather objective sleep information, assess multi-construct cognitive performance, and model/predict changes to mental acuity. Thirty participants were recruited for participation in the study, which lasted 1 week. Using the Fitbit Charge HR and a mobile version of the automated neuropsychological assessment metric called CogGauge, we gathered a series of features and utilized the unified model of performance to predict mental acuity based on sleep records. Our results suggest that individuals poorly rate their sleep duration, supporting the need for objective sleep metrics to model circadian changes to mental acuity. Participant compliance in using the wearable throughout the week and responding to the CogGauge assessments was 80%. Specific biases were identified in temporal metrics across mobile devices and operating systems and were excluded from the mental acuity metric development. Individualized prediction of mental acuity consistently outperformed group modeling. This effort indicates the feasibility of creating an individualized, mobile assessment and prediction of mental acuity, compatible with the majority of current mobile devices.", "labels": [0, 8]}
{"id": "2690", "token": "A good skin detector that is capable of capturing skin tones under different conditions is important for human-machine interaction applications. In a general situation, skin detectors, such as skin probability maps or Gaussian mixture models, achieve acceptable skin segmentation results. However, the false positive rate increases significantly when the skin tones are in shadow or when skin-like background objects are under similar illumination. In this paper, we propose a novel skin feature learning algorithm based on stacked autoencoders, which are deep neural networks. To overcome the problems encountered in skin segmentation that are caused by different ethnicities and varying illumination conditions, the stacked autoencoders are utilized to learn more discriminative representations of the skin area in both the RGB color space and the HSV color space. Unlike traditional machine learning methods, instead of predicting each pixel individually, our algorithm utilizes blocks to learn the representations and detect the skin areas. The algorithm exploits the learning ability of deep neural networks to learn high-level representations of skin tones. Experiments on test images show that the proposed algorithm achieves acceptable results on several publicly available data sets. To reduce the difficulty of detecting skin pixels in these data sets, the ground truths of these data sets are commonly focused on foreground skin area detection. Our skin detector is also able to detect background areas, as shown in our experiments.", "labels": [0, 8]}
{"id": "2902", "token": "Background: Attachment theory has been proven essential for mental health, including psychopathology, development, and interpersonal relationships. Validated psychometric instruments to measure attachment abound but suffer from shortcomings common to traditional psychometrics. Recent developments in multimodal fusion and machine learning pave the way for new automated and objective psychometric instruments for adult attachment that combine psychophysiological, linguistic, and behavioral analyses in the assessment of the construct. Objective: The aim of this study was to present a new exposure-based, automatic, and objective adult-attachment assessment, the Biometric Attachment Test (BAT), which exposes participants to a short standardized set of visual and music stimuli, whereas their immediate reactions and verbal responses, captured by several computer sense modalities, are automatically analyzed for scoring and classification. We also aimed to empirically validate two of its assumptions: its capacity to measure attachment security and the viability of using themes as placeholders for rotating stimuli. Methods: A total of 59 French participants from the general population were assessed using the Adult Attachment Questionnaire (AAQ), the Adult Attachment Projective Picture System (AAP), and the Attachment Multiple Model Interview (AMMI) as ground truth for attachment security. They were then exposed to three different BAT stimuli sets, whereas their faces, voices, heart rate (HR), and electrodermal activity (EDA) were recorded. Psychophysiological features, such as skin-conductance response (SCR) and Bayevsky stress index; behavioral features, such as gaze and facial expressions; as well as linguistic and paralinguistic features, were automatically extracted. An exploratory analysis was conducted using correlation matrices to uncover the features that are most associated with attachment security. A confirmatory analysis was conducted by creating a single composite effects index and by testing it for correlations with attachment security. The stability of the theory-consistent features across three different stimuli sets was explored using repeated measures analysis of variances (ANOVAs). Results: In total, 46 theory-consistent correlations were found during the exploration (out of 65 total significant correlations). For example, attachment security as measured by the AAP was correlated with positive facial expressions (r=.36, P=.01). AMMI's security with the father was inversely correlated with the low frequency (LF) of HRV (r=-.87, P=.03). Attachment security to partners as measured by the AAQ was inversely correlated with anger facial expression (r=-.43, P=.001). The confirmatory analysis showed that the composite effects index was significantly correlated to security in the AAP (r=.26, P=.05) and the AAQ (r=.30, P=.04) but not in the AMMI. Repeated measures ANOVAs conducted individually on each of the theory-consistent features revealed that only 7 of the 46 (15%) features had significantly different values among responses to three different stimulisets. Conclusions: We were able to validate two of the instrument's core assumptions: its capacity to measure attachment security and the viability of using themes as placeholders for rotating stimuli. Future validation of other of its dimensions, as well as the ongoing development of its scoring and classification algorithms is discussed.", "labels": [0, 8]}
{"id": "2988", "token": "Continuous monitoring of actual evapotranspiration (ET) is critical for water resources management at both regional and local scales. Although the MODIS ET product (MOD16A2) provides viable sources for ET monitoring at 8-day intervals, the spatial resolution (1 km) is too coarse for local scale applications. In this study, we propose a machine learning and spatial temporal fusion (STF)-integrated approach in order to generate 8-day 30 m ET based on both MOD16A2 and Landsat 8 data with three schemes. Random forest machine learning was used to downscale MODIS 1 km ET to 30 m resolution based on nine Landsat-derived indicators including vegetation indices (VIs) and land surface temperature (LST). STF-based models including Spatial and Temporal Adaptive Reflectance Fusion Model and Spatio-Temporal Image Fusion Model were used to derive synthetic Landsat surface reflectance (scheme 1)/VIs (scheme 2)/ET (scheme 3) on Landsat-unavailable dates. The approach was tested over two study sites in the United States. The results showed that fusion of Landsat VIs produced the best accuracy of predicted ET (R-2 = 0.52-0.97, RMSE = 0.47-3.0 mm/8 days and rRMSE = 6.4-37%). High density of cloud-clear Landsat image acquisitions and low spatial heterogeneity of Landsat VIs benefit the ET prediction. The downscaled 30 m ET had good agreement with MODIS ET (RMSE = 0.42-3.4 mm/8 days, rRMSE = 3.226%). Comparison with the in situ ET measurements showed that the downscaled ET had higher accuracy than MODIS ET. (C) 2017 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS). Published by Elsevier B.V. All rights reserved.", "labels": [0, 8]}
{"id": "3083", "token": "In recent years, support vector regression (SVR) has become an emerging and popular forecasting technique in the field of machine learning. However, it is subjected to the model selection and learning complexity O(K* N-3), especially for a massive data set (N is the size of training dataset, and K is the number of search). How to simultaneously reduce K and N can give us insight and inspiration on designing an effective and accurate selection algorithm. To this end, this paper tries to integrate the selection of training subset and model for SVR, and proposes a nested particle swarm optimization (NPSO) by inheriting the model selection of the existing training subset based SVR (TS-SVR). This nested algorithm is achieved by adaptively and periodically estimating the search region of the optimal parameter setting for TS-SVR. Complex SVR, involving large-scale training data, can be seen as extensions of TS-SVRs, yielding a nested sequence of TS-SVRs with increasing sample size. The uniform design idea is transplanted to the above modeling process, and the convergence for the proposed model is proofed. By using two artificial regression problems, Boston housing and electric load in New South Wales as empirical data, the proposed approach is compared with the standard ones, the APSO-OTS-SVR, and other existing approaches. Empirical results show that the proposed approach not only can select proper training subset and parameter, but also has better generalization performance and fewer processing time. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [0, 8]}
{"id": "3125", "token": "The use of surrogate models is a standard method for dealing with complex real-world optimization problems. The first surrogate models were applied to continuous optimization problems. In recent years, surrogate models gained importance for discrete optimization problems. This article takes this development into consideration. The first part presents a survey of model-based methods, focusing on continuous optimization. It introduces a taxonomy, which is useful as a guideline for selecting adequate model-based optimization tools. The second part examines discrete optimization problems. Here, six strategies for dealing with discrete data structures are introduced. A new approach for combining surrogate information via stacking is proposed in the third part. The implementation of this approach will be available in the open source R package SPOT2. The article concludes with a discussion of recent developments and challenges in continuous and discrete application domains. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [0, 8]}
{"id": "3291", "token": "Emerging technologies are often not part of any official industry, patent or trademark classification systems. Thus, delineating boundaries to measure their early development stage is a nontrivial task. This paper is aimed to present a methodology to automatically classify patents concerning service robots. We introduce a synergy of a traditional technology identification process, namely keyword extraction and verification by an expert community, with a machine learning algorithm. The result is a novel possibility to allocate patents which (1) reduces expert bias regarding vested interests on lexical query methods, (2) avoids problems with citation approaches, and (3) facilitates evolutionary changes. Based upon a small core set of worldwide service robotics patent applications, we derive apt n-gram frequency vectors and train a support vector machine, relying only on titles, abstracts, and IPC categorization of each document. Altering the utilized Kernel functions and respective parameters, we reach a recall level of 83% and precision level of 85%.", "labels": [0, 8]}
{"id": "3359", "token": "Aiming to an automatic sound recognizer for radio broadcasting events, a methodology of clustering the audio feature space using the discrimination ability of the audio descriptors as a criterion, is investigated in this work. From a given and close set of audio events, commonly found in broadcast news transmissions, a large set of audio descriptors is extracted and their data-driven ranking of relevance is clustered, providing a more robust feature selection. The clusters of the feature space are feeding machine learning algorithms implemented as classification models during the experimental evaluation. This methodology showed that support vector machines provide significantly good results, considering the achieved accuracy due to their ability of coping well in high dimensionality experimental conditions.", "labels": [0, 8]}
{"id": "3434", "token": "We study geometric and topological properties of the image of a smooth submanifold of under a bi-Lipschitz map to . In particular, we characterize how the dimension, diameter, volume, and reach of the embedded manifold relate to the original. Our main result establishes a lower bound on the reach of the embedded manifold in the case where and the bi-Lipschitz map is linear. We discuss implications of this work in signal processing and machine learning, where bi-Lipschitz maps on low-dimensional manifolds have been constructed using randomized linear operators.", "labels": [0, 8]}
{"id": "3477", "token": "Mobile robot localization, which allows a robot to identify its position, is one of main challenges in the field of Robotics. In this work, we provide an evaluation of consolidated feature extractions and machine learning techniques from omnidirectional images focusing on topological map and localization tasks. The main contributions of this work are a novel method for localization via classification with reject option using omnidirectional images, as well as two novel omnidirectional image data sets. The localization system was analyzed in both virtual and real environments. Based on the experiments performed, the Minimal Learning Machine with Nearest Neighbors classifier and Local Binary Patterns feature extraction proved to be the best combination for mobile robot localization with accuracy of 96.7% and an Fscore of 96.6%. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [0, 8]}
{"id": "3", "token": "There is current interest in harnessing the combined anticancer and immunological effect of nano particles (NPs) and RNA. Here, we evaluate the bioactivity of poly I:C (pIC) RNA, bound to anticancer zinc oxide NP (ZnO-NP) against melanoma. Direct RNA association to unfunctionalized ZnO-NP is shown by observing change in size, zeta potential, and absorption/fluorescence spectra upon complexation. RNA corona was visualized by transmission electron microscopy (TEM) for the first time. Binding constant (K-b = 1.6-2.8 g(-1) L) was determined by modified Stern-Volmer, absorption, and biological surface activity index analysis. The pIC ZnO-NP complex increased cell death for both human (A375) and mouse (B16F10) cell lines and suppressed tumor cell growth in BALB/C-B16F10 mouse melanoma model. Ex vivo tumor analysis indicated significant molecular activity such as changes in the level of phosphoproteins JNK, Akt, and inflammation markers IL-6 and IFN-gamma. High throughput proteomics analysis revealed zinc oxide and poly I:C-specific and combinational patterns that suggested possible utility as an anticancer and immunotherapeutic strategy against melanoma.", "labels": [6, 38]}
{"id": "180", "token": "Background: We developed and validated a kinetic microplate hemolytic assay (HA) to quantify classical and alternative complement activity in a single dilution of human plasma or serum. Methods: The assay is based on monitoring hemolysis of sensitized sheep (or uncoated rabbit) red blood cells by means of a 96-well microplate reader. The activity of the calibrator was evaluated by reference to 200 healthy adults. The conversion of 50% hemolysis time into a percentage of activity was obtained using a calibration curve plotted daily. Results: The linearity of the assay as well as interference (by hemolysis, bilrubinemia and lipemia) was assessed for classical pathway (CP). The within-day and the between-day precision was satisfactory regarding the performance of commercially available liposome immunoassay (LIA) and ELISA. Patients with hereditary or acquired complement deficiencies were detected (activity was measured <30%). We also provided a reference range obtained from 200 blood donors. The agreement of CP evaluated on samples from 48 patients was 94% with LIA and 87.5% with ELISA. The sensitivity of our assay was better than that of LIA, and the cost was lower than either LIA or ELISA. In addition, this assay was less time consuming than previously reported HAs. Conclusions: This assay allows the simultaneous measurement of 36 samples in duplicate per run of a 96-well plate. The use of a daily calibration curve allows standardization of the method and leads to good reproducibility. The same technique was also adapted for the quantification of alternative pathway (AP) activity.", "labels": [6, 38]}
{"id": "273", "token": "BACKGROUND: It is unclear whether allergen immunotherapy (AIT) can be safely initiated during the pollen season (coseasonal initiation [CSI]) because of a potential increased risk of systemic allergic reactions. OBJECTIVE: To systematically review publications reporting the safety of subcutaneous immunotherapy (SCIT) and sublingual immunotherapy (SLIT) CSI to validate or invalidate the perception of increased safety risk. METHODS: PubMed, EMBASE, Ovid, Literatura Latino Americana em Ciencias da Saude (LILACS), and Cochrane Library databases were searched without limits for studies of any design reporting SCIT or SLIT CSI for pollen allergen. Congress abstracts were included. RESULTS: Nineteen eligible studies were identified: 8 SCIT (n = 947 subjects total; n[340 double-blind placebo-controlled [DBPC]) and 11 SLIT (n = 2668 subjects total; n = 565 DBPC). Study characteristics and safety reporting were heterogeneous. No epinephrine administrations were reported. Discontinuation frequencies were 6% or less and 10% or less with SCIT and SLIT CSI, respectively. In SCIT studies, systemic allergic reaction frequency was 0% to 7% with up to peak season or CSI, 0% to 6% with after peak season or out-of-season initiation, and 0% to 7% with placebo. In SCIT studies, serious treatment-related adverse event (AE) frequency with CSI ranged from 0% to 2%; few severe AEs were reported. In SLIT studies, systemic allergic reaction frequency ranged from 0% to 4% with CSI, 0% with out-of-season initiation, and 0% to 2% with placebo. Overall, 2 serious treatment-related AEs with SLIT CSI were reported. Severe AE frequency in SLIT studies ranged from 0% to 8% with CSI, 0% to 12% with out-of-season initiation, and 0% to 8% with placebo. CONCLUSIONS: No increase in AEs of concern was observed with SCIT or SLIT CSI; however, additional data with standardized regimens and doses are needed. (C) 2016 American Academy of Allergy, Asthma & Immunology", "labels": [6, 38]}
{"id": "335", "token": "The lungs are constantly exposed to the external environment, which in addition to harmless particles, also contains pathogens, allergens, and toxins. In order to maintain tolerance or to induce an immune response, the immune system must appropriately handle inhaled antigens. Lung dendritic cells (DCs) are essential in maintaining a delicate balance to initiate immunity when required without causing collateral damage to the lungs due to an exaggerated inflammatory response. While there is a detailed understanding of the phenotype and function of immune cells such as DCs in human blood, the knowledge of these cells in less accessible tissues, such as the lungs, is much more limited, since studies of human lung tissue samples, especially from healthy individuals, are scarce. This work presents a strategy to generate detailed spatial and phenotypic characterization of lung tissue resident DCs in healthy humans that undergo a bronchoscopy for the sampling of endobronchial biopsies. Several small biopsies can be collected from each individual and can be subsequently embedded for ultrafine sectioning or enzymatically digested for advanced flow cytometric analysis. The outlined protocols have been optimized to yield maximum information from small tissue samples that, under steady-state conditions, contain only a low frequency of DCs. While the present work focuses on DCs, the methods described can directly be expanded to include other (immune) cells of interest found in mucosal lung tissue. Furthermore, the protocols are also directly applicable to samples obtained from patients suffering from pulmonary diseases where bronchoscopy is part of establishing the diagnosis, such as chronic obstructive pulmonary disease (COPD), sarcoidosis, or lung cancer.", "labels": [6, 38]}
{"id": "387", "token": "Acute Graft-versus-Host Disease (GvHD) remains a major complication of allogeneic haematopoietic stem cell transplantation, with a significant proportion of patients failing to respond to first-line systemic corticosteroids. Reliable biomarkers predicting disease severity and response to treatment are warranted to improve its management. Thus, we sought to determine whether pentraxin 3 (PTX3), an acutephase protein produced locally at the site of inflammation, could represent a novel acute GvHD biomarker. Using a murine model of the disease, we found increased PTX3 plasma levels after irradiation and at GvHD onset. Similarly, plasma PTX3 was enhanced in 115 pediatric patients on day of transplantation, likely due to conditioning, and at GvHD onset in patients experiencing clinical symptoms of the disease. PTX3 was also found increased in skin and colon biopsies from patients with active disease. Furthermore, PTX3 plasma levels at GvHD onset were predictive of disease outcome since they resulted significantly higher in both severe and therapyunresponsive patients. Multiple injections of rhPTX3 in the murine model of GvHD did not influence the disease course. Taken together, our results indicate that PTX3 constitutes a biomarker of GvHD severity and therapy response useful to tailor treatment intensity according to early risk-stratification of GvHD patients.", "labels": [6, 38]}
{"id": "458", "token": "Chronic neuroinflammation is thought to potentiate medial temporal lobe (MTL) atrophy and memory decline in Alzheimer's disease (AD). It has become increasingly important to find novel immunological biomarkers of neuroinflammation or other processes that can track AD development and progression. Our study explored which pro- or anti-inflammatory cerebrospinal fluid (CSF) biomarkers best predicted AD neuropathology over 24 months. Using Alzheimer's Disease Neuroimaging Initiative data (N = 285), CSF inflammatory biomarkers from mass spectrometry and multiplex panels were screened using step-wise regression, followed up with 50%/50% model retests for validation. Neuronal Pentraxin 2 (NPTX2) and Chitinase-3-like-protein-1 (C3LP1), biomarkers of glutamatergic synaptic plasticity and microglial activation respectively, were the only consistently significant biomarkers selected. Once these biomarlcers were selected, linear mixed models were used to analyze their baseline and longitudinal associations with bilateral MTL volume, memory decline, global cognition, and established AD biomarkers including CSF amyloid and tau. Higher baseline NPTX2 levels corresponded to less MTL atrophy [R-2 = 0.287, p < 0.001] and substantially less memory decline [R-2 = 0.560, p < 0.001] by month 24. Conversely, higher C3LP1 modestly predicted more MTL atrophy [R-2 = 0.083, p < 0.001], yet did not significantly track memory decline over time. In conclusion, NPTX2 is a novel pro -inflammatory cytokine that predicts AD-related outcomes better than any immunological biomarker to date, substantially accounting for brain atrophy and especially memory decline. C3LP1 as the microglial biomarker, by contrast, performed modestly and did not predict longitudinal memory decline. This research may advance the current understanding of AD etiopathogenesis, while expanding early diagnostic techniques through the use of novel pro -inflammatory biomarkers, such as NPTX2. Future studies should also see if NPTX2 causally affects MTL morphometry and memory performance. (C) 2016 Elsevier Inc. All rights reserved.", "labels": [6, 38]}
{"id": "559", "token": "Johne's disease, caused by infection with Mycobacterium avium subspecies paratuberculosis (MAP), is a chronic wasting disease of ruminants. Hallmark symptoms of clinical Johne's disease include diarrhea, progressive weight loss, and premature death; symptoms due largely to chronic inflammation in the small intestine. MAP colonizes resident macrophages within the ileum of the small intestine, subsequently establishing a persistent infection in the host. It has been proposed that regulatory T cells may play a role in the progression of Johne's disease, either through promotion of tolerance to MAP or via a loss in homeostasis that subsequently allows widespread inflammation. In this report, we evaluated the presence of Tregs, as well as other immune parameters, in the ileum and draining lymph nodes of MAP associated lesions. A lesion classification scheme was developed to categorize severity of MAP-induced lesions within infected tissues and subsequently regulatory T cell presence and overall immune activity were assessed corresponding to lesions of varying severity, in comparison to tissues from healthy control animals. Our results revealed a relationship between animal health and overall lesion severity within the infected tissues, as well as a relationship between bacterial burden and severity of pathology. Regulatory T cell abundance was shown to decrease with increasing lesion severity. Within the ileum, the expression of many Th1, Th2, and Treg-associated genes increased in mild lesions and decreased in severe lesions, whereas in the lymph nodes the expression of these genes tended to increase with increasing lesion severity. Based on our results, we conclude that a local loss of T cell (including Treg) activity occurs within severe Heal lesions associated with MAP, resulting in a loss of homeostasis that ultimately leads to the progression of clinical Johne's disease. (C) 2016 Elsevier B.V. All rights reserved.", "labels": [6, 38]}
{"id": "647", "token": "The development of prophylactic vaccines remains largely empirical in nature and rarely have general rules been applied in the strategic decision and the formulation of a viral vaccine. Currently, there are a total of 15 virus agents from 12 unique virus families with vaccines licensed by the U.S. Food and Drug Administration. Extensive structural information on these viral particles and potential mechanisms of protection are available for the majority of these virus pathogens and their respective vaccines. Here I review the quantitative features of these viral surface antigens in relation to the molecular mechanisms of B-cell activation and point out a potential correlation between the density of immunogenic proteins displayed on the surface of the vaccine antigen carrier and the success of a vaccine. These features help us understand the humoral immunity induced by viral vaccines on a quantitative ground and re-emphasize the importance of antigen density on the activation of the immune system. Although the detailed mechanisms behind this phenomenon remain to be explored, it implies that both the size of antigen carriers and the density of immunogenic proteins displayed on these carriers are important parameters that may need to be optimized for the formulation of a vaccine. (C) 2016 American Pharmacists Association (R). Published by Elsevier Inc. All rights reserved.", "labels": [6, 38]}
{"id": "791", "token": "The immune response is determined by the speed of the T cell reaction to antigens assured by a state of readiness for proliferation and cytokine secretion. Proliferation, apoptosis and motion of many cell types are controlled by cytoplasmic proteases - mu- and m-calpain - and their inhibitor calpastatin, together forming the calpain-calpastatin system (CCS), assumed to modify their targets only upon activation-dependent cytoplasmic Ca2+ increase. Contrastingly to this notion, using quantitative real time PCR and semiquantitative flow cytometry respectively, we show here that the CCS genes are constitutively expressed, and that both calpains are constitutively active in resting, circulating human CD4(+) and CD8(+) lymphocytes. Furthermore, we demonstrate that calpain inhibition in the resting T cells prevents them from proliferation in vitro and greatly reduces secretion of multiple cytokines. The mechanistic reason for these effects of calpain inhibition on T cell functions might be the demonstrated significant reduction of the expression of active (phosphorylated) upstream signalling molecules, including the phospholipase C gamma, p56Lck and NF kappa B, in the inhibitor-treated cells. Thus, we propose that the constitutive, self-regulatory calpain-calpastatin system activity in resting human T cells is a necessary, controlling element of their readiness for complex and effective response to antigenic challenge.", "labels": [6, 38]}
{"id": "889", "token": "Traumatic brain injury (TBI) affects an ever-growing population of all ages with long-term consequences on health and cognition. Many of the issues that TBI patients face are thought to be mediated by the immune system. Primary brain damage that occurs at the time of injury can be exacerbated and prolonged for months or even years by chronic inflammatory processes, which can ultimately lead to secondary cell death, neurodegeneration, and long-lasting neurological impairment. Researchers have turned to rodent models of TBI in order to understand how inflammatory cells and immunological signaling regulate the post-injury response and recovery mechanisms. In addition, the development of numerous methods to manipulate genes involved in inflammation has recently expanded the possibilities of investigating the immune response in TBI models. As results from these studies accumulate, scientists have started to link cells and signaling pathways to pro-and anti-inflammatory processes that may contribute beneficial or detrimental effects to the injured brain. Moreover, emerging data suggest that targeting aspects of the immune response may offer promising strategies to treat TBI. This review will cover insights gained from studies that approach TBI research from an immunological perspective and will summarize our current understanding of the involvement of specific immune cell types and cytokines in TBI pathogenesis.", "labels": [6, 38]}
{"id": "1018", "token": "Mott cells are atypical plasmacytes recognized microscopically by endoplasmic reticulum (ER) distensions (Russell bodies) a result of retained secretory product (antibody). Originally associated with parasitism, they are observed in a broad spectrum of immunopathology, sometimes involving hypergammaglobulinemia. Few descriptions of Mott cells appear in avian literature. The purpose of the manuscript is to provide examples identified by light microscopy in three poultry species. Transmission electron micrographs (TEM) of plasmacytes from the turkey oviduct mucosa are included for comparison with Mott cell light microscopic images. Wright's stained blood and bone marrow from commercial and specific pathogen free (SPF) chickens, ducks, and turkeys are the sources. Mott cell positive samples commonly occurred with leukocytosis or leukemoid reactions, polymicrobial bacteremia, and fungemia. Atypical granulocytes and leukocytes regularly accompanied Mott cells. It is proposed that circulating Mott cells are sentinels indicative of stress, dyscrasia, and pathology. Moreover, Mott cells, like other atypia, complicate the interpretation of simple heterophil/lymphocyte (H/L) ratios. As Mott cells are defective plasmacytes these observations address hematology, immunology, pathology, and welfare issues.", "labels": [6, 38]}
{"id": "1267", "token": "Hepatitis A virus is one of five types of hepatotropic viruses that cause human liver disease. A similar liver disease is also identified in ducks caused by Duck Hepatitis A virus (DHAV). Notably, many types of hepatotropic viruses can be detected in urine. However, how those viruses enter into the urine is largely unexplored. To elucidate the potential mechanism, we used the avian hepatotropic virus to investigate replication strategies and immune responses in kidney until 280 days after infection. Immunohistochemistry and qPCR were used to detect viral distribution and copies in the kidney. Double staining of CD4+ or CD8+ T cells and virus and qPCR were used to investigate T cell immune responses and expression levels of cytokines. Histopathology was detected by standard HE staining. In this study, viruses were persistently located at scattered renal tubules. No CD4+ or CD8+ T cells were recruited to the kidney, which was only accompanied by transient cytokine storms. In conclusion, the extremely scattered infection was the viral strategy to escape host immunity and may persistently shed virus into urine. The deletion of Th or Tc cell responses and transient cytokine storms indeed provide an advantageous renal environment for their persistent survival.", "labels": [6, 38]}
{"id": "1436", "token": "Allergic rhinitis (AR) is a common illness in children and can impair their quality of life. Furthermore, many children remain symptomatic despite maximizing systemic antihistamine and topical therapies. It is at this clinical juncture that immunotherapy may be considered. The efficacy and safety associated with both subcutaneous (SCIT) and sublingual (SLIT) approaches are reviewed and positioned as treatment options for pediatric patients, with specific focus on current literature as it relates to SLIT in children, including those with perennial allergic rhinitis. Although there is more extensive experience with SLIT treatment in Europe, grass and ragweed tablet forms of SLIT are approved in the US. Approaches to the care of pediatric patients with allergic rhinitis are presented. (C) 2016 American Academy of Allergy, Asthma & Immunology (J Allergy Clin Immunol Pract 2017;5:46-51)", "labels": [6, 38]}
{"id": "1593", "token": "The tumor necrosis factor (TNF) receptors and their corresponding cytokine ligands have been implicated in many aspects of the biology of immune functions. TNF receptors have key roles during various stages of T cell homeostasis. Many of them can co-stimulate lymphocyte proliferation and cytokine production. Additionally, several TNF cytokines can regulate T cell differentiation, including promoting Th1, Th2, Th17, and more recently the newly described Th9 subset. Four TNF family cytokines have been identified as regulators for IL-9 production by T cells. OX40L, TL1A, and GITRL can promote Th9 formation but can also divert iTreg into Th9, while 4-1BBL seems to inhibit IL-9 production from iTreg and has not been studied for its ability to promote Th9 generation. Regulation of IL-9 production by TNF family cytokines has repercussions in vivo, including enhancement of anti-tumor immunity and immunopathology in allergic lung and ocular inflammation. Regulating T cell production of IL-9 through blockade or agonism of TNF family cytokine receptors may be a therapeutic strategy for autoimmune and allergic diseases and in tumor.", "labels": [6, 38]}
{"id": "1762", "token": "Background: Asthma is characterized by a heterogeneous inflammatory profile and can be subdivided into T(h) 2-high and T(h) 2-low airway inflammation. Profiling of a broader panel of airway cytokines in large unselected patient cohorts is lacking. Methods: Patients (n = 205) were defined as being cytokine-low/high if sputum mRNA expression of a particular cytokine was outside the respective 10th/90th percentile range of the control group (n = 80). Unsupervised hierarchical clustering was used to determine clusters based on sputum cytokine profiles. Results: Half of patients (n = 108; 52.6%) had a classical T(h) 2-high (IL-4-, IL-5-and/or IL-13-high) sputum cytokine profile. Unsupervised cluster analysis revealed 5 clusters. Patients with an IL-4-and/or IL-13-highpattern surprisingly did not cluster but were equally distributed among the 5 clusters. Patients with an IL-5-, IL-17A-/F-and IL-25-highprofile were restricted to cluster 1 (n = 24) with increased sputum eosinophil as well as neutrophil counts and poor lung function parameters at baseline and 2 years later. Four other clusters were identified: IL-5-high or IL-10-high(n = 16), IL-6-high(n = 8), IL-22-high(n = 25). Cluster 5 (n = 132) consists of patients without cytokine-highpattern or patients with only high IL-4 and/or IL-13. Conclusion: We identified 5 unique asthma molecular phenotypes by biological clustering. Type 2 cytokines cluster with non-type 2 cytokines in 4 out of 5 clusters. Unsupervised analysis thus not supports a priori type 2 versus non-type 2 molecular phenotypes.", "labels": [6, 38]}
{"id": "1843", "token": "Waterborne diseases have emerged as global health problems and their rapid and sensitive detection in environmental water samples is of great importance. Bacterial identification and enumeration in water samples is significant as it helps to maintain safe drinking water for public consumption. Culture-based methods are laborious, time-consuming, and yield false-positive results, whereas viable but nonculturable (VBNCs) microorganisms cannot be recovered. Hence, numerous methods have been developed for rapid detection and quantification of waterborne pathogenic bacteria in water. These rapid methods can be classified into nucleic acid-based, immunology-based, and biosensor-based detection methods. This review summarizes the principle and current state of rapid methods for the monitoring and detection of waterborne bacterial pathogens. Rapid methods outlined are polymerase chain reaction (PCR), digital droplet PCR, real-time PCR, multiplex PCR, DNA microarray, Next-generation sequencing (pyrosequencing, Illumina technology and genomics), and fluorescence in situ hybridization that are categorized as nucleic acid-based methods. Enzyme-linked immunosorbent assay (ELISA) and immunofluorescence are classified into immunology-based methods. Optical, electrochemical, and mass-based biosensors are grouped into biosensor-based methods. Overall, these methods are sensitive, specific, time-effective, and important in prevention and diagnosis of waterborne bacterial diseases.", "labels": [6, 38]}
{"id": "1914", "token": "Purpose of review Altered differentiation and activation of T-cell subsets occur in patients with chronic kidney disease (CKD), but the impact on graft rejection and protective immunity during transplantation are not fully understood. Recent findings Patients with CKD have decreased frequency of naive T cells, accumulation of activated, terminally differentiated memory cells, and skewed regulatory versus T helper 17 ratio. Naive and memory T-cell subsets do not appear to improve following kidney transplantation. Retained thymic output is associated with acute rejection, whereas naive lymphopenia and accumulation of CD8(+) TEMRA cells correlate with long-term graft dysfunction. CD28(null) memory cells accumulate during CKD and appear to confer protection against acute rejection under standard immunosuppression and possibly costimulation blockade. T cells bearing CD57 are also increased in patients with CKD and may underlie rejection during costimulation blockade. Summary The mechanisms by which CKD alters the differentiation and activation status of T-cell subsets is poorly understood. Further research is also needed to understand which cell populations mediate rejection under various immunosuppressive regimens. To date, there is little use of animal models of organ failure in transplant immunology research. CKD mouse models may help identify novel pathways and targets to better control alloimmunity in posttransplant.", "labels": [6, 38]}
{"id": "2114", "token": "Middle East Respiratory Syndrome Corona Virus (MERS-CoV) is transmitted via the respiratory tract and causes severe Acute Respiratory Distress Syndrome by infecting lung epithelial cells and macrophages. Macrophages can readily recognize the virus and eliminate it. MERS-CoV infects cells via its Spike (S) glycoprotein that binds on Dipeptidyl-Peptidase 4 (DPP4) receptor present on macrophages. Whether this Spike/DPP4 association affects macrophage responses remains unknown. Herein we demonstrated that infection of macrophages with lentiviral particles pseudotyped with MERS-CoV S glycoprotein results in suppression of macrophage responses since it reduced the capacity of macrophages to produce TNFa and IL-6 in naive and LPS-activated THP-1 macrophages and augmented LPS-induced production of the immunosuppressive cytokine IL-10. MERS-CoV S glycoprotein induced the expression of the negative regulator of TLR signaling IRAK-M as well as of the transcriptional repressor PPAR gamma. Inhibition of DPP4 by its inhibitor sitagliptin or siRNA abrogated the effects of MERS-CoV S glycoprotein on IRAK-M, PPAR gamma and IL-10, confirming that its immunosuppressive effects were mediated by DPP4 receptor. The effect was observed both in THP-1 macrophages and human primary peripheral blood monocytes. These findings support a DPP4-mediated suppressive action of MERS-CoV in macrophages and suggest a potential target for effective elimination of its pathogenicity.", "labels": [6, 38]}
{"id": "2201", "token": "Dishevelled (Dvl) not only links the canonical Wnt and non-canonical Wnt pathways but can also crosstalk with other pathways. As there is no systematic study to date on Dvl in rheumatoid arthritis (RA), we explored the impact of Dvl2 on proliferation and inflammatory cytokine secretion in RA fibroblast-like synoviocytes (FLSs). Expression of Dvl2 in RA synovial tissue and RA-FLSs was measured. Dvl2 was overexpressed in collagen-induced arthritis rats and human RA-FLSs,. the apoptosis and secretion of inflammatory cytokines were observed. Genetic changes and corresponding mechanisms caused by overexpressing Dvl2 in RA-FLSs were assessed. Dvl2 was found to be overexpressed in RA synovial tissue and RA-FLSs. Overexpression of Dvl2 increased apoptosis and inhibited inflammatory cytokine secretion by RA-FLSs in vivo and in vitro, and Dvl2 inhibited expression of antiapoptotic and inflammatory genes. One possible mechanism is that Dvl2 decreases the nuclear translocation of P65 and inhibits its ability to bind to the promoters of NF-kappa B target genes. Our findings reveal an underappreciated role of Dvl2 in regulating inflammation and RA-FLS apoptosis and provide insight into crosstalk between the Wnt and nuclear factor-kappa B (NF-kappa B) pathways.", "labels": [6, 38]}
{"id": "2296", "token": "Background: Vernal keratoconjunctivitis (VKC) is a chronic and often severe bilateral conjunctivitis. VKC etiology still remains unclear although endocrine, genetic, neurogenic and environmental factors have been implicated. Vitamin D is a fat-soluble prohormone whose main function is the regulation of calcium and phosphate metabolism. The aim of this study was to evaluate serum vitamin D in children affected by VKC compared to the healthy children and investigate the relationship between its levels and disease severity. Methods: A total of 110 children, 47 affected by VKC, aged between 5 and 12 years were enrolled at the Department of Pediatrics, Division of Allergy and Immunology, Sapienza University of Rome. Used as controls were 63 healthy children with negative skin prick test (SPT), without allergic, ocular and systemic disease. Serum samples were obtained in April from all the children included in the study. Vitamin D dosage was repeated in October in 20 patients after therapy and in 20 controls. A conjunctival scraping was performed in all children affected by VKC. Results: Children affected by VKC had lower vitamin D levels compared to healthy controls and we found an increase in vitamin D levels after therapy with cyclosporine eye drops 1% although this increase was lower than that of healthy controls. Moreover we found significant correlations between vitamin D level and the severity of the disease. Conclusions: The study shows that children affected by VKC have lower vitamin D levels when compared to healthy controls and highlights a significant correlation between its levels and disease severity.", "labels": [6, 38]}
{"id": "2381", "token": "Diversity in the macrophage models currently employed in immunology studies may lead to opposed results and interpretations. In this study, we aimed to analyze the suitability of J774 macrophage-like cells as a model for the interaction between the dermatophyte Trichophyton rubrum and macrophages. J774 cells were competent in fungal phagocytosis, but succumbed to hyphal growth. Nevertheless, they could also secrete IL-1 beta in response to the dermatophyte. On the opposite direction, inflammatory, thioglycollate-induced peritoneal macrophages did not succumb to fungal growth and showed no significant IL-1 beta production. The proteomic profiling of these cells uncovered vimentin and plastin-2 as proteins whose abundance was altered by the fungal interaction. Our study indicates that this cell line could be an interesting tool in the investigation of T. rubrum infection biology.", "labels": [6, 38]}
{"id": "2442", "token": "Peripartum cardiomyopathy is a heart failure syndrome occurring late in pregnancy or during the early post-natal period. The pathophysiology of peripartum cardiomyopathy is not fully understood and various mechanisms have been postulated including an underlying inflammatory process. We here report four cases presenting with acute left ventricular systolic dysfunction. Three out of four of the patients presented with a left ventricular ejection fraction <30% and one with a left ventricular ejection fraction of 35%. All made a full clinical recovery following treatment with high-dose intravenous steroids. This case series adds to the growing body of evidence for the role for immunosuppressants in the management of peripartum cardiomyopathy.", "labels": [6, 38]}
{"id": "2772", "token": "Group 3 innate lymphoid cells (ILC3), defined by expression of the transcription factor retinoid-related orphan receptor gamma t, play key roles in the regulation of inflammation and immunity in the gastrointestinal tract and associated lymphoid tissues. ILC3 consist largely of two major subsets, NCR+ ILC3 and LTi-like ILC3, but also demonstrate significant plasticity and heterogeneity. Recent advances have begun to dissect the relationship between ILC3 subsets and to define distinct functional states within the intestinal tissue microenvironment. In this review we discuss the ever-expanding roles of ILC3 in the context of intestinal homeostasis, infection and inflammation - with a focus on comparing and contrasting the relative contributions of ILC3 subsets.", "labels": [6, 38]}
{"id": "2877", "token": "Objective: Long-term prognosis of hepatocellular carcinoma (HCC) remains poor owing to the lack of treatment options for advanced HCC. Cytokine-induced killer (CIK) cells are ex vivo expanded T lymphocytes expressing both NK- and T-cell markers. CIK cell therapy alone is insufficient for treating advanced HCC. Thus, this study aimed to determine whether treatment with CIK cells combined with valproic acid (VPA) could provide a synergistic effect to inhibit tumor growth in a mouse model of HCC. Methods: Upregulation of natural killer group 2D (NKG2D) ligands (retinoic acid early inducible 1 [RAE-1], mouse; major histocompatibility complex class I polypeptide-related sequence A [MIC-A], human) were evaluated by FACS. VPA concentrations that did not reduce tumor volume were calculated to avoid VPA cytotoxicity in a C3H mouse model of HCC. CIK cells were generated from mouse splenocytes using interferon gamma, a CD3 monoclonal antibody, and interleukin 2. The potential synergistic effect of CIK cells combined with VPA was evaluated in the mouse model and tissue pathology was investigated. Results: After 40h of incubation with VPA, RAE-1 and MIC-A expression were increased in 4 HCC cell lines compared with that in control (2.3-fold in MH-134, 2.4-fold in Huh-7, 3.7-fold in SNU-761, and 6.5-fold in SNU-475). The maximal in vivo VPA dosage that showed no significant cytotoxicity compared with control was 10mg/kg/day. CIK cells were well generated from C3H mouse splenocytes. After 7d of treatment with CIK cells plus VPA, a synergistic effect was observed on relative tumor volume in the mouse model of HCC. While the relative tumor volume in untreated control mice increased to 11.25, that in the combination treatment group increased to only 5.20 (P = 0.047). Conclusions: The VPA-induced increase in NKG2D ligands expression significantly enhanced the effects of CIK cell therapy in a mouse model of HCC.", "labels": [6, 38]}
{"id": "2957", "token": "Background: Although discovery research has identified the importance of dozens of pro-and anti-inflammatory immune mediators in the pathogenesis, maintenance, exacerbation and resolution of inflammatory diseases, most human cohort studies have incorporated few or no immunological intermediate phenotypes in their analyses. Significant hindrances have been (1) the limited panel of biomarkers known to be readily detected in healthy human populations and (2) the stability, hence utility, of such biomarkers to repeated analysis. Methods: The frequency and stability of 14 plasma biomarkers linked to in vivo immune regulation of allergic and autoimmune inflammatory disorders was determined in 140 healthy pediatric and adult participants. The impact of initial and multiple subsequent freeze/thaw cycles on pro-inflammatory (CCL2, CXCL10, IL-18, TNF alpha, IL-6), anti-inflammatory (IL-10, sTNF-RII, IL-1Ra), acute phase proteins (CRP, PTX3) and other biomarkers (sST2, IL-1RAcP) was subsequently quantified. Results: Multiple biomarkers capable of providing an innate immune signature of inflammation were readily detected directly ex vivo in healthy individuals. These biomarker levels were unaffected when comparing paired data sets from freshly obtained, never frozen plasma or serum and matched aliquots despite extensive freeze/thaw cycles. Neither age nor sex affected stability. Similarly, no quantitative differences were found following repetitive analysis of inflammatory biomarkers in culture samples obtained following in vitro stimulation with TLR and RLR ligands. Conclusions: A broad panel of in vivo and ex vivo cytokine, chemokine and acute phase protein biomarkers that have been linked to human chronic inflammatory disorders are readily detected in vivo and remain stable for analysis despite multiple freeze thaw cycles. These data provide the foundation and confidence for large scale analyses of panels of inflammatory biomarkers to provide better understanding of immunological mechanisms underlying health versus disease.", "labels": [6, 38]}
{"id": "3191", "token": "Mucosal surfaces line our body cavities and provide the interaction surface between commensal and pathogenic microbiota and the host. The barrier function of the mucosal layer is largely maintained by gel-forming mucin proteins that are secreted by goblet cells. In addition, mucosal epithelial cells express cell-bound mucins that have both barrier and signaling functions. The family of transmembrane mucins consists of diverse members that share a few characteristics. The highly glycosylated extracellular mucin domains inhibit invasion by pathogenic bacteria and can form a tight mesh structure that protects cells in harmful conditions. The intracellular tails of transmembrane mucins can be phosphorylated and connect to signaling pathways that regulate inflammation, cell-cell interactions, differentiation, and apoptosis. Transmembrane mucins play important roles in preventing infection at mucosal surfaces, but are also re-nowned for their contributions to the development, progression, and metastasis of adenocarcinomas. In general, transmembrane mucins seem to have evolved to monitor and repair damaged epithelia, but these functions can be highjacked by cancer cells to yield a survival advantage. This review presents an overview of the current knowledge of the functions of transmembrane mucins in inflammatory processes and carcinogenesis in order to better understand the diverse functions of these multifunctional proteins. (C) 2017 S. Karger AG, Basel", "labels": [6, 38]}
{"id": "3214", "token": "Guillain-Barre syndrome (GBS) is an autoimmune-mediated peripheral neuropathy of unknown cause. However, about a quarter of GBS patients have suffered a recent bacterial or viral infection, and axonal forms of the disease are especially common in these patients. Proteomics is a good methodological approach for the discovery of disease biomarkers. Until recently, most proteomics studies of GBS and other neurodegenerative diseases have focused on the analysis of the cerebrospinal fluid (CSF). However, serum represents an attractive alternative to CSF because it is easier to sample and has potential for biomarker discovery. The goal of this research was the identification of serum biomarkers associated with recovery from GBS. To address this objective, a quantitative proteomics approach was used to characterize differences in the serum proteome between a GBS patient and her healthy identical twin in order to lessen variations due to differences in genetic background, and with additional serum samples collected from unrelated GBS (N = 3) and Spinal Cord Injury (SCI) (N = 3) patients with similar medications. Proteomics results were then validated by ELISA using sera from additional GBS patients (N = 5) and healthy individuals (N = 3). All GBS and SCI patients were recovering from the acute phase of the disease. The results showed that Piccolo, a protein that is essential in the maintenance of active zone structure, constitutes a potential serological correlate of recovery from GBS. These results provided the first evidence for the Piccolo's putative role in GBS, suggesting a candidate target for developing a serological marker of disease recovery.", "labels": [6, 38]}
{"id": "3305", "token": "Hepatitis B virus (HBV) infection is a major global health challenge. HBV can cause significant morbidity and mortality by establishing acute and chronic hepatitis. Approximately 250 million people worldwide are chronically infected, and more than 2 billion people have been exposed to HBV. Since the discovery of HBV, the advances in our understanding of HBV virology and immunology have translated into effective vaccines and therapies for HBV infection. Although current therapies successfully suppress viral replication but rarely succeed in viral eradication, recent discoveries in HBV virology and immunology provide exciting rationales for novel treatment strategies aiming at HBV cure.", "labels": [6, 38]}
{"id": "3349", "token": "New hepatitis B virus (HBV) therapies are expected to have breakthrough benefit for patients. HBV functional cure is sustained hepatitis B surface antigen loss and anti-HBs gain, with normalization of serum aminotransferases off therapy. Virologic or complete cure additionally includes loss of HBV covalently closed circular DNA. Currently available endpoints of therapy are inadequate to evaluate the efficacy of many of the new therapeutics. Therefore, either new ways of using the existing virologic endpoints and laboratory values or entirely new biomarkers are needed. In this review, we discuss the currently used endpoints, potential new endpoints, as well as what new markers are needed to assess the ability of HBV therapeutics to achieve functional and virologic cure in various phases of HBV infection. In addition, we discuss how patient selection from differing phases of HBV impacts the choice of HBV drug(s) needed to achieve cure.", "labels": [6, 38]}
{"id": "3414", "token": "Background: Here we integrate verified signals from previous genetic association studies with gene expression and pathway analysis for discovery of new candidate genes and signaling networks, relevant for rheumatoid arthritis (RA). Method: RNA-sequencing-(RNA-seq)-based expression analysis of 377 genes from previously verified RA-associated loci was performed in blood cells from 5 newly diagnosed, non-treated patients with RA, 7 patients with treated RA and 12 healthy controls. Differentially expressed genes sharing a similar expression pattern in treated and untreated RA sub-groups were selected for pathway analysis. A set of connector genes derived from pathway analysis was tested for differential expression in the initial discovery cohort and validated in blood cells from 73 patients with RA and in 35 healthy controls. Results: There were 11 qualifying genes selected for pathway analysis and these were grouped into two evidence-based functional networks, containing 29 and 27 additional connector molecules. The expression of genes, corresponding to connector molecules was then tested in the initial RNA-seq data. Differences in the expression of ERBB2, TP53 and THOP1 were similar in both treated and non-treated patients with RA and an additional nine genes were differentially expressed in at least one group of patients compared to healthy controls. The ERBB2, TP53. THOP1 expression profile was successfully replicated in RNA-seq data from peripheral blood mononuclear cells from healthy controls and non-treated patients with RA, in an independent collection of samples. Conclusion: Integration of RNA-seq data with findings from association studies, and consequent pathway analysis implicate new candidate genes, ERBB2, TP53 and THOP1 in the pathogenesis of RA.", "labels": [6, 38]}
{"id": "4", "token": "DNS (Domain name System) is one of the most prevalent protocols on modern networks and is essential for the correct operation of many network activities including the malicious operation. Monitoring the DNS traffic is an effective method to detect malicious activities. In this paper, we proposed an approach to detect malicious domains by analyzing massive mobile web traffic data. We used multiple features to classify, including the textual features and the traffic statistics features of domains and presented three typical classifiers to compare the classifying effect of each. Spark framework is leveraged to speed up the calculation of a large-scale DNS traffic. The efficiency of our system makes us believe the approach can help a lot in the field of network security.", "labels": [0, 9]}
{"id": "166", "token": "We posit that commercial Wi-Fi-based unmanned aerial vehicles (UAV) are vulnerable to common and basic security attacks, capable by beginner to intermediate hackers. We do this by demonstrating that the standard ARDiscovery Connection process and the Wi-Fi access point used in the Parrot Bebop UAV are exploitable such that the UAV's ability to fly can be disrupted mid-flight by a remote attacker. We believe that these vulnerabilities are systemic in Wi-Fi-based Parrot UAVs. Our approach observed the normal operation (i.e., ARDiscovery Connection process over Wi-Fi) of the Parrot Bebop UAV. We then used a fuzzing technique to discover that the Parrot Bebop UAV is vulnerable to basic denial of service (DoS) and buffer-overflow attacks during its ARDiscovery Connection process. The exploitation of these vulnerabilities could result in catastrophic and immediate disabling of the UAV's rotors mid-flight. Also, we discovered that the Parrot Bebop UAV is vulnerable to a basic ARP (Address Resolution Protocol) Cache Poisoning attack, which can disconnect the primary mobile device user and in most cases cause the UAV to land or return home. Based on the literature and our own penetration testing, we assert that Wi-Fi-based commercial UAVs require a comprehensive security framework that utilizes a defense-in-depth approach. This approach would likely mitigate security risks associated with the three zero-day vulnerabilities described in this paper as well as other vulnerabilities reported in the literature. This framework will be effective for Parrot Wi-Fi-based commercial UAVs and likely others with similar platforms.", "labels": [0, 9]}
{"id": "341", "token": "This paper acquaints with a created application for generating Rainbow Tables and the results of testing Rainbow Tables, according to the length of the chosen chain. The paper presents a specialized application containing its own algorithms for reduction functions, changing the length of chain, generating Rainbow Tables and measuring the effectivity of the password search in detail. Within the executed tests, the dependence of Rainbow Tables size on the password length, the affection of the hash search by the size of the chosen chain and their links to collisions, which arise from the principle of using the reduction function, were observed. The results objectively describe the pros and cons of using Rainbow Tables and show the possibilities and restrictions for their effective usage.", "labels": [0, 9]}
{"id": "547", "token": "We model attacks on a cyberphysical system as a game between two players-the attacker and the system. The players may not acquire the complete information about each other, and that leads to an asymmetric information game. Furthermore, the players may have a certain fixed amount of resources, which constrains their strategies across time. Accordingly, we consider a dynamic multiplayer nonzero sum game with asymmetric information in which controllers have total resource constraints. Under certain assumptions on the information structure of the game, we devise an algorithm that computes a subclass of Nash equilibria of the game. We also study a denial-of-service attack on a cyberphysical system, model it as two-player zero-sum games, and apply our algorithm to compute the saddle-point equilibrium strategies of the attacker and the controller.", "labels": [0, 9]}
{"id": "753", "token": "Recently, deep learning has gained prominence due to the potential it portends for machine learning. For this reason, deep learning techniques have been applied in many fields, such as recognizing some kinds of patterns or classification. Intrusion detection analyses got data from monitoring security events to get situation assessment of network. Lots of traditional machine learning method has been put forward to intrusion detection, but it is necessary to improvement the detection performance and accuracy. This paper discusses different methods which were used to classify network traffic. We decided to use different methods on open data set and did experiment with these methods to find out a best way to intrusion detection.", "labels": [0, 9]}
{"id": "819", "token": "Digital audio signal provides a large capacity for embedding hidden messages using digital steganography techniques. How to prevent hazardous steganography embedding on the Internet becomes an important task in the field of network security. For the Internet environment, the steganography attack method is required to be generic and real time. An active warden-based attack method is potential to be a generic method for the steganography attack. A discrete spring transform (DST)-based generic active warden steganography attack framework has been proposed by us. In this paper, based on the DST, a real-time steganography attack method is proposed. The potential unauthorized hidden message is removed in a real-time manner when uploading or downloading the audio signal. The real-time signal perceptual quality control is achieved by the automatic feedback from the objective audio quality evaluation model. The attack parameters are adaptively changed to reach a balance between the attack performance and the audio signal quality. The simulation results validate the proposed method in terms of the steganography attack performance and the audio signal quality after the attack. Copyright (c) 2014 John Wiley & Sons, Ltd.", "labels": [0, 9]}
{"id": "910", "token": "In traditional approach, extracting important features for the application to analyze the anomaly detection problem, introduce significant overhead on the way of switch handling. Furthermore, high volumes of network traffic introduce notable issues that affect the performance and anomaly detection accuracy. Taking advantage of centralized control plane of Software Defined Networking (SDN), the task to handle the flow information is much more simplified programmatically. The accuracy of the measured flow statistic plays important role in anomaly detection. While the use of sampling is capable to lessen the scalability problem of traffic monitoring, the insufficiency of sampled flow statistic may have led to inaccurate detection rate of anomaly. In this paper, we propose an adaptive sampling strategy that is able to provide essential traffic statistics for more accurate anomaly detection in SDN. Our sampling mechanism utilizes the clustering analysis, which is used to classify the attack in the network to determine the severity of monitored traffic. By manipulating the type of service of incoming packet together, these two important parameter formulate our sampling mechanism algorithm. We show experimentally that by putting higher polling frequency on detected anomalous flow, we able to detect network attacks much more accurate.", "labels": [0, 9]}
{"id": "998", "token": "With the application of network technology, the risk of network security is gradually increasing. In order to predict the likelihood of network risks in real-time, a Time-Varying Markov Model (TVMM) for real-time risk probability prediction was proposed. The real-time risk probability prediction method is able to predict the probability of network risk in future exactly with a real-time-updating-state probability transition matrix of TVMM. The model is used to calculate the risk probability of the network at different risk levels in network attack environment. The result shows that TVMM has higher real-time objectivity and accuracy than the traditional Markov model.", "labels": [0, 9]}
{"id": "1128", "token": "Application of fuzzy rule interpolation (FRI) has been escalating for making intelligent systems viable in many areas. However, requirements of such systems may change over time and the supporting static rule base may not be able to provide accurate interpolation results in the long run. Dynamic fuzzy rule interpolation (D-FRI) is one of the potential solutions for this problem, a such has been developed in the last few years to fulfil the requirements of dynamic and pertinent rule bases for intelligent systems. Nevertheless, applications of the proposed D-FRI approach need further investigation. One potential application is for network security that is one of the biggest concerns of any organisation irrespective of their size and nature of business. Intrusion detection systems (IDSs) are considered as one of the most popular and effective security tools for generating alerts to systems or network administrators to inform possible or existing threats. A standard IDS may not be very effective or even unsuitable for an organisational or individual's requirements. This paper presents an application of D-FRI for building an effective IDS. In this implementation, the most popular open source IDS, Snort is used and the resultant intelligent IDS is named D-FRI-Snort. Experimental analysis shows that the integration of D-FRI with the IDS Snort provides an additional level of intelligence to predict the level/sensitivity of possible threats. It also provides a dynamic rule base by promoting new rules based on the current network traffic conditions, which helps Snort to reduce both false positives and false negatives.", "labels": [0, 9]}
{"id": "1482", "token": "To meet ever increasing load demand in a sustainable way, reinforcement of photovoltaic (PV) array, wind turbine (WT) and capacitor bank in distribution network is proposed in this paper. A comprehensive planning model is presented to determine location and required installation capacity of multiple PV array, WT and capacitor units in an electric power distribution network under heavy load growth situation. Intermittent power generation of renewable energy sources (RESs) are quantified with suitable probability distribution functions and incorporated in the planning model. The planning approach considers several welfare areas in the distribution systems, viz., increment of profit margin, reduction of carbon-di-oxide emission, minimization of distribution power losses, enhancement of voltage stability level and improvement of the network security considering power flow, voltage limit, line capacity, RES penetration, capacitor penetration and utility economy constraint. Non-dominated sorting based multi-objective particle swarm optimization algorithm along with fuzzy decision making criteria is used to find the best allocation alternative for mix RES and capacitor planning problem. The effectiveness of the proposed model has been tested on a typical 28-bus Indian rural distribution network. The results show that more efficient techno-eco-environmental optimization can be obtained from combined RES and capacitor planning model. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [0, 9]}
{"id": "1554", "token": "Within the policies of an organization is possible find not to allow users to access sites on the Internet for entertainment or social networks, as in the case of production organizations and educational therefore a firewall that is used implemented certain rules based on the policies of the organization, blocks access to certain defined sites while you let others free. However there is no implemented rules to block proxies of Avoidance Internet Censorship Systems, the user can access easily to those proxies. The addresses of these proxies change very frequently, so it is almost impossible to block them all, and eventually they appear more. The proposed solution is to create a firewall that uses dynamic rules, these rules are created for the dynamic firewall. A test of each address to a destination is made and if it finds that the destination is a proxy of one of these evation systems; the firewall creates a new rule and automatically implemented. In this way the user will lose access to the proxy.", "labels": [0, 9]}
{"id": "1855", "token": "Network traffic classification is elementary to network security and management. Recent research tends to apply machine learning techniques to flow statistical feature based classification methods. The Gaussian Mixture Model (GMM) based on the correlation of flows has exhibited superior classification performance. It also has several important advantages, such as robust to distributional assumptions and adaption to any cluster shape. However, the performance of GMM can be severely affected by the number of clusters. In this paper, we propose the minimum description length (MDL) criterion which can balance the accuracy and complexity of the classification model effectively by evaluating the optimal number of clusters. We establish a new classification model and analyze its performance. A large number of experiments are carried out on two real-world traffic data sets to validate the proposed approach. The results demonstrate the efficiency of our approach.", "labels": [0, 9]}
{"id": "1903", "token": "Dagger is a modeling and visualization framework that addresses the challenge of representing knowledge and information for decision-makers, enabling them to better comprehend the operational context of network security data. It allows users to answer critical questions such as Given that I care about mission X, is there any reason I should be worried about what is going on in cyberspace? or If this system fails, will I still be able to accomplish my mission?", "labels": [0, 9]}
{"id": "1954", "token": "Security is essential to enable the Internet of Things (IoT). Key security measures that work well on the traditional Internet, however, do not necessarily adapt well to the IoT. Specifically, authentication and/or authorization based on certificates provided by certificate authorities (CAs) cannot, in current form, scale to the expected 50 billion devices. And widely used encryption technologies for the Internet require too much energy for resource-constrained devices. This paper describes a secure network architecture with key distribution mechanisms using local, automated authorization entities. The architecture provides security guarantees while addressing IoT-related issues including resource constraints. For evaluation, we show that the architecture's overhead scales at a significantly slower rate than widely used SSL/TLS and works well with resource-constrained devices.", "labels": [0, 9]}
{"id": "2020", "token": "Data mining for intrusion detection is one of the most cutting-edge researches which focus on network security, database, and information decision-making. Due to the emergence of new forms of attacks and intrusion on the network, we need a new intrusion detection system which would be able to detect new and unknown attacks. Nevertheless, because of the complexity and diversity of network security alarm data, ordinarily, it is difficult to analyze and evaluate network security situation accurately. Intrusion detection is to protect network system from attacks and defend its security. We used machine learning technology in intrusion detection system in order to improve system performance effectively. In the paper, by studying the characteristics of network data intrusion, we put forward a intrusion detection system based on Rough set theory, and detect anomaly action in network. This method can extract detection rule model of network connection data, dealing with incomplete data and discrete data exit in data mining effectively. The basic ideas and techniques of data mining-based intrusion detection and the architecture of a real time data mining-based IDS are discussed. Meanwhile, we mainly analyzed the basic structure of intrusion detection system and application of several Machine Learning methods in intrusion detection which include Bayesian Classification-based method, neural networks-based method, Support Vector Machine-based method(SVM). The experiments results show that, models, methods and generation framework proposed in this paper can effectively detect network intrusion.", "labels": [0, 9]}
{"id": "2086", "token": "Network security systems inspect packet payloads for signatures of attacks. These systems use regular expression matching at their core. Many techniques for implementing regular expression matching at line rate have been proposed. Solutions differ in the type of automaton used (i.e., deterministic versus non-deterministic) and in the configuration of implementation-specific parameters. While each solution has been shown to perform well on specific rule sets and traffic patterns, there has been no systematic comparison across a large set of solutions, rule sets and traffic patterns. Thus, it is extremely challenging for a practitioner to make an informed decision within the plethora of existing algorithmic and architectural proposals. Moreover, as multi-core processors are becoming popular, many parameters need to be tuned to maximize the multi-core potential. To address this problem, we present a comprehensive evaluation of a broad set of regular expression matching techniques. We consider both algorithmic and architectural aspects. Specifically, we explore the performance, area requirements, and power consumption of implementations targeting multi-core processors and FPGAs using rule sets of practical size and complexity. We present detailed performance results and specific guidelines for determining optimal configurations based on a simple evaluation of the rule set. These guidelines can help significantlywhen implementing regular expression matching systems in practice.", "labels": [0, 9]}
{"id": "2106", "token": "Internet technology today is not free from many problems or security holes. This security holes could be exploited by an unauthorized person to steal important data. The case of the attacks occurred because the party that was attacked also did not realize the importance of network security to be applied to the system. Honeypot is a system that is designed to resemble the original production system and is made with the intention to be attacked or compromised. In this research, Cubieboard implemented using low interaction honeypot as a decoy to attract attackers. The result of this research is a low interaction honeypot implemented on embedded system with the form of Cubieboard that can emulates security vulnerabilities such as directory buster brute force, LFI, and RFI with 100% success rate, but still could not emulates SQL Injection vulnerability. One of the result of stress test with 773 samples, obtained average time of 5275 ms, deviation 2067 ms, sample throughput 367.012 per minute, and with median 5381 ms. The stress test is conducted with 50 threads and 10 ramp-ups per second.", "labels": [0, 9]}
{"id": "2222", "token": "Recent variants of Distributed Denial-of-Service (DDoS) attacks leverage the flexibility of application-layer protocols to disguise malicious activities as normal traffic patterns, while concurrently overwhelming the target destination with a large request rate. New countermeasures are necessary, aimed at guaranteeing an early and reliable identification of the compromised network nodes (the botnet). In this work we introduce a formal model for the aforementioned class of attacks, and we devise an inference algorithm that estimates the botnet hidden in the network, converging to the true solution as time progresses. Notably, the analysis is validated over real network traces.", "labels": [0, 9]}
{"id": "2370", "token": "As the conventional power systems turn towards smart grids (SGs) on a fast pace, this transition may create new and significant challenges to the existing electrical network security. Along with many important features of the SGs cyber security has emerged to be a critical issue due to the interconnection of several loads, generators, and renewable resources through the communication network. Cyber-physical attacks (CPAs) are classified as the major threatening of SGs security because it may lead to severe consequences such as large blackout and destruction of infrastructures. Cyber switching attacks (CSAs) (as a part CPAs) start to attract the attention due to its severity and speed in destabilizing the SGs, we present in this paper Thyristor-Controlled Braking Resistor (TCBR) as a solution to mitigate this type of attack. TCBR can enable us to stabilize the target generator in a relatively short time.", "labels": [0, 9]}
{"id": "2402", "token": "Complex traffic networks include a number of controlled intersections, and, commonly, multiple districts or municipalities. The result is that the overall traffic control problem is extremely complex computationally. Moreover, given that different municipalities may have distinct, non-aligned, interests, traffic light controller design is inherently decentralized, a consideration that is almost entirely absent from related literature. Both complexity and decentralization have great bearing both on the quality of the traffic network overall, as well as on its security. We consider both of these issues in a dynamic traffic network. First, we propose an effective local search algorithm to efficiently design system-wide control logic for a collection of intersections. Second, we propose a game theoretic (Stackelberg game) model of traffic network security in which an attacker can deploy denial-of-service attacks on sensors, and develop a resilient control algorithm to mitigate such threats. Finally, we propose a game theoretic model of decentralization, and investigate this model both in the context of baseline traffic network design, as well as resilient design accounting for attacks. Our methods are implemented and evaluated using a simple traffic network scenario in SUMO.", "labels": [0, 9]}
{"id": "2570", "token": "The Mobile ad-hoc network do not take any static infrastructure and they depend on their neighbors to convey message. The mobile nodules can travel all over the network in an unrestricted fashion. Unlike wired networks, there is no fixed and committed link exists between the nodes. The self-organizing capability of nodes in MANET made it trendy among crucial mission functions like military usage and emergency rescue. Hence MANET security is of essential importance. Unfortunately, the open medium, eclectic supply of nodes and dynamic topology make MANET defenseless to malevolent attackers. In this circumstance, it is crucial to foster proficient intrusion-detection mechanisms to guard MANET from a number of attacks. Lot of techniques have been suggested for intrusion detection, specifically for MANETs. This article put forward a review of some of the up to date intrusion detection procedures in MANETs and their comparisons.", "labels": [0, 9]}
{"id": "2668", "token": "Distributed Denial of Service (DDoS) attacks always remain problematic for the security of Data centers, malicious codes are injected to weaker the network and acquire unauthorized access. As protection the firewalls are initial line of defense to battle with unauthorized access, and help to the flawless transactions. Conventional firewalls rely on predefined policies to control, and policies rely on assumptions and notions. These firewalls are not so much intelligent to take run-time decision by their own at the last minute required. However if the hacker continuously stroke any port of firewall, it will hang-up and slowdown for responding, moreover chance to access the servers and entire network. This survey based on state of the art in data centers, especially DDoS challenges in DCNs, the paper based on some learning processes, which will focus to evaluate and analyse the complexity of secure connections in real-world data centers.", "labels": [0, 9]}
{"id": "2733", "token": "With the explosive growth of mobile terminal access to the Network and the shortage of IPv4, the Network Address Translation (NAT) technology has become more and more widely used. The technology not only provides users with convenient access to the Internet, but also brings trouble to network operators and regulatory authorities. This system NAT detection using NetFlow data, is often used for monitoring and forensics analysis in large networks. In the paper, in order to detect NAT devices, an Out-in Activity Degree method based on network behavior is proposed. Our approach works completely passively and is based on NetFlow data only. Our approach gets accuracy of 91.2 % in real large-scale network for a long time.", "labels": [0, 9]}
{"id": "2794", "token": "Network intrusion attempts have been on the rise recently. Researchers have shown an increased interest in assessing the security situation for entire network instead of single asset. A considerable amount of assessment models have been designed. However, there is a lack of solid and standard guidelines to define the importance of network asset. In addition, based on our knowledge, no research has been found that adequately covered the cost factor in the assessment model. Thus, the purpose of this paper is to propose a cost-sensitive entropy-based network security situation assessment model. With the aid of Analytic Hierarchy Process (AHP), the model can quantitatively determine the importance of assets in the network by considering the tangible and intangible criteria. To verify the performance of proposed model, a simulation of National Advanced IPv6 Centre (NAv6)'s network environment has been setup. The simulation results regarding security situation in particular time-interval are promising. Hence, the proposed model is able to provide network administrator a more reliable reference before any further decision making for the organization's network.", "labels": [0, 9]}
{"id": "2905", "token": "Network intrusion detection systems (NIDSs) have been developed for over twenty years and have been widely deployed in computer networks to detect a variety of network attacks. But one of the major limitations is that these systems would generate a large number of alarms, especially false alarms (positives) during the detection. To address this issue, many machine learning approaches have been applied to reduce NIDS false positives. However, we notice that multi-view based approach is often ignored by the literature, which uses one function to model a particular view and jointly optimizes all the functions to optimize and improve the learning performance. In addition, most existing studies have not implemented their algorithms into practical alam systems. In this paper, we thus develop MVPSys, a practical multi-view based false alarm reduction system to reduce false alarms more efficiently, where each view represents a set of features. More specifically, we implement a semi-supervised learning algorithm to construct two-view items and automatically exploit both labeled and unlabeled data. That is, this system can automatically extract and organize features from an incoming alarm into two feature sets: destination feature set and source feature set, where the former contains the features related to the target environment and the latter contains the features about the source environment. In the evaluation, we deploy our system into two real network environments besides using two datasets. Experimental results indicate that our system can achieve a stable filtration accuracy of over 95%, offering a significant improvement as compared with the state-of-the-art algorithms. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [0, 9]}
{"id": "2986", "token": "This paper presents a new approach to infer worldwide malware-infected machines by solely analyzing their generated probing activities. In contrary to other adopted methods, the proposed approach does not rely on symptoms of infection to detect compromised machines. This allows the inference of malware infection at very early stages of contamination. The approach aims at detecting whether the machines are infected or not as well as pinpointing the exact malware type/family. The latter insights allow network security operators of diverse organizations, Internet service providers and backbone networks to promptly detect their clients' compromised machines in addition to effectively providing them with tailored anti-malware/patch solutions. To achieve the intended goals, the proposed approach exploits the darknet Internet space and initially filters out misconfiguration traffic targeting such space using a probabilistic model. Subsequently, the approach employs statistical methods to infer large-scale probing activities as perceived by the dark space. Consequently, such activities are correlated with malware samples by leveraging fuzzy hashing and entropy based techniques. The proposed approach is empirically evaluated using a recent 60 GB of real darknet traffic and 65 thousand real malware samples. The results concur that the rationale of exploiting probing activities for worldwide early malware infection detection is indeed very promising. Further, the results, which were validated using publically available data resources, demonstrate that the extracted inferences exhibit noteworthy accuracy and can generate significant cyber security insights that could be used for effective mitigation. (C) 2015 Elsevier B.V. All rights reserved.", "labels": [0, 9]}
{"id": "3118", "token": "Intrusion detection system (IDS) is one of the important elements for providing the security in networks. Increasing the number of network-based applications on the one hand and increasing the data volumes on the other hand forced the designers to conduct some research on the novel methods for improving network security. One of the recent efforts to improve IDS performance is developing the machine learning algorithms. Random forest is one of the powerful algorithms employed in data mining. It operates based on classifier fusion principles and is implemented as detection engine in some anomaly-based IDSs. In this paper, we present a novel parallel random forest algorithm for intrusion detection systems. The original random forest algorithm has some weaknesses in feature selection, selecting efficient numbers of classifiers, number of random features for training and also in combination steps. In this research we investigate aforementioned challenges and propose solutions for them. The simulation results show the superiority of our method regarding performance, scalability and cost of misclassified samples in our method in comparison with the original random forest algorithm and Hadoop-based version of the random forest.", "labels": [0, 9]}
{"id": "3200", "token": "With the rapid development of the Internet, especially the development of mobile Internet, network size and network infrastructure changes, especially the more random access node to detect network attacks challenges traditional detection algorithm using neural networks, so that the calculated volume increased dramatically, and will detection accuracy is not high, for this problem, we use the stochastic process theory hidden Markov chain transformation neural network, so that the convergence of a substantial decline, while improving network attack detection accuracy degree.", "labels": [0, 9]}
{"id": "3255", "token": "Software Defined Networking (SDN) has recently emerged to become one of the promising solutions for the future Internet. With the logical centralization of controllers and a global network overview, SDN brings us a chance to strengthen our network security. However, SDN also brings us a dangerous increase in potential threats. In this paper, we apply a deep learning approach for flow-based anomaly detection in an SDN environment. We build a Deep Neural Network (DNN) model for an intrusion detection system and train the model with the NSL-KDD Dataset. In this work, we just use six basic features (that can be easily obtained in an SDN environment) taken from the fortyone features of NSL-KDD Dataset. Through experiments, we confirm that the deep learning approach shows strong potential to be used for flow-based anomaly detection in SDN environments.", "labels": [0, 9]}
{"id": "3450", "token": "Network structures and human behaviors are considered as two important factors in virus defense currently. However, due to ignorance of network security, normal users usually take simple activities, such as reinstalling computer system, or using the computer recovery system to clear virus. How system recovery influences virus spreading is not taken into consideration currently. In this paper, a new virus propagation model considering the system recovery is proposed first, and then in its steady-state analysis, the virus propagation steady time and steady states are deduced. Experiment results show that models considering system recovery can effectively restrain virus propagation. Furthermore, algorithm with system recovery in BA scale-free network is proposed. Simulation result turns out that target immunization strategy with system recovery works better than traditional ones in BA network.", "labels": [0, 9]}
{"id": "5", "token": "This paper presents a proof of concept from which the metaphor of fair trade is validated as an alternative to manage the private information of users. Our privacy solution deals with user's privacy as a tradable good for obtaining environmental services. Thus, users gain access to more valuable services as they share more personal information. This strategy, combined with optimistic access control and transaction registry mechanisms, enhances users' confidence in the system while encouraging them to share their information, with the consequent benefit for the community. The study results are promising considering the user responses regarding the usefulness, ease of use, information classification and perception of control with the mechanisms proposed by the metaphor.", "labels": [4, 25]}
{"id": "60", "token": "In recent years, users of ambient intelligence environments have been overwhelmed by the huge numbers of social media available. Consequentially, users have trouble finding social media suited to their needs. To help users in ambient environment get relevant media tailored to their interests, we propose a new method which adapts the Katz measure, a path-ensemble based proximity measure, for the use in social tagging services. We model the ternary relations among user, resource and tag as a weighted, undirected tripartite graph. We then apply the Katz measure to this graph, and exploit it to provide personalized recommendation for individual users within ambient intelligence environments. The experimental evaluations show that the proposed method improves the recommendation performance compared to existing algorithms.", "labels": [4, 25]}
{"id": "210", "token": "The Ambient Intelligence (AmI) paradigm applied to the healthcare sector is a promising solution to develop software-based systems capable of supporting medical procedures and activities carried out in a close, high-regulated, and complex healthcare environment. An AmI Healthcare System (AmI-HS) which may impact on the health and life of its users (i.e. doctors, caregivers, patients, etc.) is considered as a Medical Device (MDs), and thus subject to pass through a cumbersome risk-based regulatory process which evaluates and certifies the system safety before it is put on the market. Thus, a human-centred risk analysis is of paramount importance to establish the safety level of an AmI-HS. In this paper, we propose a dynamic probabilistic risk assessment (DPRA) approach for AmI-HS which allows the quantitative assessment of risk in different hazard scenarios in order both to support the design and development of AmI-HSs and to provide those objective evidences needed during the regulatory process. In addition, to support our risk-based methodology we define a probabilistic risk model (PRM), based on an extension of a Markov Decision Process (MDP), capable of taking into account two main peculiarities of AmI-HSs: context-awareness and personalisation. Some preliminary results show the feasibility of our approach and the capability of our model to assess risk of context-aware hazard scenarios.", "labels": [4, 25]}
{"id": "238", "token": "One application of Ambient Intelligence (AmI) that supports people in their daily activities is the smart home, which has become a popular topic for research over the past 10 years. The smart home can support the inhabitant in a variety of ways, such as watching for potential risks, detecting any abnormality, adapting the home for environmental conditions and inducing behavioural change. This often requires the smart home to recognise the behaviours of the inhabitant. In this paper, we introduce a method that can accurately recognise the inhabitant's behaviours. This includes both the segmentation of the sensor stream and the identification of behaviours. We demonstrate our algorithm on sensor data from real smart homes.", "labels": [4, 25]}
{"id": "565", "token": "In this paper, we present a complete overview of Ambient Intelligence (AmI) focused in its applications, considering the involved domain and technologies. The applications include AmI at home, care of elderly and people with disabilities, healthcare, education, business, public services, leisure and entertainment. The aim of this survey of AmI's applications is to show its socials and ethical implications and specially privacy issues. Intelligent Environments (IE) collect and process a massive amount of person-related and sensitive data. These data must ensure privacy of the users. An important concern in AmI's applications is privacy. Addressing design by privacy, an important challenge to consider is the development of an architecture that includes the different privacy policies and how can we fusion them in a specific application domain. Ensuring privacy in Intelligent Environments is a difficult problem to solve, as there are different perceptions of privacy and its role in computing for each user. In the so called 'design by privacy' we have to identify the relevant design issues that should be addressed for its developing. Here we present an approach to the dimensions to consider, in order to provide privacy in the design of Ambient Intelligence's applications.", "labels": [4, 25]}
{"id": "687", "token": "Ambient Intelligence promises to transform current spaces into electronic environments that are responsive, assistive and sensitive to human presence. Those electronic environments will be fully populated with dozens, hundreds or even thousands of connected devices that share information and thus become intelligent. That massive wave of electronic devices will also invade everyday objects, turning them into smart entities, keeping their native features and characteristics while seamlessly promoting them to a new class of thinking and reasoning everyday objects. Although there are strong expectations that most of the users' needs can be fulfilled without their intervention, there are still situations where interaction is required. This paper presents work being done in the field of human-computer interaction, focusing on smart home environments, while being a part of a larger project called Aging Inside a Smart Home. This initiative arose as a way to deal with a large scourge of our country, where lots of elderly persons live alone in their homes, often with limited or no physical mobility. The project relies on the mobile agent computing paradigm in order to create a Virtual Butler that provides the interface between the elderly and the smart home infrastructure. The Virtual Butler is receptive to user questions, answering them according to the context and knowledge of the AISH. It is also capable of interacting with the user whenever it senses that something has gone wrong, notifying next of kin and/or medical services, etc. The Virtual Butler is aware of the user location and moves to the computing device which is closest to the user, in order to be always present. Its avatar can also run in handheld devices keeping its main functionality in order to track user when s/he goes out. According to the evaluation carried out, the Virtual Butler is assessed as a very interesting and loved digital friend, filling the gap between the user and the smart home. The evaluation also showed that the Virtual Butler concept can be easily ported to other types of possible smart and assistive environments like airports, hospitals, shopping malls, offices, etc.", "labels": [4, 25]}
{"id": "798", "token": "This paper proposes the use of an autonomous assistant mobile robot in order to monitor the environmental conditions of a large indoor area and develop an ambient intelligence application. The mobile robot uses single high performance embedded sensors in order to collect and geo-reference environmental information such as ambient temperature, air velocity and orientation and gas concentration. The data collected with the assistant mobile robot is analyzed in order to detect unusual measurements or discrepancies and develop focused corrective ambient actions. This paper shows an example of the measurements performed in a research facility which have enabled the detection and location of an uncomfortable temperature profile inside an office of the research facility. The ambient intelligent application has been developed by performing some localized ambient measurements that have been analyzed in order to propose some ambient actuations to correct the uncomfortable temperature profile.", "labels": [4, 25]}
{"id": "902", "token": "Ambient Intelligence is the vision of future in which environments support the people living in them. This environment is self-effacing, interconnected, adaptable, dynamic, embedded, and intelligent. The vision is to disappear the technology instead processors and sensors are integrated in everyday objects. To develop such an environment wherein technology is invisible to the user and environment directly communicates with the user. A completely interactive environment that could assists the users in every possible manner. In order to design and develop such an environment, there is a need to shift technology from machine to human communication to machine to machine communication (M2M). For such communication there is the requirement of real time data, energy and the decision making concepts which are considered as the main objectives that needs to be fulfilled. In this paper we present the major contribution of various researchers in this field. Further we have also discussed the major challenges and risks associated with such intelligent environment and a methodology to overcome with the challenges in AmI environment.", "labels": [4, 25]}
{"id": "976", "token": "The Ambient Intelligence (AmI) paradigm represents the vision of the next wave of computing. By relying on various computing and networking techniques, AmI systems have the potential to enhance our everyday lives in many different aspects. One area in which widespread application of this innovative paradigm promises particularly significant benefits is health care. The work presented here contributes to realizing such promise by proposing a functioning software application able to learn the behaviors and habits, and thereby anticipate the needs, of inhabitants living in a technological environment, such as a smart house or city. The result is a health care system that can actively contribute to anticipating, and thereby preventing, emergency situations to provide greater autonomy and safety to disabled or elderly occupants, especially in cases of critical illness.", "labels": [4, 25]}
{"id": "1112", "token": "Ambient intelligence (AmI) deals with a new world of ubiquitous computing devices, where physical environments interact intelligently and unobtrusively with people. AmI environments can be diverse, such as homes, offices, meeting rooms, schools, hospitals, control centers, vehicles, tourist attractions, stores, sports facilities, and music devices. In this paper, we present the design and implementation of a testbed for AmI using Raspberry Pi mounted on Raspbian OS. We analyze the performance of k-means clustering algorithm. For evaluation we considered respiratory rate and heart rate metrics. The simulation results show that the k-means clustering algorithm has a good performance.", "labels": [4, 25]}
{"id": "1234", "token": "Nowadays many organizations experience security incidents due to unauthorized access to information. To reduce the risk of such incidents, security policies are often employed to regulate access to information. Such policies, however, are often too restrictive, and users do not have the rights necessary to perform assigned duties. As a consequence, access control mechanisms are perceived by users as a barrier and thus bypassed, making the system insecure. In this paper, we draw a bridge between the social concept of conviviality and access control. Conviviality has been introduced as a social science concept for ambient intelligence and multi-agent systems to highlight soft qualitative requirements like user-friendliness of systems. To bridge the gap between conviviality and security, we propose a methodological framework for updating and adapting access control policies based on conviviality recommendations. Our methodology integrates and extends existing techniques to assist system designers in the derivation of access control policies from socio-technical requirements of the system, while taking into account the conviviality of the system. We illustrate our framework using the Ambient Assisted Living use case from the HotCity of Luxembourg.", "labels": [4, 25]}
{"id": "1359", "token": "Ambient Intelligence (AmI) is currently a perspective area of development intelligent systems that react on human presence, their behavior and AmI adapts to requirements based on contextual knowledge. The important issue in the study of AmI is thinking about context-aware preference. In the context of ubiquitous computing technologies there is not any access for users to the system at one point, but in different contexts. This creates need for context-sensitive preferences. The aim of context reasoning is getting new knowledge, so that systems or services were more intelligent. This process is not a trivial problem, so that we propose multidimensional view on context-aware knowledge for support of contextual reasoning. In this paper we introduce a new TCAP procedure for transformation context-aware preference through OLAP in the AmI. The OLAP technology enables us better analyzing contextual dependence on preferences and choosing relevant content for users in the AmI environment.", "labels": [4, 25]}
{"id": "1461", "token": "Assistive Technologies (AT) are an application area where several Artificial Intelligence techniques and tools have been successfully applied to support elderly or impeded people on their daily activities. However, approaches to AT tend to center in the user-tool interaction, neglecting the user's connection with its social environment (such as caretakers, relatives and health professionals) and the possibility to monitor undesired behaviour providing both adaptation to a dynamic environment and early response to potentially dangerous situations. In previous work we have presented COAALAS, an intelligent social and norm-aware device for elderly people that is able to autonomously organize, reorganize and interact with the different actors involved in elderly-care, either human actors or other devices. In this paper we put our work into context, by first examining what are the desirable properties of such a system, analysing the state-of-the-art on the relevant topics, and verifying the validity of our proposal in a larger context that we call AVICENA. AVICENA's aim is develop a semi-autonomous (collaborative) tool to promote monitored, intensive, extended and personalized therapeutic regime adherence at home based on adaptation techniques.", "labels": [4, 25]}
{"id": "1613", "token": "In Semantic Web applications, reasoning engines that are data intensive commonly materialise inferences to speed up processing at query time. However, in evolving systems, such as smart environments, semantic-based context aware systems (SCAS) [6] or social software with user-generated data, knowledge does not grow monotonically: newer facts may contradict older ones, knowledge may be deprecated, discarded or updated such that knowledge must sometimes be retracted. We are describing a technique to retract explicit and inferred statements, when some information becomes obsolete, as well as retracting any statement that would lead to get back the removed explicit statements. This technique is based on OWL justifications and is triggered whenever a knowledge base becomes inconsistent, such that the system stays in a consistent state all the time, in spite of uncontrolled evolution. We prove termination and correctness of the algorithm, and describe the implementation and evaluation of the proposal.", "labels": [4, 25]}
{"id": "1780", "token": "Social interactions play an important role in the overall well-being. Current practice of monitoring social interactions through questionnaires and surveys is inadequate due to recall bias, memory dependence and high end-user effort. However, sensing capabilities of smart-phones can play a significant role in automatic detection of social interactions. In this paper, we describe our method of detecting interactions between people, specifically focusing on interactions that occur in synchrony, such as walking. Walking together between subjects is an important aspect of social activity and thus can be used to provide a better insight into social interaction patterns. For this work, we rely on sampling smartphone accelerometer and Wi-Fi sensors only. We analyse Wi-Fi and accelerometer data separately and combine them to detect walking in synchrony. The results show that from seven days of monitoring using seven subjects in real-life setting, we achieve 99% accuracy, 77.2% precision and 90.2% recall detection rates when combining both modalities.", "labels": [4, 25]}
{"id": "1906", "token": "This paper presents a novel framework, called Bean, which aims to monitor, evaluate and enhance pre-school children's skills and abilities through playing in Ambient Intelligence environments. The framework includes: (i) a model of children development based on the ICF-CY model and the Denver - II assessment tool, aiming at early detection of children's potential developmental issues to be further investigated and addressed if necessary; (ii) a reasoning mechanism for the automated extraction of child development knowledge, based on interaction monitoring, targeted to model relevant aspects of child's developmental stage, maturity level and skills; (iii) content editing tools and reporting facilities for parents and therapists. The framework has been implemented in the context of an AmI environment for supporting children play in AmI, deploying a collection of augmented artifacts, as well as a collection of digital reproductions of popular games.", "labels": [4, 25]}
{"id": "2081", "token": "This paper addresses the need to enhance transparency in ambient intelligent environments by developing more natural ways of interaction, which allow the users to communicate easily with the hidden networked devices rather than embedding obtrusive tablets and computing equipment throughout their surroundings. Ambient intelligence vision aims to realize digital environments that adapt to users in a responsive, transparent, and context-aware manner in order to enhance users' comfort. It is, therefore, appropriate to employ the paradigm of computing with words (CWWs), which aims to mimic the ability of humans to communicate transparently and manipulate perceptions via words. One of the daily activities that would increase the comfort levels of the users (especially people with disabilities) is cooking and performing tasks in the kitchen. Existing approaches on food preparation, cooking, and recipe recommendation stress on healthy eating and balanced meal choices while providing limited personalization features through the use of intrusive user interfaces. Herein, we present an application, which transparently interacts with users based on a novel CWWs approach in order to predict the recipe's difficulty level and to recommend an appropriate recipe depending on the user's mood, appetite, and spare time. The proposed CWWs framework is based on linear general type-2 (LGT2) fuzzy sets, which linearly quantify the linguistic modifiers in the third dimension in order to better represent the user perceptions while avoiding the drawbacks of type-1 and interval type-2 fuzzy sets. The LGT2-based CWWs framework can learn from user experiences and adapt to them in order to establish more natural human-machine interaction. We have carried numerous real-world experiments with various users in the University of Essex intelligent flat. The comparison analysis between interval type-2 fuzzy sets and LGT2 fuzzy sets demonstrates up to 55.43% improvement when general type-2 fuzzy sets are used than when interval type-2 fuzzy sets are used instead. The quantitative and qualitative analysis both show the success of the system in providing a natural interaction with the users for recommending food recipes where the quantitative analysis shows the high statistical correlation between the system output and the users' feedback; the qualitative analysis presents social science evaluation confirming the strong user acceptance of the system.", "labels": [4, 25]}
{"id": "2150", "token": "Purpose - This paper aims to describe the creation of innovative and intelligent systems to optimise energy efficiency in manufacturing. The systems monitor energy consumption using ambient intelligence (AmI) and knowledge management (KM) technologies. Together they create a decision support system as an innovative add-on to currently used energy management systems. Design/methodology/approach - Energy consumption data (ECD) are processed within a service-oriented architecture-based platform. The platform provides condition-based energy consumption warning, online diagnostics of energy-related problems, support to manufacturing process lines installation and ramp-up phase and continuous improvement/optimisation of energy efficiency. The systems monitor energy consumption using AmI and KM technologies. Together they create a decision support system as an innovative add-on to currently used energy management systems. Findings - The systems produce an improvement in energy efficiency in manufacturing small-and medium-sized enterprises (SMEs). The systems provide more comprehensive information about energy use and some knowledge-based support. Research limitations/implications - Prototype systems were trialled in a manufacturing company that produces mooring chains for the offshore oil and gas industry, an energy intensive manufacturing operation. The paper describes a case study involving energy-intensive processes that addressed different manufacturing concepts and involved the manufacture of mooring chains for offshore platforms. The system was developed to support online detection of energy efficiency problems. Practical implications - Energy efficiency can be optimised in assembly and manufacturing processes. The systems produce an improvement in energy efficiency in manufacturing SMEs. The systems provide more comprehensive information about energy use and some knowledge-based support. Social implications - This research addresses two of the most critical problems in energy management in industrial production technologies: how to efficiently and promptly acquire and provide information online for optimising energy consumption and how to effectively use such knowledge to support decision making. Originality/value - This research was inspired by the need for industry to have effective tools for energy efficiency, and that opportunities for industry to take up energy efficiency measures are mostly not carried out. The research combined AmI and KM technologies and involved new uses of sensors, including wireless intelligent sensor networks, to measure environment parameters and conditions as well as to process performance and behaviour aspects, such as material flow using smart tags in highly flexible manufacturing or temperature distribution over machines. The information obtained could be correlated with standard ECD to monitor energy efficiency and identify problems. The new approach can provide effective ways to collect more information to give a new insight into energy consumption within a manufacturing system.", "labels": [4, 25]}
{"id": "2228", "token": "This paper introduces the architecture of an emotion-aware ambient intelligent and gerontechnological project named Improvement of the Elderly Quality of Life and Care through Smart Emotion Regulation. The objective of the proposal is to find solutions for improving the quality of life and care of the elderly who can or want to continue living at home by using emotion regulation techniques. A series of sensors is used for monitoring the elderlies' facial and gestural expression, activity and behaviour, as well as relevant physiological data. This way the older people's emotions are inferred and recognized. Music, colour and light are the stimulating means to regulate their emotions towards a positive and pleasant mood. Then, the paper proposes a gerontechnological software architecture that enables real-time, continuous monitoring of the elderly and provides the best-tailored reactions of the ambience in order to regulate the older person's emotions towards a positive mood. After describing the benefits of the approach for emotion recognition and regulation in the elderly, the eight levels that compose the architecture are described.", "labels": [4, 25]}
{"id": "2367", "token": "With the ever-growing prevalence of dementia, nursing costs are increasing, while the ability to live independently vanishes. Dem@Home is an ambient assisted living framework to support independent living while receiving intelligent clinical care. Dem@Home integrates a variety of ambient and wearable sensors together with sophisticated, interdisciplinary methods of image and semantic analysis. Semantic Web technologies, such as OWL 2, are extensively employed to represent sensor observations and application domain specifics as well as to implement hybrid activity recognition and problem detection. Complete with tailored user interfaces, clinicians are provided with accurate monitoring of multiple life aspects, such as physical activity, sleep, complex daily tasks and clinical problems, leading to adaptive non-pharmaceutical interventions. The method has been already validated for both recognition performance and improvement on a clinical level, in four home pilots.", "labels": [4, 25]}
{"id": "2576", "token": "This paper describes ImAtHome, an iOS application for smart home configuration and management. This application has been built over the framework HomeKit, made available in iOS, for communicating with and controlling home automation accessories. Attention has been put on the design of the interaction with such an application, in order to make the interaction style as much coherent as possible with iOS apps and supporting users without programming skills to unwittingly create event-condition action rules that, in other similar systems, are usually defined through if-then constructs. The results of a user test demonstrate that ImAtHome is easy to use and well accepted by end users of different age and background.", "labels": [4, 25]}
{"id": "2669", "token": "In this paper we explore how future smart environments can be given a sense of humor. Humor requires smartness. Entering witty remarks in a conversation requires understanding of the conversation, the conversational partner, the context and the history of the conversation. We can try to model interaction smartness and how to use it in creating not only witty remarks, but also to create humorous events. Smart sensors and actuators, embedded in our environments and our wearables allow us to make changes to a digitally enhanced physical environment. Witty remarks in language can have their counterpart in witty events in digital environments, including social media environments with their own communication characteristics. Sequential and parallel juxtapositions of incongruous and contrasting events invade our communication and, in addition, can be expected to emerge or to be created in digitally enhanced physical environments too, accidentally and intentionally.", "labels": [4, 25]}
{"id": "2780", "token": "We present EasyHouse, a system developed to allow people with disabilities and their family members to control their home environment (e.g., turn on/off a light, turn on/off the TV) using a smartphone. The user interface was designed to be adjustable to the needs of each user. The development of EasyHouse followed an iterative user-centered design approach. A paper-based low-fidelity prototype was built based on user requirements and from the first author's own experience as a researcher with cerebral palsy. After several design and evaluation iterations, a functional prototype has been evaluated in a real context with real users. Preliminary results indicate that the proposed system is suitable for both people with and without motor disabilities, and provides an adequate method for controlling home appliances when there is a family member with motor disabilities.", "labels": [4, 25]}
{"id": "2839", "token": "Compositionality is a property of natural language which is of prime importance: It enables humans to form and conceptualize potentially novel and complex ideas, by combining words. On the other hand, the symbol grounding problem examines the way meaning is anchored to entities external to language, such as sensory percepts and sensory-motor routines. In this paper we aim towards the exploration of the intersection of compositionality and symbol grounding. We thus propose a methodology for constructing empirically derived models of grounded meaning, which afford composition of grounded semantics. We illustrate our methodology for the case of adjectival modifiers. Grounded models of adjectively modified and unmodified colors are acquired through a specially designed procedure with 134 participants, and then computational models of the modifiers dark and light are derived. The generalization ability of these learnt models is quantitatively evaluated, and their usage is demonstrated in a real-world physical humanoid robot. We regard this as an important step towards extending empirical approaches for symbol grounding so that they can accommodate compositionality: a necessary step towards the deep understanding of natural language for situated embodied agents, such as sensor-enabled ambient intelligence and interactive robots.", "labels": [4, 25]}
{"id": "2942", "token": "Ambient intelligence environments are technologically augmented surroundings that aim to provide personalized services to the users based on their context. Identifying these services for the users has become an increasingly challenging task. The overwhelming number of services in the ambient environment has made the selection and management of services even more challenging. To address this problem, researchers have proposed several techniques, such as creating a user model and selecting services based on that model; applying rule-based approach to match the relevant services; utilizing a combination of user's profile, context, interaction history and service reputation to select the best services for the user, and so on. Most of these techniques obtain the preference of a user based on his/her own interaction and profile and do not consider the power of collaborative selection approach. In this paper, we propose to use the collaborative recommendation technique to select services for a user based on multiple users' interactions and profile. Accordingly, we demonstrate the potential of the proposed approach through preliminary experiment.", "labels": [4, 25]}
{"id": "3027", "token": "The Internet of Things is the natural continuity of the Ambient Intelligence where smart and ambient environments are built mainly by integrating a large number of interconnected smart objects (sensors, actuators, Smartphone, appliances, etc.) with heterogeneous capabilities abstracted as software services. These services can be composed on the fly and provided, all the time and everywhere, to assist users in their daily activities. A key issue in user-centered services composition is to intelligently and effectively discover and select the most relevant services that best match the users' requirements and closely meet the specified quality-of-service level. Monitoring seamlessly the provided services and enhancing their quality, is still a challenging issue due mainly to the dynamicity and uncertainty characterizing ambient environments. In this paper, we propose a new service-oriented, user-centered and event-aware Framework capable of performing services monitoring to handle automatically events that may occur in ambient environments. This monitoring is based on a dynamic services discovery and selection process to enhance self-adaptation to unpredicted changes, and ensure services continuity with best quality. The overall proposed Framework has been implemented and validated through a scenario dedicated to daily activity recognition in an Ambient-Assisted Living environment. In addition, the obtained performances from extensive tests show clearly the efficiency and feasibility of the proposed approach in the case of a large-scale environment.", "labels": [4, 25]}
{"id": "3215", "token": "This study provides a timely and flexible location-aware service (LAS) to mobile users in a dynamic environment. Few previous studies have examined similar concepts. In the proposed methodology, the inaccuracy of user positioning and the uncertainty of manual service preparation are considered and modeled by using fuzzy numbers. These numbers are used as inputs to establish a fuzzy integer-nonlinear programming model applied in identifying the most suitable service location and path. A required service is prepared immediately before a user reaches the recommended service location. To manage simultaneous requests from multiple users, the concepts of fuzzy modeling, route planning, and parallel machine scheduling are combined. Thus, the proposed LAS can distribute multiple users among service locations, thereby enabling users to avoid unnecessary waiting, which is a major problem associated with existing LASs. To assess the effectiveness of the proposed methodology, two experiments were conducted in small areas in Taichung City and Taipei City, Taiwan. The experimental results revealed that the waiting times of users were substantially reduced, increasing the average satisfaction level. However, improving the accuracy of user positioning does not necessarily facilitate achieving a high average satisfaction level. (C) 2015 Elsevier B.V. All rights reserved.", "labels": [4, 25]}
{"id": "3259", "token": "With rapid development of mobile technologies, people can easily obtain surrounding information through their mobile devices. Meanwhile, weather forecasting information is important for many people in the daily life. Most of current weather information systems only illustrate the basic weather information, such as the temperature and the precipitation probability, by a simple text-based or graphic-based presentation without involving too much environmental information. To integrate weather information with ambient intelligence, this paper aims at showing our implementation experience about how to realize our ambient mesoscale weather forecasting system (AMWFS). With an augmented reality presentation in the system, a more intuitive navigation interface provides users a new way of accessing weather information.", "labels": [4, 25]}
{"id": "3393", "token": "An improved solution for drug distribution is presented in this paper. It is divided into two parts: i) a multi-operator evolutionary algorithm in charge of calculating the initial delivery routes and ii) an ambient intelligence-based support system able to tracing the merchandise along the distribution route. The first one establishes the routes to be followed by the vehicles, based on a proposal of estimation of the travel times. The second one is formed by a system able to recognize and trace the drugs inside each vehicle. A laboratory experimentation has been conducted in order to demonstrate the adequacy of the route calculator. In addition, a field experimentation has been carried out by implementing the traceability system in a delivery van which of the drug distributor in the city of Bilbao. Note to Practitioners-Motivated by the specific needs found by a drug distributor in managing deliveries to pharmacies involved in its supply chain, this paper considers an optimization problem as the proper way to model the particularities found in this scenario. This paper proposes the use of a combinatorial optimization problem as the way to model problems. Due to the fact that distributor's clients are located in different cities, the proposal considers travel times both between cities and inside the city. In addition, rush hours are also taken into account, in order to provide a more realistic model. Finally, a radio frequency identification-based solution is proposed, in order to implement traceability in the delivered products, as well as to prevent human errors. Additionally, in case an unavoidable error occurs, the solution offers also an incident management mechanism.", "labels": [4, 25]}
{"id": "3480", "token": "Privacy in image and video data has become an important subject since cameras are being installed in an increasing number of public and private spaces. Specifically, in assisted living, intelligent monitoring based on computer vision can allow one to provide risk detection and support services that increase people's autonomy at home. In the present work, a level-based visualisation scheme is proposed to provide visual privacy when human intervention is necessary, such as at telerehabilitation and safety assessment applications. Visualisation levels are dynamically selected based on the previously modelled context. In this way, different levels of protection can be provided, maintaining the necessary intelligibility required for the applications. Furthermore, a case study of a living room, where a top-view camera is installed, is presented. Finally, the performed survey-based evaluation indicates the degree of protection provided by the different visualisation models, as well as the personal privacy preferences and valuations of the users.", "labels": [4, 25]}
{"id": "6", "token": "This paper presents a new hybrid-structure machine, which possesses the distinct merit of multimode fault-tolerant operation for driving Mars Rover. Namely, the proposed machine is designed with three operation modes, including Mode I for the normal operation, Mode II for the remedial field-excited operation, and Mode III for the remedial rotor operation. To obtain these operation modes, the machine design adopts the outer rotor structure with a segmented-iron ring and a special teeth-split inner stator. In this way, the proposed machine is capable of providing the desired torque output at low speeds under the normal or fault situations. Both the machine design principle and the corresponding results are given to verify the validity of the idea. Furthermore, the different combinations of the torque outputs under different operation modes for four-wheel motors of Mars Rover are analyzed and discussed.", "labels": [3, 23]}
{"id": "40", "token": "Although vibratory finishing machines have been widely employed in industry for over 50 years, modeling the vibratory excitation system of the machine has not been previously published. This paper proposes a novel mathematical model of the bowl type vibratory finishing machine. This model is used to analyze the dynamic behavior of the mechanical excitation system considering both free and forced vibrations. The influence of key parameters identified by the proposed model and their impact on machine performance is discussed. Furthermore, implications for machine design and process optimization are presented. Finally, validation of the developed model is presented through correlation of results obtained from the theoretical analysis with data from experimental tests. (C) 2015 CIRP.", "labels": [3, 23]}
{"id": "106", "token": "This study aims at presenting the process of machine design and agricultural implements by means of a reference model, formulated with the purpose of explaining the development activities of new products, serving as a guideline to coach human resources and to assist in formalizing the process in small and medium-sized businesses (SMB), i.e. up to 500 employees. The methodology used included the process modeling, carried out from case studies in the SMB, and the study of reference models in literature. The modeling formalism used was based on the IDEF0 standard, which identifies the dimensions required for the model detailing: input information; activities; tasks; knowledge domains; mechanisms; controls and information produced. These dimensions were organized in spreadsheets and graphs. As a result, a reference model with 27 activities and 71 tasks was obtained, distributed over four phases of the design process. The evaluation of the model was carried out by the companies participating in the case studies and by experts, who concluded that the model explains the actions needed to develop new products in SMB.", "labels": [3, 23]}
{"id": "201", "token": "The paper deals with the lack of qualified professionals, especially in the technical branches of industry, and the range of possibilities how to spread knowledge and know-how among students as well as working-age population. The Department of Machine Design of the University of West Bohemia has taken the first step to reach this goal we have created interactive learning materials using 10 projects taken from the real practice that should be primarily used by students of the University of West Bohemia. Currently, the materials are available to full-time students as well as students of hybrid courses. Nevertheless, there is a potential to offer these learning materials to general public and thus support the amount of qualified labour in engineering branches not only in West Bohemian region. There is also a prospect to create more learning materials from different branches (their choice should be made based on demand) which would support the quality of education regardless the original profession, age and handicap.", "labels": [3, 23]}
{"id": "350", "token": "Recently, Vernier permanent magnet (VPM) machines, one special case of magnetic flux-modulated (MFM) machines, benefiting from their compact, simple construction and low-speed/high-torque characteristics, have been receiving increasing interest. In this paper, the Vernier structure is integrated with an axial-flux PM machine to obtain the magnetic gear effect and produce an improved torque density for direct-drive wind power generation application. Another advantage of the proposed machine is that the stator flux rotating speed can be relatively high when the shaft speed is low. With this benefit, sensorless control strategy can be easily implemented in a wide speed range. In this paper, an improved sliding mode observer (SMO) is proposed to estimate the rotor position and the speed of the proposed machine. With the estimated shaft speeds, the maximum power point tracking (MPPT) control strategy is applied to maximize the wind power extraction. The machine design and the sensorless MPPT control strategy are verified by finite element analysis and experimental verification.", "labels": [3, 23]}
{"id": "479", "token": "This paper highlights a magnetic equivalent circuit model for wound rotor synchronous machine design. The model includes provisions to calculate the performance of machines with an arbitrary number of damper windings in either the q- or d- axis. The computational cost of the model is considered on several modern computing platforms. Its use within design allows for a comprehensive, accurate exploration of a design space on a timeline that is consistent with most commercial product development.", "labels": [3, 23]}
{"id": "534", "token": "Cross-sectional ovalization of thin-walled circular steel tube because of large plastic bending, also known as the Brazier effect, usually occurs during the initial stage of tube's continuous rotary straightening process. The amount of ovalization, defined as maximal cross section flattening, is an important technical parameter in tube's straightening process to control tube's bending deformation and prevent buckling. However, for the lack of special analytical model, the maximal section flattening was determined in accordance with the specified charts developed by experienced operators on the basis of experimental data; thus, it was inevitable that the localized buckling might occur during some actual straightening operations. New normal strain component formulas were derived based on the thin shell theory. Then, strain energy of thin-walled tube (per unit length) was obtained using the elastic-plastic theory. A rational model for predicting the maximal section flattening of the thin-walled circular steel tube under its straightening process was presented by the principle of minimum potential energy. The new model was validated by experiments and numerical simulations. The results show that the new model agrees well with the experiments and the numerical simulations with error of less than 10%. This new model was expected to find its potential application in thin-walled steel tube straightening machine design.", "labels": [3, 23]}
{"id": "611", "token": "This paper describes a computationally efficient approach for mapping rotor power loss in permanent magnet (PM) machines. The PM loss mapping methodology discussed here utilizes a small number of time-step finite-element analyses (FEAs) to determine the parameters of a functional representation of loss variation with speed (frequency) and stator current and is intended for a rapid evaluation of machine performance over the entire torque-speed envelope. The research focus is placed on field-oriented-controlled brushless AC PM machines with surface-mounted PM rotor construction, although the method could be adapted for other rotor formats. The loss mapping procedure accounts for the axial segmentation of the PM array through the use of an equivalent electrical resistivity of the segmented PM array, which is obtained from three-dimensional (3-D) FEA. The PM loss can be accurately mapped across the full operational envelope, including the field-weakened mode, through a single 3-D and four two-dimensional time-step FEAs. The proposed methodology is validated on an 18-slot 16-pole surface-mounted brushless AC PM machine design. The loss mapping procedure results closely agree with the computationally demanding alternative of direct 3-D finite-element prediction of the PM power loss undertaken at each of the machine's operating points.", "labels": [3, 23]}
{"id": "875", "token": "This paper details modeling to support the design of an air-core permanent-magnet-based energy-harvest system for use within an in-pipe mobile water-quality sensor. A challenge presented by this system is that the electrical and mechanical dynamics of the device are strongly coupled. Recently, a rigorous electrical/mechanical model was established to address this challenge in order to determine expected energy harvest, given the geometric/material parameters and electrical/mechanical inputs. An initial focus herein is the development of parameter measurement techniques for purposes of model validation. Subsequently, based upon hardware results, an alternative friction model is derived and utilized to explore the effect of friction on expected energy harvest.", "labels": [3, 23]}
{"id": "983", "token": "Analytical method based on magnetic equivalent circuits (MEC) is widely used for the preliminary machine design due to short calculation time and low computational cost, but the calculate result is normally considered to be not as accurate as finite element method (FEM). To address the MEC less accurate and FEM time-consuming challenge, a novel design and analysis procedure of permanent magnet synchronous generators (PMSGs) was proposed in this paper. The initial physical and electromagnetic features of PMSGs were presented by MEC at first design stages, the electromagnetic analyses were realized by FEM based on electromagnetic simulation software. The field-circuit coupled design method could facilitate accuracy and shorten time cycle of the generator design. Using RMxprt as simulation tool had realized the convenient and fast modeling, the parametric analysis of armature diameter, axial length, air gap and number of conductors per slots were carried out. The results show that the magnetic density distribution of the generators becomes better, and the efficiency is improved. The validity and applicability of the method is verified. Moreover, it will provide a basis for the further 3D optimization design of the generators.", "labels": [3, 23]}
{"id": "1198", "token": "To enable important scientific discoveries, ESO has defined a new ground-based telescope: the European Extremely Large Telescope (E-ELT). The baseline design features a telescope with a 39-m-class primary mirror (M1), making it the largest and most powerful telescope in the world. The M1 consists of 798 hexagonal segments, each about 1.4 m wide, but only 50 mm thick. In the last stages of the manufacturing process of these M1 segments, a nanometre-accurate metrology method is required for the M1 to be within specifications. The segments have to be measured on their whiffle-tree support structures with a nanometre-level uncertainty, with a total budget on form accuracy of 50 nm RMS for any segment assembly. In this paper a measurement machine design is presented based on a non-contact single-point scanning technique, capable of measuring with nanometre accuracy, being universal, fast and with low operational costs, providing suitable metrology for M1 segments. A tactile precision probe is implemented to be able to use the machine in earlier stages of the segment manufacturing process. In particular, this paper describes the design of the air-bearing motion system and the separate metrology system based on a moving Sintered Silicon Carbide tube, a fixed Zerodur metrology frame and an interferometric system for a direct and short metrology loop. Preliminary calculations show nanometre-level measurement uncertainty after calibration. (C) 2014 Elsevier Inc. All rights reserved.", "labels": [3, 23]}
{"id": "1349", "token": "To explore further, Modern telescopes are equipped with larger diameter mirror. Owing to deadweight and external force, it is difficult to maintain the position and attitude between primary mirror and mirror cell. Hydraulic supporting system is a optional choice to solve this problem, which requires high quality hydraulic oil and efficient oil filling. In this paper, the influence of gas content ( GC) on oil bulk modulus was discussed. Then an oil preconditioning and filling machine was designed. GC was detected using an oil particle size detecting instrument before and after preconditioning, and the result shows that GC decreases obviously from 0.1% to 0.002%. Oiling filling operation was also carried out on primary mirror test rig.", "labels": [3, 23]}
{"id": "1535", "token": "A synchronous reluctance motor (SynRelM) and a permanent magnet assisted synchronous reluctance motor (PM-assisted SynRelM) at a rated power level between 15 and 40 kW have been designed with the help of finite element analysis (FEA). Their performances levels are compared to an off-the-shelf inverter-fed variable speed squirrel cage induction motor (SCIM) and a surface mounted permanent magnet synchronous motor (SMPMSM), respectively. In the comparison the resulting average torque over the operating speed range and the torque ripple are investigated. Two prototypes have been fabricated and experimental measurements have been carried out to validate simulation data. It was identified that SynRelMs, especially assisted with permanent magnets (PMs), could compete with induction motors - and even PM synchronous motors (PMSMs) under certain operating conditions.", "labels": [3, 23]}
{"id": "1703", "token": "A magnetizer design methodology that takes into account systematic errors such as the variation in flux density (B), and the z-component of the magnetic field (H-z), is proposed. The effect of the sample diameter and the effective length of the yoke, i.e. yoke depth on H-z are analysed. Experimental results at 1.5 T and 60 H-z showed a reduction of 81 %, 72 % and 30 % by a large magnetizer, shielding and reducing the yoke depth from 80 mm to 10 mm, respectively. This was in comparison to an unshielded compact magnetizer. H-z is also dependent on magnetic loading. Furthermore, at 2 T and 60 Hz, magnetic contributions dominated H-z such that the effectiveness of shielding and reducing the yoke depth decreased to 27 % and 4 %, respectively. To achieve these very high flux densities, the magnetizers were designed to be compact (sample diameter of <= 100 mm and narrow airgaps of <= 2 mm). This reduction in size increases the leakage field above and below the sample to the same level of magnitude as the applied field, which affects the measurement of the magnetic field (H). Two H-coil sizes with a sensitivity difference of 60 % are used to show that the measured H is independent of the coil size, but depends on the leakage field. Their measured core loss difference under pulsating and rotating fields was about 6 %.", "labels": [3, 23]}
{"id": "1801", "token": "To restrain the influence of armature reaction, flux barriers is added to rotor structure and enhance the output power ability of brushless doubly-fed machine. Design scheme of brushless doubly-fed machine with barrier rotor is provided. Based on field-circuit coupled finite element method, The asynchronous operation performance of brushless doubly-fed machine with barrier rotor is studied under the condition of no-load, including adjusting voltage adjusting speed and series resistance adjusting voltage. The prototype is carried out on the condition of no-load asynchronous operation; comparison analysis of simulation speed values and tested speed values is realized. The designed machine is reasonable and reliable.", "labels": [3, 23]}
{"id": "1898", "token": "This paper deals with the characterization and construction of a rotating brushless PM exciter intended for synchronous generator excitation purposes. Traditionally, PM exciters are used as pre-exciters in synchronous generator excitations systems. In order to reduce the number of components and to increase the step time response of the system, a PM exciter is designed as an outer pole PM machine, with permanent magnets on the stator and armature windings on the rotor. The exciter was constructed electrically and mechanically to be fitted into an in-house synchronous generator test setup. A finite element model of the exciter was validated with no-load measurements of voltages and magnetic flux densities. The exciter was then characterized with unsaturated and saturated parameters.", "labels": [3, 23]}
{"id": "1951", "token": "Electric machines and their corresponding power electronic drives are key components of electric/hybrid electric vehicle (EV/HEV) powertrains. Thus, computationally-efficient models for electric machines and drives are essential for powertrain-level design, simulation, and optimization. In this paper, a finite-element-based method for quickly generating torque-speed curves and efficiency maps for electric machines and drives is presented. First, magneto-static finite element analysis (FEA) is conducted on a base machine design. This analysis produces normalized torque, flux linkage, current, and losses for the operating points of interest. These values are then adjusted based upon changing the size of the machine and the effective number of turns of the machine windings to quickly generate a variety of new machine designs and their corresponding efficiency maps. Results suggest that the proposed techniques can be useful for EV/HEV powertrain design and optimization.", "labels": [3, 23]}
{"id": "1998", "token": "Both an accurate machine design and an adequate metrology loop definition are critical factors when precision positioning represents a key issue for the final system performance. This article discusses the error budget methodology as an advantageous technique to improve the measurement accuracy of a 2D-long range stage during its design phase. The nanopositioning platform NanoPla is here presented. Its specifications, e.g., XY-travel range of 50 mm x 50 mm and sub-micrometric accuracy; and some novel designed solutions, e.g., a three-layer and two-stage architecture are described. Once defined the prototype, an error analysis is performed to propose improvement design features. Then, the metrology loop of the system is mathematically modelled to define the propagation of the different sources. Several simplifications and design hypothesis are justified and validated, including the assumption of rigid body behavior, which is demonstrated after a finite element analysis verification. The different error sources and their estimated contributions are enumerated in order to conclude with the final error values obtained from the error budget. The measurement deviations obtained demonstrate the important influence of the working environmental conditions, the flatness error of the plane mirror reflectors and the accurate manufacture and assembly of the components forming the metrological loop. Thus, a temperature control of +/- 0.1 degrees C results in an acceptable maximum positioning error for the developed NanoPla stage, i.e., 41 nm, 36 nm and 48 nm in X-, Y- and Z-axis, respectively.", "labels": [3, 23]}
{"id": "2151", "token": "In two-pole Induction Machines the shaft leads to a fictitious increase of the inner yoke in the rotor. This effect is influenced by axial cooling vents in the rotor. Pre-existing analytical calculation methods estimate the magnetic voltage drop in the rotor for only one path of the magnetic flux. This is done by simplified boundary conditions and leads to inaccurate results. In this paper a semi-analytical method is introduced. Therefore the branch current method is used and the solution of the nonlinear equation system is disclosed. The results of the analytical calculations are validated by Finite Element Analysis. The involvement of the semi-analytical calculation in the magnetic circuit is illustrated. Further refinement steps are described. Applications for the semi-analytical calculation method are introduced for machine design considerations.", "labels": [3, 23]}
{"id": "2276", "token": "This paper proposes a new type of curve, an elliptical roulette, which it initially applies to rotary lobe pumps. Once the new rotor profile has been mathematically modeled using the principle of gearing, equations can be derived to assess the presence or absence of undercutting in the tooth profile. The effect of the new profile properties on pumping performance is evaluated using a specially developed three-dimensional fluid analysis model. The proposed curve is tested using six novel rotor profiles based on the elliptical axial ratio parameter lambda (a shorter axis divided by a larger axis). These six new cases and a traditional case are analyzed under the same volume and clearance conditions and their differences compared. The results show that a smaller elliptical axial ratio design produces better flow characteristics. In particular, an elliptical axial ratio smaller than 0.6 not only achieves high discharge efficiency but allows vibration and noise to be controlled by the flow rate fluctuation coefficient, which approximates the traditional indicator. The proposed curve can thus serve as a useful reference for pump or rotary fluid machine design. (C) 2015 Elsevier Ltd. All rights reserved.", "labels": [3, 23]}
{"id": "2358", "token": "This paper presents various experimental tests on the sensorless capability of induction motors (IM). An intentionally created saliency is introduced in the rotor so as to allow the rotor position to be estimated by means of a high-frequency (HF) injected signal in the stator winding. Experimental measurements are carried out on three prototypes, two with saliency and the third without saliency, as reference. The critical aspects in the prototype realization are discussed in this paper. Suggestion on how to solve them from the machine design point of view is included. The rotor saliency has been measured by means of an HF injection. Then, the steady-state performance has been measured, together with the mechanical characteristic of the three prototypes. FE analysis is used to predict the variation of the IM parameters with rotor position. The results are compared with those achieved from measurements.", "labels": [3, 23]}
{"id": "2498", "token": "Currently, an interest in electric vehicles (EVs) exhibited by automakers, government agencies and customers make it as more attractive research. This is due to carbon dioxide emitted by conventional combustion engine that worsens the greenhouse effect nowadays. Since electric motors are the core of EVs, it is a pressing need for researchers to develop advanced electric motors. As one of the candidates, switched flux machine (SFM) is initiated in order to cope with the requirement. This paper proposes a new alternate circumferential and radial flux (A1CiRaF) of permanent magnet switched flux machines (PMSFM) for light weight electric vehicles. Firstly, AlCiRaF PMSFM is compared with the conventional PMSFM based on some design restrictions and specifications. Then the design refinements techniques are conducted by using deterministic optimization method in order to improve preliminary performance of machine. Finally the optimized machine design has achieved maximum torque and power of 47.43 Nm and 12.85 kW, respectively, slightly better than that of conventional PMSFM.", "labels": [3, 23]}
{"id": "2632", "token": "Non-salient permanent magnet machines are considered poor candidates for flux weakening operations due to their inherent low-inductance characteristics. In this paper, a two-pole 24-slot non-salient PM machine design is proposed that can utilize a winding switching technique to achieve wide speed range operation. A very wide speed range operation (from 3 to 1 ratio to as much as 13 to 1) is demonstrated. This is accomplished by simply rearranging the winding coils on the stator periphery. Moreover, a control strategy is proposed that not only utilizes the flux weakening using winding switching, but also flux weakening using a negative d-axis current to maximize the speed range of the machine. The machine is operated with two inverters to control the current in the machine winding over the entire speed range. A dq model for the machine is also presented. Analytical, simulated, and experimental results are provided to validate the proposed machine drive system.", "labels": [3, 23]}
{"id": "2867", "token": "Hydropower has long been recognized as a renewable power source. Due to economic reasons, high and medium head potentials have been primarily developed. Later, low-head potentials became a feasible solution with the application of modern Bulb generators. Although Bulb generators have been developed and applied since the 1930s, new techniques and materials have been used to overcome technical and design challenges, which are described herein.", "labels": [3, 23]}
{"id": "2985", "token": "Inspired by the matrix-based methods used in feature extraction and selection, one matrix-pattern-oriented classification framework has been designed in our previous work and demonstrated to utilize one matrix pattern itself more effectively to improve the classification performance in practice. However, this matrix-based framework neglects the prior structural information of the whole input space that is made up of all the matrix patterns. This paper aims to overcome such flaw through taking advantage of one structure learning method named Alternative Robust Local Embedding (ARLE). As a result, a new regularization term R-gl is designed, expected to simultaneously represent the globality and the locality of the whole data domain, further boosting the existing matrix-based classification method. To our knowledge, it is the first trial to introduce both the globality and the locality of the whole data space into the matrixized classifier design. In order to validate the proposed approach, the designed Rgi is applied into the previous work matrix-pattern-oriented Ho-Kashyap classifier (MatMHKS) to construct a new globalized and localized MatMHKS named GLMatMHKS. The experimental results on a broad range of data validate that GLMatMHKS not only inherits the advantages of the matrixized learning, but also uses the prior structural information more reasonably to guide the classification machine design. (C) 2014 Elsevier B.V. All rights reserved.", "labels": [3, 23]}
{"id": "3104", "token": "Scaling laws are used when the size of a certain machine design with known performance needs to be adjusted for a new application with known requirements, or when a machine design is geometrically scaled and one needs to determine its performance. Scaling laws derived in this study allow one to quickly and accurately recalculate parameters of a geometrically scaled permanent magnet machine. They basically consist of two separate important scaling procedures: axial scaling and radial scaling. The third and inevitable scaling procedure is rewinding, which is used to adjust the winding for a required voltage level. Exact but simple analytical equations for the various parameters (torque, power, losses, mass, resistance, inductance, efficiency etc.) of the machine are derived using three independent scaling factors, one for each scaling procedure. Special attention is given to the inclusion of end-winding influence and three-dimensional permanent magnet loss effects. Algorithms for fast determination of winding parameters for a given voltage and fast determination of scaling factors for scaling based on the torque requirement with stack length limitation are presented. All derived scaling equations are numerically validated using two state-of-the-art motor design software packages with automated extraction of parameters based on finite-element calculations.", "labels": [3, 23]}
{"id": "3135", "token": "For a multi-objective optimization problem applied to the electric machine design, a new robust surrogate-assisted algorithm is proposed in this research. The proposed algorithm can find a robust and well-distributed Pareto front set rapidly and precisely for robust nondominated solutions by using a kriging surrogate model and an uncertainty consideration with worst case scenario. The outstanding performances of the proposed algorithm are verified by a test function. Furthermore, through the application of the optimal design process of the interior permanent magnet synchronous motor, the feasibility of this algorithm is verified.", "labels": [3, 23]}
{"id": "3226", "token": "The Ignitor Program maintains the objective of approaching D-T ignition conditions by incorporating systematical advances made with relevant high field magnet technology and with experiments on high density well confined plasmas in the present machine design. An additional objective is that of charting the development of the high field line of experiments that goes from the Alcator machine to the ignitor device. The rationale for this class of experiments, aimed at producing poloidal fields with the highest possible values (compatible with proven safety factors of known plasma instabilities) is given. On the basis of the favourable properties of high density plasmas produced systematically by this line of machines, the envisioned future for the line, based on novel high field superconducting magnets, includes the possibility of investigating more advanced fusion burn conditions than those of the D-T plasmas for which Ignitor is designed. Considering that a detailed machine design has been carried out (Coppi et al 2013 Nucl. Fusion 53 104013), the advances made in different areas of the physics and technology that are relevant to the Ignitor project are reported. These are included within the following sections of the present paper: main components issues, assembly and welding procedures; robotics criteria; non-linear feedback control; simulations with three-dimensional structures and disruption studies; ICRH and dedicated diagnostics systems; anomalous transport processes including self-organization for fusion burning regimes and the zero-dimensional model; tridimensional structures of the thermonuclear instability and control provisions; superconducting components of the present machine; envisioned experiments with high field superconducting magnets.", "labels": [3, 23]}
{"id": "3419", "token": "Search Engines are based on bivalent logic and probability theory with lack of real world conceptual knowledge, higher precision and reasoning ability. Ranked links or snippets are less effective with big data Analysis and web of information. State of art Search Engine Google endeavor to retrieve good quality document, Msn Engine i.e. Bing endeavor decision boosting. Advanced algorithms account in user intents semantics and societal patterns on Web with recommendation system as product (recommendation Engines). Search engines have advanced from Text based to voice based (Dialogue based) to Image based (multimedia as input Question to search). Major advancement analysis of search Engine Enhancement, search Engines have advanced from traditional data base retrieval machine to web based machines from horizontal engines to Vertical Engines (Naukari.com, Quickr.com) with dedicated crawler Technology at heart. Information of web is structured instructed and posses a huge challenge to big data analytics. All though Retrieval results are optimistic yet they Lack in ability to interpret user Question. Precise answering from relevant Informatics is Search Engine Enhancement. Time complexity and memory are Algorithmic and Machine design parameters that support optimized search result. Question Answering Search Engine (QA Engine) is machine with deductive reasoning capability ability to amalgamate information from various knowledge datasets. QA Engine is front linear area in advanced information retrieval techniques, state of art technology to future of search engines, expert systems. QA search engines have advanced from Shallow Technique (keyword technique) to template based Structured Knowledge processing Engines, profile based engines, and context based machines to cross language machines to Multimedia QA Engines. Community based QA Yahoo answer, stack overflow to specialized search engines like ask.com, qura.com, true knowledge. Question Answering system have been embedded in Google Search Engine(Google Question Answering). IBM's Watson, a cognitive machine Thinking machine like Humans is decision support Engine developed under Deep QA project with advanced Natural language processing Information Retrieval with deep mining, a machine learning model that learns over time with reasoning model at base. With advent of android platform web based services like Apple Siri, Android Assistant questioner technology is art that assists. Enhancement future search engines with analysis (thinking), cognitive ability. This manuscript I present in Architecture on Question answering Search Engine that is search Engine Enhancement with Finite State Machine which facilitate answering question to time complexity The abstract, methodology, algorithmic analysis, of 20 research paper facilitate a future research and integration of proposed Architecture of Question Answering Search Engine.", "labels": [3, 23]}
{"id": "3466", "token": "For the characteristic of compact structure, low inertia, high rigidness and accuracy, parallel mechanisms are worthwhile to be popularized in the field of agricultural robotization, especially in situations that require precise movement in limited space. Focusing on the harvesting task of strawberries in ridge culture, a 4-PPPR robot manipulator with three translational DOF and one rotational DOF is devised in this paper. A type synthesis method of G(F) set theory is used to design its topology structure in 3D space. Compared to traditional machine design methods, this synthesis method allow one to decide the manipulator's configuration in a Topdown logic initially from the appointed features of the manipulator's moving platform. A software simulation is carried out to demonstrate this mechanism can meet all the movement requirements by driving the four active joints allocated on the fixed platform.", "labels": [3, 23]}
{"id": "7", "token": "Objective To describe the communication techniques used by clients and veterinarians during companion animal visits in Australia. Design A cross-sectional descriptive study. Methods A total of 64 veterinary consultations were audiotaped and analysed with the Roter Interaction Analysis System (RIAS); clients completed appointment level measures, including their satisfaction and perceptions of relational communication. Results Participants were 24 veterinarians and 64 clients. Statements intended to reassure clients were expressed frequently in the consultations, but in 59% of appointments empathy statements were not expressed towards either the client or the patient. In 10% of appointments, veterinarians did not used any open-ended questions. Overall client satisfaction was high and veterinarians' expressions of empathy directed to the client resulted in higher levels of client satisfaction. Clients' perceptions of relational communication were related to several veterinarian and client nonverbal scales. Conclusions A focus on developing evidence-based clinical communication skills is expected to further enhance the veterinarian-client-patient relationship and associated clinical outcomes. Particular recommendations include the development of a broader emotion-handling repertoire, increased emphasis on the use of open-ended enquiry, including assessment of the client's perspective, as well as attention to aspects of nonverbal communication. The study provides preliminary evidence for the importance of verbal expressions of empathy during the companion animal consultation.", "labels": [2, 18]}
{"id": "73", "token": "The purpose of this article is to elucidate a development problem of nonverbal means of communication as a condition of reflection formation in communication in children with speech underdevelopment. A research technique to characterise nonverbal encoding and decoding of nonverbal means of communication has been offered by the authors. Experimental study of nonverbal encoding and decoding is carried out, and also the analysis of the obtained experimental data is provided. (C) 2016 The Authors Published by Elseiver Ltd. This is an open access article under the CC BY-NC-ND license.", "labels": [2, 18]}
{"id": "296", "token": "Facial expression is an important channel for human nonverbal communication. This paper presents a novel and effective approach to automatic 3D/4D facial expression recognition based on the muscular movement model (MMM). In contrast to most of existing methods, the MMM deals with such an issue in the viewpoint of anatomy. It first automatically segments the input 3D face (frame) by localizing the corresponding points within each muscular region of the reference using iterative closest normal point. A set of features with multiple differential quantities, including coordinate, normal, and shape index values, are then extracted to describe the geometry deformation of each segmented region. Meanwhile, we analyze the importance of these muscular areas, and a score level fusion strategy is exploited to optimize their weights by the genetic algorithm in the learning step. The support vector machine and the hidden Markov model are finally used to predict the expression label in 3D and 4D, respectively. The experiments are conducted on the BU-3DFE and BU-4DFE databases, and the results achieved clearly demonstrate the effectiveness of the proposed method.", "labels": [2, 18]}
{"id": "367", "token": "The knowledge and application of certain skills related to nonverbal communication have become very important for the military environment nowadays, especially due to the increasing number of troops deployed in unfamiliar cultural environments such as the Afghan theater of operations. Therefore, knowing how to interact with the local, prideful and conservative population can be an indisputable advantage. The paper approaches certain aspects of nonverbal behavior as a way of transmitting messages or attitudes within the Afghan culture. After defining specific subdivisions and concepts of the nonverbal communication (such as proxemics, kinesics, oculesics, haptics, vocalics, olfactics, chronemics etc) the paper also includes a case study, relevant for any combatant or civilian that may further be deployed to the untamed Afghanistan.", "labels": [2, 18]}
{"id": "396", "token": "This study conducted at one university in Guangzhou, mainly examined the English majors' pragmatic failure in both verbal and nonverbal communication and explores the possible causes from students' perspectives. Combination of quantitative method and qualitative method were employed in the research including testing, questionnaire, interviews and observation. The results indicate that the average pragmatic competence of the subjects is still in a poor level. They committed pragmatic failure not only in verbal communication but also in nonverbal one. The study explored the causes of the failures from learners' perspective and offered implications for further research.", "labels": [2, 18]}
{"id": "497", "token": "The purpose of this study is to understand the children's expression with verbal and nonverbal communication in the Autistic spectrum. We study the emotional readiness and the music therapeutic activities which exploit the elements of music. The method followed focused on the research field of special needs education. Assumptions on the parameters investigated in relation to communication: (a) the spontaneous interest to the other and (b) facilitating the access to music and games - cooperation activities with others in the classroom, in the school yard and with extension to family members. In the results, we found that communication in Accession elementary special education school can be significantly improved while the music therapeutic activities and the pedagogical practice recording high levels of interest in musical dance games. The conclusions showed that the content of personalised music therapist activities aimed Emotional Organisation can support communication techniques in children have little verbal communication.", "labels": [2, 18]}
{"id": "608", "token": "Eyes play an important role in expressing emotions in nonverbal communication. In the present study, emotional expression classification was performed based on the features that were automatically extracted from the eye area. First, the face area and the eye area were automatically extracted from the captured image. Afterwards, the parameters to be used for the analysis through discrete wavelet transformation were obtained from the eye area. Using these parameters, emotional expression analysis was performed through artificial intelligence techniques. As the result of the experimental studies, 6 universal emotions consisting of expressions of happiness, sadness, surprise, disgust, anger and fear were classified at a success rate of 84% using artificial neural networks.", "labels": [2, 18]}
{"id": "748", "token": "A communicative act that involves the presence of two or more persons always involves a nonverbal aspect. The focus of the article is on nonverbal situations as a basis for the evolution of belief narratives. This pre-narrative aspect has not received much attention in narrative research as most analyses are based on texts that already exist in verbalised form. However, on many occasions the basis for a belief narrative is a nonverbal act that has triggered its witness or re-narrator(s) to interpret it within the framework of vernacular belief. Hence, texts that contain a nonverbal part consist of two components: 1) description of a nonverbal occurrence; 2) its meaning/interpretation that is verbalised by the narrator within the framework of a topical belief tradition. By bringing examples from Estonian belief narratives, the author points out some models and patterns that leap to the eye in texts narrating about nonverbal occurrences (e.g. the context of described situations, the types and results of activities described, etc.). As a theoretical basis, works on communication theory and vernacular belief research are used.", "labels": [2, 18]}
{"id": "1002", "token": "Objective: Investigating the strategies that nurses use to watch the hospitalized elderly. Method: this is an exploratory study of qualitative nature. The research was conducted at a University Hospital with fifteen clinical nurses. To facilitate the data collection was used the interview technique. The empirical material was analyzed qualitatively, using the Technique of Content Analysis. Results: From the qualitative analysis emerged three themes: reception and individualized nursing care and respect for the autonomy of elderly patients; respect to beliefs, values, the privacy and identity of the elderly patient, recovery of verbal and nonverbal communication to the patient and his family. Conclusion: This study demonstrates the commitment of nurses participating in the research regarding the humanized nursing care directed to hospitalized elderly.", "labels": [2, 18]}
{"id": "1083", "token": "This paper presents a mixed reality (MR) system that results from the integration of a telepresence system and an application to improve collaborative space exploration. The system combines free viewpoint video with immersive projection technology to support nonverbal communication (NVC), including eye gaze, interpersonal distance, and facial expression. Importantly, these features can be interpreted together as people move around the simulation, maintaining a natural social distance. The application is a simulation of Mars, within which the collaborators must come to agreement over; for example, where the Rover should land and go. The first contribution is the creation of an MR system supporting contextualization of NVC. Two technological contributions are prototyping a technique to subtract a person from a background that may contain physical objects and/or moving images and a lightweight texturing method for multiview rendering, which provides balance in terms of visual and temporal quality. A practical contribution is the demonstration of pragmatic approaches to sharing space between display systems of distinct levels of immersion. A research tool contribution is a system that allows comparison of conventional authored and video-based reconstructed avatars, within an environment that encourages exploration and social interaction. Aspects of system quality, including the communication of facial expression and end-to-end latency are reported.", "labels": [2, 18]}
{"id": "1154", "token": "The ingredients of a betel chew are usually kept in a special box or bowl used exclusively for betel chewing. Tepak sirih reflects the life and value of the Malay community especially on traditional customs and codes of conduct. It is obvious that Tepak sirih plays an important role in the everyday life of the Malays. However, as time passes, the importance of Tepak sirih is now only confined to ceremonial and traditional events and activities. Only decorated and embroidered Tepak sirih are used in ceremonies such as visit and observe (adat merisik), proposal (adat meminang) and engagement (adat bertunang). This study identifies and examines the role of Tepak sirih as a nonverbal communication in the marriage customs of the Malay community. This study was conducted at Kampung Seri Kedah, Sungai Leman, Sekinchan Selangor. The finding has shown that Tepak sirih used in a Malay wedding is seen as a symbol of opening of a conversation, symbol of asking, symbol of accepting, symbol of rejecting, and symbol of unity. Tepak sirih is placed in front of other items used in a wedding. In a Malay wedding, only Tepak sirih bertekad which is made from wood and embroidered is used. The interior of the Tepak sirih holds small globular covered boxes (cembul), a little cylindrical container for sliced areca nut, lime, gambier and cloves. All the cembul then must be placed according to the Malay customs. Furthermore, the Malay community believe that something bad may occur if the customs are not followed. In addition, arranging cembul in tepak is seen as a sign to educate the Malay community about the importance of following rules. During engagement (adat bertunang) tepak sirih plays is seen as a symbol of acceptace to live together and also promises. Engagement is a tie of promise of a man and a woman before they get married (akad nikah).", "labels": [2, 18]}
{"id": "1280", "token": "Introduction: Gesture is integrally linked with language and cognitive systems, and recent years have seen a growing attention to these movements in patients with schizophrenia. To date, however, there have been no investigations of gesture in youth at ultra high risk (UHR) for psychosis. Examining gesture in UHR individuals may help to elucidate other widely recognized communicative and cognitive deficits in this population and yield new clues for treatment development. Method: In this study, mismatch (indicating semantic incongruency between the content of speech and a given gesture) and retrieval (used during pauses in speech while a person appears to be searching for a word or idea) gestures were evaluated in 42 UHR individuals and 36 matched healthy controls. Cognitive functions relevant to gesture production (i.e., speed of visual information processing and verbal production) as well as positive and negative symptomatologies were assessed. Results: Although the overall frequency of cases exhibiting these behaviors was low, UHR individuals produced substantially more mismatch and retrieval gestures than controls. The UHR group also exhibited significantly poorer verbal production performance when compared with controls. In the patient group, mismatch gestures were associated with poorer visual processing speed and elevated negative symptoms, while retrieval gestures were associated with higher speed of visual information-processing and verbal production, but not symptoms. Conclusions: Taken together these findings indicate that gesture abnormalities are present in individuals at high risk for psychosis. While mismatch gestures may be closely related to disease processes, retrieval gestures may be employed as a compensatory mechanism. (C) 2014 Elsevier B.V. All rights reserved.", "labels": [2, 18]}
{"id": "1363", "token": "The main aim of this paper is to identify the personal factors of the salesman, which are more relevant to achieving sales success. The second aim is to categorize the verbal and nonverbal communication in personal sales process, but it should taken in account the fact, that the every of those level can have different significant, for each person. And the last task of current research is to determine, if there are some differences between men and women perception of personal sales process. Data were collected during the research, which was conducted in the Czech Republic on more than 500 respondents. All respondents rated the personal factors of salesman and his verbal and nonverbal communication within 4 videos, which were played to respondents. The data from current research were analysed via factor analysis. The conceptual model of personal selling has been adapted for the Czech Republic, with regard to cross-cultural differences.", "labels": [2, 18]}
{"id": "1432", "token": "Autism, known as a spectrum disorder (ASD) is seen in early childhood or by three years of age. ASD is a neuro-developmental disorder characterized by deficits in social responsiveness, impairments in verbal and nonverbal communication. The purpose of this paper is to demonstrate the relevance of e-learning technology to the area of training the caregivers of autistic children. Our search focused on a number of data banks that contain numerous references to autism and home based treatment. Our results found only ten papers published since 2010 that met our criteria for inclusion. Six were demonstrations of e learning to teach caregivers and professionals the basics of applied behavior analysis and some techniques for skill training. The remainder of the studies fell into the telehealth category which involved direct communication between a professional and caregiver in the home. The studies suggest that home based service delivery is effective and offers both the social service system and parents considerable financial savings. The use of Web based platform (e learning and telehealth) is depicted as an aid to caregivers of autistic children. The need for more studies of the variables related to home based service delivery is noted.", "labels": [2, 18]}
{"id": "1570", "token": "Background The impact of changing non-verbal consultation behaviours is unknown. Aim To assess brief physician training on improving predominantly non-verbal communication. Design and setting Cluster randomised parallel group trial among adults aged >= 16 years attending general practices close to the study coordinating centres in Southampton. Method Sixteen GPs were randomised to no training, or training consisting of a brief presentation of behaviours identified from a prior study (acronym KEPe Warm: demonstrating Knowledge of the patient; Encouraging [back-channelling by saying 'hmm', for example]; Physically engaging [touch, gestures, slight lean]; Warm-up: cool/professional initially, warming up, avoiding distancing or non-verbal cut-offs at the end of the consultation); and encouragement to reflect on videos of their consultation. Outcomes were the Medical Interview Satisfaction Scale (MISS) mean item score (1-7) and patients' perceptions of other domains of communication. Results Intervention participants scored higher MISS overall (0.23, 95% confidence interval [CI] = 0.06 to 0.41), with the largest changes in the distress-relief and perceived relationship subscales. Significant improvement occurred in perceived communication/partnership (0.29, 95% CI = 0.09 to 0.49) and health promotion (0.26, 95% CI = 0.05 to 0.46). Non-significant improvements occurred in perceptions of a personal relationship, a positive approach, and understanding the effects of the illness on life. Conclusion Brief training of GPs in predominantly nonverbal communication in the consultation and reflection on consultation videotapes improves patients' perceptions of satisfaction, distress, a partnership approach, and health promotion.", "labels": [2, 18]}
{"id": "1686", "token": "This article draws an analogy between physical nonverbal gesture and the textual conventions of new and social media to argue that the vital nonverbal functions of face-to-face communication are not absent from digital media, but that communicative functions typically enacted nonverbally are transposed into new spaces of interaction afforded by synchronous and near-synchronous textual media. Digital and social media text is conversational text that fulfills the phatic needs of typical social interaction: 'keeping in touch' does not in any way constitute a cultural regression but represents the fundamental ground of human cognition, which is inescapably both social and technologically dependent. An analysis of examples from the popular microblogging service Twitter serves to illustrate the gestural functions of digital media text, including the enactment of mediated social 'spaces'. The closing section explores the theoretical implications for identity and agency of connecting embodied nonverbal communication to digital media communication that is all too often erroneously understood to be or implicitly approached as 'disembodied'.", "labels": [2, 18]}
{"id": "1818", "token": "This study investigates the influence of (1) viewing situations (solovs. group-viewing) and (2) interpersonal communication in a group-viewing situation on television entertainment. In a field study combining a survey and video observation, (1) entertainment of participants watching television alone or in a group, and (2) entertainment between different groups was compared. To assess interpersonal communication while watching television, group verbal and nonverbal communication behavior was recorded. Results suggest that the presence of others did not influence viewers' core enjoyment. Further, while the amount of nonverbal communication behavior did not affect viewers' core enjoyment, particular topics of conversation influenced specific enjoyment qualities, with conversations indicating involvement in the television show intensifying viewers' empathy, and conversations indicating emotional experiences while watching television decreasing viewers' suspense. Results are discussed regarding nonverbal and verbal mechanisms that underlie entertainment in different social conditions.", "labels": [2, 18]}
{"id": "1968", "token": "Nonverbal behavior plays an important role in any human-human interaction. Teaching-an inherently social activity-is not an exception. So far, the effect of nonverbal behavioral cues accompanying lecture delivery was investigated in the case of traditional ex-cathedra lectures, where students and teachers are co-located. However, it is becoming increasingly more frequent to watch lectures online and, in this new type of setting, it is still unclear what the effect of nonverbal communication is. This article tries to address the problem and proposes experiments performed over the lectures of a popular web repository (Videolectures). The results show that automatically extracted nonverbal behavioral cues (prosody, voice quality and gesturing activity) predict the ratings that Videolectures users assign to the presentations.", "labels": [2, 18]}
{"id": "2034", "token": "Background: Down syndrome is a common human genetic disorder caused by trisomy of chromosome 21. Individuals with Down syndrome can present with a range of health issues during their lives that may require imaging for diagnosis. Radiographers, therefore, play a significant role in the management and communication of Down syndrome patients' health. Purpose: This review identified patient-centered strategies that radiographers should use to provide quality imaging services for Down syndrome patients, who may have limited verbal ability and behavioral issues. Method: A systematic review using the established PRISMA guidelines was undertaken of current literature obtained through the Ovid and Scopus databases. A total of 189 articles were found, of which 41 were categorized and analyzed in detail. Findings: A high level of care for Down syndrome patients will require longer than usual procedures, and the patients will not respond well to being rushed or ignored. Down syndrome patients have difficulty verbalizing, yet they understand more than is often thought. Individuals may require increased imaging time to give them time to respond, especially to pain. Patients are at risk of injury with AAI or other pathologies, and caution should be taken with flexion and extension spine x-rays. Radiographs may reveal undisclosed physical abuse. Conclusion: Specific strategies with verbal and nonverbal communication help to facilitate communication, reduce anxiety and fear, and improve compliance with Down syndrome patients. Patients may require an increased level of care; increased imaging time; and allowing support people to be present during the examination process.", "labels": [2, 18]}
{"id": "2115", "token": "Behaviour is central to many fields, but metatheoretical definitions specifying the most basic assumptions about what is considered behaviour and what is not are largely lacking. This transdisciplinary research explores the challenges in defining behaviour, highlighting anthropocentric biases and a frequent lack of differentiation from physiological and psychical phenomena. To meet these challenges, the article elaborates a metatheoretical definition of behaviour that is applicable across disciplines and that allows behaviours to be differentiated from other kinds of phenomena. This definition is used to explore the phenomena of language and to scrutinise whether and under what conditions language can be considered behaviour and why. The metatheoretical concept of two different levels of meaning conveyed in human language is introduced, highlighting that language inherently relies on behaviours and that the content of what-is-being-said, in and of itself, can constitute (interpersonal) behaviour under particular conditions. The analyses reveal the ways in which language meaningfully extends human's behavioural possibilities, pushing them far beyond anything enabled by non-language behaviours. These novel metatheoretical concepts can complement and expand on existing theories about behaviour and language and contribute a novel piece of theoretical explanation regarding the crucial role that language has played in human evolution.", "labels": [2, 18]}
{"id": "2354", "token": "Intelligence from a human source, that is falsely thought to be true, is potentially more harmful than a total lack of it. In addition to the collection the veracity assessment of the gathered information is one of the most important phases of the process. Lie detection and veracity assessment methods have been studied widely but a comprehensive analysis of these methods' applicability is lacking. Multi Criteria Analysis was conducted to compare scientifically valid lie detection and veracity assessment methods in terms of accuracy, ease of use, time requirements, need for special equipment and unobtrusiveness. Results of the analysis showed that Studied Features of Discourse and Nonverbal Communication gained the highest ranking. They were assessed to be the easiest and fastest to apply, and to have required temporal and contextual sensitivity. Plausibility and Inner Logic, MACE and CBCA were also found to be useful, but with some limitations.", "labels": [2, 18]}
{"id": "2461", "token": "Objective: to investigate the effectiveness of the Micro Expression Training Tool (METT) and the Subtle Expression Training Tool (SETT) to help improve the non-verbal communication skills of medical students. Methods: In a randomized controlled trial, all participants were randomly allocated to either a training (n = 41) or control group (n = 41) and were pre-tested before education with METT and SETT at baseline. Then, training students took second tests after a 1-h class about interpreting micro and subtle expressions and control students took the second tests without the class. Results: METT pre-test scores were positively related with female gender, agreeableness, whereas SETT pre-test scores were negatively related with age and positively related with female gender. Mean METT score increases of 29.3% and mean SETT score increases of 36.2% were observed after training, whereas the control group achieved only a mean METT score increase of 11.0% at second testing. Increases in both test scores in the training group were significantly higher than in the control group. Conclusion: METT and SETT are effective, simple tools for improving the micro-and subtle-expression reading skills of medical students. Practice implications: METT and SETT can be effective for improving the non-verbal communication skills of medical students. (C) 2016 Elsevier Ireland Ltd. All rights reserved.", "labels": [2, 18]}
{"id": "2582", "token": "Sex parties are environments where men who have sex with men (MSM) have the opportunity to have sex with multiple partners over a brief period of time. Dim lighting and nonverbal communication are the characteristics of sex parties that make sexual communication more challenging. We report on qualitative data from 47 MSM who attended sex parties in New York City. Participants responded to distinct hypothetical scenarios involving the use of color-coded wristbands to communicate (1) condom use preferences, (2) sexual position (e.g., top, bottom), and (3) human immunodeficiency virus (HIV) status at sex parties. The majority had positive-to-neutral attitudes toward color-coded wristbands to indicate (1) condom use preference and (2) sexual position (70.8, 75.0 % HIV positive; 63.6, 81.8 %, HIV negative, respectively). These men cited that wristbands would facilitate the process of pursuing partners with similar interests while also avoiding the discomforts of verbal communication. In contrast, 41.7 % of HIV-positive and 50.0 % of HIV-negative men expressed unfavorable attitudes to using wristbands to communicate HIV status. These men cited the potential for HIV-status discrimination as well as suspicions around dishonest disclosure. Although participants were receptive to utilizing color-coded wristbands at sex parties to convey certain information, it may be unfeasible to use wristbands to communicate HIV status.", "labels": [2, 18]}
{"id": "2685", "token": "There remains conflict in the literature about the lateralisation of affective face perception. Some studies have reported a right hemisphere advantage irrespective of valence, whereas others have found a left hemisphere advantage for positive, and a right hemisphere advantage for negative, emotion. Differences in injury aetiology and chronicity, proportion of male participants, participant age, and the number of emotions used within a perception task may contribute to these contradictory findings. The present study therefore controlled and/or directly examined the influence of these possible moderators. Right brain-damaged (RBD; n = 17), left brain-damaged (LSD; n = 17), and healthy control (HC; n = 34) participants completed two face perception tasks (identification and discrimination). No group differences in facial expression perception according to valence were found. Across emotions, the RBD group was less accurate than the HC group, however RBD and LBD group performance did not differ. The lack of difference between RBD and LBD groups indicates that both hemispheres are involved in positive and negative expression perception. The inclusion of older adults and the well-defined chronicity range of the brain-damaged participants may have moderated these findings. Participant sex and general face perception ability did not influence performance. Furthermore, while the RBD group was less accurate than the LED group when the identification task tested two emotions, performance of the two groups was indistinguishable when the number of emotions increased (four or six). This suggests that task demand moderates a study's ability to find hemispheric differences in the perception of facial emotion. (C) 2014 Elsevier Inc. All rights reserved.", "labels": [2, 18]}
{"id": "2857", "token": "Objectives: The aim of the present study is to investigate the organization of Armstrong's nonverbal behavior in deceptive statements and in those statements in which deception is not proven. The final aim of this study is to show that T-pattern methodology can be a useful tool in research about doping behavior. Design: In this observational study we focused on Armstrong's micro-expressions (action units, gaze movements, head movements) drawing observational material from different videos excerpts where Armstrong made doping-related statements. A baseline of Armstrong's deceptive behavior was established by selecting three video samples from 2005 in which he fully denied ever having taken performance-enhancing drugs. They were compared to the interview conducted by Oprah Winfrey in January 2013, in which he admitted doping but denied the specific charges of bullying and corruption. Method: Our approach is based on the detection of statistically significant hierarchical sequences of behaviors in time, called T-patterns (temporal patterns). The algorithm, implemented in Theme software, determines whether apparently arbitrary events sequentially repeat, within a specified time interval, at a rate greater than that expected by chance. Results: Data analyses allowed identifying distinctive patterns for each of the two conditions. The baseline showed a very limited number of patterns, highlighting low level of complexity and the presence of stereotyped behaviors. In the Oprah video samples, the number and complexity of distinctive patterns was significantly higher, and most of them included gaze shifting behaviors. Conclusions: T-pattern methodology might be an effective strategy to detect nonverbal features of deception, integrated with more traditional and established practice, in order to improve anti-doping measures and fight this spreading phenomenon. (C) 2014 Elsevier Ltd. All rights reserved.", "labels": [2, 18]}
{"id": "3072", "token": "Objective: To determine the opinion of nursing faculty and a researcher on the effectiveness of non-verbal communication in the classroom. Methods: This descriptive study included 11 nursing professors filmed for 220 minutes. Fourteen aspects of non-verbal communication were evaluated. Opinions about the effectiveness of non-verbal communication are expressed as simple frequencies. Results: Professors identified 71.43% of postures (as coherent, good, effective, and adequate), 62.5% of facial expressions (efficient, positive, and reinforcing/following the speech), 83.33% of voice rhythms (effective, good, and adequate speed), 61.11% of physical energy levels (good rhythm, active, attentive, effective, adequate, and alert), and 78.95% of body postures (kept moving, standing, remaining on feet, using hand movements to illustrate points, attention focused on students, position close to students' desks). A less frequent inefficient non-verbal communication was seen among. Conclusion: Nursing professors' opinions on non-verbal communication in the classroom were general and non-specific, indicating inadequate application of non-verbal communication. Professors identified inefficient non-verbal communication behavior less often than did one of the current researchers.", "labels": [2, 18]}
{"id": "3260", "token": "This investigation explores the relationship between verbal and non-verbal communication and coexistence in school settings among 30 fourth grade students between the ages of 8 and 11 from a district school. The data collection methods used were the participant observation and the semi-structured interview. After analyzing the information recorded, it is shown that students identify the characteristics of verbal and non-verbal communication and link them to their social behavior at school; thus, the article acknowledges the importance of communication and coexistence habits learned at home and which, together with those acquired at school, become patterns that guide their behavior. This favors the understanding of coexistence processes in schools.", "labels": [2, 18]}
{"id": "3288", "token": "Temporary anaesthesia or analgosedation used for awake craniotomies carry substantial risks like hemodynamic instabilities, airway obstruction, hypoventilation, nausea and vomiting, agitation, and interference with test performances. We tested the actual need for sedatives and opioids in 50 patients undergoing awake craniotomy for brain tumour resection in eloquent or motoric brain areas when cranial nerve blocks, permanent presence of a contact person, and therapeutic communication are provided. Therapeutic communication was based on the assumption that patients in such an extreme medical situation enter a natural trance-like state with elevated suggestibility. The anaesthesiologist acted as a continuous guide, using a strong rapport, nonverbal communication, hypnotic suggestions, such as dissociation to a safe place, and the reframing of disturbing noises, while simultaneously avoiding negative suggestions. Analgesics or sedatives were at hand according to the principle as much as necessary, but not more than needed. No sedation was necessary for any of the patients besides for the treatment of seizures. Only two-thirds of the patients requested remifentanil, with a mean dosage of 96 mu g before the end of tumour resection and a total of 156 mu g. Hemodynamic reactions indicative of stress were mainly seen during nerve blockades and neurological testing. Postoperative vigilance tests showed equal or higher scores than preoperative tests. The main challenges for patients undergoing awake craniotomies include anxiety and fears, terrifying noises and surroundings, immobility, loss of control, and the feeling of helplessness and being left alone. In such situations, psychological support might be more helpful than the pharmacological approach. With adequate therapeutic communication, patients do not require any sedation and no or only low-dose opioid treatment during awake craniotomies, leaving patients fully awake and competent during the entire surgical procedure without stress. This approach can be termed awake-awake-awake-technique.", "labels": [2, 18]}
{"id": "3356", "token": "The quest of developing realistic facial animation is ever-growing. The emergence of sophisticated algorithms, new graphical user interfaces, laser scans and advanced 3D tools imparted further impetus towards the rapid advancement of complex virtual human facialmodel. Face-to-face communication being the most natural way of human interaction, the facial animation systems became more attractive in the information technology era for sundry applications. The production of computer-animated movies using synthetic actors are still challenging issues. Proposed facial expression carries the signature of happiness, sadness, angry or cheerful, etc. The mood of a particular person in the midst of a large group can immediately be identified via very subtle changes in facial expressions. Facial expressions being very complex as well as important nonverbal communication channel are tricky to synthesize realistically using computer graphics. Computer synthesis of practical facial expressions must deal with the geometric representation of the human face and the control of the facial animation. We developed a new approach by integrating blend shape interpolation (BSI) and facial action coding system(FACS) to create a realistic and expressive computer facial animation design. The BSI is used to generate the natural face while the FACS is employed to reflect the exact facial muscle movements for four basic natural emotional expressions such as angry, happy, sad and fear with high fidelity. The results in perceiving the realistic facial expression for virtual human emotions based on facial skin color and texture may contribute towards the development of virtual reality and game environment of computer aided graphics animation systems. Graphical Abstract Realistic facial expressions of avatar. [GRAPHICS]", "labels": [2, 18]}
{"id": "3543", "token": "Introduction: This article is part of the Focus Theme of Methods of Information in Medicine on Pervasive Intelligent Technologies for Health. Background: Effective nonverbal communication between patients and clinicians fosters both the delivery of empathic patient-centered care and positive patient outcomes. Although nonverbal skill training is a recognized need, few efforts to enhance patient-clinician communication provide visual feedback on nonverbal aspects of the clinical encounter. Objectives: We describe a novel approach that uses social signal processing technology (SSP) to capture nonverbal cues in real time and to display ambient visual feedback on control and affiliation two primary, yet distinct dimensions of interpersonal nonverbal communication. To examine the design and clinician acceptance of ambient visual feedback on nonverbal communication, we 1) formulated a model of relational communication to ground SSP and 2) conducted a formative user study using mixed methods to explore the design of visual feedback. Methods: Based on a model of relational communication, we reviewed interpersonal communication research to map nonverbal cues to signals of affiliation and control evidenced in patient-clinician interaction. Corresponding with our formulation of this theoretical framework, we designed ambient real-time visualizations that reflect variations of affiliation and control. To explore clinicians' acceptance of this visual feedback, we conducted a lab study using the Wizard-of-Oz technique to simulate system use with 16 healthcare professionals. We followed up with seven of those participants through interviews to iterate on the design with a revised visualization that addressed emergent design considerations. Results: Ambient visual feedback on nonverbal communication provides a theoretically grounded and acceptable way to provide clinicians with awareness of their nonverbal communication style. We provide implications for the design of such visual feedback that encourages empathic patient-centered communication and include considerations of metaphor, color, size, position, and timing of feedback. Conclusions: Ambient visual feedback from SSP holds promise as an acceptable means for facilitating empathic patient-centered nonverbal communication.", "labels": [2, 18]}
{"id": "8", "token": "Past research has shown that the gender typicality of applicants' faces affects leadership selection irrespective of a candidate's gender: A masculine facial appearance is congruent with masculine-typed leadership roles, thus masculine-looking applicants are hired more certainly than feminine-looking ones. In the present study, we extended this line of research by investigating hiring decisions for both masculine-and feminine-typed professional roles. Furthermore, we used eye tracking to examine the visual exploration of applicants' portraits. Our results indicate that masculine-looking applicants were favored for the masculine-typed role (leader) and feminine-looking applicants for the feminine-typed role (team member). Eye movement patterns showed that information about gender category and facial appearance was integrated during first fixations of the portraits. Hiring decisions, however, were not based on this initial analysis, but occurred at a second stage, when the portrait was viewed in the context of considering the applicant for a specific job.", "labels": [2, 17]}
{"id": "87", "token": "Although detection of deception accuracy rate has been researched extensively, the person perception components that are the basis for these judgments remain unclear. To explore this, 30 academics' person perceptions, as well as truthfulness judgment, of the individual presenting a televised appeal were measured using a 14-item scale. Twelve appeals (6 genuine and 6 false) for information regarding the whereabouts of a missing relative, or for information to apprehend the person who murdered their relative, were used. The person perception scale consisted of (1) global, abstract judgments (open, deceptive, genuine, trustworthy, and emotional) and (2) behavioural indices (facial pleasantness, facial animation, arousal, tension, involvement, verbal; consistency, plausibility and directness, and vocal certainty). Multiple regression identified person perceptions of openness, (non)deceptiveness, genuineness, trustworthiness, and verbal plausibility as significant predictors of truthfulness judgments. Future research should now explore the relationship of these person perception components of truth judgments to the accuracy.", "labels": [2, 17]}
{"id": "255", "token": "Previous studies have noted that narcissists do, in some cases, experience benefits. The current study adds to this discussion by examining whether age might moderate the links between narcissism and a self-reported benefit (life satisfaction) and an observer-reported benefit (observer ratings of personality). In a sample of college students and their family members (N = 807), the authors demonstrate that narcissism positively correlates with life satisfaction for adolescents and emerging adults, but not for adult participants. In addition, the relationship between narcissism and observer-reported neuroticism was weakly negative for undergraduate students, but significant and positive for their mothers. Taken together, these results suggest that narcissism is more beneficial for adolescents and emerging adults than for adults. Both sets of analyses also pointed to the importance of studying narcissism as a multifaceted construct. Findings are discussed with respect to personality development theories that emphasize adult role adoption.", "labels": [2, 17]}
{"id": "471", "token": "This work addresses the creation of a development framework where application developers can create, in a natural way, immersive physical activities where users experience a 3D first-person perception of full body control. The proposed framework is based on commercial motion sensors and a Head-Mounted Display (HMD), and a uses Unity 3D as a unifying environment where user pose, virtual scene and immersive visualization functions are coordinated. Our proposal is exemplified by the development of a toy application showing its practical use.", "labels": [2, 17]}
{"id": "681", "token": "Heroes are ubiquitous in literature and popular discourse, yet little is known about cognitive representations of heroes. We examined lay conceptions of heroes using a prototype approach, compared heroes with other persons of influence, and studied how individuals use hero features to identify heroes. In Study 1, participants (N = 189) generated open-ended descriptions of heroes, which were sorted by independent coders into 26 meaningful categories. In Study 2, participants (N = 365) rated the centrality of these features, and subsequently classified each feature as either central (e.g., brave, moral integrity) or peripheral (e.g., humble, proactive). In a reaction time (RT) paradigm, participants in Study 3 (N = 33) identified central features of heroes faster than peripheral features. In Study 4, participants (N = 25) remembered more central hero features than peripheral features in a surprise recall task. In Study 5 (N = 89), participants most strongly identified a hero when the target was described with central features (vs. peripheral or neutral features). In Studies 6 (N = 212) and 7 (N = 307), participants' ratings evidenced that the prototypical features of heroes did not fit conceptually as well for role models and leaders. In all, these studies contribute new ideas to existing knowledge about heroes, and contribute to a shared understanding of what a hero means to people. Our research is thus an important step in refining heroism into a scientific concept. The notion of the prototypical features of heroes provides a basis for future hero research and intervention.", "labels": [2, 17]}
{"id": "788", "token": "A survey of adolescents (N = 1,646) documented third-person perception regarding media depictions of dating/relationship violence. It also contributes to the growing literature documenting optimistic bias as a strong predictor of third-person perception and draws from the optimistic bias literature considering new variables including self-esteem, self-efficacy, and experience with violence.", "labels": [2, 17]}
{"id": "880", "token": "The goal of the present research was to test whether score-related changes in opponents' nonverbal behavior influence athletes' confidence in beating their opponents. In an experiment, 40 participants who were experienced basketball players watched brief video clips depicting athletes' nonverbal behavior. Video clips were not artificially created, but showed naturally occurring behavior. Participants indicated how confident they were in beating the presented athletes in a hypothetical scenario. Results indicated that participants' confidence estimations were influenced by opponents' score-related nonverbal behavior. Participants were less confident about beating a leading team and more confident about beating a trailing team, although they were unaware of the actual score during the depicted scenes. The present research is the first to show that in-game variations of naturally occurring nonverbal behavior can influence athletes' confidence. This finding highlights the importance of research into nonverbal behavior in sports, particularly in relation to athletes' confidence.", "labels": [2, 17]}
{"id": "955", "token": "Although aesthetic preferences are known to be important in person perception and can play a significant role in everyday social decisions, the effect of the age of the observer on aesthetic preferences for faces of different ages has not yet been fully investigated. In the present study we investigated whether aesthetic preferences change with aging, with an age-related bias in favoring faces from one's own age group. In addition, we examined the role of age on both the perceptual qualities and the social attributes of faces that may influence these aesthetic judgements. Both younger and older adult observers provided ratings to images of younger, middle-aged and older unfamiliar faces. As well as attractiveness, the rating dimensions included other perceptual (distinctiveness, familiarity) and social (competence, trustworthiness and dominance) factors. The results suggested a consistent aesthetic preference for youthful faces across all ages of the observers but, surprisingly, no evidence for an age-related bias in attractiveness ratings. Older adults tended to provide higher ratings of attractiveness, competence and trustworthiness to the unfamiliar faces, consistent with the positivity effect previously reported. We also tested whether perceptual factors such as face familiarity or distinctiveness affected aesthetic ratings. Only ratings of familiarity, but not distinctiveness, were positively associated with the attractiveness of the faces. Moreover, ratings of familiarity decreased with increasing age of the face. With regard to the social characteristics of the faces, we found that the age of the face negatively correlated with ratings of trustworthiness provided by all observers, but with the competence ratings of older observers only. Interestingly, older adults provided higher ratings of perceived competence and trustworthiness to younger than older faces. However, our results also suggest that higher attractiveness ratings, together with older aged faces, led to more positive evaluations of competence. The results are discussed within the context of an age-related decline in the differentiation of faces in memory. Our findings have important implications for a better understanding of age-related perceptual factors and cognitive determinants of social interactions with unfamiliar others across the adult lifespan.", "labels": [2, 17]}
{"id": "1046", "token": "We examine the relationship between TV viewing and economic expectations during economic recession. A content analysis of 84 hours of local network primetime programming (news and nonnews) identifies a moderate bias toward economic pessimism in the broadcasts. A survey of the adult population (N = 356) points at a significant positive relationship between TV viewing (total viewing and viewing of news programming) and economic pessimism at both the national and the personal levels. A similar relationship exists between TV viewing and optimistic biasthe tendency to be more pessimistic on economic matters at the national than at the personal level. These results remain significant when controlled for demographics, trust in national institutions, evaluation of current economic situation and consumption of media other than TV, and corroborate a second-order cultivation effect in the economic context.", "labels": [2, 17]}
{"id": "1186", "token": "Facial hair, like many masculine secondary sexual traits, plays a significant role in perceptions of an array of sociosexual traits in men. While there is consensus that beards enhance perceptions of masculinity, age, social dominance, and aggressiveness, the perceived attractiveness of facial hair varies greatly across women. Given the ease with which facial hair can be groomed and removed entirely, why should some men retain beards and others choose to remove them? We hypothesized that men with relatively sexist attitudes would be more likely to allow their facial hair to grow than men with less sexist attitudes. Men from the USA (n = 223) and India (n = 309) completed an online survey measuring demographic variables, ambivalent sexism, and facial hair status. After controlling for demographic variables, men with facial hair were significantly higher in hostile sexism than clean-shaven men; hostile sexism was a significant predictor of facial hair status over and above demographic variables; and facial hair was more frequent among ambivalent and hostile sexists than among benevolent and non-sexists. It is suggested that sexist men choose to grow facial hair because it maximizes sexual dimorphism and augments perceived masculinity and dominance.", "labels": [2, 17]}
{"id": "1337", "token": "Accurate person perception is crucial in social decision-making. One of the central elements in successful social perception is the ability to understand another's response bias; this is because the same behavior can represent different inner states depending on whether other people are yea-sayers or naysayers. In the present study, we have tried to investigate how the internal biases of others are perceived. Using a multi-trial learning paradigm, perceivers made predictions about a target's responses to various suggested activities and then received feedback for each prediction trial-by-trial. Our hypotheses were that (1) the internal decision criterion of the targets would be realized through repeated experiences, and (2) due to positive-negative asymmetry, yea-sayers would be recognized more gradually than naysayers through the probabilistic integration of repeated experiences. To find neural evidence that tracks probabilistic integration when forming person knowledge on response biases, we employed a model-based fMRI with a State-Space Model. We discovered that person knowledge about yea-sayers modulated several brain regions, including caudate nucleus, DLPFC, hippocampus, etc. Moreover, when person knowledge was updated with incorrect performance feedback, brain regions including the caudate nucleus, DLPFC, dmPFC, and TPJ were also involved. There were overlapping regions for both processes, caudate nucleus and DLPFC, suggesting that these regions take crucial roles in forming person knowledge with repeated feedback, while reflecting acquired information up to the current prediction. (C) 2014 Elsevier Inc. All rights reserved.", "labels": [2, 17]}
{"id": "1430", "token": "The human body plays a central role in nonverbal communication, conveying attitudes, personality, and values during social interactions. Three experiments in a large, open classroom setting investigated whether the visibility of torso-located cues affects nonverbal communication of similarity. In Experiments 1 and 2, half the participants wore a black plastic bag over their torso. Participants interacted with an unacquainted same-sex individual selected from a large class who was also wearing (or also not wearing) a bag. Experiment 3 added a clear bag condition, in which visual torso cues were not obscured. Across experiments, black bag-wearing participants selected partners who were less similar to them on attitudes, behaviors, and personality compared to the bag-less-and clear bag-participants. Nonverbal cues in the torso communicate information about similarity of attitudes, behavior, and personality; the center of the body plays a surprisingly central role in early-stage person perception and attraction.", "labels": [2, 17]}
{"id": "1501", "token": "Does physical warmth lead to caring and sharing? Research suggests that it does; physically warm versus cold conditions induce prosocial behaviors and cognitions. Importantly, previous research has not traced the developmental origins of the association between physical warmth and affection. The association between physical warmth and sharing may be captured in specific cognitive models of close social relations, often referred to as attachment styles. In line with this notion, and using a dictator game set-up, the current study demonstrates that children who relate to their friends with a secure attachment style are more generous toward their peers in warm than in cold conditions. This effect was absent for children who relate to friends with an insecure attachment style. Notably, however, these children not just always shared less: They allocated more stickers to a friend than to a stranger. These findings provide an important first step to understand how fundamental embodied relations develop early in life. We discuss broader implications for grounded cognition and person perception.", "labels": [2, 17]}
{"id": "1560", "token": "The present investigation examined how three salient features of narrative thinking (situation model construction, linguistic concreteness, and perspective-taking) influenced the social inference process. Results of four experiments indicated that compared with those given other objectives, perceivers given narrative objectives were: (a) more likely to make situation rather than trait attributions for observed behaviors (Experiment 1), (b) less likely to make implicit trait inferences (Experiment 2), and (c) less likely to rely on behavior valence when making evaluative judgments (Experiment 4). Linguistic analyses indicated that narrative construction consistently entailed the creation of situation models of events and linguistic concreteness, but only situation model creation mediated the relationship between narrative and inferences. Experiment 3 confirmed the mediating role of situation models: Perceivers with narrative objectives made trait inferences only when behaviors were inconsistent with contextual information. The role of these core narrative features on social perceptions is discussed.", "labels": [2, 17]}
{"id": "1622", "token": "The third-person effect (TPE) hypothesis states that people typically perceive the media messages to have greater influence on others than on themselves. Though this self-other perceptual bias has been shown to be robust across a variety of message contexts, past research has typically utilized Caucasian college student samples. The current study addresses this shortcoming in the literature by examining whether the TPE hypothesis holds for low-income, low-education, Spanish-speaking female adults with regard to the perceived effects of health news coverage. Our findings showed that most participants chose equal to others when estimating health news effects on themselves instead of less than others or more than others. Results from ordinal logistic regression showed that the propensity toward TPE was related to optimistic bias and certain indicators of acculturation. Our findings suggest the need for future TPE research in Hispanic populations and further efforts to investigate TPE from an intercultural perspective.", "labels": [2, 17]}
{"id": "1692", "token": "The present research finds that anthropomorphism, or attributing human characteristics to nonhuman objects, increases consumers' preference for products with superior appearance. This effect occurs because consumers apply the belief of beautiful is good, a pervasive stereotype in person perception, to the judgment of anthropomorphized products. Seven experiments test the propositions. The results show that product anthropomorphism (vs. nonanthropomorphism) leads consumers to spend more time and money searching for information about appearance attributes (experiments 1 and 2), to indicate greater preference for products with superior appearance (experiments 4, 6, and 7), and to purchase products with superior appearance (experiments 3 and 5). The experiments also show that the effect of anthropomorphism on consumer preference is mediated by consumers' conviction of beautiful is good in person perception. This effect is alleviated when consumers' beliefs about the association between the attractive physical appearance of a person and the positive personal traits of this person are challenged. These results are robust across a wide range of product categories and consumers. Theoretical contributions and marketing implications are discussed.", "labels": [2, 17]}
{"id": "1724", "token": "Faces and voices, in isolation, prompt consistent social evaluations. However, most human interactions involve both seeing and talking with another person. Our main goal was to investigate how facial and vocal information are combined to reach an integrated person impression. In Study 1, we asked participants to rate faces and voices separately for perceived trustworthiness, attractiveness, and dominance. Most previous studies relied on stimuli in which extra-vocal information (e.g., verbal content, prosody) may have confounded voice-based effects; to prevent these unwanted influences, we used brief, neutral vowel sounds. Voices, like faces, led to the formation of highly reliable impressions. Voice trustworthiness correlated with voice attractiveness, mirroring the relation between face trustworthiness and attractiveness, but did not correlate with voice dominance. Inconsistent with the possibility that face and voice evaluations are indicative of real character traits, we found no positive correlations between judgments of trustworthiness or dominance based on faces and the same judgments based on voices (there was also no correlation between face attractiveness and voice attractiveness). In Study 2, we asked participants to evaluate male targets after seeing their faces and hearing their voices. Faces and voices contributed equally to judgments of trustworthiness and combined to produce a significant interaction effect. For attractiveness, faces were given more weight than voices, possibly due to the predominantly visual character of the attractiveness concept (there was no interaction effect). For dominance, the reverse pattern was true, with voices having a larger effect than faces on final judgments. In this case the auditory cues may be perceived to be more reliable because of the strong links between voice pitch, masculinity, and dominance.", "labels": [2, 17]}
{"id": "1860", "token": "The present study examined whether the grade point averages (GPAs) of university students could be predicted from appearance-based ratings of their Conscientiousness. Undergraduate participants (N = 249) provided self-reports of their Big Five personality traits and copies of their student transcripts from which their GPAs were obtained. Photographs of these undergraduates were then taken from which their personality traits were judged by unacquainted perceivers. Both aggregated and single perceiver-ratings of Conscientiousness predicted GPA. Aggregated perceiver-ratings predicted GPA incrementally over self-ratings, suggesting that appearance-based judgements of Conscientiousness may contain trait-relevant information beyond the scope of self-reports. These results contribute to a growing literature documenting the validity of appearance-based judgements of personality traits.", "labels": [2, 17]}
{"id": "1922", "token": "The 3-stage model of social inference posits that people categorize behaviors and characterize actors or situations effortlessly, but they correct these characterizations with additional information effortfully. The current article tests this model using developmental data, assuming that the less cognitively demanding processes in the model (i.e., categorization, characterization) should appear earlier in development, whereas the more demanding correction process should not appear until later in development. Using 2 different paradigms, Studies 1 and 3 found that younger children failed to take situational information into account while characterizing the actor. Study 2 found that younger children failed to take dispositional information into account while characterizing the situation. In contrast, in these 3 studies, older children used the available information to correct their characterizations of the actors and of the situations. Consistent with the 3-stage model, during elementary school years, children start to integrate additional information when drawing explicit social inferences. In Study 4, children of all age levels used a prior expectancy to draw a dispositional inference, ignoring situational information, suggesting that characterizations based on prior expectancies about an actor are a highly efficient process, not contemplated by the model. The 4 studies together illustrate how developmental data can be valuably used to test adult socio-cognitive models, to extend their validity, or to simply further inform those models.", "labels": [2, 17]}
{"id": "2051", "token": "People can reliably distinguish the sex of faces across age groups. Rates of accuracy are lower for infants, however, likely because they lack the pronounced sexually dimorphic features that develop during puberty. Given that previous research has shown that perceivers categorize adult sex automatically, we wondered whether this would extend to the faces of infants for whom sex is less legible. We tested this using a semantic priming paradigm in which infant faces preceded the categorization of stereotypically male and female names. Results showed that participants categorized the sex of male names significantly faster following perceptions of male versus female infant faces (though female faces did not significantly facilitate the processing of female names). The asymmetry in interference for male but not female faces supports evidence for a male default in conceptions of sex among infants previously found for adults. Individuals may therefore process sex automatically in the absence of overt cues (e.g., post-pubertal sexually dimorphic features or stereotypical clothing), providing additional evidence for the depth and flexibility of social categorization.", "labels": [2, 17]}
{"id": "2206", "token": "Fregoli delusion is the mistaken belief that some person currently present in the deluded person's environment (typically a stranger) is a familiar person in disguise. The stranger is believed to be psychologically identical to this known person (who is not present) even though the deluded person perceives the physical appearance of the stranger as being different from the known person's typical appearance. To gain a deeper understanding of this contradictory error in the normal system for tracking and identifying known persons, we conducted a detailed survey of all the Fregoli cases reported in the literature since the seminal Courbon and Fail (1927) paper. Our preliminary reading of these cases revealed a notable lack of definitional clarity. So, we first formulated a classification scheme of different person misidentification delusions so as to identify those cases that qualified as instances of Fregoli according to the above characterization: the mistaken belief that a known person is present in the environment in a different guise to his or her typical appearance. We identified 38 clear cases of this type and set out to answer a series of questions motivated by current hypotheses about the origin of the Fregoli delusion. We asked whether the patients misidentified particular strangers, made reference to the misidentified known persons using wigs or plastic surgery (or other techniques to disguise their appearance), misidentified many different strangers or only one, showed other symptoms (in particular, other misidentification delusions), and made inferences about the motives of the known persons in disguise. We conclude by discussing the implications of our findings for current hypotheses concerning the origin of the Fregoli delusion.", "labels": [2, 17]}
{"id": "2403", "token": "The rising number of newly insured young adults brought on by health care reform will soon increase demands on primary care physicians. Physicians will face more young adult patients, which presents an opportunity for more prevention-oriented care. In the present study, we evaluated whether brief observer reports of young adults' personality traits could predict which individuals would be at greater risk for poor health as they entered midlife. Following the cohort of 1,000 individuals from the Dunedin Multidisciplinary Health and Development Study (Moffitt, Caspi, Rutter, & Silva, 2001), we show that very brief measures of young adults' personalities predicted their midlife physical health across multiple domains (metabolic abnormalities, cardiorespiratory fitness, pulmonary function, periodontal disease, and systemic inflammation). Individuals scoring low on the traits of Conscientiousness and Openness to Experience went on to develop poorer health even after accounting for preexisting differences in education, socioeconomic status, smoking, obesity, self-reported health, medical conditions, and family medical history. Moreover, personality ratings from peer informants who knew participants well, and from a nurse and receptionist who had just met participants for the first time, predicted health decline from young adulthood to midlife despite striking differences in level of acquaintance. Personality effect sizes were on par with other well-established health risk factors such as socioeconomic status, smoking, and self-reported health. We discuss the potential utility of personality measurement to function as an inexpensive and accessible tool for health care professionals to personalize preventive medicine. Adding personality information to existing health care electronic infrastructures could also advance personality theory by generating opportunities to examine how personality processes influence doctor-patient communication, health service use, and patient outcomes.", "labels": [2, 17]}
{"id": "2518", "token": "We report an experiment investigating whether dancing to the same music enhances recall of person-related memory targets. The experiment used 40 dancers (all of whom were unaware of the experiment's aim), two-channel silent-disco radio headphones, a marked-up dance floor, two types of music, and memory targets (sash colors and symbols). In each trial, 10 dancers wore radio headphones and one of four different colored sashes, half of which carried cat symbols. Using silent-disco technology, one type of music was surreptitiously transmitted to half the dancers, while music at a different tempo was transmitted to the remaining dancers. Pre-experiment, the dancers' faces were photographed. Post-experiment, each dancer was presented with the photographs of the other dancers and asked to recall their memory targets. Results showed that same-music dancing significantly enhanced memory for sash color and sash symbol. Our findings are discussed in light of recent eye-movement research that showed significantly increased gaze durations for people observing music-dance synchrony versus music-dance asynchrony, and in relation to current literature on interpersonal entrainment, group cohesion, and social bonding.", "labels": [2, 17]}
{"id": "2667", "token": "Participants were asked to assess their own personality (i.e. Big Five scales), the personality of politicians shown in brief silent video clips, and the probability that they would vote for these politicians. Response surface analyses (RSA) revealed noteworthy effects of self-ratings and observer-ratings of openness, agreeableness, and emotional stability on voting probability. Furthermore, the participants perceived themselves as being more open, more agreeable, more emotionally stable, and more extraverted than the average politician. The study supports previous findings that first impressions affect decision making on important issues. Results also indicate that when only nonverbal information is available people prefer political candidates they perceive as having personality traits they value in themselves. (C) 2014 The Authors. Published by Elsevier Inc.", "labels": [2, 17]}
{"id": "2737", "token": "Reading other people's eyes is a valuable skill during interpersonal interaction. Although a number of studies have investigated visual patterns in relation to the perceiver's interest, intentions, and goals, little is known about eye gaze when it comes to differentiating intentions to love from intentions to lust (sexual desire). To address this question, we conducted two experiments: one testing whether the visual pattern related to the perception of love differs from that related to lust and one testing whether the visual pattern related to the expression of love differs from that related to lust. Our results show that a person's eye gaze shifts as a function of his or her goal (love vs. lust) when looking at a visual stimulus. Such identification of distinct visual patterns for love and lust could have theoretical and clinical importance in couples therapy when these two phenomena are difficult to disentangle from one another on the basis of patients' self-reports.", "labels": [2, 17]}
{"id": "2891", "token": "Many changes in nature do not directly threaten humans, but do negatively influence nature itself, thereby posing an impersonal risk. We examine the optimistic bias (OB) for an impersonal risk, the first-person perception (FPP) of an impersonal risk, and the influence of media reporting and proximity of an impersonal risk on FPP and OB. Finally, we investigate the relationship between OB and FPP. We conducted a field experiment (N = 479) in 12 German cities where an invasive moth species had infested culturally important horse chestnut trees. We found OB for this nature change that decreased for people living in an area subject to this impersonal nature risk. After the treatments, neither the proximity of impersonal risk nor the journalistic style of media reporting had a significant effect on OB. An FPP was found that was not influenced significantly by either different journalistic styles or the proximity of impersonal risk. A nonsignificant swap-in-signs relation between OB and FPP was found depending on journalistic style.", "labels": [2, 17]}
{"id": "3073", "token": "The purpose of this paper is to develop a model for individual social behavior, B, that incorporates the contributions of both the personality of the actor, P, and the relevant features of the situation, S, in which he or she is performing. In analyzing the original formula by Lewin, viz., B=f(P.S), the paper first considers the importance accorded the situation in previous theorizing about Asianness'. It then analyzes the contributions of the actor's personality, noting in particular that actors come to develop broad expectancies for situational outcomes, P(S), associated with situations they encounter. Those situations are glossed for social psychological purposes in terms of their affordances for potential yields relative to the actor's motivations for sociality and status. These situational affordances are defined by the normative prescriptions believed to be operative in that situation for acceptable enactments of behaviors aimed at attaining the actor's goals for sociality and status. That normative pressure is objective, though it may be judged by the actor, and is termed the O(S) component of the situation. It is held with some degree of consensus, CO(S), by others in, or observers of, the situation. These two components specify the strength' of the situation for social psychological purposes, yielding an elaborated Lewinian formula B=f(P.P[S].O[S].CO[S]). The culture of the participants, national, organizational, familial or dyadic, will determine the beta weights linking the components of the formula.", "labels": [2, 17]}
{"id": "3182", "token": "Via mental simulation, future previews have been shown to optimize behavioral selection and enhance task performance. Yet little is known about the critical factors that determine exactly how and when imagination impacts behavior. Noting the theoretical importance of vantage point (i.e., field vs. observer perspective) during mental imagery, here we explored the possibility that spatial visual perspective influences the real-time behavioral correlates of simulated (i.e., imagined) events. Participants were instructed to imagine positive and negative social encounters from either a field or an observer vantage point. Throughout each imagined interaction, postural movement in the anterioposterior (i.e., front-back) plane served as a real-time index of approach-withdrawal behavior. The results revealed that mental simulations were accompanied by functionally adaptive behavior (i. e., approach or withdrawal) but only when events were imagined from a field perspective. The theoretical and practical implications of these findings are considered.", "labels": [2, 17]}
{"id": "3303", "token": "People commonly reference minority friendships when expressing conceivably prejudiced attitudes. The prevalence of this strategy suggests a widespread belief that having minority friends makes one look less racist, but to date, there is little research demonstrating whether or not this is the case. White and Asian participants were presented with a Facebook profile depicting a White target who posted an anti-Asian statement. Being depicted with Asian friends (Study 1) or even verbally claiming that they had Asian friends (Study 2) reduced attributions of racism irrespective of whether they were being evaluated by White or Asian observers. Furthermore, the presence of Asian friends made the conceivably racist comments seem relatively benign, and observers were less offended and upset by them. The data suggest that minority friendships can partially offset costs associated with expressing prejudice.", "labels": [2, 17]}
{"id": "3437", "token": "BackgroundTwo important influences on students' evaluations of teaching are relationship and professor effects. Relationship effects reflect unique matches between students and professors such that some professors are unusually effective for some students, but not for others. Professor effects reflect inter-rater agreement that some professors are more effective than others, on average across students. AimsWe attempted to forecast students' evaluations of live lectures from brief, video-recorded teaching trailers. SampleParticipants were 145 college students (74% female) enrolled in introductory psychology courses at a public university in the Great Lakes region of the United States. MethodsStudents viewed trailers early in the semester and attended live lectures months later. Because subgroups of students viewed the same professors, statistical analyses could isolate professor and relationship effects. ResultsEvaluations were influenced strongly by relationship and professor effects, and students' evaluations of live lectures could be forecasted from students' evaluations of teaching trailers. That is, we could forecast the individual students who would respond unusually well to a specific professor (relationship effects). We could also forecast which professors elicited better evaluations in live lectures, on average across students (professor effects). Professors who elicited unusually good evaluations in some students also elicited better memory for lectures in those students. ConclusionsIt appears possible to forecast relationship and professor effects on teaching evaluations by presenting brief teaching trailers to students. Thus, it might be possible to develop online recommender systems to help match students and professors so that unusually effective teaching emerges.", "labels": [2, 17]}
{"id": "9", "token": "The effect of sand grain shape and size on the mechanical behavior of geotextile-reinforced sands is investigated in the present research, based on the results of triaxial compression tests. Six clean uniform sands differing in grain shape (subangular or rounded grains) and/or grain size as well as one non-woven and three woven geotextiles with or without apertures, were used in this experimental investigation. Triaxial compression tests were conducted on specimens with a diameter of 70 mm and a height of 144 mm, consisting of dry and dense sands reinforced with 3, 5 and 7 horizontal geotextile disks. The geotextile-reinforced sands present higher strength and axial strain at failure than the unreinforced sands. The strength of reinforced sands increases with decreasing sand grain size, with increasing number of geotextile layers and is affected by the grain shape of sand, since it was observed that reinforced sands with subangular grains attain higher strength values than the reinforced sands with rounded grains. The triaxial compression tests yielded bilinear failure envelopes for all geotextile-reinforced sands.", "labels": [4, 26]}
{"id": "114", "token": "The filter media in polyester is one of the most geotextile materials used in aerosol and drainage filtration, particularly for soil reinforcement in civil engineering due to its appropriate properties and its low cost. However, the current understanding of the durability and stability of this material in real service conditions, especially under severe long-term conditions are completely limited. This work presents an investigation of the chemical aging of a commercial nonwoven polyester membrane under different temperatures and pH environments in relation to its morphology, mechanical properties and molar mass. The results showed a significant reduction of mechanical properties in term of tensile strength, puncture resistance and tearing forces of the membrane after aging process due to the chemical degradation. The molar mass and mechanical properties changes with temperature and pH showed a complex dependence of material properties on environmental conditions. Based on the obtained results, the lifetime of the material at different temperatures was determined by the use of the Arrhenius model. These results provide useful information to a better understanding of phenomena occurring during chemical aging of the polyester nonwoven membranes and may help to predict the service lifetime of this material in conditions of use encounteredin service. (C) 2014 Elsevier Ltd. All rights reserved.", "labels": [4, 26]}
{"id": "234", "token": "The use of polyacrylamide (PAM)-based flocculants has become an essential component of most geotextile tube dewatering projects. Although knowledge of the residual flocculant concentration in geotextile tube supernatant and effluent is essential to the safe use of PAM-based flocculants, residual flocculant concentration is not commonly measured in geotextile tube dewatering operations. Furthermore, there is no ASTM standard test method for measuring residual flocculant concentrations in water. This paper presents a comparative study of two different methods that are commonly used to measure residual flocculant concentrations in water: the Streaming Current Detection (SCD) method and the China Clay Settling Rate (CCSR) method, to evaluate their applicability to the geotextile tube industry. The comparison is based on an analysis of measured residual PAM concentrations obtained for five different cationic PAM polymers used to flocculate Tully fines soil. Optimum flocculant doses for the Tully fines soil were determined using the jar test (ASTM D2035-08) for three different solids concentrations by mass (5, 15, and 33 %). The SCD and CCSR methods were performed on the supernatants of Tully fines that were conditioned at their optimum doses and at concentrations 50 % above their optimum dose. Laboratory test results showed that both the SCD and CCSR methods produced similar residual PAM concentration results for the polymer/soil combinations tested. The SCD method, however, produced more consistent and repeatable results in comparison to the CCSR method. The SCD method was also easier to use and could be performed in shorter amounts of time than the CCSR method. Based on the results, it is recommended that the SCD method be standardized and used to measure residual PAM-based flocculant concentrations in geotextile tube supernatant and effluent.", "labels": [4, 26]}
{"id": "336", "token": "Results from interface shear tests on sand-geosynthetic interfaces are examined in light of surface roughness of the interacting geosynthetic material. Three different types of interface shear tests carried out in the frame of direct shear-test setup are compared to understand the effect of parameters like box fixity and symmetry on the interface shear characteristics. Formation of shear bands close to the interface is visualized in the tests and the bands are analyzed using image-segmentation techniques in MATLAB. A woven geotextile with moderate roughness and a geomembrane with minimal roughness are used in the tests. The effect of surface roughness of the geosynthetic material on the formation of shear bands, movement of sand particles, and interface shear parameters are studied and compared through visual observations, image analyses, and image-segmentation techniques.", "labels": [4, 26]}
{"id": "430", "token": "Plastic wastes, particularly polyethylene terephthalate (PET) generated from used bottled water constitute a worldwide environmental issue. Reusing the PET waste for geotechnical applications not only reduces environmental burdens of handling the waste, but also improves inherent engineering properties of soil. This paper investigated factors affecting shear strength improvement of PET-mixed residual soil. Four variables were considered: (i) plastic content; (ii) plastic slenderness ratio; (iii) plastic size; and (iv) soil particle size. A series of unconfined compression tests were performed to determine the optimum configurations for promoting the shear strength improvement. The results showed that the optimum slenderness ratio and PET content for shear strength improvement were 1:3 and 1.5%, respectively. Large PET pieces (i.e., 1.0 cm(2)) were favorable for fine-grained residual soil, while small PET pieces (i.e., 0.5 cm2) were favorable for coarse-grained residual soil. Higher shear strength improvement was obtained for PET-mixed coarse-grained residual soil (148%) than fine-grained residual soils (117%). The orientation of plastic pieces in soil and frictional resistance developed between soil particles and PET surface are two important factors affecting the shear strength performance of PET-mixed soil.", "labels": [4, 26]}
{"id": "508", "token": "Geosynthetic structures created for channel erosion protection offer environmental friendly benefits and have demonstrably lower construction and lifetime costs than similar hard structures. A geotextile mattress with a sloping curtain (GMSC) offers an alternative countermeasure against channel erosion. In the present study, experiments were conducted to investigate the working mechanism and effectiveness of GMSCs which were installed on movable beds in a rectangular flume. The bathymetry of the plastic sand beds was measured before and after the tests. The results showed that the presence of the GMSC led to sediment deposition and dune formation at both upstream and downstream edges of the GMSC structure. This will prevent bottom erosion near the structure and increase its stability against flow-induced sediment scour, so that the erodible beds will be protected.", "labels": [4, 26]}
{"id": "682", "token": "In a wide spectrum of geotechnical applications, materials undergo large deformations and/ or large displacements. On modeling these problems with a Lagrangian finite element method, the mesh can become too distorted and re-meshing is essential. In the past decades, considerable efforts have been made to adopt what is called meshfree methods to mitigate the problems related to mesh distortion. One of these methods is the Material Point Method (MPM) that represents the continuum field as Lagrangian material points (particles), which can move through the fixed background of an Eulerian mesh. In this paper, the tensile membrane is modeled using the coupled FEM-MPM approach which adopts two-dimensional triangular elements for the membrane discretisation which is free to move through a three-dimensional mesh of non-structured tetrahedral elements. Apart from the membrane, the soil is treated with the classical procedure of MPM. To show the potential of the method and the presented membrane scheme, a failure of an embankment with and without geotextile has been presented in this paper. The analyses of failure mechanism and the embankment stability using undrained conditions were investigated to determine the critical embankment height and the corresponding geotextile forces. For the sake of comparison, Plaxis 2D with large deformation formulation is considered as a reference solution.", "labels": [4, 26]}
{"id": "739", "token": "This study presents the results of geogrid pullout tests conducted in wet and fine-grained soils. Failures of reinforced soil structures have often involved inadequate drainage due to the use of fine-grained soils, which has led to stringent specifications for backfill material in such structures although there are significant economic reasons for relieving the specifications. One approach to improve the issue is to reinforce fine-grained soils with geosynthetic providing both reinforcement and lateral drainage. Although using reinforcement with in-plane drainage capability is conceptually promising, transmissivity requirements for this application have not been properly evaluated. Pullout tests were conducted on cohesive soils using geogrids with the same tensile strength but with and without in-plane drainage channels. The results indicate that geogrids with in-plane drainage layers show higher pullout resistance than conventional geogrids. The finding contributes to promoting the use of poorly draining soils as backfill material.", "labels": [4, 26]}
{"id": "846", "token": "In double-lined tunnels, geotextiles are installed between shotcrete and concrete linings to drain ground water that is in the circumferential boundary of the tunnels. During the concrete lining placement, the geotextile often experiences pressures from young concrete on the curved and rough shotcrete surfaces. The pressures are transferred through a waterproof membrane, and act in the normal direction to the curved shotcrete face. The geotextile flow behavior under these conditions cannot be represented by standard geotextile permeability tests. Instead, it requires specially designed performance tests that consider field conditions. A new device to evaluate the permeability of the geotextile in pressurized curved flow channels is proposed; it adopts a flexible loading system and a curved and rough model plate. Testing of geotextiles used for tunnel drainage systems, using the proposed arrangement, shows that the effects of the tortuousity of the flow in pressurized channels affects significantly the geotextile permeability.", "labels": [4, 26]}
{"id": "993", "token": "Alternating flows in the ground have a detrimental effect on the internal stability of the ground at the bottom of bodies of water, at offshore structures, coastal protection structures, and revetments. A test apparatus for alternating flow was constructed for the purpose of investigating various problems relating to alternating flow in the ground. It was used to conduct investigations into the stability of granular filters for offshore wind turbines subjected to high levels of alternating hydraulic loads. The design criteria for granular filters subjected to oscillating loads must be considerably more stringent than those for granular filters subjected to unidirectional flow. It was also possible to demonstrate that the hydraulic loads due to waves have a significant effect on the filter stability in the area relevant for offshore structures.", "labels": [4, 26]}
{"id": "1017", "token": "Predicting the behavior of geotextiles made of polyesters and polypropylene fibers is described by differential equations derived from mechanical models. Thereby, we describe the behavior of geotextiles up to the elastic limit. The elastic limit represents the permissible load which the geotextile material may be subjected to during exploitation, and without distorting its structure. The elastic limit is defined by analyzing the stress-strain curve of analyzed geotextiles. Nonwoven geotextile materials of polyester and polypropylene fibers with surface mass of 150, 200, 250, 300 and 500g/m(2) were used as experimental material.", "labels": [4, 26]}
{"id": "1125", "token": "In this paper, hydraulic performance and self-healing capacity of geotextile clay liners containing various amounts of nano-clay are studied. Nano-clay was employed as a substitute of a portion of bentonite. For comparison, the hydraulic performance and self-healing capacity of common geotextile clay liners (geotextile clay liners without any additives) were also experimentally studied. A novel instrument was developed to evaluate the self-healing capacity of geotextile clay liners samples. Atterberg limits and free swell index of neat and modified clayey samples were also measured. Experimental results showed that nano-clay considerably reduces the hydraulic conductivity of geotextile clay liners. It also improves the self-healing capacity of geotextile clay liners. The free swell index and liquid limits of bentonite specimens containing nano-clay were considerably higher than that of normal specimens. It can be concluded that factors affecting the free swell index of bentonite can change the self-healing capacity of geotextile clay liners. In this study, the specimen containing 15% nano-clay showed the best performance in hydraulic conductivity and self-healing capacity among all specimens. In the final, the effect of nano-clay inclusion on the permeability of bentonite is showed through an analytical model using the results of surface tension measurements.", "labels": [4, 26]}
{"id": "1213", "token": "This investigation was conducted to determine the variations in the dimensions of multi-component geosynthetic clay liners (GCLs). Two GCLs were tested: a sample with a relatively smooth geofilm, and a sample with a textured geofilm. Discrete effects of cyclic wetting-drying, initial moisture content, overburden pressure, temperature, and underlying subgrade soil were determined. Coupled effects of underlying subgrade soil and climatic conditions were evaluated in an outdoor simulated field environment. Cyclic wetting and drying resulted in net shrinkage of GCLs, with shrinkage strains of 11 % and 4 % in the machine and cross-machine directions, respectively. Specimens with high initial moisture contents (75 % to 125 %) underwent more shrinkage in the early wet-dry cycles than those with low initial moisture (22 % to 50 %), however, the initial moisture had no significant effect on the ultimate shrinkage. In the machine direction, strains exceeded values that would cause panel separation in the field within the first two cycles, whereas at least seven cycles were required for panel separation strains in the cross-machine direction. Temperature effects alone did not result in significant shrinkage. Specimens placed on soil subgrades without wetting or drying underwent moisture changes however experienced less shrinkage than those subjected to wet-dry cycling. The GCLs underwent significant diurnal temperature variations (up to 55 C) outdoors. However, the shrinkage of these specimens was similar to that observed in the subgrade tests. The specimens with higher initial moisture contents underwent more dimensional change than the specimens at lower moistures. The type of geosynthetic in contact with the underlying soil influenced GCL soil systems. Woven geotextile sides on soil subgrades resulted in high moisture transfer and shrinkage.", "labels": [4, 26]}
{"id": "1367", "token": "The objective of this paper is to formulate and validate an accurate MPM approach for the numerical simulation of the large displacement of membranes containing soil. In the proposed approach, the membrane is discretised by a surface mesh that allows accurate simulation of membrane stresses. The membrane is free to move through a three-dimensional grid for a continuum consisting of tetrahedral elements. The approach is applied to model a geocontainer being released from a split barge, taking into account the frictional contact between the geotextile and the barge. No-slip contact is assumed between the geotextile and the soil inside. The effect of geocontainer interaction is investigated by dropping a second container. Copyright (c) 2014 John Wiley & Sons, Ltd.", "labels": [4, 26]}
{"id": "1616", "token": "A simplified method for the design of impermeable geosynthetic tubes inflated using liquid is proposed in this paper. Adopting a computer program for an existing theoretical model, relationships between pumping pressure and geometric parameters for geosynthetic tubes can be established. A set of simplified dimensionless design equations are then derived using the Chapman-Richard curve fitting method. The validity of this simplified method was verified using other established methods and laboratory model tests. The proposed simplified method can thus be used for routine or preliminary design. (C) 2014 Elsevier Ltd. All rights reserved.", "labels": [4, 26]}
{"id": "1664", "token": "Chemical cross-linking and the high molecular weight of superabsorbent copolymers (SAPs) are the two main causes of their resistance to biodegradation. However, SAP particles are colonized by microorganisms. For the purposes of this study, the dry technical copolymer of acrylamide and potassium acrylate containing 5.28 % of unpolymerized monomers was wrapped in a geotextile and incubated in unsterile Haplic Luvisol soil as a water absorbing geocomposite. The highest number of soil bacteria that colonized the hydrated SAP and utilized it as the sole carbon and energy source was found after the first month of incubation in soil. It was equal to 7.21-7.49 log(10) cfu g(-1) of water absorbed by the SAP and decreased by 1.35-1.61 log(10) units within the next 8 months. During this time, the initial SAP water holding capacity of 1665.8 g has decreased by 24.40 %. Moreover, the 5 g of SAP dry mass has declined by 31.70 %. Two bacteria, Rhizobium radiobacter 28SG and Bacillus aryabhattai 31SG isolated from the watered SAP were found to be able to biodegrade this SAP in pure cultures. They destroyed 25.07 and 41.85 mg of 300 mg of the technical SAP during the 60-day growth in mineral Burk's salt medium, and biodegradation activity was equal to 2.95 and 6.72 mu g of SAP mu g(-1) of protein, respectively. B. aryabhattai 31SG and R. radiobacter 28SG were also able to degrade 9.99 and 29.70 mg of 82 mg of the ultra-pure SAP in synthetic root exudate medium during the 30-day growth, respectively.", "labels": [4, 26]}
{"id": "1863", "token": "Frictionless plain bearing for post-tensioned slab on ground A new method for building large concrete slabs on ground on a frictionless support was developed at Vienna University of Technology. An Austrian patent for this method was granted and an international patent application has been filed. The feasibility of this new method has been demonstrated in large field tests on concrete slab strips with a length of 60 m, a width of 1.0 m and a thickness of 30 cm. The frictionless support is obtained by first placing an air-tight membrane, then a geotextile and at last a second air-tight membrane on the ground where the concrete slab is to be built. In the next step the membranes are sealed at the boundary. After casting the slab on top of the second membrane, low air pressure is applied in the clearance between the two membranes. This clearance is created by the geotextile. Shortening of the slab due to the loss of hydration heat, early shrinkage and post-tensioning is possible without causing friction forces between slab and subsoil because the self-weight of the slab is balanced by the applied air pressure.", "labels": [4, 26]}
{"id": "2021", "token": "This paper describes the construction and testing of six 1-m-high model embankments constructed at three different gravimetric water content (GWC) values to study their performance and to validate a set of moisture reduction factors (MRFs) introduced by the authors in their recent studies. The earlier MRF values were obtained from a series of pullout and interface shear tests on the same soil and reinforcement materials. The MRF in this study is defined as the ratio of soil-reinforcement interface shear strength at an increased GWC value [e.g., optimum moisture content (OMC) + 2%] to the shear strength at OMC - 2% representing construction conditions. Therefore, MRF values can be used to account for an anticipated reduction in the shear strength of the soil-geotextile reinforcement interface caused by wetting in the stability analysis and design of reinforced soil structures constructed with marginal soils. The embankment models were built using a lean clay (CL) at the GWC values ranging between OMC - 2% and OMC + 2%, which included a single-reinforcement layer near the top of the embankment. This provided a horizontal soil-reinforcement interface subjected to shear sliding of an overriding block of soil caused by surcharge loading of the embankment. Two different woven polypropylene geotextile products were used to build the six model embankments. Each model was instrumented with a total of 67 sensors to measure the soil GWC, matric suction and excess pore pressure, reinforcement strains, earth pressure, and deformations of the embankment model and the test box during the test. Results from the embankment tests in this study indicate that the change in the matric suction and GWC could have a significant influence on the soil-geotextile reinforcement interface strength. Wetting of the soil and the soil-geotextile interface during construction or service life of reinforced soil slopes could considerably reduce their shear strength, resulting in lower factors of safety for their stability. The results of the study showed that within the range of GWC values examined (i.e., OMC +/- 2%), the embankment model constructed at OMC - 2% yielded the greatest shear strength and stability when subjected to a strip footing load. The MRF values for the model embankments constructed at OMC + 2% were found to be as low as 0.74-0.79 for models that were reinforced with different woven geotextiles of comparable apparent opening size (AOS) but different ultimate strength values. The MRF results presented in this study, although obtained from soils with different as-compacted GWC values, indicate that the loss of soil-reinforcement interface shear capacity as a result of wetting in reinforced soil structures involving marginal fills could be significant and deserve proper attention in the design of these systems. (C) 2016 American Society of Civil Engineers.", "labels": [4, 26]}
{"id": "2160", "token": "In order to develop and successfully implement a cost effective ground treatment design for railway embankment traversing through soft alluvium deposits for high speed train, a fully instrumented trial embankment was carried out at Tokai, State of Kedah, Malaysia for verification of design. Cost effective ground treatment of prefabricated vertical drain (PVD) with temporary surcharging and geotextile basal reinforcement were widely adopted for the 200km long railway embankment and were designed to meet the stringent performance requirements. From the back analyses using Finite Element Modeling (FEM) of the fully instrumented trial embankment, the performance of the ground treatment is evaluated and verified. Additional FEM analyses were carried out to develop a construction control chart to be used during construction to allow high embankments to be built without compromising on the stability during construction and to meet the tight construction schedule and technical requirements. This paper will present the FEM back analyses results of the fully instrumented trial embankment, the construction control chart developed together with the pre-planned action plan during construction.", "labels": [4, 26]}
{"id": "2220", "token": "The succession of events after revegetation has rarely been studied. A plant consortium with a good initial development may come to be inadequate later, resulting in exposed soil, susceptible to the weathering forces. The objective of this study was to monitor characteristics associated with vegetative stabilization and, in the long term, the appearance of new cover forms or soil exposure in response to planting grasses and legumes on a steep road slope alongside a highway. After four years of recovery, new forms of soil cover or exposure were observed in the experimental plots, called typologies, described below: brachiaria grass cover, legume plants, gordura grass, invasive species, geotextile, decomposing residues, microphytic crusts, soil crust, exposed soil, erosion, and rock outcrops. The characteristics of these typologies were quantified by two surveys, before and after the rainy season. In addition, the different typologies of each experimental plot were mapped; these maps were used to analyze the dynamics, spatial distribution, frequency, and competition among typologies identified in the two surveys. Of the total 11 typologies, the vegetation species and microphytic crusts were the most relevant for revegetation. Microphytic crusts were very important in the initial stage of ecological succession, resulting in rapid stabilization and reclamation of degraded surfaces and favoring the appearance of invasive species. The seasonal variation between the two surveys showed that erosion and soil exposure decreased with increase in vegetation cover and microphytic crust development.", "labels": [4, 26]}
{"id": "2434", "token": "Soil and carbon redistribution on arable land and the associated impacts on carbon sequestration and mineralisation may play an important role in the global carbon cycle. While our insight in the process-chain of erosion, transport and deposition has significantly grown over recent years, there are still major gaps in understanding making it difficult to make an overall assessment of erosion processes on carbon exchange between the soil and the atmosphere. One issue is the potential effect soil degradation and erosion processes may have on CO2 effluxes at eroding sites. The major goal of this study was therefore to analyse and understand the effects of interrill erosion, soil crusting and soil aggregate breakdown on in situ CO2 effluxes. Therefore a set of rainfall simulations were carried out on bare loess-burden soil with different antecedent soil moisture content. All treatments were compared with controls protected from rain drop impact using a fine-meshed geotextile. As expected, runoff and sediment delivery was significantly larger on bare compared to covered soils, while surface runoff and sediment delivery increased (in most cases) with rising antecedent soil moisture as well as rainfall duration. Crust thickness increased with antecedent soil moisture and rainfall intensity and was in general smaller for the controls. However, variations in crust thickness did not result in significant differences in in situ measured CO2 effluxes. Also the destruction of the soil crust after six to seven days of measurements did not have a significant effect. This leads to the conclusion that crusting and interrill erosion has no or only a minor effect on in situ CO2 effluxes. Nevertheless, it should be recognised that topsoil carbon is preferentially removed due to interrill erosion which may result in additional CO2 release at depositional sites or in stream and/or standing water bodies. (C) 2012 Elsevier B.V. All rights reserved.", "labels": [4, 26]}
{"id": "2534", "token": "Slope supported by gabion and geotextile bag both have a high supporting strength, and with local materials, convenient construction, adaptability, environmental protection, low noise, low engineering cost and other advantages. So, it has a rapid development and wide application. To achieve supporting and retaining structure of a red beds slope to effectively play the role of protection, convenient construction and reduce project cost. Under the same conditions of indoor model, a comparative analysis of the natural slope model without shoring, model supported by geotextile or gabion is carried out. Obtain a conclusion that the protective effect of the gabion is better, specific suggestions on the suitability and construction of the supporting structure of the gabion are put forward.", "labels": [4, 26]}
{"id": "2583", "token": "In this article, through aeolian sand sample study in Inner Mongolia Baotou area, to determine the aeolian sand maximum dry density and optimum moisture content. On this basis, the aeolian sand cohesion and internal friction angle were measured by the quick direct shear test when aeolian sand was at the optimum moisture content and near the most largest compactness. And the bearing capacity of retaining wall model which regarded aeolian sand as fillers was determined. Then bearing capacity change of aeolian sand wrapped before and after was compared. Experimental results showed that: when the aeolian sand was in the wet and compacted state, its cohesion was 3.31 kPa and internal friction angle was 36.8 degrees. The aeolian sand bearing capacity was 153.8kPa by the plate loading test. The aeolian sand wrapped with a geotextile bearing capacity was 194.1kPa. Through the aeolian sand research of Baotou area, it provides a useful reference for the construction of highway and railway and application of wrap-reinforced retaining wall which is a new retaining structure in the region, and the aeolian sand is treated as a special filling material in these structures.", "labels": [4, 26]}
{"id": "2711", "token": "Construction of roads in soft soils is often associated with design and construction difficulties due to their compressibility nature and weak strength. Road pavements in such areas when subjected to traffic loading that are static and dynamic in nature experience a rapid deterioration of the base material and progressive permanent surface deformation. Both reduce serviceability, and subsequently, the design life of the pavement. In this study, reinforcement geosynthetics (geogrids and geotextiles) were used as reinforcement inclusions within a granular base underlying a soft subgrade having a California Bearing Ratio less than 2 % in a 1.0 m(3) steel test box. Bench scale plate load tests (static and cyclic) were conducted on a 305mm diameter circular steel plate on the two-layer system using a Universal Compression Machine. Static loading was applied at a rate of 1.2 mm/min. Dynamic sinusoidal load was superimposed atop a static hold down force of 4 kN. The dynamic load was linearly increased with an incremental load of 4 kN for every 8 cycles at a frequency of 0.2 Hz. For the tests, settlement failure of the composite system was considered at a deformation of 75mm as prescribed for unpaved roads. The results showed that there was a significant improvement in bearing capacity and reduction in settlement accruing from geosynthetic inclusion as shown by the bearing capacity ratio (BCR) of 1.21, 1.29, and 1.63 for geogrid, geotextile, and geogrid-geotextile combinations, respectively. Additionally, a settlement reduction factor (SRF) of 18 % for geogrid, 23 % for geotextile, and 31 % for the geogrid-geotextile combination resulted. There was also an improvement in extended pavement life as depicted by the traffic benefit ratio (TBR) greater than 1 for all reinforced base layers. Comparing geotextile and geogrid reinforced pavements, the results showed that geosynthetic tensile strength is not the governing performance indicator.", "labels": [4, 26]}
{"id": "2778", "token": "Compacted clay liners are vulnerable to desiccation cracking if exposed to atmospheric conditions for extended periods of time. Three clayey soils typically used as landfill liners were studied in relatively large-scale containers exposed to real atmospheric conditions for a full annual cycle. Desiccation cracking and particularly the variation in depth of cracks were examined in soil pairs; one set was directly exposed to atmospheric conditions and the other covered with a white separator geotextile. Cracks started to grow deeper in time with some variations with rainfall events up to a few months followed by no significant increase later. Smaller crack depths were observed for the soil with the lowest plasticity index. Using a geotextile cover resulted in 35-79% reduction in average crack depth. Hydraulic conductivity of the soils increased at the end of the experiment with greater increase for soils with deeper cracks. (C) 2016 American Society of Civil Engineers.", "labels": [4, 26]}
{"id": "2809", "token": "Reinforced soil is a composite material in which elements of high tensile resistance are implemented to increase the tensile resistance of the soil. Geotextiles are one of the major groups of geosynthetic products that are used for soil reinforcement. This paper deals with the effects of using nonwoven geotextile to improve the ultimate bearing capacity of footings resting on sand with medium density. The plate load tests were performed using 27 cm x 27 cm and 35 cm x 35 cm square plates, and the effects of the depth of the first layer of geotextile, vertical spacing as well as the number of geotextile layers on the ultimate bearing capacity of the footings were studied. Moreover, the impact of plate size and sample size was examined numerically by performing 3-D finite element analyses with different sizes of the square plate. The experimental results showed that the maximum bearing capacity is achieved for the system with four geotextile layers, vertical spacing of 0.3B between geotextile layers and geotextile width of 4B, where B is the width of the plate. The numerical analyses indicated that with increasing the size of the plate up to 65 cm, the values of the bearing capacity ratio (BCR) gradually decrease; however, additional increase in the size of the plate has a little impact on BCR values.", "labels": [4, 26]}
{"id": "3112", "token": "In this article, the load-settlement characteristics of unreinforced and reinforced two-layered soil during the loading process are investigated. A series of bearing ratio tests was performed on a granular soil as the base layer overlaying a cohesive soil as the subgrade layer. Three reinforcing conditions (unreinforced, reinforced with nonwoven geotextile, and reinforced with geogrid) at the interface of layers, with four compaction moisture contents (CMCs) of the subgrade layer and three thicknesses of the base layer for both soaked and non-soaked conditions are considered. The results show that the CMC of the subgrade layer has a significant effect on the behavior of two-layered soil, such as swelling amount and the efficiency of the reinforcements. Reinforcing with geogrid resulted in a considerable increase in strength of the soaked samples due to adhesion between geogrids and clayey subgrade layer. For nonwoven geotextiles, strength of the two-layered soil decreased at shallow penetration depths due to reinforcements; and as the penetration increased in depth, the strength also increased. Also, it was found that with decreases in base layer thickness, the test variable's value (i.e., CMC), and the type of geosynthetic reinforcement have significant effects on the behavior of two-layered soil.", "labels": [4, 26]}
{"id": "3245", "token": "To investigate the reflective crack-propagation behavior and provide control techniques for asphalt pavements widening, the finite-element models were built to simulate the widened asphalt pavement with a latent joint. The developed finite-element model considered the influence factors, including the loading modes (i.e., the symmetrical and unsymmetrical loading modes), the thickness and modulus of the asphalt concrete surface, the modulus of the new and existing stabilized bases, and the sheet stiffness of the reinforced geosynthetic. The finite-element simulation results show that increasing the thickness or reducing the modulus of the asphalt concrete surface effectively delays the propagation speed of the reflective cracks. The cracking potential reaches the minimum when the new and existing bases have a uniform modulus. Additionally, geosynthetic reinforcement across the joints significantly reduces the stress concentration around the crack tip and slows down the propagation of the reflective cracks. These benefits become greater when increasing the sheet stiffness of the geosynthetic. Finally, an experimental study was conducted to investigate the influence of the types of the asphalt overlay and the geosynthetic reinforcement on the reflective crack-propagation behavior. The experimental results indicate that the geosynthetic-reinforced structure with a lower modulus of the asphalt concrete surface significantly increases the fatigue life of widened pavements, and the polypropylene geotextile performs better than the glass-fiber grid in terms of the extension of the fatigue life.", "labels": [4, 26]}
{"id": "3330", "token": "Slope instability due to rainwater infiltration poses a serious problem, and causes thousands of deaths and severe damage to infrastructures each year. In the present study, the effect of inclusion of hybrid-geosynthetic layers within a slope subjected to rainfall was investigated numerically. The analysis was done with and without hybrid-geosynthetic layers embedded in a silty sand slope having 2V:1H inclination with rainfall intensities ranging from 2 mm/h to 80 mm/h. The rainfall was simulated numerically for 24 h, and seepage, deformation and stability analyses were performed at the onset of rainfall, during rainfall, and up to 24 h after rainfall. Further, the need for both drainage and reinforcement function in the reinforced slope was highlighted by analysing the effect of geotextile and geogrid layer inclusions separately on the slope subjected to rainfall. The results indicate that, the inclusion of hybrid-geosynthetic layers was effective, as it lowered the phreatic surface by causing a reduction in excess pore water pressure. Further, the static global stability of a hybrid-geosynthetic-reinforced slope was found to increase considerably under all intensities of rainfall, while the deformation values were significantly lower for the reinforced slope as compared with that of the unreinforced slope.", "labels": [4, 26]}
{"id": "3402", "token": "The global growth of Geosynthetics for the last few decades or so has been substantially enhancing at an average of 10% per annum. Within the domain of geotextile, jute geotextile (JGT), a class of natural technical textile has carved out a niche in this emerging technology. Though far behind its man-made counterpart in growth, its effectiveness in addressing a host of different geotechnical problems and more importantly its eco-congruity is gaining increasing acceptability worldwide. The major uses of JGT are in road construction - low- and medium-volume roads in particular, soil erosion control, etc. Traditional sacking quality jute-woven fabrics (both plain and twill weaves) are being used in the above-mentioned applications. But use of conventional jute sacking fabrics being not application-specific and function-oriented deserves rethinking on adoption of the conventional jute fabrics used for flexible packaging in road construction, soil erosion control as well as other geotechnical construction. It is in this context that development of potentially important JGT for strengthening rural roads as well as in river bank protection assumes significance. It was realized that such JGT should be woven whose property parameters should be functionally apt for serving the purpose. The paper outlines a structured approach to fabric engineering related to JGT in tune with different prime parameters of design concerning rural road construction and river bank protection along with optimization and standardization of the fabric by comparative analysis of the different tests results of property parameters of the developed JGT samples.", "labels": [4, 26]}
{"id": "11", "token": "The purpose of this study was to compare personality traits using the Big Five personality taxonomy and alcohol consumption of classical and heavy metal musicians. Also, we compared personality traits of classical and heavy metal musicians with norms for the Croatian population, and data on alcohol consumption with a representative sample of the general Croatian population. Participants in the study were men (N = 249) playing either classical (N = 113) or heavy metal music (N = 136). Personality was measured with the IPIP-50 personality questionnaire and participants answered several questions about alcohol consumption. We found no significant differences in personality traits between classical and heavy metal musicians, but both classical and heavy metal musicians differed significantly in personality from the norms, having higher scores on extraversion, agreeableness, and especially intellect. Belonging to a heavy metal musicians group was associated with consuming alcohol more often. Also, frequency of alcohol consumption was statistically higher for heavy metal musicians than in the general population.", "labels": [5, 30]}
{"id": "88", "token": "Addictions, including alcohol use disorders, are characterized by the loss of control over drug seeking and consumption, but the neural circuits and signaling mechanisms responsible for the transition from controlled use to uncontrolled abuse remain incompletely understood. Prior studies have shown that compulsive-like' behaviors in rodents, for example, persistent responding for ethanol (EtOH) despite punishment, are increased after chronic exposure to EtOH. The main goal of the current study was to assess the effects of chronic intermittent EtOH (CIE) exposure on multiple, putative measures of compulsive-like EtOH seeking in C57BL/6J mice. Mice were exposed to two or four weekly cycles of CIE and then, post-withdrawal, tested for progressive ratio responding for EtOH, sustained responding during signaled EtOH unavailability and (footshock) punished suppression of responding for EtOH. Results showed that mice exposed to CIE exhibited attenuated suppression of EtOH seeking during punishment, as compared with air-exposed controls. By contrast, CIE exposure affected neither punished food reward-seeking behavior, nor other putative measures of compulsive-like EtOH seeking. Ex vivo reverse transcription polymerase chain reaction analysis of brain tissue found reduced sensitivity to punished EtOH seeking after CIE exposure was accompanied by a significant increase in gene expression of the GluN1 and GluN2A subunits of the N-methyl-d-aspartate receptor, specifically in the medial orbitofrontal cortex. Moreover, slice electrophysiological analysis revealed increased N-methyl-d-aspartate receptor-mediated currents in the orbitofrontal cortex after CIE exposure in test-naive mice. Collectively, the current findings add to the growing body of evidence demonstrating that chronic exposure to EtOH fosters resistance to punished EtOH seeking in association with adaptations in cortical glutamatergic transmission.", "labels": [5, 30]}
{"id": "219", "token": "Oxycodone DETERx (R) (Collegium Pharmaceutical Inc, Canton, Massachusetts) is an extended-release, microsphere-in-capsule, abuse-deterrent formulation designed to retain its extended-release properties after tampering (eg, chewing/crushing). This randomized, double-blind, placebocontrolled, triple-dummy study evaluated the oral abuse potential of intact and chewed oxycodone DETERx capsules compared with crushed immediate-release oxycodone. Subjects with a history of recreational opioid use who were nondependent/nontolerant to opioids were enrolled. Treatments included intact oxycodone DETERx (high-fat, high-calorie meal and fasted), chewed oxycodone DETERx (high-fat, high-calorie meal and fasted), crushed immediate-release oxycodone (fasted), and placebo (high-fat, high-calorie meal). Plasma samples were collected to determine pharmacokineticparameters. The primary endpoint was drug liking at the moment; other endpoints included drug effects questionnaire scores, Addiction Research Center Inventory/Morphine Benzedrine Group score, pupillometry measurements, and safety. Thirty-eight subjects completed the study. Chewed and intact oxycodone DETERx were bioequivalent, unlike crushed immediate-release oxycodone, which yielded higher peak oxycodone plasma concentrations compared with all methods of oxycodone DETERx administration. The mean maximum (peak) effect (Emax)for drug liking was significantly lower for chewed and intact oxycodone DETERx than for crushed immediate-release oxycodone (P < .01). The time to Emax was significantly longer for chewed and intact oxycodone DETERx than for crushed immediate-release oxycodone (P < .0001). Scores for feeling high and Addiction Research Center Inventory/Morphine Benzedrine Group scores demonstrated lower abuse potential for chewed and intact oxycodone DETERx compared with crushed immediate-release oxycodone. Study treatments were well tolerated; no subjects experienced serious adverse events. These results demonstrate the lower oral abuse potential of chewed and intact oxycodone DETERx than crushed immediate-release oxycodone.", "labels": [5, 30]}
{"id": "369", "token": "Background and aimsCognitive impairment has been associated with excessive alcohol use, but its neural basis is poorly understood. Chronic excessive alcohol use in adolescence may lead to neuronal loss and volumetric changes in the brain. Our objective was to compare the grey matter volumes of heavy- and light-drinking adolescents. DesignThis was a longitudinal study: heavy-drinking adolescents without an alcohol use disorder and their light-drinking controls were followed-up for 10 years using questionnaires at three time-points. Magnetic resonance imaging was conducted at the last time-point. SettingThe area near Kuopio University Hospital, Finland. ParticipantsThe 62 participants were aged 22-28years and included 35 alcohol users and 27 controls who had been followed-up for approximately 10 years. MeasurementsAlcohol use was measured by the Alcohol Use Disorders Identification Test (AUDIT)-C at three time-points during 10years. Participants were selected based on their AUDIT-C score. Magnetic resonance imaging was conducted at the last time-point. Grey matter volume was determined and compared between heavy- and light-drinking groups using voxel-based morphometry on three-dimensional T1-weighted magnetic resonance images using predefined regions of interest and a threshold of P<0.05, with small volume correction applied on cluster level. FindingsGrey matter volumes were significantly smaller among heavy-drinking participants in the bilateral anterior cingulate cortex, right orbitofrontal and frontopolar cortex, right superior temporal gyrus and right insular cortex compared to the control group (P<0.05, family-wise error-corrected cluster level). ConclusionsExcessive alcohol use during adolescence appears to be associated with an abnormal development of the brain grey matter. Moreover, the structural changes detected in the insula of alcohol users may reflect a reduced sensitivity to alcohol's negative subjective effects.", "labels": [5, 30]}
{"id": "394", "token": "Cocaine users characteristically display preferences for smaller immediate rewards over larger delayed rewards, and this delay discounting (DD) has been proposed as an endophenotype of cocaine addiction. Recent evidence suggests that the norepinephrine system and more specifically the alpha 2A-adrenergic receptor (ADRA2A) are impacted by chronic cocaine use while also being potentially involved in the neural mechanisms underlying DD. Hence, we investigated the effects of ADRA2A polymorphisms and ADRA2A mRNA expression levels on DD of cocaine users and stimulant-naive controls. Two hundred and twenty-three participants (129 cocaine users and 94 stimulant-naive healthy controls) completed a computerized DD paradigm and were genotyped for three single nucleotide polymorphisms (SNPs; rs1800544, rs521674 and rs602618) in the ADRA2A gene, while their peripheral ADRA2A mRNA expression was quantified in whole blood samples. The three SNPs were in near-perfect linkage disequilibrium. Accordingly, significant group*genotype interactions were found for all three ADRA2Avariants revealing steeper DD in cocaine users (but not in controls) carrying the G-allele of SNP rs1800544, the T-allele of rs521674 and the C-allele of rs602618. Similarly, high ADRA2A mRNA expression levels were significantly associated with a reduced tendency to choose smaller more immediate rewards (over larger delayed rewards) in cocaine users but not in controls. As the relationship between DD and cocaine use was moderated by ADRA2A SNPs and by peripheral ADRA2A gene expression, we propose that the norepinephrine systemis involved in DD deficits observed in cocaine using individuals. Consequently, pharmacological compounds targeting ADRA2Asmight be considered for the symptom-specific treatment of delay aversion in stimulant addiction.", "labels": [5, 30]}
{"id": "476", "token": "OBJECTIVE There is increasing interest in neuromodulation for addiction. Methamphetamine abuse is a global health epidemic with no proven treatment. The objective of this study was to examine the effects of intermittent nucleus accumbens shell (AcbSh) deep brain stimulation (DBS) on operant methamphetamine intake and on methamphetamine seeking when stimulation is delivered in an environment different from that of drug use. METHODS Eighteen rats were implanted with intravenous (IV) catheters and bilateral AcbSh electrodes and subsequently underwent daily sessions in 2-lever (active/methamphetamine and inactive/no reward) operant chambers to establish IV methamphetamine self-administration. After stable responding was achieved, 3 hours of DBS or sham treatment was administered (sham: 0 mu A, n = 8; active: 200 mu A, n = 10) in a separate nondrug environment prior to the daily operant sessions for 5 consecutive days. Immediately following each DBS/sham treatment, rats were placed in the operant chambers to examine the effects of remote stimulation on methamphetamine intake. After the 5 days of therapy were finished, rats reestablished a posttreatment baseline, followed by extinction training, abstinence, and 1 day of relapse testing to assess methamphetamine-seeking behavior. RESULTS There was a decrease in total methamphetamine intake in rats receiving active DBS versus sham on Days 1 (42%) and 2 (44%). Methamphetamine administration returned to baseline levels following the cessation of DBS therapy. Compared with baseline drug responding, methamphetamine seeking was reduced (57%) in the DBS group but not in the sham group. CONCLUSIONS It is feasible to deliver noncontinuous DBS outside of the drug use environment with a resultant decrease in IV methamphetamine intake and seeking. The AcbSh is a neuroanatomical substrate for psychostimulant reinforcement and may be a target for intermittent neuromodulatory therapies that could be administered during brief periods of sobriety.", "labels": [5, 30]}
{"id": "533", "token": "BackgroundIf people do not recognize posttraumatic stress disorder (PTSD) symptoms, they may not realize they are suffering from the disorder. Likewise, if people do not know that effective treatments exist, they may be unlikely to seek care. This study examined what people with PTSD symptoms know about PTSD and its treatment. We hypothesized that military service and prior receipt of PTSD treatment would be associated with greater PTSD knowledge. MethodsWe conducted an online survey assessing knowledge in three domains: trauma, PTSD symptoms, and effective PTSD treatments. Participants were 301 adults (50% veterans) who were drawn from a national research panel and screened positive for PTSD. ResultsWhen asked to identify items from a list, participants had better recognition for traumatic events (M = 72.2% of items correct) and PTSD symptoms (M = 62.3%) than for effective PTSD treatments (M = 37.9%). Across domains, participants often identified false items as true. Most participants thought divorce was a trauma that could cause PTSD, that drug addiction was a PTSD symptom, and that support groups are effective PTSD treatments. Prior receipt of PTSD treatment was associated with better symptom recognition (b = .86, P = .003). Being a military veteran was associated with better trauma recognition (b = .56, P = .025), but poorer treatment recognition (b = -.65, P = .034). ConclusionsPeople with PTSD symptoms lack knowledge about the disorder, especially regarding effective treatments. Public education about PTSD is needed so that people recognize when to seek care and which treatments to choose.", "labels": [5, 30]}
{"id": "618", "token": "It has been demonstrated that people suffering from substance-related addictions are less empathic than their non-addicted counterparts. Our first aim was to verify if this is also true for behavioral addictions. We hypothesized that problem gamblers are less empathic than healthy controls. Our second aim was to identify a cognitive marker of empathy that could be targeted in cognitive rehabilitation strategies. We propose that a potential cognitive marker of empathy could be visuospatial perspective-taking. Specifically, we hypothesized that visuospatial perspective-taking performances are lower in problem gamblers compared to healthy controls and that these visuospatial performances predict empathy. Thirty-one non-gamblers, 24 healthy gamblers, and 21 problem gamblers performed a visuospatial perspective-taking task before completing the Interpersonal Reactivity Index (IRI; Davis, 1980; Davis, 1983). Problem gamblers had decreased empathy and lower performance at the visuospatial perspective-taking task than non-gamblers and healthy gamblers. Furthermore, we confirmed that visuospatial perspective-taking abilities predict empathy on the IRI dimensions of interpersonal perspective-taking and personal distress. The present study provides new evidence that reduced empathy is not limited to subjects with substance-related addictions; rather, it extends to behavioral addictions. Visuospatial perspective-taking may be a viable cognitive marker for use as a rehabilitation target of empathy.", "labels": [5, 30]}
{"id": "779", "token": "The review examines Attention Deficit Hyperactivity Disorder (ADHD in its Child and Adult form) and its various presentations (Hyperactive Impulsive, Inattentive, and Combined) with a particular focus on environmental (incl. social factors), lifestyles and comorbidities. It is argued that ADHD is best understood in a holistic and interactive context and a vast empirical literature is presented to illustrate the point: Environmental factors include stress in general as well as exposure to toxins (phthalates, bisphenol A). Social factors are illustrated by effects of social deprivation and seduction to unhealthy lifestyles. Maternal lifestyle during pregnancy is pointed out (particularly her exposure to nicotine, alcohol, caffeine, and drugs, even seemingly benign medications like acetaminophen), which all tend to be related to ADHD. Family environment is discussed with respect to protective effect of (mainly authoritative and autocratic) parenting styles. Societal factors include mainly economic and political issues: income inequality and poverty (low SES is an ADHD risk factor) and a growing moral dilemma between a humanistic effort to globally spread the knowledge of ADHD and the medicalization and commercialization of the disorder. The second part of the review is devoted to ADHD related lifestyles and resulting comorbidities (e.g., food addiction and obesity, substance abuse, electronic media dependencies and conduct and personality disorders). Although ADHD is a neurodevelopmental disorder, its assessment and treatment are also linked to environmental, behavioral and social factors and their interactions.", "labels": [5, 30]}
{"id": "942", "token": "The aim of this study was to evaluate the association between crack/cocaine addiction and dental health in men. Forty crack/cocaine-addicted patients and 120 nonaddicted patients (>= 18 years) underwent full-mouth dental examinations. Decayed, missing, and filled teeth (DMFT) were identified using the criteria recommended by the World Health Organization. Crack/cocaine addiction was determined, based on the medical records and interviews of each patient. All drug-addicted patients used both crack and cocaine. The chi-square test and logistic regression analysis were used to assess the association between DMFT and crack/cocaine addiction (p <= 0.05). Decayed teeth showed a positive association with crack/cocaine addiction (odds ratio (OR) = 3.65; 95% confidence interval (CI), 1.68-7.92; p = 0.001), whereas filled and missing teeth showed a negative association ( filled teeth: OR = 0.37; 95% CI, 0.18-0.76; p = 0.008; missing teeth: OR = 0.33; 95% CI, 0.13-0.81; p = 0.02). The DMFT was only associated with age (OR = 2.12; 95% CI, 1.11-4.08, p = 0.023). In the present population, crack/cocaine addiction was associated with a greater decayed teeth index and a lower filled and missing teeth index. Programs aimed to encourage self-esteem and encourage individuals to seek dental care are required for this population. Further studies using a larger sample size and studies with women are required to confirm the results.", "labels": [5, 30]}
{"id": "1034", "token": "Background: Ukraine's HIV epidemic is concentrated among people who inject drugs (PWID), however, coverage with opioid agonist therapies (OATS) available mostly at specialty addiction clinics is extremely low. OAT integrated into primary healthcare clinics (PHCs) provides an opportunity for integrating comprehensive healthcare services and scaling up OAT. Methods: A pilot study of PHC-based integrated care for drug users conducted in two Ukrainian cities between 2014 and 2016 included three sub-studies: 1) cross-sectional treatment site preference assessment among current OAT patients (N=755); 2) observational cohort of 107 PWID who continued the standard of care versus transition of stabilized and newly enrolled PWID into PHC-based integrated care; and 3) pre/post analysis of attitudes toward PWID and HIV patients by PHC staff (N=26). Results: Among 755 OAT patients, 53.5% preferred receiving OAT at PHCs, which was independently correlated with convenience, trust in physician, and treatment with methadone (vs. buprenorphine). In 107 PWID observed over 6 months, retention in treatment was high: 89% in PWID continuing OAT in specialty addiction treatment settings (standard of care) vs 94% in PWID transitioning to PHCs; and 80% among PWID newly initiating OAT in PHCs. Overall, satisfaction with treatment, subjective self-perception of well-being, and trust in physician significantly increased in patients prescribed OAT in PHCs. Among PHC staff, attitudes towards PWID and HIV patients significantly improved over time. Conclusions: OAT can be successfully integrated into primary care in low and middle-income countries and improves outcomes in both patients and clinicians while potentially scaling-up OAT for PWID. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [5, 30]}
{"id": "1093", "token": "BACKGROUND: Cocaine addiction is characterized by patterns of compulsive drug-taking, including preoccupation with obtaining cocaine and loss of control over drug intake. The lateral hypothalamic hypocretin/orexin (HCRT) system has been implicated in drug-taking and the reinstatement of drug-seeking. Evidence suggests that HCRT may drive drug-seeking through activation of specific brain regions implicated in stress system dysfunction, including the central amygdala (CeA). The role of HCRT in the persistence of compulsive-like cocaine-taking has yet to be fully elucidated. METHODS: Systemic and intra-CeA microinfusions of the HCRT-receptor 1 antagonist, SB-334867, were administered to rats allowed either short (1 hour; ShA) or long (6 hours; LgA) access to cocaine self-administration. Animals were tested for fixed and progressive ratio responding for cocaine and stress-induced reinstatement of drug-seeking. In addition, using electrophysiological techniques on in vitro slices, we investigated gamma-aminobutyric acidergic (GABAergic) neurotransmission in the medial CeA and the sensitivity of GABAergic synapses to modulation of the HCRT system in ShA or LgA rats. RESULTS: We found systemic administration of SB-334867 (0, 7.5, 15, 30 mg/kg) dose dependently decreased cocaine intake specifically in LgA rats but not in ShA rats. Microinjections of SB-334867 (20 nmol) bilaterally into the CeA significantly reduced cocaine intake in LgA rats. We also observed a significant attenuation of yohimbine-induced reinstatement of cocaine-seeking after intra-CeA SB-334867 (10 nmol) administration. Finally, electrophysiological data indicated enhanced GABAergic neurotransmission within the medial CeA in LgA rats, which was blocked with SB-334867(10 mu mol/L). CONCLUSIONS: These findings suggest that HCRT neurotransmission within the CeA is implicated in compulsive-like cocaine-seeking.", "labels": [5, 30]}
{"id": "1221", "token": "Background and aimsBarriers linked to drug control systems are considered to contribute to inequitable access to controlled medicines, leaving millions of people in pain and suffering. Most studies focus on access to opioids for the treatment of severe (cancer) pain. This study aims to identify specific access barriers for patients with opioid dependence in legislation and regulations of 11 central and eastern European countries. MethodsThis study builds on a previous analysis of legislation and regulations as part of the EU 7th Framework Access To Opioid Medication in Europe (ATOME) project. An in-depth analysis was undertaken to determine specific barriers for patients with opioid dependence in need of opioid analgesics or opioid agonist therapy (OAT). For each country, the number and nature of specific potential barriers for these patients were assessed according to eight categories: prescribing; dispensing; manufacturing; usage; trade and distribution; affordability; penalties; and other. An additional keyword search was conducted to minimize the omission of barriers. Barriers in an additional category, language, were recorded qualitatively. Countries included Bulgaria, Cyprus, Estonia, Greece, Hungary, Latvia, Lithuania, Serbia, Slovakia, Slovenia and Turkey. ResultsTen of the 11 countries (all except Estonia) showed specific potential barriers in their legislation and regulations. The total number of barriers varied from two (Slovenia) to 46 (Lithuania); the number of categories varied from one (Slovenia) to five (Lithuania). Most specific potential barriers were shown in the categories prescribing', usage' and other'. The total number in a single category varied from one to 18 (Lithuania, prescribing). Individual differences between countries in the same specific potential barrier were shown; for example, variation in minimum age criteria for admission to OAT ranging from 15 (Lithuania, in special cases) to 20years (Greece). All countries had stigmatizing language in their legislation. ConclusionsPatients with opioid dependence are likely to experience specific barriers to accessing opioids in addition to those experienced by other non-dependent patients.", "labels": [5, 30]}
{"id": "1377", "token": "Background and AimsDysfunction in brain regions underlying impulse control, reward processing and executive function have been associated previously with adolescent alcohol misuse. However, identifying pre-existing neurobiological risk factors, as distinct from changes arising from early alcohol-use, is difficult. Here, we outline how neuroimaging data can identify the neural predictors of adolescent alcohol-use initiation and misuse by using prospective longitudinal studies to follow initially alcohol-naive individuals over time and by neuroimaging adolescents with inherited risk factors for alcohol misuse. MethodA comprehensive narrative of the literature regarding neuroimaging studies published between 2010 and 2016 focusing on predictors of adolescent alcohol use initiation and misuse. FindingsProspective, longitudinal neuroimaging studies have identified pre-existing differences between adolescents who remained alcohol-naive and those who transitioned subsequently to alcohol use. Both functional and structural grey matter differences were observed in temporal and frontal regions, including reduced brain activity in the superior frontal gyrus and temporal lobe, and thinner temporal cortices of future alcohol users. Interactions between brain function and genetic predispositions have been identified, including significant association found between the Ras protein-specific guanine nucleotide releasing factor 2 (RASGRF2) gene and reward-related striatal functioning. ConclusionsNeuroimaging predictors of alcohol use have shown modest utility to date. Future research should use out-of-sample performance as a quantitative measure of a predictor's utility. Neuroimaging data should be combined across multiple modalities, including structural information such as volumetrics and cortical thickness, in conjunction with white-matter tractography. A number of relevant neurocognitive systems should be assayed; particularly, inhibitory control, reward processing and executive functioning. Combining a rich magnetic resonance imaging data set could permit the generation of neuroimaging risk scores, which could potentially yield targeted interventions.", "labels": [5, 30]}
{"id": "1494", "token": "There is little evidence about barriers to pain management or their relationships with pain outcomes of hospice patients with cancer. The purpose of the study was to determine the barriers reported by hospice patients with cancer and their caregivers and the relationships with demographic characteristics and the patients' pain. In this cross-sectional study, we used selected baseline data from an ongoing randomized clinical trial of patient and lay caregiver dyads receiving home-level hospice care. Participants used an Internet-enabled tablet to complete the valid, reliable measures of pain intensity, pain management barriers (Barriers Questionnaire 13 items [BQ-13]), and demographic characteristics. The responses indicate that the 2 areas of highest concern (mean scores >3) to both patients and caregivers were pain means disease progression and constipation. Additionally, 3 other areas of highest concern (mean scores >3) to caregivers were addiction pain medicine causing one to do embarrassing things and confusion. The mean BQ-13 scores ranged from 0.2 to 4.9 and averaged 2.6 +/- 0.9 for the patients and ranged from 0.5 to 4.7 and averaged 2.7 +/- 0.9 for the caregivers. Mean barrier scores remain high and were not different between patients and their caregivers or significantly related to the patients' pain intensity. However, there were differences in race, ethnic, and hospice setting in the barrier scores. Patients with Hispanic heritage reported higher barrier scores than non-Hispanic patients. Together, these findings not only support prior research findings but also contribute new insights about pain intensity and pain barriers that are relevant to hospices serving minorities with cancer.", "labels": [5, 30]}
{"id": "1641", "token": "Although dysregulation of the dopaminergic mesolimbic system is generally considered central to addiction, the involvement of other circuits is increasingly being appreciated. An interaction between locus coeruleus (LC) noradrenergic neurons and the posterior ventral tegmental area (pVTA) dopaminergic system, in the processing of drug-triggered reward, has been suggested, but not demonstrated in behaving animals. Herein, we try to tease out the precise role of noradrenergic neurons in the LC-VTA circuit in mediating reward and reinforcement behavior associated with ethanol. In the standard two-lever (active/inactive) operant paradigm, the rats were trained to self-administer ethanol in pVTA and subjected to pharmacological intervention. Intra-pVTA administration of phenylephrine (alpha-1 adrenoceptor agonist) increased ethanol self-administration, while prazosin and disulfiram (agents that reduce noradrenergic tone) produced opposite effects. While degeneration [N-(2-chloroethyl)-N-ethyl-2bromobenzylamine hydrochloride, DSP-4, intraperitoneal route] or silencing (lidocaine or muscimol, both via intra-LC route) of the LC noradrenergic neurons decreased, phenylephrine via the intra-LC route reinstated ethanol self-administration. Furthermore, lidocaine reduced ethanol self-administration, but the effect was fully attenuated by noradrenaline given directly in the pVTA. This suggests that the feedback signals from LC to pVTA are necessary to sustain the ethanol self-infusion activity. Ethanol self-administration significantly increased tyrosine hydroxylase immunoreactivity in pVTA and LC; the response was blocked by DSP-4 pre-treatment. While dopamine D1, but not D2, receptors were localized on noradrenergic LC neurons, pre-treatment with SCH-23390 (intra-LC) dampened the lever press activity. We suggest that two-way communications between VTA and LC regions is essential for ethanol-triggered reinforcement behavior.", "labels": [5, 30]}
{"id": "1742", "token": "With the rise of restrictions imposed by law for gases emission, several technologies both for petrodiesel (PD) or diesel engines are been applied, such as the sulfur reduction and the injection electronic command, followed of gases recirculation and/or after-treatment. The utilization of biofuels is considered as an interesting option for pollutants reduction. In this study was evaluated the performance on short duration tests (minor period than the factory indication of the lubricant lifespan) of the Diesel engine fueled with four vegetable oils. With the aim to select the most interesting oils for future evaluations in long duration tests. The analyzed variables were fuel consumption, power relative loss and opacity, for oils of linseed, crambe, rapseed, jatropha, with 100 degrees C preheating and engine work temperature (60 degrees C) comparing those with the PD. It was verified that the vegetable oils, on average, present a lower consumption than the PD for the cases of working without load, however with load, they presented higher consumption. In addiction were observed that the oils show a higher relative power loss in relation of PD and provides lower emission of particulate matter. Crambe and canola presented the best performance among the evaluated oils.", "labels": [5, 30]}
{"id": "1947", "token": "Objective: Childhood maltreatment is widely accepted as a risk factor for drug addiction from adolescence to adulthood. However, the influence of childhood maltreatment on drug treatment related variables, such as drug abstinence motivation and self-concept, as well as self-efficacy, remains unclear. This study aims at exploring whether self-concept mediates the relationship between childhood maltreatment and abstinence motivation, as well as self-efficacy, among drug addicts. Methods: This study involves 816 (550 males, 226 females, mean age = 34.59, range = 16-58 years) drug addicts from compulsory detoxification units. Participants completed questionnaires, including the childhood trauma questionnaire 28- item short form (CTQ- SF), Tennessee self-concept scale (TSCS), general self-efficacy scale (GSES), and drug abstinence motivation questionnaire (DAMQ). Results: The structural equation model (SEM) analysis, including total and specific forms of maltreatment scores, showed that childhood maltreatment was negatively associated with self-concept, self-efficacy, and abstinence motivation. Self-concept was positively associated with self-efficacy and abstinence motivation. Conversely, significant association between self-efficacy and abstinence motivation did not exist. An indirect analysis showed that self-concept mediated the relationship between childhood maltreatment and self-efficacy. Critically, selfconcept arbitrated the relationship between childhood maltreatment and abstinence motivation. The indirect effect of self-concept between childhood maltreatment and abstinence motivation still existed when the total scores of maltreatment were replaced by the scores of specific forms of maltreatment. Conclusions: These results demonstrated that self-concept is a critical factor in understanding the relationship between childhood maltreatment and abstinence motivation, as well as self-efficacy, among drug addicts. Improving the sense of self-worth may be an effective intervention therapy among drug addicts with childhood maltreatment history. (C) 2017 Elsevier Ltd. All rights reserved.", "labels": [5, 30]}
{"id": "2031", "token": "Amphetamine and other drugs of abuse have both short-term and long-lasting effects on brain function, and drug sensitization paradigms often result in chronic impairments in behavioral flexibility. Here we show that acute amphetamine administration temporarily renders rats less sensitive to reward omission, as revealed by a decrease in lose-shift responding during a binary choice task. Intracerebral infusions of amphetamine into the ventral striatum did not affect lose-shift responding but did increase impulsive behavior in which rats chose to check both reward feeders before beginning the next trial. In contrast to acute systemic and intracerebral infusions, sensitization through repeated exposure induced long-lasting increased sensitivity to reward omission. These treatments did not affect choices on trials following reward delivery (i.e. win-stay responding), and sensitization increased spine density in the sensorimotor striatum. The dichotomous effects of amphetamine on short-term and long-term loss sensitivity, and the null effect on win-stay responding, are consistent with a shift of behavioral control to the sensorimotor striatum after drug sensitization. These data provide a new demonstration of such a shift in a novel task unrelated to drug administration, and suggests that the dominance of sensorimotor control persists over many hundreds of trials after sensitization. This article is part of a Special Issue entitled: Cognitive Flexibility. (C) 2016 IBRO. Published by Elsevier Ltd. All rights reserved.", "labels": [5, 30]}
{"id": "2258", "token": "Objective: The aims of this study are to clarify the state of information regarding opioids for families and what kinds of experiences they had with opioids while the patient was followed as an outpatient and inpatient. Participants: This study was part of a cross-sectional nationwide survey of bereaved families of patients with cancer, namely, the Japan Hospice and Palliative Care Evaluation 2 study. The participants in this study comprised 572 bereaved families who had experienced the death of a family member during the period from January 2008 to December 2009 at 1 of 103 certificated palliative care units. Main Outcome Measures: In response to the question of how much improvement was needed for information regarding opioids, 41% answered improvement is not necessary at all, 43% answered improvement is slightly necessary, 14% answered improvement is necessary, and 2% answered improvement is extremely necessary. Regarding anxiety about the use of opioid, it was found that 14% of respondents indicated opioids are very safe, 65% of respondents indicated opioids are relatively safe, 19% of respondents indicated opioids are not so safe, and 2% of respondents indicated opioids are not so safe at all. from the information obtained for opioids. It was found that 90% of families agreed with the item, I would like to be clearly explained that drugs for medical purposes are safe and that the patient will not develop a drug addiction and their life expectancy will not be reduced. Conclusion: From this study, it is important for families of patients with cancer to be explained profound and careful information of opioid.", "labels": [5, 30]}
{"id": "2387", "token": "Hookah tobacco smoking (HTS) has been increasing, particularly among young adults and has similar health effects compared to cigarette smoking. The link between HTS and poly-tobacco use is well documented, but fewer show an association between HTS and alcohol use. It is essential to identify factors that increase the risk for or addictiveness and consequences of HTS, given its growing prevalence. This study examined whether the association between HTS and poly-tobacco use differed as a function of age and alcohol consumption within in a sample of 1223 adult cigarette smokers. Approximately 20% of participants reported HTS. Compared to non-users, hookah users were more likely to be male, highly educated, and to report drug and alcohol use, binge drinking, and poly-tobacco use but were less likely to be heavy smokers (>= 10 cigarettes per day). Regression analyses predicting number of tobacco products used (excluding cigarettes and HTS) indicated a three-way interaction of HTS, frequency of alcohol use, and age such that the association between HIS and number of tobacco products used was strongest for younger respondents who consumed alcohol more frequently. As observed in previous studies, alcohol is an important risk factor in the relationship between HTS and poly-tobacco use, particularly among younger cigarette smokers. The links between alcohol, HTS, and poly-tobacco use should be considered when developing HTS education and prevention materials directed toward younger cigarette smokers. Findings provide information relevant to FDA's interest in the addiction potential of HTS and its link to poly-tobacco use. (C) 2017 Elsevier Ltd. All rights reserved.", "labels": [5, 30]}
{"id": "2545", "token": "This study was aimed to test the association between perceived stress and problematic social networking site (SNS) usage, and to figure out whether psychological resilience moderated this relationship. The Perceived Stress Scale, Connor-Davidson Resilience Scale, and Facebook Intrusion Questionnaire were administered to 499 Chinese college students. The results showed that (1) perceived stress was positively associated with problematic SNS usage; (2) psychological resilience was negatively related with problematic SNS usage; and (3) psychological resilience moderated the relationship between perceived stress and problematic SNS usage. Specifically, the relationship between perceived stress and problematic SNS usage was statistically significant for students with a lower level of psychological resilience, while no significant association was found for those with a higher level of psychological resilience. The findings emphasize the importance of enhancing psychological resilience to decrease the likelihood of college students who experience higher level of stress from using SNS problematically. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [5, 30]}
{"id": "2727", "token": "Cocaine dependence frequently co-occurs with personality disorders, leading to increased interpersonal problems and greater burden of disease. Personality disorders are characterised by patterns of thinking and feeling that divert from social expectations. However, the comorbidity between cocaine dependence and personality disorders has not been substantiated by measures of brain activation during social decision-making. We applied functional magnetic resonance imaging to compare brain activations evoked by a social decision-making taskthe Ultimatum Gamein 24 cocaine dependents with personality disorders (CDPD), 19 cocaine dependents without comorbidities and 19 healthy controls. In the Ultimatum Game participants had to accept or reject bids made by another player to split monetary stakes. Offers varied in fairness (in fair offers the proposer shares similar to 50 percent of the money; in unfair offers the proposer shares <30 percent of the money), and participants were told that if they accept both players get the money, and if they reject both players lose it. We contrasted brain activations during unfair versus fair offers and accept versus reject choices. During evaluation of unfair offers CDPD displayed lower activation in the insula and the anterior cingulate cortex and higher activation in the lateral orbitofrontal cortex and superior frontal and temporal gyri. Frontal activations negatively correlated with emotion recognition. During rejection of offers CDPD displayed lower activation in the anterior cingulate cortex, striatum and midbrain. Dual diagnosis is linked to hypo-activation of the insula and anterior cingulate cortex and hyper-activation of frontal-temporal regions during social decision-making, which associates with poorer emotion recognition.", "labels": [5, 30]}
{"id": "2843", "token": "Purpose of the review The availability of the Children's Health Exposure Assessment Resource funded by the National Institute of Environmental Health Sciences provides new opportunities for exploring the role of tobacco smoke exposure in causing harm to children. Recent findings Children of smokers are exposed to nicotine and other harmful tobacco smoke chemicals in utero as well as in their environment. This passive exposure to tobacco smoke has a variety of negative effects on children. In-utero exposure to tobacco smoke causes poor birth outcomes and influences lung, cardiovascular, and brain development, placing children at increased risk of a number of adverse health outcomes later in life, such as obesity, behavioral problems, and cardiovascular disease. Furthermore, most smokers start in their adolescence, an age of increased nicotine addiction risk. Biomarkers of tobacco exposure helps clarify the role tobacco chemicals play in influencing health both in childhood and beyond. Although electronic cigarettes (e-cigarettes) appear to be a nicotine delivery device of reduced harm, it appears to be a gateway to the use of combustible cigarette smoking in adolescents. Summary Pediatric researchers interested in elucidating the role of tobacco smoke exposure in adverse outcomes in children should incorporate biomarkers of tobacco exposure in their studies.", "labels": [5, 30]}
{"id": "2984", "token": "Socioeconomic status (SES) has been consistently linked to poorer access, utilization and outcomes of health care services, but this relationship has been understudied in adolescent substance abuse treatment research. This study examined SES differences in adolescent's treatment participation and long-term outcomes of abstinence and 12-step attendance over five years after treatment. Data are from 358 adolescents (ages 13-18) who were recruited at intake to substance abuse treatment between 2000 and 2002 at four Kaiser Permanente Northern California outpatient treatment programs. Follow-up interviews of adolescents and their parents were conducted at 1, 3, and 5 years, with over 80% response rates across time points. Using parent SES as a proxy for adolescent SES, no socioeconomic differences were found in treatment initiation, treatment retention, or long-term abstinence from alcohol or drugs. Parent education, but not parent income, was significantly associated with 12 step attendance post-treatment such that adolescents with higher parent edification were more likely to attend than those with lower parent education. Findings suggest a lack of socioeconomic disparities in substance abuse treatment participation in adolescence, but potential disparities in post-treatment 12-step attendance during the transition from adolescence to young adulthood. (C) 2017 Elsevier Ltd. All rights reserved.", "labels": [5, 30]}
{"id": "3060", "token": "Pharmaceutical opioid (PO) use and harms are increasing dramatically. Treatment related stigma may present as a treatment barrier for people who use PO. Additionally, differences in social support between PO and other opioid treatment populations may positively influence treatment outcomes. A scoping methodology was utilised to map current knowledge, with searches performed in Medline, PsycINFO and Embase. Eligibility criteria required articles related to stigma and social support in treatment for PO use. The search identified 44 relevant articles. Stigma themes included individual perceptions of opioid dependence, community perceptions of opioid dependence, blame as a stigmatising factor, language surrounding opioid use, and treatment experience. Social support themes included family as support, web-based support, friends as support, partners as support and social network therapy. Limited literature was found focussing specifically on stigma and social support in people who use PO, highlighting that this is an important area for future work.", "labels": [5, 30]}
{"id": "3127", "token": "Craving has been considered one of the core features of addiction. It can be defined as the urge or conscious desire to use a drug elicited by the drug itself, drug-associated cues or stressors. Craving plays a major role in relapse, even after prolonged periods of abstinence, as well as in the maintenance of drug seeking in non-abstinent addicts. The circuitry of craving includes medial parts of the prefrontal cortex, ventral striatal zones, ventral tegmental area, ventral pallidum, and limbic regions. Interestingly, the cerebellum shows reciprocal loops with many of these areas. The cerebellum has been linked traditionally to motor functions but increasing evidence indicates that this part of the brain is also involved in functions related to cognition, prediction, learning, and memory. Moreover, the functional neuroimaging studies that have addressed the study of craving in humans repeatedly demonstrate cerebellar activation when craving is elicited by the presentation of drug-related cues. However, the role of cerebellar activity in these craving episodes remains unknown. Therefore, the main goal of this review is to provide a brief update on craving studies and the traditional neural basis of this phenomenon, and then discuss and propose a hypothesis for the function of the cerebellum in craving episodes. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [5, 30]}
{"id": "3286", "token": "PURPOSE Brief intervention to reduce cannabis is a promising technique that could be adapted for use in primary care, but it has not been well studied in this setting. We tested the efficacy of a brief intervention conducted by general practitioners among cannabis users aged 15 to 25 years. METHODS We performed a cluster randomized controlled trial with 77 general practitioners in France. The intervention consisted of an interview designed according to the FRAMES (feedback, responsibility, advice, menu, empathy, self-efficacy) model, while the control condition consisted of routine care. RESULTS The general practitioners screened and followed up 261 young cannabis users. After 1 year, there was no significant difference between the intervention and control groups in the median number of joints smoked per month among all users (17.5 vs 17.5; P=.13), but there was a difference in favor of the intervention among nondaily users (3 vs 10; P=.01). After 6 months, the intervention was associated with a more favorable change from baseline in the number of joints smoked (-33.3% vs 0%, P=.01) and, among users younger than age of 18, smoking of fewer joints per month (12.5 vs 20, P=.04). CONCLUSIONS Our findings suggest that a brief intervention conducted by general practitioners with French young cannabis users does not affect use overall. They do, however, strongly support use of brief intervention for younger users and for moderate users.", "labels": [5, 30]}
{"id": "3340", "token": "Background: Registries for drug deaths may include different persons and provide different characteristics of the deceased. The aim of this study was to establish whether a database of drug-induced deaths (Cause of Death Registry (CDR) using the European Monitoring Centre for Drugs and Drug Addiction (EMCDDA) definition and the Police registry of drug deaths) included the same persons and provided the same characteristics of the deceased and thus yielded the same information for establishing targeted prevention measures. Methods: Notifications from 2007 to 2009 were drawn from the CDR and the police registry of drug deaths and the unique Norwegian personal identification number was used to match the registrations. Results: The two sources of drug deaths yielded 1384 registrations, encompassing 929 individuals of whom only 49% were included in both registries. A large proportion of the deceased (40%) were not listed in the police registry. This group was older (mean age 43 years vs. 35 years); dependence and suicide were listed more often as cause of death (33% vs. 8%); and heroin was listed less often as the type of drug causing death (24% vs. 67%) than those included in both registries. In particular, among women not included in the police registry, the cause of death was identified with much greater frequency as pharmaceuticals with morphine or codeine (47% vs. 16%). Conclusion: The large discrepancies in size, overlap, and characteristics of the deceased included in two sources of drug death imply that prevention measures based on the two sources will differ. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [5, 30]}
{"id": "3516", "token": "The occurrence of repetitive behaviours that are often harmful has been attributed to traits traditionally described as impulsive or compulsive e.g. substance dependence, excessive gambling, and hoarding. These behaviours are common and often co-occur in both the general population and psychiatric populations. The lack of measures to concurrently index a range of such behaviours led to the development of the Impulsive-Compulsive Behaviours (ICB) Checklist This study aims to validate the ICB Checklist in a general community sample. Factor analyses revealed a two-factor structure, demonstrating good model fit in two independent samples. These were labelled Impulsive-Compulsions and Compulsive-Impulsions, comprising of classically compulsive and impulsive behaviours respectively. Reliability and construct validity were further confirmed using correlations with existing Measures of impulsivity and compulsivity. Results suggest that the ICB Checklist is a valid and practical assessment that can be used to monitor behavioural clusters characterised by deficits in inhibition. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [5, 30]}
{"id": "13", "token": "Recent work has shown robust associations between morality and cleanliness. However, it is not known whether this association is equally consequential for everyone. I predicted that individuals high (vs. low) in God-belief would be more likely to draw upon feelings of cleanliness to represent their moral concerns. To test this hypothesis, I used a 2-week daily sampling protocol. In an initial session, I measured participants' (N = 135) level of God-belief. I then measured participants' levels of daily cleanliness, neuroticism, impulsivity, and prosocial behaviors every evening. Daily feelings of cleanliness predicted lower levels of neuroticism but only for those high in God-belief. Daily impulsive behaviors predicted lower feelings of cleanliness, and daily prosocial behaviors predicted higher feelings of cleanliness. God-belief moderated these effects such that they were stronger for those higher, than lower, in God-belief. In closing, I discuss potential reasons for these moderation effects and other theoretical considerations.", "labels": [2, 19]}
{"id": "139", "token": "Purpose - Although previous research has established that moral emotion, moral judgment, and moral identity influence consumer intention to engage in prosocial behavior (e.g. donating, volunteering) under some circumstances, these factors, in reality, can concurrently influence judgment process. Therefore, it is important to get a more nuanced understanding of how the combinations of each factor can lead to a high intention to engage in prosocial behavior. The paper aims to discuss these issues. Design/methodology/approach - This research employs fuzzy-set qualitative comparative analysis to explore different configurations of moral emotion, judgment, and identity that lead to a high consumer intention to engage in prosocial behavior. Findings - Findings indicate four configurations of moral emotion, moral judgment, and moral identity that lead to a high intention to engage in prosocial behavior. Research limitations/implications - This research focuses on the case of a hospital in Indonesia; thus, it is important not to overgeneralize the findings. Nonetheless, from a methodological standpoint, opportunity emerges to broaden the examinations in other service and cultural contexts. Practical implications - The findings of this research can help the hospital to develop effective combinations of advertising and marketing strategies to promote prosocial behavior among its customers. Originality/value - This paper provides the first empirical evidence on the existence of multiple pathways of moral emotion, judgment, and identity that lead to a high consumer intention to engage in prosocial behavior. The implications of this research also highlight the importance of cultural context in understanding consumer behavior.", "labels": [2, 19]}
{"id": "217", "token": "The Dark Triad traits, including narcissism, Machiavellianism and psychopathy, are assumed to link to poor personal morality. However, an increasing number of studies suggested that narcissism was brighter than Machiavellianism and psychopathy. In a sample of Chinese adolescents (N = 2828), relationships among the Dark Triad traits, moral identity (both internalization and symbolization) and prosocial behavior were examined. The results showed that narcissism was positively related to internalization, symbolization and prosocial behavior, whereas Machiavellianism and psychopathy were negatively related to internalization and prosocial behavior but not related to symbolization. Further, the positive links between narcissism and personal morality was moderated by self-esteem, such that the links were weaker among high self-esteem individuals than low self-esteem ones. These findings highlighted the bright but fragile side of narcissism and were discussed from cognitive and motivational perspectives. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [2, 19]}
{"id": "297", "token": "Sharing materials is a complex social behavior that may lead to longterm development of friendships and concomitant increases in related prosocial behaviors. Given the complexities of sharing behaviors, children with social delays or deficits may not recognize when, how, and with whom to share. Because children with social delays or deficits, especially those with disabilities, may not engage in typical sharing behaviors, and because these behaviors are important, identifying interventions for sharing and related social behaviors are crucial. The purpose of this review was to identify sharing interventions, evaluate methodological rigor, and assess intervention effectiveness. Twenty single-case designs published in 11 articles were included. Some studies reported variable results and had considerable methodological limitations. Results of high-quality studies are promising and provide a foundation for future research on sharing behaviors.", "labels": [2, 19]}
{"id": "406", "token": "Young adolescents are generally considered to be self-absorbed. Studies indicate that they lack relevant general cognitive abilities, such as impulse control, that mature in early adulthood. However, their idealism may cause them to be more intolerant of unfair treatment to others and thus result in their engaging in more altruistic behavior. The present study aimed to clarify whether young adolescents are more altruistic than adults and thus indicate whether altruistic competence is domain-specific. One hundred 22 young adolescents and adults participated in a face-to-face, two-round, third-party punishment experiment. In each interaction group, a participant served as an allocator who could share money units with a stranger; another participant who knew the allocator could punish the acquaintance for the stranger. Participants reported their emotions after the first round, and at the end of the experiment, the participants justified their behavior in each round. The results indicated that the young adolescents both shared more and punished more than did the adults. Sharing was associated with a reference to fairness in the justifications, but altruistic punishment was associated with subsequent positive emotion. In sum, greater altruism in young adolescents compared to adults with mature cognitive abilities provides evidence of domain-specificity of altruistic competence. Moreover, sharing and altruistic punishment are related to specific cognitive and emotional mechanisms, respectively.", "labels": [2, 19]}
{"id": "521", "token": "Fulfillment of the basic psychological needs for competence, relatedness, and autonomy is believed to facilitate people's integrative tendencies to process psychological conflicts and develop a coherent sense of self. The present study therefore used event-related potentials (ERPs) to examine the relation between need fulfillment and the amplitude of conflict negativity (CN), a neurophysiological measure of conflict during personal decision making. Participants completed a decision-making task in which they made a series of forced choices according to their personal preferences. Three types of decision-making situations were created on the basis of participants' unique preference ratings, which were obtained prior to ERP recording: low-conflict situations (choosing between an attractive and an unattractive option), high-conflict approach-approach situations (choosing between two similarly attractive options), and high-conflict avoidance-avoidance situations (choosing between two similarly unattractive options). As expected, CN amplitudes were larger in high- relative to low-conflict situations, and source localization analyses suggested that the anterior cingulate cortex was the generating structure of the CN. Most importantly, people reporting higher need fulfillment exhibited larger CN amplitudes in avoidance-avoidance situations relative to low-conflict situations; to a lesser extent, they also exhibited larger CN amplitudes in approach-approach situations relative to low-conflict situations. By contrast, people reporting lower need fulfillment exhibited CN amplitudes that poorly discriminated the three decision situations. These results suggest that need fulfillment may promote self-coherent functioning by increasing people's receptivity to and processing of events that challenge their abilities to make efficient, self-congruent choices.", "labels": [2, 19]}
{"id": "730", "token": "Human prosociality is often assumed to emerge from exerting reflective control over initial, selfish impulses. However, recent findings suggest that prosocial actions can also stem from processes that are fast, automatic and intuitive. Here, we attempt to clarify when prosocial behavior may be intuitive by examining prosociality as a form of reward seeking. Using event-related potentials (ERPs), we explored whether a neural signature that rapidly encodes the motivational salience of an event-the P300-can predict intuitive prosocial motivation. Participants allocated varying amounts of money between themselves and charities they initially labelled as high- or low-empathy targets under conditions that promoted intuitive or reflective decision making. Consistent with our predictions, P300 amplitude over centroparietal regions was greater when giving involved high-empathy targets than low-empathy targets, but only when deciding under intuitive conditions. Reflective conditions, alternatively, elicited an earlier frontocentral positivity related to response inhibition, regardless of target. Our findings suggest that during prosocial decision making, larger P300 amplitude could (i) signal intuitive prosocial motivation and (ii) predict subsequent engagement in prosocial behavior. This work offers novel insight into when prosociality may be driven by intuitive processes and the roots of such behaviors.", "labels": [2, 19]}
{"id": "811", "token": "The neuropeptide oxytocin (OXT) facilitates prosocial behavior and selective sociality. In the context of stress, OXT also can down-regulate hypothalamic-pituitary-adrenal (HPA) axis activity, leading to consideration of OXT as a potential treatment for many socioaffective disorders. However, the mechanisms through which administration of exogenous OXT modulates social behavior in stressful environmental contexts are not fully understood. Here, we investigate the hypothesis that autonomic pathways are components of the mechanisms through which OXT aids the recruitment of social resources in stressful contexts that may elicit mobilized behavioral responses. Female prairie voles (Microtus ochrogaster) underwent a stressor (walking in shallow water) following pretreatment with intraperitoneal OXT (0.25 mg/kg) or OXT antagonist (OXT-A, 20 mg/kg), and were allowed to recover with or without their sibling cagemate. Administration of OXT resulted in elevated OXT concentrations in plasma, but did not dampen the HPA axis response to a stressor. However, OXT, but not OXT-A, pretreatment prevented the functional coupling, usually seen in the absence of OXT, between paraventricular nucleus (PVN) activity as measured by c-Fos immunoreactivity and HPA output (i.e. corticosterone release). Furthermore, OXT pretreatment resulted in functional coupling between PVN activity and brain regions regulating both sympathetic (i.e. rostral ventrolateral medulla) and parasympathetic (i.e. dorsal vagal complex and nucleus ambiguous) branches of the autonomic nervous system. These findings suggest that OXT increases central neural control of autonomic activity, rather than strictly dampening HPA axis activity, and provides a potential mechanism through which OXT may facilitate adaptive and context-dependent behavioral and physiological responses to stressors. (C) 2016 Published by Elsevier Inc.", "labels": [2, 19]}
{"id": "982", "token": "This study examined the psychometric properties of the Child Adjustment and Parent Efficacy Scale-Developmental Disability (CAPES-DD), a brief inventory for assessing emotional and behavioral problems of children with developmental disabilities aged 2- to 16-years, as well as caregivers' self-efficacy in managing these problems. A sample of 636 parents participated in the study. Children's ages ranged from 2 to 15. Exploratory and confirmatory factor analyses supported a 21-item, three-factor model of CAPES-DD child adjustment with 13 items describing behavioral (10 items) and emotional (3 items) problems and 8 items describing prosocial behavior. Three additional items were included due to their clinical usefulness and contributed to a Total Problem Score. Factor analyses also supported a 16-item, one factor model of CAPES-DD self-efficacy. Psychometric evaluation of the CAPES-DD revealed scales had satisfactory to very good internal consistency, as well as very good convergent and predictive validity. The instrument is to be in the public domain and free for practitioners and researchers to use. Potential uses of the measure and implications for future validation studies are discussed. (C) 2015 Elsevier Ltd. All rights reserved.", "labels": [2, 19]}
{"id": "1149", "token": "The importance of names has been demonstrated for decision making related to individuals as well as companies. While previous researchers have focused on traits such as the fluency of names, we present three studies that focus on the role of the hard e or [A] sound in relation to helping behavior. Because pronunciation of the [A] sound requires a facial movement that mimics a smile particularly when the sound occurs at the end of a name, our research complements previous findings generated by the theory of embodied cognition in which biting on a pencil or chopstick evoked behavioral and mood changes. Study 1 finds that participants are more likely to help someone whose name ends with the [A] sound while study 2 utilizes a broader set of contrasting sounds and finds a basic preference for the [A] sound that is specific to women. Study 3 shows that women are significantly more likely to recall addressing their parents as Mommy or Daddy when soliciting help rather than Mom or Dad. Our findings complement previous research concerning motherese and highlight a phonetic cue for prosocial behavior that appears to offer insights for marketing and management. Just as the current studies are important in understanding interpersonal interactions, the findings have direct relevance for marketing campaigns that focus on consumer engagement.", "labels": [2, 19]}
{"id": "1253", "token": "As an entertainment technology, video games are a popular social activity that can allow for multiple players to cooperatively engage on-screen challenges. Emerging research has found that when people play together, the resulting teamwork can have beneficial impacts on their prosocial orientations after gameplay - especially when the players are cooperative with one another. The present study wanted to expand the scope of these beneficial interpersonal effects by considering both inter- and intrapersonal factors. In an experimental study (N = 115) we manipulated the difficulty of a game (easy or hard) and the behavior of a confederate teammate (supportive or unsupportive playing style). We found that neither coplayer supportiveness nor game difficulty had an effect on the expectations of a teammate's prosocial behavior or one's own prosocial behavior toward the teammate after the game (operationalized as willingness to share small amounts of money with one's teammate after playing). Increased expectations of prosocial behavior from one's teammate were related to one's own prosocial behaviors, independent of our manipulations. Considering these results, we propose alternative theoretical approaches to understanding complex social interactions in video games. Furthermore, we suggest to explore other types of manipulations of game difficulty and cooperation between video game players as well as alternative measures of prosocial behavior.", "labels": [2, 19]}
{"id": "1293", "token": "Objectives: This investigation was conducted to determine whether contesting orientations add predictive utility for prosocial behavior, both in and out of sports, beyond other variables related to the component processes of moral action. Design: Cross-sectional. Methods: Intercollegiate US athletes (n = 2380; 56.4% male), from both individual and team sports, completed measures of contesting orientation, three moral variables (moral attentiveness, moral identity, integrity), three sport-specific variables (athletic identity, goal orientation, and fear of failure), and three outcome variables (sportspersonship, academic honesty, and prosocial helping). Data was analyzed using both correlational and regression analyses. Results: Regression analyses demonstrated that contesting orientations were the best predictors of sportspersonship, but were insignificant predictors of nonsport forms of prosocial behavior. Conclusions: Consistent with contesting theory, contesting orientation are salient and potent predictors of sportspersonship, but do not predict behavior outside of contest situations. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [2, 19]}
{"id": "1392", "token": "One avenue substantially researched and supported in early childhood research is the importance and the cultivation of self-regulation skills in the classroom. Most educational research on self-regulation skills has illustrated the importance between the enhancement of these skills and long-term academic success. Notwithstanding, there is little empirical research in early childhood that links the advancement of self-regulation skills to other contributing educational components, such as the cultivation of children's pro-social skills.This review seeks to establish a link between children's self-regulation and pro-social skills and discusses implications for future research and practice.", "labels": [2, 19]}
{"id": "1422", "token": "Although the vast majority of existing work on empathy focuses exclusively on the socio-emotional consequences of empathizing with others' negative emotions, mounting evidence supports the view that empathy for others' negative emotions and empathy for others' positive emotions are distinct capacities. The present work seeks to marry this burgeoning literature on the separability of positive and negative empathy to the influential literature on approach and avoidance motivation by examining how these two distinct empathic capacities relate to the (pro)social motivations to assist others to approach positivity vs. avoid negativity. The results of two studies show that whereas positive empathy is associated with an other-focused motivation to assist others to approach positive outcomes and is predictive of helping only when that help is framed as a means of propelling others toward greater positivity, negative empathy is associated with an other-focused motivation to assist others to avoid negative outcomes and is associated with helping only when that help is framed as a means of assisting others to avoid further suffering. In addition to contributing to the emerging literature on the separability of positive and negative empathy, these results also help to extend the influential approach/avoidance distinction to the domain of other-focused motivation. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [2, 19]}
{"id": "1559", "token": "Amidst an ongoing debate surrounding the traditional dichotomy of whether video games are good or bad for children, in this paper we present Path of Trust, a novel, prosocial game that aims at helping children understand the importance of teamwork and learn how and when to express trustworthiness. We have created a colorful, non-violent digital game, in which children aged 7-10 can be exposed to prosocial content and develop specific prosocial attitudes, such as cooperation and trustworthiness, driven by the fact that video games with prosocial content can be used to improve social interactions. The game was designed to maintain an attractive and engaging nature, which is usually associated with games that are often vilified within social circles in terms of being packed with tons of action and violence. We conducted two separate studies to test our game's modeling of prosocial behavior, which demonstrate the potential of the game as a tool for teaching important prosocial behavior to children.", "labels": [2, 19]}
{"id": "1753", "token": "This exploratory study utilized a concurrent triangulation mixed methods design to investigate how parents respond to considerate and engaging forms of children's prosocial behavior, whether some prosocial behaviors are more likely to receive reinforcement, and whether reinforcement is associated with specific types of prosocial behavior. Parents of 74 preschoolers completed a questionnaire regarding their child's general prosociality, provided open-ended responses to prosocial vignettes, and completed a questionnaire assessing reinforcement. Open-ended responses showed reinforcement was highly variable across parents and prosocial behaviors. Across open-ended and response-option formats, social reinforcement responses of parent approval, character attributions, and showing love emerged as common reinforcement responses to prosocial behavior, and evidencing similar relationships with comforting and cooperating behaviors. These results suggest that there are multiple ways parents respond to child prosocial behaviors, many of which seem to be attempts to encourage prosociality.", "labels": [2, 19]}
{"id": "1816", "token": "A review of recent studies of early childhood altruism is followed by a report of a study of development of altruism in early childhood at ages 3, 4 and 5 years in terms of children's ability and willingness to help, share, and donate. 178 preschool children were videotaped while interacting in pairs matched by age and sex in an age-appropriate, structured altruism task in which opportunities to help and share arose in the natural flow of events. Results indicate that even the youngest children (age 3) displayed some altruistic acts; both the number of children showing altruism, and their number of altruistic acts, were greater at each succeeding age level. Sharing was the most common altruistic behavior, and it was more frequent than helping and donation behaviors at earlier ages. Possible explanations for the different developmental trajectories of different altruistic acts are discussed, with emphasis on the differing cognitive and empathic demands of the situation. Main contributions of the study include demonstration of (1) different developmental trajectories for different types of altruistic acts; (2) age-related increase in spontaneous altruistic acts toward peers between 3 and 5 years of age; (2) the utility of a naturalistic, structured observational task to study spontaneous altruism towards peers in young children.", "labels": [2, 19]}
{"id": "1971", "token": "Communication between parents and their children represents an important factor of family socialization. Nevertheless, little is known about why parents communicate in different ways and how these qualitative differences in parent-child communication may affect the child. Building on self-determination theory, the present study focuses on motivational antecedents of need-supportive communication as a function of parental child-related beliefs (i.e.,long-term goals that parents have set for their children's future, and parental child-related behavior expectations in terms of parental dissatisfaction or satisfaction with child behavior). Moreover, the effect of perceived need-supportive communication on children's prosocial behavior and (externalizing and internalizing) behavioral difficulties will be addressed. Three waves of data from 1125 mothers and adolescents aged between 10 and 17 years were analyzed using growth-curve modeling. We found linearly increasing trajectories in extrinsic parental goals for children and dissatisfaction with child behavior, and decreasing trajectories of need-supportive communication. Individual differences do not vary significantly over time. In addition, holding extrinsic parental goals for children positively predicts parents' dissatisfaction with their child's behavior and negatively predicts need-supportive communication. Parents' dissatisfaction with their child's behavior also contributes to decreasing need-supportive communication. As expected, need-supportive communication predicts prosocial behavior and externalizing behavioral difficulties. When need-supportive communication decreases over time, both externalizing and internalizing behavioral difficulties increase. Furthermore, the effect of mothers beliefs on adolescents socioemotional development was mediated through perceived mother's communication quality. These results suggest that parental child-related beliefs are important motivational antecedents of parent-child communication that may prevent behavioral difficulties.", "labels": [2, 19]}
{"id": "2039", "token": "Is there a dark side to organic food? Eskine reported that participants exposed to organic food became much more morally judgmental and much less prosocial relative to participants exposed to neutral or comfort foods. This research sparked tremendous media interest, but was based on one experiment with a small sample size. We report three attempts to replicate Eskine using samples conferring high power, preregistered analysis plans, and original materials. Across two direct replications and an online conceptual replication, we found that organic food exposure has little to no effect on moral judgments (d = 0.06, 95% confidence interval [CI] [-0.14, 0.26], N = 377) and prosocial behavior (d = 0.03, 95% CI [-0.17, 0.23], N = 377). Mere exposure to organic food is probably not sufficient to substantially change moral behavior.", "labels": [2, 19]}
{"id": "2088", "token": "High achievement expectations and academic pressure from parents have been implicated in rising levels of stress and reduced well-being among adolescents. In this study of affluent, middle school youth, we examined how perceptions of parents' emphases on achievement (relative to prosocial behavior) influenced youth's psychological adjustment and school performance, and examined perceived parental criticism as a possible moderator of this association. The data were collected from 506 (50 % female) middle school students from a predominately white, upper middle class community. Students reported their perceptions of parents' values by rank ordering a list of achievement- and prosocial-oriented goals based on what they believed was most valued by their mothers and fathers for them (the child) to achieve. The data also included students' reports of perceived parental criticism, internalizing symptoms, externalizing symptoms, and self-esteem, as well as school-based data on grade point average and teacher-reported classroom behavior. Person-based analyses revealed six distinct latent classes based on perceptions of both mother and father emphases on achievement. Class comparisons showed a consistent pattern of healthier child functioning, including higher school performance, higher self-esteem, and lower psychological symptoms, in association with low to neutral parental achievement emphasis, whereas poorer child functioning was associated with high parental achievement emphasis. In variable-based analyses, interaction effects showed elevated maladjustment when high maternal achievement emphasis coexisted with high (but not low) perceived parental criticism. Results of the study suggest that to foster early adolescents' well-being in affluent school settings, parents focus on prioritizing intrinsic, prosocial values that promote affiliation and community, at least as much as, or more than, they prioritize academic performance and external achievement; and strive to limit the amount of criticism and pressure they place on their children.", "labels": [2, 19]}
{"id": "2234", "token": "When it comes to the pursuit of happiness, popular culture encourages a focus on oneself. By contrast, substantial evidence suggests that what consistently makes people happy is focusing prosocially on others. In the current study, we contrasted the mood-and well-being-boosting effects of prosocial behavior (i.e., doing acts of kindness for others or for the world) and self-oriented behavior (i.e., doing acts of kindness for oneself) in a 6-week longitudinal experiment. Across a diverse sample of participants (N = 473), we found that the 2 types of prosocial behavior led to greater increases in psychological flourishing than did self-focused and neutral behavior. In addition, we provide evidence for mechanisms explaining the relative improvements in flourishing among those prompted to do acts of kindness-namely, increases in positive emotions and decreases in negative emotions. Those assigned to engage in self-focused behavior did not report improved psychological flourishing, positive emotions, or negative emotions relative to controls. The results of this study contribute to a growing literature supporting the benefits of prosocial behavior and challenge the popular perception that focusing on oneself is an optimal strategy to boost one's mood. People striving for happiness may be tempted to treat themselves. Our results, however, suggest that they may be more successful if they opt to treat someone else instead.", "labels": [2, 19]}
{"id": "2417", "token": "Previous work has revealed that secure parental attachment promotes prosocial behaviors, but its underlying mechanism is less commonly explored. Drawing upon Bowlby's attachment theory, the current study examined the role of self-control in the link between parental attachment and prosocial behaviors. Six hundred and seven Chinese adolescents participated in the study completing measures that assessed parental attachment, self-control, and prosocial behaviors. Results showed that secure maternal attachment, rather than paternal attachment, was directly related to more prosocial behaviors in total sample and girls. Importantly, self-control mediated the links between both maternal and paternal attachment and prosocial behaviors across sex. In conclusion, self-control partly addresses how individuals who report being securely attached to parents engage in more prosocial behaviors. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [2, 19]}
{"id": "2444", "token": "The effects of video games on children's psychosocial development remain the focus of debate. At two timepoints, 1 year apart, 194 children (7.27-11.43 years old; male = 98) reported their gaming frequency, and their tendencies to play violent video games, and to game (a) cooperatively and (b) competitively; likewise, parents reported their children's psychosocial health. Gaming at time one was associated with increases in emotion problems. Violent gaming was not associated with psychosocial changes. Cooperative gaming was not associated with changes in prosocial behavior. Finally, competitive gaming was associated with decreases in prosocial behavior, but only among children who played video games with high frequency. Thus, gaming frequency was related to increases in internalizing but not externalizing, attention, or peer problems, violent gaming was not associated with increases in externalizing problems, and for children playing approximately 8 h or more per week, frequent competitive gaming may be a risk factor for decreasing prosocial behavior. We argue that replication is needed and that future research should better distinguish between different forms of gaming for more nuanced and generalizable insight.", "labels": [2, 19]}
{"id": "2535", "token": "The study examined the social skills of 92 Russian children (males = 64) adopted by Italian families. The children, aged between 8 and 14 years, were compared with a control group of children who grew up with the biological family. Evaluation by both parents and children of the children's social competence were investigated. The results showed that, according to the parents' reports, the adopted children had more problems in social functioning than peers in the control group, along with a greater propensity to use maladaptive behaviors such as Oppositive Behavior, Rule-Breaking Behavior, Aggressive Behavior and Externalization. By contrast, according to the children's assessments, the adopted children were less aggressive and used prosocial behaviors to a greater extent than children raised in the biological family. The views of the parents and the children about the children's aggressive behavior were mutually conflicting. Finally, the influence of adoption related variables on the social competence of children was examined. Contrary to our expectations, there were no significant relationships between social competence and age of adoption, the duration of institutionalization and the time spent in the adoptive family. (C) 2017 Elsevier Ltd. All rights reserved.", "labels": [2, 19]}
{"id": "2631", "token": "Preschoolers have a sophisticated understanding of reward and punishment. Here we investigated whether children spontaneously correct unfair punishments. Across two experiments, 3- and 4-year-olds engaged in a block-tower building task with a puppet in order to receive a reward (four stickers to be shared between the puppet and the child). The puppet then either accidentally or intentionally knocked over the tower. In both cases, an adult, who did not observe the intentionality of the outcome, punished the puppet by giving all the stickers to the child. After hearing the puppet protest, children were more likely to correct the adult's punishment (i.e., share stickers with the puppet) when puppet's actions were accidental rather than intentional. Our results suggest that rather than passively accepting rewards and punishments imposed by authority figures, young children spontaneously correct situations they potentially believe are unfair. (C) 2016 Elsevier Inc. All rights reserved.", "labels": [2, 19]}
{"id": "2695", "token": "The present study examined teachers' domain-specific self-efficacy (TSE) in relation to individual students with a variety of social-emotional behaviors in class. Using a sample of 526 third-to sixth-grade students and 69 teachers, multilevel modeling was conducted to examine students' externalizing, internalizing, and prosocial behaviors as predictors of TSE toward individual students, and the potential moderating roles of teaching experience and teachers' perceived amount of classroom misbehavior. Results showed that most of the variance in TSE occurred within teachers. Students' externalizing behavior was negatively associated with TSE for instructional strategies, behavior management, student engagement, and emotional support. In contrast, teachers reported higher levels of self-efficacy toward students with high levels of prosocial behavior, irrespective of teaching domain. Students' internalizing behavior predicted lower levels of TSE for instructional strategies and emotional support, and higher levels of TSE for behavior management. Last, teachers' perceived levels of classroom misbehavior exacerbated the negative association between externalizing student behavior and TSE for behavior management. These findings illustrate the importance of viewing TSE from a dyadic perspective.", "labels": [2, 19]}
{"id": "2868", "token": "Recent research with Western populations has demonstrated that children use imitation flexibly to engage in both instrumental and conventional learning. Evidence for children's imitative flexibility in non-Western populations is limited, however, and has only assessed imitation of instrumental tasks. This study (N = 142, 6- to 8-year-olds) demonstrates both cultural continuity and cultural variation in imitative flexibility. Children engage in higher imitative fidelity for conventional tasks than for instrumental tasks in both an industrialized, Western culture (United States), and a subsistence-based, non-Western culture (Vanuatu). Children in Vanuatu engage in higher imitative fidelity of instrumental tasks than in the United States, a potential consequence of cultural variation in child socialization for conformity.", "labels": [2, 19]}
{"id": "2966", "token": "Wealth is associated with differences in people's self-concepts. We propose that these self-concepts should define the types of appeals that are most effective at motivating generosity. Across three field studies, we randomly assigned participants to view an appeal for a charitable organization that emphasized agency (the pursuit of personal goals) or communion (the pursuit of shared goals). When the appeal emphasized agency, wealthier individuals reported greater willingness to give and donated more money to charity. In contrast, when the appeal emphasized communion, less wealthy individuals reported greater willingness to give. These findings could not be explained by relevant demographic characteristics such as age, ethnicity, or gender. This work adds to a growing body of research suggesting that wealth does not inherently result in selfishness or generosity. By tailoring messages to fit with people's self-concepts, it is possible to catalyze giving across the socioeconomic spectrum. (C) 2016 Elsevier Inc. All rights reserved.", "labels": [2, 19]}
{"id": "3221", "token": "Theory and research suggests that individuals with greater social capital (i.e., resources and benefits gained from relationships, experiences, and social interactions) may be more likely to be active, prosocial bystanders in bullying situations. Therefore, the goal of the current study was to examine the association of social capital (social support and social skills) with prosocial bystander behavior, and the role of internalizing problems as a potential barrier to this relation among 299 students (45.8% girls, 95% White) in sixth, seventh, and eighth grades. Results indicate a positive relation between social capital and prosocial bystander behavior. In addition, internalizing problems were a significant risk factor that may hinder youth-particularly girls-from engaging in defending behavior. Prosocial bystanders are an essential component to prevent and reduce bullying and further research is needed to better understand how to foster prosocial behavior in bullying situations, perhaps by utilizing social capital, related to school bullying.", "labels": [2, 19]}
{"id": "3462", "token": "Despite extensive literature on parental monitoring, few studies have focused on father-youth solicitation in particular and none on solicitation via communication technology. To address this gap, this study explored the relationships between fathers' online and in-person solicitation of their adolescent and emerging adult children, and the youth's internalizing, externalizing, and prosocial behaviors. A sample of US fathers (N = 158) reported on solicitation patterns, use of technology, and their child's behaviors. The results revealed differences by demographics, and an inverse trend between online and in-person solicitation in relation to internalizing, externalizing, and prosocial behaviors. Regression analyses revealed that online solicitation of information from the youth's friends was related to greater internalizing and externalizing, and less prosocial behavior. These findings support research suggesting that some forms of online solicitation may be interpreted by adolescents and emerging adults as intrusive and a violation of privacy.", "labels": [2, 19]}
{"id": "14", "token": "Purpose: The aim of this paper was to study the feasibility of manufacturing a customizable trocar-cannula system for vitreoretinal surgery utilizing commercially available three-dimensional (3D) printing technology. Methods: A digital model of a trocar-cannula system for vitreoretinal surgery was created using computer-aided design (CAD) software and printed utilizing a laser-sintering 3D printer in modified ABS thermoplastic material. The trocar-cannula prototypes were tested in pig eyes. Results: A customizable digital model was created using commercially available CAD software. Three trocar-cannulas were printed. The smallest cannulas that could be printed had dimensions between 21 and 22G. The trocar-cannulas were inserted in pig eyes after performing sclerotomies with a commercially available 20G MVR blade. One cannula broke during insertion. Conclusions: This study demonstrates the feasibility of printing a trans conjunctival vitrectomy trocar-cannula system with commercially available 3D print technology. The 3D printer and build material used resulted in trocar-cannulas with functional limitations including a minimum size achievable and mechanical resistance. (C) 2017 S. Karger AG, Basel", "labels": [3, 20]}
{"id": "121", "token": "Integrating more functionality in a smaller form factor with higher performance and lower-power consumption is pushing semiconductor technology scaling to its limits. 3-D chip stacking is touted as the silver bullet technology that can keep Moore's momentum and fuel the next wave of consumer electronic products. Additionally, the complexity of digital designs imposes that computer-aided design algorithms are getting harder and slower. This paper introduces a framework for application implementation onto 3-D reconfigurable architectures. In contrast to existing approaches, the proposed solution is customizable according to constraints posed by the application and the target 3-D device in order to improve performance metrics. Experimental results highlight the effectiveness of our framework, as we achieve average enhancements in terms of maximum operation frequency and power consumption by 35% and 47%, respectively, as compared to state-of-the-art algorithms.", "labels": [3, 20]}
{"id": "211", "token": "Temperature variation during semiconductor device operation can be significant and how this affects contact resistance is investigated. This paper reports improvements to analytical modeling for determining specific contact resistance (SCR) by including the effect of temperature. A technique for extracting the value of SCR using technology computer-aided design (TCAD) modeling is also demonstrated. SCR results obtained for analytical and TCAD models for metal-to-silicon contacts are compared and this shows the significance of temperature in the analyticalmodel. Small changes in electron affinity and, hence, barrier height due to changes in temperaturemust be considered in order to obtain reliable analytical expressions for SCR.", "labels": [3, 20]}
{"id": "405", "token": "This paper reports on a model-assisted bundle adjustment (BA) framework in which visually-derived features are fused with an underlying three-dimensional (3D) mesh provided a priori. By using an approach inspired by the expectation-maximization (EM) class of algorithms, we introduce a hidden binary label for each visual feature that indicates if that feature is considered part of the nominal model, or if the feature corresponds to 3D structure that is absent from the model. Therefore, in addition to improved estimates of the feature locations, we can identify visual features that correspond to foreign structure on the ship hull. We show that this framework is a special case of the Gaussian max-mixtures framework, which can be efficiently incorporated into state-of-the-art graph-based simultaneous localization and mapping (SLAM) solvers. In addition, the precision of our bundle adjustment framework allows the identification of structural deviations between 3D structure inferred from bundle-adjusted camera imagery and the prior model. These structural deviations are clustered into shapes, which allow us to fuse camera-derived structure back into the 3D mesh. This augmented model can be used within a 3D photomosaicing pipeline, providing a visually intuitive 3D reconstruction of the ship hull. We evaluate our pipeline using the Bluefin Robotics hovering autonomous underwater vehicle (HAUV) surveying the SS Curtiss, where a 3D mesh derived from computer aided design (CAD) drawings serves as the prior model. In addition to more consistent visual reconstructions, we can update the prior mesh with 3D information corresponding to underwater structure, such as biofouling or manually-placed cylindrical shapes with known dimensions. (C) 2016 Elsevier B.V. All rights reserved.", "labels": [3, 20]}
{"id": "563", "token": "Selective laser melting (SLM) process, an additive manufacturing (AM) technology, has had a rapid growth in the biomedical and aerospace markets because of the ability to manufacture complex designs directly from computer-aided design (CAD) using materials such as titanium and aluminum alloys. Although this technology allows designers to fabricate geometries not achievable with conventional manufacturing, it has some restrictions. The paper presents the technological problems and restrictions resulting in the production of structures in aluminum alloy by SLM. In particular, it analyzed the input file of the process, .STL file, and the dimensional limits of geometries with sharp edges as a simple parallelepiped with a square base since the understanding of the limitations can help the designer in the creation of new components. The creation of function-independent design rules, easily transferrable on individual part designs, could allow a wide industrial usage and a better knowledge of AM technologies. The results presented in this paper showed that the choice of parameters of conversion from the CAD model to .STL file could be a restriction for the software for preprocessing part but also affects the surface roughness. Moreover, if a SLM machine with a laser beam of 100 mu m is used, it is not possible to produce geometries with sharp edges with size base below 0.8 mm in an aluminum alloy.", "labels": [3, 20]}
{"id": "689", "token": "The 2-D analytical solution of electrostatic potential and enhanced drain current is modeled for a dual metal surround gate junctionless transistor (DMSGJLT) by solving the Poisson equation using the parabolic approximation technique. The gate engineered DMSGJLT produces an increase in the mobility of electrons in the channel. Enhancement in drain current of 35 mu A is obtained than single metal JLT for the same dimension. Due to that, the gain increases, short channel effects and leakage current decreases. The electrostatic potential, threshold voltage, drain current, transconductance, drain-induced barrier lowering, power and delay predicted by the analytical solution have excellent agreement with the simulation results obtained from Technology Computer-Aided Design. The analytical modeling provides useful insight on physics of short channel effects. The inverter circuit is implemented with a DMSGJLT and is compared with that of a single metal device. The noise margin analysis is made for the inverter circuit employing both dual metal and single metal devices. It is found that gate engineering improves the noise margin to a much extend and due to this, the voltage loss is also improved with a DMSGJLT.", "labels": [3, 20]}
{"id": "774", "token": "Pythagorean-normal (PN) surfaces, defined as rational surfaces admitting rational offsets, are important for industrial Computer-aided Design. Traditionally PN surfaces are considered from the point of view of Laguerre geometry, using three main models: cyclographic model, Blaschke cylinder or isotropic model. We propose a unifying formalism to deal with PN surfaces: all these models are embedded into one ambient pseudo-Euclidean space , that is known as a model for Lie sphere geometry. Various relations between different models are described in terms of closed formulas in the geometric algebra and illustrated by examples of applications.", "labels": [3, 20]}
{"id": "920", "token": "Computer assisted technologies offer new opportunities in medical imaging and rapid prototyping in biomechanical engineering. Three dimensional (3D) modelling of soft tissues and bones are becoming more important. The accuracy of the analysis in modelling processes depends on the outline of the tissues derived from medical images. The aim of this study is the evaluation of the accuracy of 3D models of a dog femur derived from computed tomography data by using point cloud method and boundary line method on several modelling software. Solidworks, Rapidform and 3DSMax software were used to create 3D models and outcomes were evaluated statistically. The most accurate 3D prototype of the dog femur was created with stereolithography method using rapid prototype device. Furthermore, the linearity of the volumes of models was investigated between software and the constructed models. The difference between the software and real models manifests the sensitivity of the software and the devices used in this manner.", "labels": [3, 20]}
{"id": "1045", "token": "OBJECTIVES: To study the effect of the angulation between the left pulmonary artery (LPA) and the main pulmonary artery on pulmonary haemodynamics. METHODS: A 3D model of patient-specific pulmonary artery (PA) was reconstructed as an original model. Four models with descendent LPA angulation equalled to 120 degrees, 110 degrees, 100 degrees and 90 degrees, were reconstructed by computer-aided design for the virtual simulation of the pulmonary flow under different surgical strategies. Computational fluid dynamics was introduced to calculate the pulmonary blood flow in five models. Streamlines, wall shear stress, energy loss and flow distribution ratio were calculated and compared to determine the better haemodynamics in the pulmonary artery. RESULTS: Vortices were formed at the lower wall of the opening of right PA and LPA in models with LPA angles equal to or less than 100 degrees (Models 3 and 4). Relative high wall shear stress areas at the lateral and lower wall of LPA opening had an ascendant tendency as the angle declined. Decreased flow distribution ratio to left lung (original model: 0.58, Model 1: 0.63, Model 2: 0.586, Model 3: 0.564, Model 4: 0.55) and increased energy loss (original model: 385.2 mV, Model 1: 239.4 mV, Model 2: 384.3 mV, Model 3: 430.9 mV, Model 4: 439.8 mV) in a cardiac cycle were noted as the angle reduced. CONCLUSIONS: Acute LPA angulation is associated with adverse haemodynamic performance. This should be particularly addressed during the reconstruction of pulmonary artery in the repair of tetralogy of Fallot.", "labels": [3, 20]}
{"id": "1301", "token": "Background: Temporo-Mandibular Joint (TMJ) replacement has been used clinically for years. The objective of this study was to evaluate outcomes achieved in patients with two different categories of TMJ prostheses. Material and Methods: All patients who had a TMJ replacement (TMJR) implanted during the study period from 2006 through 2012 were included in this 3-year prospective study. All procedures were performed using the Biomet Microfixation TMJ Replacement System, and all involved replacing both the skull base component (glenoid fossa) and the mandibular condyle. Results: Fifty-seven patients (38 females and 19 males), involving 75 TMJs with severe disease requiring reconstruction (39 unilateral, 18 bilateral) were operated on consecutively, and 68 stock prostheses and 7 custom-made prostheses were implanted. The mean age at surgery was 52.6 +/- 11.5 years in the stock group and 51.8 +/- 11.7 years in the custom-made group. In the stock group, after three years of TMJR, results showed a reduction in pain intensity from 6.4 +/- 1.4 to 1.6 +/- 1.2 (p<0.001), and an improvement in jaw opening from 2.7 +/- 0.9 cm to 4.2 +/- 0.7 cm (p<0.001). In the custom-made group, after three years of TMJR, results showed a reduction in pain intensity from 6.0 +/- 1.6 to 2.2 +/- 0.4 (p<0.001), and an improvement in jaw opening from 1.5 +/- 0.5 cm to 4.3 +/- 0.6 cm (p<0.001). No statistically significant differences between two groups were detected. Conclusions: The results of this three-year prospective study support the surgical placement of TMJ prostheses (stock prosthetic, and custom-made systems), and show that the approach is efficacious and safe, reduces pain, and improves maximum mouth opening movement, with few complications. As such, TMJR represents a viable technique and a stable long-term solution for cranio-mandibular reconstruction in patients with irreversible end-stage TMJ disease. Comparing stock and custom-made groups, no statistically significant differences were detected with respect to pain intensity reduction and maximum mouth opening improvement.", "labels": [3, 20]}
{"id": "1396", "token": "A higher kinematic pair that converts rotary motion into helical motion is presented as an alternative to the screw joint (a lower kinematic pair). First, the existence of a rolling transmission pair for a rotary-to-helical motion conversion is proven. Then, the corresponding pair of rolling surfaces (pitch surfaces) and their relative position is defined for any set of kinematic transmission parameters. Some calculated.examples are presented. A method for gear-tooth forming from the pitch surfaces using Boolean operations with a computer-aided design (CAD) program is proposed. Finally, applying this methodology, a pair of gears for rotary into helical transmission has been obtained using a 3D printer. The prototype presents negligible clearances and backlash, high reversibility, as well as continuous gearing without interference. The meshing equation for a simple generating surface is also provided.", "labels": [3, 20]}
{"id": "1531", "token": "The implementation of intraoral and extraoral computer-aided-design and computer-aided-manufacturing (CAD/CAM) systems in prosthetic dentistry has simplified the procedure, shortened the period of design and manufacture and improved accuracy and aesthetic properties of dental restorations. Three-dimensional (3D) digitisation has become an adequate replacement for conventional dental impressions. The market offers a variety of diverse optical intraoral and extraoral CAD/CAM systems equipped with digitisation devices that are based on different working principles. The main goal of this research is to determine whether precision and accuracy differ among optical digitisation devices. The research includes five high-end devices: Cerec AC, Cerec InEos, Trios, KaVo Everest and Sinergia Scan. The evaluation methodology of the experiment is based on CAD inspection. The results, obtained from accuracy and precision measurements with tolerance levels of 0.01, 0.25 and 0.05 mm, indicate that there is a difference in accuracy and precision between optical digitisation devices based on different working principles.", "labels": [3, 20]}
{"id": "1582", "token": "PURPOSE. This in vitro study evaluated the effects of four different cements on the color attributes of a zirconia ceramic. MATERIALS AND METHODS. 40 zirconia ceramic disk specimens (0.5 mm thickness, 10 mm diameter, 0.1 mm cement space) were fabricated by a computer-aided design and computer-aided manufacturing system. The specimens were divided into 4 groups of 10 specimens and cemented to composite substrates using four different cements including: Glass lonomer, Panavia F2.0, Zinc Phosphate, and TempBond. The L*, a*, and b* color attributes of the specimens were measured before and after cementation by a spectrophotometer. Additionally, Delta E values were measured to determine color changes for the groups and then compared with the perceptional threshold of Delta E = 3.3. Repeated Measures ANOVA, Tukey Post Hoc, Bonferroni, One-way ANOVA, and One-sample t-test tests were used to analyze the data. All tests were carried out at the 0.05 level of significance. RESULTS. Statistically significant differences were detected in the AE values for Zinc Phosphate (P<.0001) and TempBond (P<.0001) groups. However, there were no statistically significant differences in this respect for Glass lonomer (P=.99) and Panavia F2.0 (P=1) groups. The means and standard deviations of the Delta E values for Glass lonomer, Panavia F2.0, Zinc Phosphate, and Tempbond groups were 2.11 +/- 0.66, 0.94 +/- 0.39, 5.77 +/- 0.83, and 7.50 +/- 1.16 Unit, respectively. CONCLUSION. Within the limitations of this study, it was concluded that Zinc Phosphate and Tempbond cements affected the color attributes of the tested zirconia ceramic beyond the perceptional threshold. However, Glass lonomer and Panavia F2.0 cements created acceptable color changes.", "labels": [3, 20]}
{"id": "1651", "token": "Independently adjustable multielectrode arrays are routinely used to interrogate neuronal circuit function, enabling chronic in vivo monitoring of neuronal ensembles in freely behaving animals at a single-cell, single spike resolution. Despite the importance of this approach, its widespread use is limited by highly specialized design and fabrication methods. To address this, we have developed a Scalable, Lightweight, Integrated and Quick-to-assemble multielectrode array platform. This platform additionally integrates optical fibers with independently adjustable electrodes to allow simultaneous single unit recordings and circuit-specific optogenetic targeting and/or manipulation. In current designs, the fully assembled platforms are scalable from 2 to 32 microdrives, and yet range 1-3 g, light enough for small animals. Here, we describe the design process starting from intent in computer-aided design, parameter testing through finite element analysis and experimental means, and implementation of various applications across mice and rats. Combined, our methods may expand the utility of multielectrode recordings and their continued integration with other tools enabling functional dissection of intact neural circuits.", "labels": [3, 20]}
{"id": "1814", "token": "The design of horizontal axis wind turbine (HAWT) blades involves several geometric complexities. As a result, the modeling of these blades by commercial computer-aided design (CAD) software is not easily accomplished. In the present paper, the HAWT blade is divided into structural and aerodynamic surfaces with a G1 continuity imposed on their connecting region. The widely used method of skinning is employed throughout the current work for surface approximation. In addition, to ensure the compatibility of section curves, a novel approach is developed based on the redistribution of input airfoil points. In order to evaluate deviation errors, the Hausdorff metric is used. The fairness of surfaces is quantitatively assessed using the standard strain energy method. The above-mentioned algorithms are successfully integrated into a MATLAB program so as to enhance further optimization applications. The final surfaces created by the procedure developed during the present study can be exported using the IGES standard file format and directly interpreted by commercial CAD and FE, software. (C) 2016 Society for Computational Design and Engineering. Publishing Servies by Elsevier.", "labels": [3, 20]}
{"id": "1978", "token": "The electrical instrumentation control systems (EICS) 'As-built' documentations of a copper mine were found to possess a significant errors and omissions, which hindered the asset owner's ability to undertake effective and efficient operations and maintenance. A Systems Information Model (SIM) was used to retrospectively create a connected system to ensure all physical equipment and the associated connections that were constructed are modelled in an object-orientated database. In creating the SIM, the existing errors and omissions in the 'As-built' documentation were quantified, and cost savings that could be achieved for a future planned copper mine, with a similar design, were identified. The limitations of using conventional computer-aided-design (CAD) to design and document EICS are discussed. It is recommended that retrospectively creating a SIM can provide owners and operators with significant productivity benefits as well as ensure the asset's integrity. The case study presented provides asset owners and operators with the empirical evidence to challenge conventional thinking surrounding the design, engineering and documentation of EICS using CAD and alternatively consider the use of SIM. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [3, 20]}
{"id": "2087", "token": "Background:Postdecompressive craniotomy defect management following failed prior cranioplastyis challenging. The authors describe a staged technique utilizing free muscle transfer, tissue expansion, and custom polyetheretherketone (PEEK) implants for the management of previously failed cranioplasty sites in patients with complicating local factors.Methods:Consecutive patients with previously failed cranioplasties following large decompressive craniectomies underwent reconstruction of skull and soft tissue defects with staged free latissimus muscle transfer, tissue expansion, and placement of custom computer-aided design and modeling PEEK implants with a temporalis-plus modification to minimize temporal hollowing. Implants were placed in a vascularized pocket at the third stage by elevating a plane between the previously transferred latissimus superficial fascia (left on the skin) and muscle (left on the dura/bone). Patients were evaluated postoperatively for cranioplasty durability, aesthetic outcome, and complications.Results:Six patients with an average of 1.6 previously failed cranioplasties underwent this staged technique. Average age was 33 years. Average defect size was 139 cm(2). Average time to procedure series completion was 14.9 months. There were no flap failures. One patient had early postoperative incisional dehiscence following PEEK implant placement that was managed by immediate scalp flap readvancement. At 21.9 month average follow-up, there were no cranioplasty failures. Three patients (50%) underwent 4 subsequent refining outpatient procedures. All patients achieved complete coverage of their craniectomy defect site with hear-bearing skin, acceptable head shape, and normalized head contour.Conclusions:The described technique resulted in aesthetic, durable craniectomy defect reconstruction with retention of native hear-bearing scalp skin in a challenging patient population.", "labels": [3, 20]}
{"id": "2200", "token": "The quest for high-performance flexible circuits call for scaling of the minimum feature size in thin-film transistors (TFTs). Although reduced channel lengths can guarantee an improvement in the electrical properties of the devices, proper design rules also play a crucial role to minimize parasitics when designing fast circuits. In this letter, systematic computer-aided design simulations have guided the fabrication of high-performance flexible operational amplifiers (opamps) and logic circuits based on indium-gallium-zinc-oxide TFTs. In particular, the performance improvements due to the use of an additional third metal layer for the interconnections have been estimated for the first time. Encouraged by the simulated enhancements resulting by the decreased parasitic resistances and capacitances, both TFTs and circuits have been realized on a free-standing 50-mu m-thick polymide foil using three metal layers. Despite the thicker layer stack, the TFTs have shown mechanical stability down to 5-mm bending radii. Moreover, the opamps and the logic circuits have yielded improved electrical performance with respect to the architecture with two metal layers: gain-bandwidth-product increased by 16.9%, for the first one, and propagation delay (t(pd)) decreased by 43%, for the latter one.", "labels": [3, 20]}
{"id": "2334", "token": "This paper presents the first method that enables the fully automatic generation of triangular meshes suitable for the so-called non-uniform rational B-spline (NURBS)-enhanced finite element method (NEFEM). The meshes generated with the proposed approach account for the computer-aided design boundary representation of the domain given by NURBS curves. The characteristic element size is completely independent of the geometric complexity and of the presence of very small geometric features. The proposed strategy allows to circumvent the time-consuming process of de-featuring complex geometric models before a finite element mesh suitable for the analysis can be produced. A generalisation of the original definition of a NEFEM element is also proposed, enabling to treat more complicated elements with an edge defined by several NURBS curves or more than one edge defined by different NURBS. Three examples of increasing difficulty demonstrate the applicability of the proposed approach and illustrate the advantages compared with those of traditional finite element mesh generators. Finally, a simulation of an electromagnetic scattering problem is considered to show the applicability of the generated meshes for finite element analysis. (C) 2016 The Authors. International Journal for Numerical Methods in Engineering published by John Wiley & Sons Ltd.", "labels": [3, 20]}
{"id": "2477", "token": "Exchanging computer-aided design (CAD) model data among heterogeneous CAD systems is indispensable for collaborative product development. Currently, the industry mainly uses the standardized neutral files-based methods to implement such exchange. While at the same time, the application of web ontology language (OWL) file and underlying semantic web technologies in CAD model data exchange is gaining importance and popularity within the academia. The coexistence of different types of methods has generated a series of controversies and questions within the industry and the academia. Yet, can the neutral files-based exchange methods completely implement model data exchange among heterogeneous CAD systems? What challenges have been addressed to date by the developed CAD model data exchange standards? Why OWL has been introduced to CAD model data exchange? Does CAD model data exchange really need OWL? Are there any issues in existing neutral files-based exchange methods and OWL file-based exchange methods need to be addressed in future studies? This paper proposes to conduct a study of the standardized neutral files-based exchange methods and OWL file-based exchange methods. An in-depth analysis of the widely used standard for the exchange of product model data (STEP) method and the newly emerging OWL methods is first provided. Then, the paper makes a detailed comparison between these two types of methods based on this analysis. Finally, some issues in the two types of methods that need to be addressed in the future are discussed.", "labels": [3, 20]}
{"id": "2548", "token": "This study compares the degree of creativity of forty-two conceptual designs proposed as solutions to two innovative design problems developed in face-to-face and virtual collaborative environments. The solutions obtained were evaluated by three experts applying the Moss metric, which considers the level of usefulness and the level of unusualness. The average values and the trends of the data were obtained, and an analysis of the variance was also performed to determine whether the environment influences the degree of creativity. The results show that it cannot be proved that the level of creativity is influenced by working face-to-face or virtually, that is, whether information and communication technologies are used or not has no effect on the final result.", "labels": [3, 20]}
{"id": "2621", "token": "We here explore for the very first time how an advanced multiscale mathematical modeling approach may support the design of a provenly successful tissue engineering concept for mandibular bone. The latter employs double-porous, potentially cracked, single millimeter-sized granules packed into an overall conglomerate-type scaffold material, which is then gradually penetrated and partially replaced by newly grown bone tissue. During this process, the newly developing scaffold-bone compound needs to attain the stiffness of mandibular bone under normal physiological conditions. In this context, the question arises how the compound stiffness is driven by the key design parameters of the tissue engineering system: macroporosity, crack density, as well as scaffold resorption/bone formation rates. We here tackle this question by combining the latest state-of-the-art mathematical modeling techniques in the field of multiscale micromechanics, into an unprecedented suite of highly efficient, semi-analytically defined computation steps resolving several levels of hierarchical organization, from the millimeter- down to the nanometer-scale. This includes several types of homogenization schemes, namely such for porous polycrystals with elongated solid elements, for cracked matrix-inclusion composites, as well as for assemblies of coated spherical compounds. Together with the experimentally known stiffnesses of hydroxyapatite crystals and mandibular bone tissue, the new mathematical model suggests that early stiffness recovery (i.e., within several weeks) requires total avoidance of microcracks in the hydroxyapatite scaffolds, while mid-term stiffness recovery (i.e., within several months) is additionally promoted by provision of small granule sizes, in combination with high bone formation and low scaffold resorption rates.", "labels": [3, 20]}
{"id": "2815", "token": "Additive manufacturing (AM) technology is capable of building 3D near-net-shaped functional parts directly from computer models using unit materials, such as powder or wire. Additive manufacturing's computer-aided design offers superior geometrical flexibility. The near-net-shaping capability also significantly reduces materials waste. These benefits make AM desirable for critical applications, such as aerospace, ground transportation, and medical. Confident utilization of the technology requires thorough understanding of the AM materials, ensuring that structural integrity and performance requirements are met or exceeded. In this study, Ti-6Al-4V fabricated by two AM techniques: Laser Engineered Net Shaping (LENS) and Electron Beam Melting (EBM) were investigated and critically compared. Samples were built using various processing parameters and heat treated under different conditions, which resulted in different microstructures and mechanical properties. Characteristic microstructures were determined for all cases. Room temperature tensile and fatigue crack growth properties were also evaluated and compared in different orientations with respect to the building direction. The effects of post-AM heat treatments on microstructure and properties were also studied. The results are systematically presented and discussed from the material/process optimization, structural design, and fatigue life prediction perspectives. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [3, 20]}
{"id": "2916", "token": "Discontinuous Galerkin (DG) methods allow high-order flow solutions on unstructured or locally refined meshes by increasing the polynomial degree and using curved instead of straight-sided elements. However, one of the currently largest obstacles to applying these methods to aerodynamic configurations of medium to high complexity is the availability of appropriate higher-order curved meshes. In this article, we describe a complete chain of higher-order unstructured grid generation and higherorder DG flow solution applied to a turbulent flow around a three-dimensional high-lift configuration. This includes (i) the generation of an appropriately coarse straight-sided mesh; (ii) the evaluation of additional points on the computer-aided design geometry of the curved-wall boundary for defining a piecewise polynomial boundary representation; (iii) a higher order mesh deformation to translate the curvature from the wall boundary into the interior of the computational domain; and (iv) the description of a DG discretization, which is sufficiently stable to allow a flow computation on the resulting curved mesh. Finally, a fourth-order flow solution of the Reynolds-averaged Navier-Stokes and k-! turbulence model equations is computed on a fourth-order unstructured hybrid mesh around the three-dimensional high-lift simulation of wing-flow noise generation configuration. Copyright (C) 2016 John Wiley & Sons, Ltd.", "labels": [3, 20]}
{"id": "2993", "token": "Bioprinting is an emerging technology that allows the assembling of both living and non-living biological materials into an ideal complex layout for further tissue maturation. Bioprinting aims to produce engineered tissue or organ in a mechanized, organized, and optimized manner. Various biomaterials and techniques have been utilized to bioprint biological constructs in different shapes, sizes and resolutions. There is a need to systematically discuss and analyze the reported strategies employed to fabricate these constructs. We identified and discussed important design factors in bioprinting, namely shape and resolution, material heterogeneity, and cellular-material remodeling dynamism. Each design factors are represented by the corresponding process capabilities and printing parameters. The process-design map will inspire future biomaterials research in these aspects. Design considerations such as data processing, bio-ink formulation and process selection are discussed. Various printing and crosslinking strategies, with relevant applications, are also systematically reviewed. We categorized them into 5 general bioprinting strategies, including direct bioprinting, in-process crosslinking, post-process crosslinking, indirect bioprinting and hybrid bioprinting. The opportunities and outlook in 3D bioprinting are highlighted. This review article will serve as a framework to advance computer-aided design in bioprinting technologies.", "labels": [3, 20]}
{"id": "3115", "token": "BackgroundSingle-tooth replacement often requires a prefabricated dental implant and a customized crown. The benefits of individualization of the abutment remain unclear. PurposeThis randomized controlled clinical trial aims to study potential benefits of individualization of zirconia implant abutments with respect to preservation of marginal bone level and several clinical and patient-based outcome measures. Material and MethodsFifty participants with a missing premolar were included and randomly assigned to standard (ZirDesign, DentsplySirona Implants, Molndal, Sweden) or computer aided design/computer aided manufacturing (CAD/CAM) customized (Atlantis, DentsplySirona Implants, Molndal, Sweden) zirconia abutment therapy. Peri-implant bone level (primary outcome), Plaque-index, calculus formation, bleeding on probing, gingiva index, probing pocket depth, recession, appearance of soft tissues and patients' contentment were assessed shortly after placement and one year later. ResultsNo implants were lost and no complications related to the abutments were observed. Statistically significant differences between stock and CAD/CAM customized zirconia abutments could not be demonstrated for any of the operationalized variables. ConclusionThe use of a CAD/CAM customized zirconia abutment in single tooth replacement of a premolar is not associated with an improvement in clinical performance or patients' contentment when compared to the use of a stock zirconia abutment.", "labels": [3, 20]}
{"id": "3153", "token": "Representation of curves and, surfaces is a basic topic in computer graphic and computer aided design (CAD). In this paper we focus on theoretical and practical issues in using radial basis functions (RBF) for reconstructing implicit curves and surfaces from point clouds. We study the conditioning of the problem and give some insight on how the problem parameters and the results have to be taken in order to achieve meaningful solutions and avoid artifacts. Moreover, a strategy for decreasing the conditioning of the problem is suggested and a general framework for preconditioning and solving the problem, even for large datasets, is also provided. (C) 2016 IMACS. Published by Elsevier B.V. All rights reserved.", "labels": [3, 20]}
{"id": "3206", "token": "Having access to the right information at the right time has been, and remains a pervasive problem during operations and maintenance (O&M) and thus hinders an asset owner's ability to ensure their facilities performance are being optimized. Typically, asset managers are often confronted with 'As-built' documentation that is prepared using Computer-Aided-Design (CAD) and is often incomplete, erroneous and/or redundant, which adversely impacts an asset's integrity and productivity during O&M. With this mind, the quality of information contained within 'As-Built' electrical documentation for an 'Underground Railway Station' is evaluated by quantifying the errors and omissions contained within them. The cost to document information using CAD compared to the development of a System Information Model (SIM) is determined. A retrospective SIM is constructed and a bi-directional link with a three dimensional (3D) model is established to ensure the integrity of the information required for O&M. The use of a SIM instead of CAD can provide engineers with a new medium and process for preparing the design and documentation of electrical systems as it provides them with an ability to obtain significant productivity and cost benefits. The empirical research presented in this paper provides the impetus for future research in the fertile and unexplored area of Digital Asset Management for infrastructure projects. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [3, 20]}
{"id": "3469", "token": "In this paper, the self-heating and mutual thermal coupling in a state-of-the-art SiGe:C multi-finger heterojunction bipolar transistor (HBT) was investigated in static dc operation conditions. Multi-finger HBT structure was created using Sentaurus structure editor with dimensions similar to the layout of SiGe:C multi-finger HBTs in ST-Microelectronics BiCMOS55 (B55) technology (f (T) >300 GHz, f (max) >400 GHz) as per ST's BiCMOS55 process design kit guidelines. Three-dimensional thermal technology computer aided design (TCAD) simulations were carried out to obtain the temperature distribution in static dc operation. The lattice temperature (T (Lattice)) and heat flux (F (Heat)) distribution inside the device were studied. The impact of back-end-of-line (BEOL) layers on static thermal behavior of the state-of-the-art SiGe:C multi finger HBTs was also investigated. The temperature dependent thermal resistance of different fingers of the trench isolated SiGe multi-finger HBT was extracted without and with back-end-of-line (BEOL) effect. An electro-thermal dc compact model of self-heating and mutual thermal coupling in multi-finger HBTs was proposed and applied to compare the modeling results with the TCAD simulation results. Very good agreement was achieved between results obtained from TCAD simulation and those obtained from compact model-based simulation.", "labels": [3, 20]}
{"id": "3521", "token": "Introduction. Bone repair frequently requires time-consuming implant construction, particularly when using un-formed implants with poor handling properties. Wetherefore developed osteoinductive, micro-fibrous surface patterned demineralized bone matrix (DBM) fibers for engineering both defect-matched and general three-dimensional implants. Methods and results. Implant molds were filled with demineralized human cortical bone fibers there were compressed and lyophilized, forming mechanically strong shaped DBM scaffolds. Enzyme linked immunosorbent assays and mass spectrometry confirmed that DBM fibers contained abundant osteogenic growth factors (bone morphogenetic proteins, insulin-like growth factor-I) and extracellular matrix proteins. Mercury porosimetry and mechanical testing showed interconnected pores within the mechanically stable, custom DBM fiber scaffolds. Mesenchymal stem cells readily attached to the DBM and showed increasing metabolic activity over time. DBM fibers further increased alkaline phosphatase activity in C2C12 cells. In vivo, DBM implants elicited osteoinductive potential in a mouse muscle pouch, and also promoted spine fusion in a rat arthrodesis model. Significance. DBM fibers can be engineered into custom-shaped, osteoinductive and osteoconductive implants with potential for repairing osseous defects with precise fitment, potentially reducing operating time. By providing pre-formed and custom implants, this regenerative allograft may improve patient outcomes following surgical bone repair, while further advancing personalized orthopedic and craniomaxillofacial medicine using three-dimensional-printed tissue molds.", "labels": [3, 20]}
{"id": "17", "token": "Water resources assessment in arid lands is of a particular interest, not only in scientific terms, but also under the concept of sustainable development. The study area (El Ambagi basin), represents a remote arid area with a scarcity of data. The measured effective porosity and permeability revealed high potentialities of the Nubian sandstone and Oligocene sediments. The hydrogeologic setting indicates favorable conditions for groundwater accumulation where there is an opportunity of recharge, and thus, the sustainability of the groundwater. The research approach is based on geological investigations as well as several data layers in the GIS environment including landforms, lithology, slope, soil, morphometric parameters, structural lineaments, and geophysical data. Several specific sites were suggested as targets for future groundwater explorations. The studied basin contains four sub-basins which have an intensive drainage network. The morphometric parameters revealed that they have potential for surface runoff occurrence and also for groundwater recharge. Two of the investigated sub-basins show high hazard degrees and should be protected to avoid flash floods. The estimated runoff volume from a single rainfall event (27 mm) can reach 3316.42 x 10(3) m(3). Hence, management of rainwater harvesting and protection measures against flash floods are necessary. A future water resources management strategy, based on results of the multidisciplinary study, is proposed.", "labels": [4, 28]}
{"id": "187", "token": "The rainfall data of Ludhiana for a period of 32 years covering 1981 to 2012 have been collected from School of Climate Change and Agricultural Meteorology. The study was planned to find the rainfall variability and amount of rainfall at different probability levels for the year 1981-2012. The rainfall data was analyzed on weekly basis to work out the initial & conditional probability for rainfall at different levels, i.e., >5 mm, >10 mm, >20 mm, >30 mm, >40 mm and >50 mm using Markov chain model. In addition to this, incomplete gamma distribution was also used to find out the occurrence of rainfall events at different probability levels, i.e., 20, 30, 40, 50, 65 and 75 per cent. The study results in estimation of maximum and minimum initial probability and conditional probability (wet and dry) for standard meteorological week. The results will be useful for deciding the sowing time, irrigation/fertilizer scheduling and harvesting time for different crops. In addition to this study will be useful for determining the runoff volume, peak runoff rate and hence can be used for designing of rainwater harvesting structures.", "labels": [4, 28]}
{"id": "287", "token": "Rainwater harvesting technology is considered an innovative and effective mechanism for reducing drinking water risks due to arsenic contamination and water salinity in coastal Bangladesh. However, adoption of such tanks remains elusive. Most studies on disaster risk communication are predominantly based on individual-level cognitive modeling approaches, which fail to address the role of social groups, human relations, and other collective social factors in the dissemination process of disaster preventive measures. From the viewpoint of social implementation, community adoption of unfamiliar technology for disaster risk mitigation and preparedness requires another approach. Given the challenge to promote rainwater harvesting technology in the study area of coastal Bangladesh, this study examines the role of various social networks including cohesive groups (friends), structural equivalent groups (individuals who have the same position in society), and spatial groups (neighbors) in three information sharing and processing activities-hearing, observation, and discussion. Results show that those individuals who have similar cohesive affiliations tend to become hearing and discussion partners. Cohesive groups share a learning opportunity and are bounded by normative constraints in terms of direct and intimate social relations. Spatial groups facilitate observation, which provides visual learning. Structurally equivalent groups are not relevant in adoption dissemination; therefore competition or similar social environment did not influence the rainwater tank dissemination activities.", "labels": [4, 28]}
{"id": "398", "token": "The low water availability in several regions of southeastern Hellas and particularly in several islands, such as Crete, has resulted in the construction of various types of water reservoir for collection and storage of rainwater, since their very early habitation. Since then, technologies for the construction and use of several types of cisterns have been developed. In Crete during the Minoan era, water cisterns were very well practiced as a basic means for water supply in several settlements. The Minoan water cistern technologies were further developed, mainly by enlargement of the scale of water systems, at subsequent stages of the Hellenic civilizations. Furthermore, more advanced water cistern technologies were invented, with a peak during the Hellenistic period which followed Alexander the Great, during which time they spread over a geographical area from Hellas to the west and to the east. The Romans inherited the cistern technologies and further developed them mainly by changing their application scale from small to large. Characteristic paradigms of Cretan cisterns are considered which justify the significance of that technology for water supply in areas with low water availability during the whole Cretan history. Herein, nowadays climatic conditions and water resources management in Crete are presented and discussed.", "labels": [4, 28]}
{"id": "452", "token": "Over the last 30 years leading thinkers have taken us beyond mechanistic and reductionist analysis into systems theory and the critical boundary judgements that are fundamental to systems analysis. In defining and discussing boundary conditions, we also redefine values and facts imposed on hydrological and economic analysis that underpins decisions about government policy in water resources. The repeal of legislation for distributed interventions (water-efficient appliances and rainwater harvesting) that was previously enacted to improve the security of a regional water supply system is examined as a case study. The results of the analysis were defined by the costs and benefits that are inside or outside of the boundaries of legitimate and recognized consideration. This paper refers to those differences as boundary conditions and considers how those boundary conditions affect the outcome of analysis. Setting of boundary conditions (what is included, what is excluded and assumptions) in engineering and economic analysis dominates outcomes of decisions about government policy. These insights have general application to development of government water policy. The investigations outlined in this paper were combined to create an enhanced version of a systems analysis of a policy for setting targets for water savings on all new dwellings. It was established, using appropriate boundary conditions, that a 40% target for water savings is feasible for South East Queensland (SEQ) and provides a cost-benefit ratio of 2.1. These results indicate that a policy of mandating targets for sustainable buildings would provide substantial benefits to the state of Queensland, water utilities and citizens.", "labels": [4, 28]}
{"id": "555", "token": "Recently, rainwater harvesting systems have received increased attention due to their capability for adapting to water scarcity and climate change. However, a key obstacle to the implementation of rainwater harvesting systems is that they are often not financially feasible given difficulty in determining optimal system size. A key premise of previous studies was that all rainwater harvesting systems are constructed in a single construction event even though it is possible to construct a system in multiple stages. This assumption limits managerial flexibility in the construction of rainwater harvesting systems, which is particularly valuable in scenarios where it is difficult to forecast future rainfall patterns. Therefore, we propose a multi-stage system expansion strategy for the implementation of rainwater harvesting systems using decommissioned septic tanks under scenarios of uncertainty in rainfall from a real option perspective as a means to improve the financial feasibility of implementing rainwater harvesting systems. We tested this strategy by evaluating a proposed rainwater harvesting system for a midsize apartment complex in Jeonju, South Korea. The multi-stage expansion strategy generated an option value of 9,896 USD. This study will help to improve the financial feasibility of rainwater harvesting systems by adding the value of managerial flexibility through a sequential expansion of RWH systems as new information becomes available.", "labels": [4, 28]}
{"id": "694", "token": "The present study refers to Building-Integrated Solar Thermal (BIST) systems based on vacuum-tube collectors and it consists of two parts. In the first part, a literature review is presented, including studies about vacuum-tube technology (vacuum-tube/BIST systems, the environmental profile of vacuum-tube collectors, etc.). Critical issues, for example related to the integration of vacuum-tube collectors into the building, are highlighted. The review shows that most of the proposed vacuum-tube/BIST concepts are about facade-integration and there are few studies about the environmental profile of vacuum-tube collectors. As a continuity of the issues presented in the first part, the second part includes a case study about the environmental comparison of a vacuum-tube/BIST system with a flat-plate/BIST configuration, based on life cycle assessment. The systems are gutter-integrated, patented and they have been developed/tested at the University of Corsica, in France. Multiple life-cycle impact assessment methodologies, environmental indicators, scenarios and databases are adopted. The results reveal that the energy payback time is 1.8 and 0.5 years, for the flat-plate/BIST and for the vacuum-tube/BIST, respectively, while by using recycling these values become 0.5 and 0.1 years, respectively. Energy-return-on-investment, greenhouse-gas payback time and avoided impact during use phase (by adopting USEtox, ecological footprint and France's electricity as well as with reference domestic-gas-boiler CO2.eq emissions) are also presented. The findings of the present work: 1) are compared with the literature and good agreement is observed, 2) verify that considerably higher impact can be avoided by utilizing the vacuum-tube/BIST instead of the flat-plate/BIST system. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [4, 28]}
{"id": "778", "token": "Rainwater harvesting is an important technology in cities that can contribute to a number of functions, such as sustainable water management in the face of demand growth and drought as well as the detention of rainwater to increase flood protection and reduce damage to waterways. The objective of this article is to investigate the integrity of residential rainwater harvesting systems, drawing on the results of the field inspection of 417 rainwater systems across Melbourne that was combined with a survey of householders' situation, maintenance behaviour and attitudes. Specifically, the study moves beyond the assumption that rainwater systems are always operational and functional and draws on the collected data to explore the various reasons and rates of failure associated with pumps and pump switches, leaving for later further exploration of the failure in other components such as the collection area, gutters, tank, and overflows. To the best of the authors' knowledge, there is no data like this in academic literature or in the water sector. Straightforward Bayesian Network models were constructed in order to analyse the factors contributing to various types of failures, including system age, type of use, the reason for installation, installer, and maintenance behaviour. Results show that a number of issues commonly exist, such as failure of pumps (5% of systems), automatic pump switches that mediate between the tank and reticulated water (9% of systems), and systems with inadequate setups (i.e. no pump) limiting their use. In conclusion, there appears to be a lack of enforcement or quality controls in both installation practices by sometimes unskilled contractors and lack of ongoing maintenance checks. Mechanisms for quality control and asset management are required, but difficult to promote or enforce. Further work is needed into how privately owned assets that have public benefits could be better managed. Crown Copyright (C) 2016 Published by Elsevier B.V. All rights reserved.", "labels": [4, 28]}
{"id": "842", "token": "In Colombia, several communities with limited or uncertain access to drinking water services collect rainwater for various domestic uses. This paper presents the results of a water quality analysis of the rainwater runoff from roofs in Kennedy (Bogota) to evaluate the suitability of adapting this water to satisfy domestic uses in this district. Based on the high values of turbidity and biochemical oxygen demand, and on the high concentrations of total suspended solids and heavy metals found in the studied rainwater, it is concluded that the water samples are not suitable for any of the domestic uses currently employed by the citizenry. Nevertheless, a high spatial and temporal variability was detected, in addition to variability as a function of the roof material. In particular cases, the runoff water from roofs may be adapted as an alternative source for domestic uses in the district.", "labels": [4, 28]}
{"id": "919", "token": "This article is crafted around assessment and analysis of health risks associated with domestic rooftop water harvesting in India, with the prime objective of bringing to the forefront the deterrent issues and challenges in rainwater harvesting in general and domestic rooftop water harvesting in particular. This is based on a study on health risk assessment of a domestic rooftop water harvesting project conducted in the Nagaur district of Rajasthan, India, providing a critical reflection and exemplifying the prevalent scenario in the arid regions of the world. The methodology used for deriving the conclusions is failure mode and effects analysis. A set of risks were graded according to their severity based on their risk priority number scores evolved, including various contaminants polluting the harvested rainwater. The findings bear implications for planning of reconstructive changes to be incorporated and thus providing the necessary outlook for effective alleviation of the deterrents and make rainwater harvesting the premium solution for realization of the Millennium Development Goals by providing access to safe drinking water to the populace chiefly in the developing countries where the problem of scarce safe water is grave.", "labels": [4, 28]}
{"id": "1025", "token": "Rainwater harvesting could increase the resilience of ecosystems on the Loess Plateau and thus ensure the sustainability of livelihoods that depend on them. As such, it is a key component of strategies for adapting to global climate change. In this study, we used a new method to quantify the rainwater harvesting potential (RWHP) across the whole Loess Plateau and to characterize its spatial and temporal variation over the last four decades on the basis of the variable infiltration capacity model. It was found that that the mean RWHP of the study region was 731.10x10(8)m(3), and the average water layer thickness was 114.34mm. There is considerable scope for rainwater harvesting across the Loess Plateau as a whole, to the extent that it could potentially provide enough water to implement the Grain for Green' Project. The annual average RWHP decreased slightly from 1971 to 2010, and Hurst exponent analysis indicated that this trend will exhibit long-term persistence. The annual RWHP was highest in the southeast of the Loess Plateau and lowest in the northwest. Areas with high RWHP values tended to be clustered around the middle reach of the Yellow River. For most areas, there was no significant change between 1971 and 2010. Those areas for which there was a significant decrease in RWHP were primarily located around the upper-middle reaches of the Weihe River, the upper reach of Jinghe River, the eastern Guanzhong Plain, the Qinhe River watershed and the area around Dongsheng. Quantitative assessments of RWHP are likely to be useful for guiding the development and use of innovative rainwater harvesting technologies around the world and could help to relieve the problems caused by water shortages on the Loess Plateau while simultaneously eliminate the major cause of soil erosion. Copyright (c) 2012 John Wiley & Sons, Ltd.", "labels": [4, 28]}
{"id": "1076", "token": "Agriculture is the largest employing sector that involves 44.7% of manpower of Pakistan's total population and participates about 23% in GDP of Pakistan but on the other side, country is facing the shortage of water. The 60% of population lives in rural and hilly areas while implementing the schemes of water in hilly areas is not feasible because of high expenditures and less progress. Moreover, supplying of water in hilly areas is time consuming, unsafe and expensive work therefore, hilly areas rainwater harvesting is the most appropriate and feasible technique. This paper represents the study of runoff pattern and to investigate the potential water harvesting sites in Potohar Plateau of Pakistan. The techniques, such as Geographic Information System, Remote Sensing, HEC-GeoHMS and HEC-HMS were used for delineation of water channels, drainage line and for estimation of runoff generation. The results revealed that 60% of the study area has potential for rainwater harvesting in order to accumulate and store runoff generated from annual rainfall.", "labels": [4, 28]}
{"id": "1251", "token": "With respect to the current vulnerable climatic condition, water quality has become a matter of the highest worldwide concern. Rainwater harvesting is the most acceptable solution for overcoming this problem. Among various rainwater harvesting systems, green roof rainwater harvesting is a significant tool for improving the standard of living for rapidly growing populations in the whole world, in terms of both water demand and protecting the environment from pollution. This paper assesses the water quality parameter (dissolved oxygen (DO), pH, conductivity, and temperature) of rainwater harvesting from green roofs in humid tropic center under tropical climate conditions. It shows that the values of electric conductivity are always within Class I according to Interim National Water Quality Standards (INWQS) and Water Quality Index (WQI). Depletions of DO and pH values were observed for the green roof runoff, and the runoff quality ranged between Class I and III under INWQS and WQI. Lower value of pH indicates that harvested rainwater from green roofs is more acidic than the standard neutral value. Harvested water must be processed through general water treatment methods like filtration, disinfection, and through reverse osmosis storage tank. The indoor temperatures are always within an acceptable range.", "labels": [4, 28]}
{"id": "1345", "token": "Rainwater harvesting (RWH) provides various social, environmental, and economic benefits. It is important to first consider individual preferences and willingness to use harvested water for different purposes in order to encourage a community to use RWH and establish strategies that allow for the introduction of an alternative water supply, and additionally foster water management through sustainable practices. This paper presents the willingness of individuals to use RWH in three localities (Guanajuato, Romita, and Silao) of the state of Guanajuato, Mexico, evaluated through the acceptance of using the collected rainwater found in the results of 504 questionnaires directly applied to owners and dwelling users in urban areas of the localities studied. Other aspects related with RWH were included in the study, such as some characteristics of the population and their dwellings.", "labels": [4, 28]}
{"id": "1491", "token": "The objective reality of uneven water resource distribution and imbalanced water demand of the human society makes it inevitable to transfer water. It has been an age-old method to adopt the inter-basin water transfers (IBTs) for alleviating and even resolving the urgent demand of the water-deficient areas. A number of countries have made attempts and have achieved enormous benefits. However, IBTs inevitably involve the redistribution of water resources in relevant basins and may cause changes of the ecological environment in different basins. Such changes are two-sided, namely, the positive impacts, including adding new basins for water-deficient areas, facilitating water cycle, improving meteorological conditions in the recipient basins, mitigating ecological water shortage, repairing the damaged ecological system, and preserving the endangered wild fauna and flora, as well as the negative impacts, including salinization and aridification of the donor basins, damage to the ecological environment of the donor basins and the both sides of the conveying channel system, increase of water consumption in the recipient basins, and spread of diseases, etc. Because IBTs have enormous ecological risk, it is necessary to comprehensively analyze the inter-basin water balance relationship, coordinate the possible conflicts and environmental quality problems between regions, and strengthen the argumentation of the ecological risk of water transfer and eco-compensation measures. In addition, there are some effective alternative measures for IBTs, such as attaching importance to water cycle, improving water use efficiency, developing sea water desalination, and rainwater harvesting technology, etc.", "labels": [4, 28]}
{"id": "1699", "token": "In this study, the quality of collected rainwater at a downtown middle school rainwater harvesting system was evaluated by measuring physical, chemical, and microbiological parameters such as pH, dissolved oxygen (DO), chemical oxygen demand (COD), total nitrogen (TN), total phosphorus (TP), NO3, PO4, total coliform (TC), Escherichia coli, and some metals (i. e. Al, Cr, Mn, Zn, Cu, As, Cd, and Pb) (2003 to 2011). The analysis shows that the collected water quality is poor, which presents health, considering the high levels of bacterial indicators detected in the harvested rainwater, i. e. turbidity (1.4 to 15.5 NTU) and E. coli (120 and 35 CFU/100 mL in 2007 to 210 and 60 CFU/100 mL in 2011). This study shows that deteriorating water quality was caused by system contamination due to the absence of maintenance. Based on this study, proper operation and maintenance are generally the simplest and most effective ways of maintaining water quality.", "labels": [4, 28]}
{"id": "1893", "token": "Water supply reliability is expected to be affected by both precipitation amount and distribution changes under recent and future climate change. We compare historical (1951-2010) changes in annual-mean and annual-maximum daily precipitation in the global set of station observations from Global Historical Climatology Network and climate models from the Inter-Sectoral Impact Model Intercomparison Project (ISI-MIP), and develop the study to 2011-2099 for model projections under high radiative forcing scenario (RCP8.5). We develop a simple rainwater harvesting system (RWHS) model and drive it with observational and modeled precipitation. We study the changes in mean and maximum precipitation along with changes in the reliability of the model RWHS as tools to assess the impact of changes in precipitation amount and distribution on reliability of precipitation-fed water supplies. Results show faster increase in observed maximum precipitation (10.14% per K global warming) than mean precipitation (7.64% per K), and increased reliability of the model RWHS driven by observed precipitation by an average of 0.2% per decade. The ISI-MIP models show even faster increase in maximum precipitation compared to mean precipitation. However, they imply decreases in mean reliability, for an average 0.15% per decade. Compared to observations, climate models underestimate the increasing trends in mean and maximum precipitation and show the opposite direction of change in reliability of a model water supply system.", "labels": [4, 28]}
{"id": "2025", "token": "This paper presents the findings of an integrated household water treatment and reuse system for agriculture in La Soukra, Tunisia. The researchers found that the system has an internal rate of return of 17% and a net present value range from USD 26,000 (at a 5% discount rate) to USD 11,000 (for a 10% discount rate). Benefits included more water for irrigation, reduced costs to service providers, increased agricultural production from greenhouses and expanded agricultural options. These results suggest that investments in rainwater harvesting and greywater treatment at the farm level can increase the financial feasibility of peri-urban farms, which are often faced with pressure from urban growth. The systems can also help build household resilience to broader environmental change by lowering the exposure of farmers to burdens associated with infrequent access to water and poor-quality soil.", "labels": [4, 28]}
{"id": "2093", "token": "Availability of safe drinking water is considered a key challenge in the coastal region of Bangladesh. High concentrations of salinity, iron and arsenic, and the unavailability of suitable aquifers, have deterred the exploitation of groundwater resources. In addition the cyclonic storm surge is a major threat to this system. Cyclones accompanied by storm surges in the coastal area cause significant deterioration of drinking water supply and sanitation. Water professionals have launched some initiatives to promote small-scale, alternative safe water sources (e. g. rainwater harvesting, pond sand filters and piped water techniques) to provide sustainable solutions to the problem. However, a systematic evaluation of the alternatives that considers social, technical and economic criteria has not been carried out so far. The present study is an attempt to evaluate the alternative options for drinking water supply in a cyclone-prone area. The authors conducted a multi-criteria analysis and reached the conclusion that rainwater harvesting is the most suitable option for the area. Moreover, the final result was shared with the users to obtain their feedback to ensure sustainability of the water source.", "labels": [4, 28]}
{"id": "2233", "token": "Urban stormwater runoff could have negative impacts on water resources and the environment. Rainwater Harvesting (RWH) can serve both as a stormwater control and water conservation measure. Cistern size and irrigation scheduling are two of the factors that directly impact the total runoff from a residential unit with a RWH system and the amount of potable water used for irrigation. The effectiveness of RWH was evaluated for four soil types; Sand, Sandy Loam, Loamy Sand, and Silty Clay, with a root zone of 15.2 cm using three irrigation scheduling methods (Evapotranspiration (ET)-based, soil moisture-based, and time-based), and five cistern sizes. Total runoff volumes and total supplemental potable water used were compared among the three irrigation scheduling systems and a control treatment without RWH. A model was developed to simulate the daily water balance for the treatments. Irrigation and runoff volumes were compared for the various scenarios. Silty clay soil resulted with 83 % more runoff than Sandy soil, while Sandy soil required on average 58 % more supplemental water than Silty Clay soil. On average, the 833 L cistern resulted with 41 % savings in water supply and 45 % reduction in total runoff. Results showed that the greatest volumes of runoff predicted were for the silty clay soil Control Treatment using a time-based irrigation scheduling method, while the least volumes calculated were for the sandy loam soil time-based irrigation scheduling treatment with 833 L cistern size. The greatest volumes of total supplemental water predicted were for sandy loam soil Control Treatment, while the least volumes were for silty clay soil ET-based irrigation scheduling treatment with 833 L cistern size. Regression equations were developed to allow for users to select a RWH cistern size based on the amount of water they want to save or runoff to reduce.", "labels": [4, 28]}
{"id": "2317", "token": "Majority of the population is dependent on the conventional energy sources for their day today needs. Leading edge research on the renewable sources of energy is on a rise in order to meet the increasing energy demand without straining the environment. The objective of this project is to harvest potential energy inherent in tall buildings because of the high altitudes using micro-pelton turbine at the ground from grey water and rain water. Purified Grey water is collected in a tank placed at the centre of the building and rain water collection tank is placed at the top of the building. A control system is designed for optimum power output from the turbine and to monitor the levels of water. Separation and storage of used rainwater in a tank is also controlled. The pelton turbine is designed and further analyzed in ANSYS - Fluent, computationally for the power output. When number of high rises is escalating and awareness about rainwater harvesting and renewable sources of energy is indispensable, this source of energy will turn out to be viable option.", "labels": [4, 28]}
{"id": "2431", "token": "This study was aimed at developing an optimization approach to rainwater harvesting (RWH) considering three (3) water consumption scenarios (WCS). These scenarios which include basic water need (BWN), pour flush (PF) and full plumbing connection (FPC) corresponding to 50 litres per capita per day (lpcd), 75(lpcd) and 150(lpcd) respectively were simulated for different categories of buildings. Reliability of supply was determined by first obtaining composite surplus/deficit of rainwater followed by optimizing the redistribution of surplus rainwater harvested to deficient buildings. Results showed that when total annual rainfall intercepted by roof exceeded total demand, 100% reliability of water supply was guaranteed. Reliability was found to be a linear function of storage. When reliability of supply is possible, the optimized storage bears an inverse exponential relationship to the roof plan area per capita. The relationship between surplus/deficit and roof plan area per capita follows a one-phase decay pattern. An optimal redistribution of surplus water from self-sufficient buildings to deficient ones gave an improvement in supply reliability from 64 to 87% for basic water need, 47 to 58% for pour flush and 28 to 29% for full plumbing connection.", "labels": [4, 28]}
{"id": "2479", "token": "Health risk concerns associated with household use of rooftop-harvested rainwater (HRW) constitute one of the main impediments to exploit the benefits of rainwater harvesting in the United States. However, the benchmark based on the U.S. EPA acceptable annual infection risk level of <= 1 case per 10,000 persons per year (<= 10(-4) pppy) developed to aid drinking water regulations may be unnecessarily stringent for sustainable water practice. In this study, we challenge the current risk benchmark by quantifying the potential microbial risk associated with consumption of HRW-irrigated home produce and comparing it against the current risk benchmark. Microbial pathogen data for HRW and exposure rates reported in literature are applied to assess the potential microbial risk posed to household consumers of their homegrown produce. A Quantitative Microbial Risk Assessment (QMRA) model based on worst-case scenario (e.g. overhead irrigation, no pathogen inactivation) is applied to three crops that are most popular among home gardeners (lettuce, cucumbers, and tomatoes) and commonly consumed raw. The infection risks of household consumers attributed to consumption of these home produce vary with the type of produce. The lettuce presents the highest risk, which is followed by tomato and cucumber, respectively. Results show that the 95th percentile values of infection risk per intake event of home produce are one to three orders of magnitude (10(-7) to 10(-3)) lower than U.S. EPA risk benchmark (<= 10(-4) pppy). However, annual infection risks under the same scenario (multiple intake events in a year) are very likely to exceed the risk benchmark by one order of magnitude in some cases. Estimated 95th percentile values of the annual risk are in the 10(-4) to 10(-3) pppy range, which are still lower than the 10(-3) to 10(-1) pppy risk range of reclaimed water irrigated produce estimated in comparable studies. We further discuss the desirability of HRW for irrigating home produce based on the relative risk of HRW to reclaimed wastewater for irrigation of food crops. The appropriateness of the <= 10(-4) pppy risk benchmark for assessing safety level of HRW-irrigated fresh produce is questioned by considering the assumptions made for the QMRA model. Consequently, the need of an updated approach to assess appropriateness of sustainable water practice for making guidelines and policies is proposed. (C) 2013 Elsevier Ltd. All rights reserved.", "labels": [4, 28]}
{"id": "2513", "token": "The predictive nature of digital soil mapping makes it a labour-and cost-effective way of facilitating soil surveys. A digital elevation model was used to generate terrain attributes that can be used to infer the distribution of soil associations relative to the topography. Two study areas - Gladstone and Potsane - in the Free State Province of South Africa were considered. Slope, aspect, contour and plan curvature, topographic wetness index and topographic morphological unit were used to develop a model for predicting soil associations. Discriminant analysis was employed to develop the model. The model was trained on data obtained from Gladstone and validated on data from Gladstone and Potsane. Predicting soil form was unsatisfactory. Prediction done on soil associations, with soils grouped as deep, shallow and valley-bottom soils (criteria closely related to the suitability for in-field rainwater harvesting), achieved acceptable improvement in prediction accuracy. For Gladstone, when analysis was done using equal prior probability, accuracy percentages of 56.9%, 51.5% and 58.3% were found for calibration, cross-validation and areas suited to in-field rainwater harvesting, respectively. With prior probability set in accordance to sample frequency, the accuracy percentages were improved to 83.1%, 80.0% and 94.6%, respectively. In Potsane, the prediction accuracy percentage was low (38.23%) with equal prior probability but markedly improved (67.65%) when prior probability was similar to sample frequency. These results support the validity of the statement that the predictive nature of digital soil mapping makes it a labour-and cost-effective way of facilitating soil surveys.", "labels": [4, 28]}
{"id": "2732", "token": "Rainwater harvesting (RWH) is a decentralized practice that provides both water supply and runoff reduction benefits that are often difficult to assess. To assist in this evaluation, a model was developed that simulates a single RWH system in Richmond, Virginia, using storage volume, roof area, irrigated area, an indoor nonpotable demand, and a storage dewatering goal as independent design variables. Water supply and runoff capture reliability are assessed for a wide variety of cases. Tradeoff curves were developed to evaluate the design variable substitution when reliability was held constant. A reliability function was fit to the simulation results, and a solution method was developed to solve for an unknown variable as a function of the others. This method evaluates different design cases that provide the same water supply and/or runoff reliability, demonstrating that the design variables can be substituted for each other, using care to restrict substitutions between functional inputs or (separately) functional outputs. This method can provide guidance for designers in selecting equivalent RWH systems and regulators in assessing runoff reduction goals. Results indicate that the dewatering goal enhances runoff capture reliability but reduces water supply reliability moderately. Increases in storage volume increased both water supply and runoff capture reliability. Irrigated area has a much larger, negative effect on water supply reliability, and roof area has a similar negative effect on runoff capture reliability. As irrigated area increases for the same population, runoff capture reliability increases but eventually remains constant, reflecting the dominance of indoor demand, which in turn reflects the simulation's assumption of seasonal irrigation. Applications indicate that land uses that provide larger demands, such as offices, commercial sites, and high-density residential sites, may be better suited than lower-density residential lots where RWH is more commonly employed.", "labels": [4, 28]}
{"id": "2844", "token": "There is a need for in-situ soil moisture conservation in arid and semi-arid regions due to insufficient rainfall for agriculture. For this purpose, a combination implement [integrated reservoir tillage system (RT)] comprised of a single-row chisel plow, single-row spike tooth harrow, modified seeder, and spiked roller was developed and compared to the popular tillage practices, viz., minimum tillage (MT) and conventional tillage (CT) in an arid Mediterranean environment in Egypt. The different tillage practices were conducted at tillage depths of 15, 20, and 25 cm and forward speeds of 0.69,1, 1.25, and 1.53 m s(-1). Some soil physical properties, runoff, soil loss, water harvesting efficiency and yield of wheat were evaluated. The different tillage practices caused significant differences in soil physical properties as the RT increased soil infiltration, producing a rate of 48% and 65% higher than that obtained in MT and CT, respectively. The lowest values of runoff and soil loss were recorded under RT as 4.91 mm and 0.65 t ha(-1), whereas the highest values were recorded under CT as 11.36 mm and 1.66 t ha(-1), respectively. In conclusion, the RT enhanced the infiltration rate, increased water harvesting efficiency, reduced runoff and achieved the highest yield of wheat. The best tillage operating parameters appeared to be at a tillage depth of 20 cm and speed between 1.00 and 1.25 ms(-1). (C) 2015 Elsevier B.V. All rights reserved.", "labels": [4, 28]}
{"id": "2921", "token": "Integrating micro-flood irrigation with in-field rainwater harvesting (IRWH) was proposed and experiments were conducted in the 2007-2008 production season at Parady's Experimental Farm of the University of the Free State, South Africa. Three water regimes, dryland (DL), supplemental (SPI), and full irrigation (FI), were tested with 1, 2, and 3m runoff strip width (RSW) to determine their effects on soil water balance components for the integrated IRWH. Four blocks with nine subplots were prepared for the 3x3 split plot factorial experimental design. Plots were 30m long with a standard 1m width. Site specific data were used to estimate rainfall-runoff and deep drainage functions. Soil water content (SWC) was measured with a Neutron water meter. Evapo-transpiration (ET) was partitioned into evaporation and transpiration using a beta parameter. Deep drainage was the least significantly affected. Rainfalls not less than 24mm had significantly higher gains on change in SWC for the 2m and 3m RSW. During dry spells these RSWs had significantly higher SWC deficit. For the vegetative and reproductive growth stages evaporation from the 3m RSW constituted not less than 60% of ET compared to less than 40% from 1m RSW. The 1m RSW had significantly higher ET and T, irrespective of water regime with the highest values from irrigation treatments. The 1m RSW can, therefore, be used with either FI or SPI to optimize soil water balance for the integrated IRWH water management.", "labels": [4, 28]}
{"id": "3013", "token": "The rapid urbanization and the constant expansion of urban areas during the last decades have locally led to increasing water shortage. Rainwater harvesting (RWH) systems have the potential to be an important contributor to urban water self-sufficiency. The goal of this study was to select an environmentally optimal RWH strategy in newly constructed residential buildings linked to rainwater demand for laundry under Mediterranean climatic conditions, without accounting for water from the mains. Different strategies were environmentally assessed for the design and use of RWH infrastructures in residential apartment blocks in Mediterranean climates. The harvested rainwater was used for laundry in all strategies. These strategies accounted for (i) tank location (i.e., tank distributed over the roof and underground tank), (ii) building height considering the number of stories (i.e., 6, 9, 12, and 15), and (iii) distribution strategy (i.e., shared laundry, supply to the nearest apartments, and distribution throughout the building). The RWH systems consisted of the catchment, storage, and distribution stages, and the structural and hydraulic calculations were based on Mediterranean conditions. The quantification of the environmental performance of each strategy (e.g., CO(2)eq. emissions) was performed in accordance with the life cycle assessment methodology. According to the environmental assessment, the tank location and distribution strategy chosen were the most important variables in the optimization of RWH systems. Roof tank strategies present fewer impacts than their underground tank equivalents because they enhance energy and material savings, and their reinforcement requirements can be accounted for within the safety factors of the building structure without the tank. Among roof tanks and depending on the height, a distribution strategy that concentrates demand in a laundry room was the preferable option, resulting in reductions from 25 to 54 % in most of the selected impact categories compared to distribution throughout the building. These results may set new urban planning standards for the design and construction of buildings from the perspective of sustainable water management. In this sense, a behavioral change regarding demand should be promoted in compact, dense urban settlements.", "labels": [4, 28]}
{"id": "3342", "token": "The performance of onsite rainwater harvesting (RWH) system in Mediterranean climate was assessed. A stochastic model quantifying the necessary storage, as a function of rainfall (frequency, depth), roof area, residents' number, specific water use (toilet flushing, laundry) and the required efficiency was developed. Two performance indicators were calculated: water saving efficiency (RSE) - proportion of water used supplied by the RWH system; and rainwater use efficiency (RUE) proportion of rainwater actually used. The maximum storage capacity and WSE decreased with increasing number of residents for a given roof area, and with an increasing roof area for constant number of residents. For variable storage volume, RUE increased with increasing storage capacity and reached a maximum with an increase in residents' number and a decrease in the roof area. The model enables to determine WSE and RUE for specific storage volumes or to determine the desired WSE and calculate the necessary storage.", "labels": [4, 28]}
{"id": "3474", "token": "Goat production is an important agricultural activity in Jordan. The country is one of the poorest countries in the world in terms of water scarcity. Provision of sufficient quantity of good quality drinking water is important for goats to maintain feed intake and production. This study aimed to evaluate the seasonal availability and quality of goats' drinking water sources, accessibility, and utilization in different zones in the Karak Governorate in southern Jordan. Data collection methods comprised interviews with purposively selected farmers and quality assessment of water sources. The provision of drinking water was considered as one of the major constraints for goat production, particularly during the dry season (DS). Long travel distances to the water sources, waiting time at watering points, and high fuel and labor costs were the key reasons associated with the problem. All the values of water quality (WQ) parameters were within acceptable limits of the guidelines for livestock drinking WQ with exception of iron, which showed slightly elevated concentration in one borehole source in the DS. These findings show that water shortage is an important problem leading to consequences for goat keepers. To alleviate the water shortage constraint and in view of the depleted groundwater sources, alternative water sources at reasonable distance have to be tapped and monitored for water quality and more efficient use of rainwater harvesting systems in the study area is recommended.", "labels": [4, 28]}
{"id": "18", "token": "McEliece and Goldreich-Goldwasser-Halevi (GGH) cryptosystems are two instances of code and lattice-based cryptosystems whose security are based on the hardness of coding theoretic and lattice problems, respectively. However, such cryptosystems have a number of drawbacks which make them inefficient in practice. On the other hand, low density lattice codes (LDLCs) are practical lattice codes which can achieve capacity over additive white Gaussian noise channel and also can be encoded and decoded efficiently. This paper introduces a public key cryptosystem based on Latin square LDLCs, by which a relationship can be attained between code and lattice-based cryptography. In this way, we can exploit the efficient properties of codes and lattices, simultaneously to improve the security and efficiency of the proposed scheme. For instance, the security of this scheme is based on the hard problems related to lattices, i.e., closest vector problem and shortest basis problem, which in turn lead to increase the security level. On the other hand, we exploit the low complexity decoding algorithm of LDLCs to reduce the computational complexity. Moreover, this property allows using the larger values of the codeword length. Also, we use the special Gaussian vector, whose variance is upper bounded by Poltyrev bound, as the perturbation (error) vector. These strategies make the proposed scheme to be secure against the conventional cryptanalytic attacks.", "labels": [0, 10]}
{"id": "132", "token": "Internet banking is one of many services provided by financial institutions that have become very popular with an increasing trend. Due to the increased amount of usage of the service, Internet banking has become a target from adversaries. One of the points that are at risk of an attack is the login process. Therefore, it is necessary to have a security mechanism that can reduce this risk. This research designs and develops a multi-factor authentication protocol, starting from a registration system, which generates authentication factors, to an actual authentication mechanism. These factors can be categorised into two groups: short term and long term. For the authentication protocol, only three messages need to be exchanged between a client and a financial institution's server. Many cryptographic processes are incorporated into the protocol, such as symmetric and asymmetric cryptography, a symmetric key generation process, a method for generating and verifying digital signatures. All of the authentication messages have been proved and analysed by the logic of GNY and the criteria of OWASP-AT-009. Even though there are additional factors of authentication, users do not really feel any extra load on their part, as shown by the satisfactory survey.", "labels": [0, 10]}
{"id": "195", "token": "One of major ideas to design a multivariate public key cryptosystem (MPKC) is to generate its quadratic forms by a polynomial map over an extension field. In fact, Matsumoto-Imai's scheme (1988), HFE (Patarin, 1996), MFE (Wang et al., 2006) and multi-HFE (Chen et al., 2008) are constructed in this way and Sflash (Akkar et al., 2003), Quartz (Patarin et al., 2001), Gui (Petzoldt et al, 2015) are variants of these schemes. An advantage of such extension field type MPKCs is to reduce the numbers of variables and equations to be solved in the decryption process. In the present paper, we study the security of MPKCs whose quadratic forms are derived from a quadratic map over an extension field and propose a new attack on such MPKCs. Our attack recovers partial information of the secret affine maps in polynomial time when the field is of odd characteristic. Once such partial information is recovered, the attacker can find the plain-text for a given cipher-text by solving a system of quadratic equations over the extension field whose numbers of variables and equations are same to those of the system of quadratic equations used in the decryption process.", "labels": [0, 10]}
{"id": "264", "token": "Mobile adhoc network is dynamic in nature and it operates completely in an infrastructure-less environment. It discovers the way routes dynamically to reach the destination. Securing a dynamic way route, which is not known before establishing communication, is always a challenge in the mobile ad hoc network. Most of the existing secure routing protocols target to evade specific type of attacks or malicious behaviour of the nodes or networks. We propose a novel secure way routing protocol for securing the dynamic way routes in MANET. It provides a unique session key for each route to secure the data communication. Moreover, it authenticates the data packets using asymmetric cryptography and secures the routing field message using two-way asymmetric cryptography. The proposal is implemented and tested for assessing the protocol's performance. We have also compared the protocol with the other secure routing protocols for evaluating its performance.", "labels": [0, 10]}
{"id": "423", "token": "Mobile Cloud Computing (MCC) combines the features of mobile computing, cloud computing, and wireless networks to create the healthy computational resources to mobile cloud users. The aim of MCC is to execute the highly attractive mobile applications on a plethora of mobile cellular telephones, with highly rich user experience. From the perspective of mobile computing, Quality of Service (QoS) provisioning depends on the efficiency of the handoff process. Thus, it is highly important to introduce an energy efficient and secure handoff process to improve the performance. In this paper, we propose a Secure Seamless Fast Handoff (SSFH) scheme to improve the energy efficiency and the QoS in the MCC. The proposed scheme consists of four layers: application layer, service layer, infrastructure layer, and media layer. These four layers collectively handle the security, energy-efficiency, and the QoS. Existing service-oriented architectures designed for the MCC are based on the symmetric encryption protocols to support the application layer. However, it is much easier for an adversary to expose the symmetric key and gain access to the confidential data. The application layer is secured using a combination of both attribute-based encryption and an asymmetric encryption cryptography. To extend the mobile lifetime, energy detection (ED) model is deployed at the infrastructure layer to detect the energy level of the mobile devices prior to the pre-registration process. Furthermore, a dual authentication process is performed on the service and at the application layer to minimize the possibility of identity high jacked or impersonation attack. The media layer supports the secure handoff process using policy enforcement module that allows only legitimate users to complete the re registration process after initiating the handoff. Thus, a significant amount of the bandwidth and energy could be preserved. Finally, the secure service-oriented architecture is programmed using C++ platform and the results are compared with other well-known existing service-oriented architectures. The experimental results confirm the validity and the effectiveness of our proposed architecture. (C) 2017 Elsevier Ltd. All rights reserved.", "labels": [0, 10]}
{"id": "493", "token": "Quantum secure direct communication can transmit a secret message directly through quantum channels without first generating a shared secret key. In the most of the existing protocols, quantum secure direct communication is possible only when both communicating participants have quantum capabilities. So what happens if either party of two participants just has classical capabilities? In this paper, we propose a semiquantum secure direct communication protocol with Einstein-Podolsky-Rosen photon pairs in which the classical sender Bob transmits a secret message to quantum Alice directly. After checking the security of quantum channels, Bob encodes his secret message on Alice's code sequence. Then, quantum Alice extracts Bob's secret message by measuring her home qubits and the received code qubits, respectively. In addition, we demonstrate the security of the proposed protocol against some individual eavesdropping attacks. The efficiency analysis shows that our protocol can provide higher efficiency.", "labels": [0, 10]}
{"id": "607", "token": "In this paper, we presented a novel approach of low energy consumption architecture of S-Box used in Advanced Encryption Standard (AES) algorithm using programmable second order reversible cellular automata (RCA(2)). The architecture entails a low power implementation with minimal delay overhead and the performance of proposed RCA(2) based S-Box in terms of security is evaluated using the cryptographic properties such as nonlinearity, correlation immunity bias, strict avalanche criteria, entropy and also found that the proposed architecture is secure enough for cryptographic applications. Moreover, the proposed AES algorithm architecture simulation studies show that energy consumption of 68.726 nJ, power dissipation of 3.856 mW for 0.18-mu m at 13.69 MHz and energy consumption of 29.408 nJ, power dissipation of 1.65 mW for 0.13-mu m at 13.69 MHz. The proposed AES algorithm with RCA(2) based S-Box shows a reduction power consumption by 50 % and energy consumption by 5 % compared to best classical S-Box and composite field arithmetic based AES algorithm. Apart from that, it is also shown that RCA(2) based S-Boxes are dynamic in nature, invertible, low power dissipation compared to that of LUT based S-Box and hence suitable for Wireless Body Area Network (WBAN) applications.", "labels": [0, 10]}
{"id": "773", "token": "We consider a new type of attack on a coherent quantum key distribution protocol [coherent one-way (COW) protocol]. The main idea of the attack consists in measuring individually the intercepted states and sending the rest of them unchanged. We have calculated the optimum values of the attack parameters for an arbitrary length of a communication channel and compared this novel attack with a standard beam-splitting attack.", "labels": [0, 10]}
{"id": "1020", "token": "This study explores a new security problem existing in various state-ofthe- art quantum private comparison (QPC) protocols, where a malicious third-party (TP) announces fake comparison (or intermediate) results. In this case, the participants could eventually be led to a wrong direction and the QPC will become fraudulent. In order to resolve this problem, a new QPC protocol is proposed, where a second TP is introduced to monitor the first one. Once a TP announces a fake comparison (or intermediate) result, participants can detect the fraud immediately. Besides, due to the introduction of the second TP, the proposed protocol allows strangers to compare their secrets privately, whereas the state-of-the-art QPCs require the involved clients to know each other before running the protocol.", "labels": [0, 10]}
{"id": "1097", "token": "Due to the ever-increasing efficiency of computer systems, symmetric cryptosystem are becoming more vulnerable to linear cryptanalysis brute force attacks. For example, DES with its short key (56 bits) is becoming easier to break, while AES has a much longer key size (up to 256 bits), which makes it very difficult to crack using even the most advanced dedicated cryptanalysis computers. However, more complex algorithms, which exhibit better confusion and diffusion characteristics, are always required. Such algorithms must have stronger resistance against differential and linear cryptanalysis attacks. This paper describes the development of an algorithm that implements a pseudo random number generator (PRNG) in order to increase the key generation complexity. Experimental results on both DES and AES cryptosystems complemented with the PRNG have shown an average improvement of up to 36.3% in the avalanche error computation over the original standard systems, which is a considerable improvement in the time complexity of both systems.", "labels": [0, 10]}
{"id": "1177", "token": "To the best of our knowledge, we present the first hardware implementation of isogeny-based cryptography available in the literature. Particularly, we present the first implementation of the supersingular isogeny Diffie-Hellman (SIDH) key exchange, which features quantum-resistance. We optimize this design for speed by creating a high throughput multiplier unit, taking advantage of parallelization of arithmetic in F p(2), and minimizing pipeline stalls with optimal scheduling. Consequently, our results are also faster than software libraries running affine SIDH even on Intel Haswell processors. For our implementation at 85-bit quantum security and 128-bit classical security, we generate ephemeral public keys in 1.655 million cycles for Alice and 1.490 million cycles for Bob. We generate the shared secret in an additional 1.510 million cycles for Alice and 1.312 million cycles for Bob. On a Virtex-7, these results are approximately 1.5 times faster than known software implementations running the same 512-bit SIDH. Our results and observations show that the isogeny-based schemes can be implemented with high efficiency on reconfigurable hardware.", "labels": [0, 10]}
{"id": "1434", "token": "To access the distributed web applications in a computer network, mobile agents have long been proved to be a successful tool. The power of a mobile agent lies in migrating to the destination hosts directly for retrieving the information under consideration. Since many businesses run their sensitive data in distributed servers, it has been a mandatory demand that before the information is downloaded, the mobile agents need to be authenticated and authorized. To provide such authentication, digital signatures based on well known algorithms such as RSA, ECC have been proposed in the past. The main drawback of these works is that the they are not computationally efficient during the encryption and decryption of keys which are used to encrypt and decrypt the content. Thus, the major contribution of our work is to reduce the computational complexity for the authentication of mobile agents through a new hierarchical access management scheme. The computational costs are reduced during the key derivation and signature verification processes. The proposed work not only reduces the computational time, but provides flexibility to give fine grained access to the mobile agents to access only the authorized files. Extensive simulations prove that our approach significantly reduces the computational overhead than the recent works in the literature and hence this approach is best suited for implementation in the distributed web environments.", "labels": [0, 10]}
{"id": "1598", "token": "Data owners with large volumes of data can outsource spatial databases by taking advantage of the cost-effective cloud computing model with attractive on-demand features such as scalability and high computing power. Data confidentiality in outsourced databases is a key requirement and therefore, untrusted third-party service providers in the cloud should not be able to view or manipulate the data. This paper proposes DISC (Dynamic Index for Spatial data on the Cloud), a secure retrieval scheme to answer range queries over encrypted databases at the Cloud Service Provider. The dynamic spatial index is also able to support dynamic updates on the outsourced data at the cloud server. To be able to support secure query processing and updates on the Cloud, spatial transformation is applied to the data and the spatial index is encrypted using Order-Preserving Encryption. With transformation and cryptography techniques, DISC achieves a balance between efficient query execution and data confidentiality in a cloud environment. Additionally, a more secure scheme, DISC*, is proposed to balance the trade-off between query results returned and security provided. The security analysis section studies the various attacks handled by DISC. The experimental study demonstrates that the proposed scheme achieves a lower communication cost in comparison to existing cloud retrieval schemes.", "labels": [0, 10]}
{"id": "1656", "token": "This work is the extended version of Alam,lou et al. (in: Tillich et al. (eds.) The 9th International workshop on coding and cryptography 2015 (WCC2015), 2015) which proposed the first code-based group signature. The new group signature scheme we present here has numerous advantages over all existing post-quantum constructions and even competes (in terms of properties) with pairing based constructions: it allows to add new members during the lifetime of the group (dynamic). Plus, it appears that our scheme might be extended into a traceable signature according to the definition of Kiayias et al. (in: Cachin and Camenisch (eds.) Advances in cryptology-EUROCRYPT 2004, 2004) (KTY model) while handling membership revocation. Our security is based on a relaxation of the model of Bellare et al. (in: Topics in cryptology-CT-RSA 2005, 2005) (BSZ model) verifying the properties of anonymity, traceability and non-frameability. The main idea of our scheme consists in building an offset collision of two syndromes associated to two different matrices: a random one which enables to build a random syndrome from a chosen small weight vector; and a trapdoor matrix for the syndrome decoding problem, which permits to find a small weight preimage of the previous random syndrome to which a fixed syndrome is added. These two small weight vectors will constitute the group member's secret signing key whose knowledge will be proved thanks to a variation of Stern's authentication protocol. For applications, we consider the case of the code-based CFS signature scheme (Nicolas in Advances in cryptology-ASIACRYPT 2001, 2001) of Courtois, Finiasz and Sendrier. If one denotes by N the number of group members, CFS leads to signatures and public keys sizes in . Along with this work, we also introduce a new kind of proof of knowledge, Testable weak Zero Knowledge (TwZK), implicitly covered in the short version of this paper (Alam,lou et al. in: Tillich et al. (eds.) The 9th international workshop on coding and cryptography 2015 (WCC2015), 2015). TwZK proofs appear particularly well fitted in the context of group signature schemes: it allows a verifier to test whether a specific witness is used without learning anything more from the proof. Under the random oracle model (ROM), we ensure the security of our scheme by defining the One More Syndrome Decoding problem, a new code-based problem related to the syndrome decoding problem (Berlekamp et al. in IEEE Trans Inf Theory 24(3):384-386, 1978).", "labels": [0, 10]}
{"id": "1763", "token": "In this paper, a novel high-speed elliptic curve cryptography (ECC) processor implementation for point multiplication (PM) on field-programmable gate array (FPGA) is proposed. A new segmented pipelined full-precision multiplier is used to reduce the latency, and the Lopez-Dahab Montgomery PM algorithm is modified for careful scheduling to avoid data dependency resulting in a drastic reduction in the number of clock cycles (CCs) required. The proposed ECC architecture has been implemented on Xilinx FPGAs' Virtex4, Virtex5, and Virtex7 families. To the best of our knowledge, our single-and three-multiplier-based designs show the fastest performance to date when compared with reported works individually. Our one-multiplier-based ECC processor also achieves the highest reported speed together with the best reported area-time performance on Virtex4 (5.32 mu s at 210 MHz), on Virtex5 (4.91 mu s at 228 MHz), and on the more advanced Virtex7 (3.18 mu s at 352 MHz). Finally, the proposed three-multiplier-based ECC implementation is the first work reporting the lowest number of CCs and the fastest ECC processor design on FPGA (450 CCs to get 2.83 mu s on Virtex7).", "labels": [0, 10]}
{"id": "1910", "token": "The smart-grid concept takes the communications from the enclosed and protected environment of a substation to the wider city or nationwide area. In this environment, cyber security takes a key role in order to secure the communications. The challenge is to be able to secure the grid without impacting the latency while, at the same time, maintaining compatibility with older devices and non secure services. At the lower level, added security must not interfere with the redundancy and the latency required for the real-time substation automation communications. This paper studies how to integrate IEEE MAC Security standard (MACsec) in the substation environment, especially when used in substation system communications that have stringent response time requirements and zero recovery time as defined in IEC 62439-3.", "labels": [0, 10]}
{"id": "2045", "token": "Information security can be achieved using cryptography, steganography or a combination of them, where data is firstly encrypted using any of the available cryptography techniques and then hid into any hiding medium. Recently, the famous genomic DNA has been introduced as a hiding medium, known as DNA steganography, due to its notable ability to hide huge data sets with a high level of randomness and hence security. Despite the numerous cryptography techniques, to our knowledge only the vigenere cipher and the DNA-based playfair cipher have been combined with the DNA steganography, which keeps space for investigation of other techniques and coming up with new improvements. This paper presents a comprehensive analysis between the DNA-based playfair, vigenere, RSA and the AES ciphers, each combined with a DNA hiding technique. The conducted analysis reports the performance diversity of each combined technique in terms of security, speed, hiding capacity in addition to both key size and data size. Moreover, this paper proposes a modification of the current combined DNA-based playfair cipher technique, which makes it not only simple and fast but also provides a significantly higher hiding capacity and security. The conducted extensive experimental studies confirm such outstanding performance in comparison with all the discussed combined techniques. (C) 2016 Elsevier Ireland Ltd. All rights reserved.", "labels": [0, 10]}
{"id": "2273", "token": "Biometrics deals with authenticating a person's identity based on the physiological or behavioral characteristics. Visual cryptography (VC) is a promising information security technique that allows the secret sharing of images without any cryptographic computations. Various existing schemes were introduced for securing the raw biometric data and template in the database using the VC technique. The complexity of encryption plays a vital role in security improvement. In order to overwhelm the above limitations, a secure authentication management for polar iris templates is presented using VC technique. The collaborative splitting of pixels in all directions presented in this paper was done in order to improve security. At first, the input image was segmented using the Canny edge detection and Hough transform. Subsequently, the normalization module transformed the iris texture from the Cartesian to polar-coordinates. The polar iris image was further separated into two shares, namely, share 1 and share 2, using VC technique. To accomplish more security than the existing methods, both 2-discrete wavelet transform (DWT) and advanced encryption standard (AES) shifting techniques were introduced in VC, termed as transform based AES (TAES). After receiving the encrypted image, the feature extraction is carried out by multi-scale local binary pattern (MLBP). The share 1 images are stored in the user database, whereas the share 2 images are stored in the server database. K-NN classifier is employed to recognize and retrieve the share 2 from the user database on the basis of features. Finally, reconstruction was performed from recognized share 1 and share 2 images by using the inverse process of TAES. The experimental results exhibit better peak signal to noise ratio (PSNR), mean square error (MSE) and normalized correlation (NC), false acceptance rate (FAR), false rejection rate (FRR), and equal error rate (EER) than the other existing methods.", "labels": [0, 10]}
{"id": "2300", "token": "In this paper, we detail two side-channel attacks against the McEliece public-key cryptosystem. They are exploiting timing differences on the Patterson decoding algorithm in order to reveal one part of the secret key: the support permutation. The first one is improving two existing timing attacks and uses the correlation between two different steps of the decoding algorithm. This improvement can be deployed on all error-vectors with Hamming weight smaller than a quarter of the minimum distance of the code. The second attack targets the evaluation of the error locator polynomial and succeeds on several different decoding algorithms. We also give an appropriate countermeasure.", "labels": [0, 10]}
{"id": "2380", "token": "The improved version of the author's previously declared asymmetric cipher protocol based on matrix power function (MPF) is presented. Proposed modification avoids discrete logarithm attack (DLA) which could be applied to the previously declared protocol. This attack allows us to transform the initial system of MPF equations to so-called matrix multivariate quadratic (MMQ) system of equations, which is a system representing a subclass of multivariate quadratic (MQ) systems of equations. We are making a conjecture that avoidance of DLA in protocol, presented here, should increase its security, since an attempt to solve the initial system of MPF equations would appear to be no less complex than solving the system of MMQ equations. No algorithms are known to solve such a system of equations. Security parameters and their secure values are defined. Security analysis against chosen plaintext attack (CPA) and chosen ciphertext attack (CCA) is presented. Measures taken to prevent DLA attack increase the security of this protocol with respect to the previously declated protocol.", "labels": [0, 10]}
{"id": "2440", "token": "The security of traditional identity-based signature (IBS) is totally built upon the assumption that the private key is absolutely secure. However, with the increasing use of mobile and unprotected devices in today's cryptosystems, the threat of key exposure represents a more serious and realistic concern. To mitigate the damage of key exposure in the setting of IBS, we propose to integrate key evolution and user revocation into IBS, and present forward-secure identity-based signature with user revocation (FS-RIBS). Specifically, we formalize the syntax and security definition of FS-RIBS, and give a concrete construction. The proposed scheme is proven secure in the standard model under a q-type complexity assumption. To demonstrate the merits of our scheme, we theoretically analyse its performance by comparing it with other related works. Moreover, we provide an implementation and the corresponding timing results of our scheme to show its practicability.", "labels": [0, 10]}
{"id": "2657", "token": "For cryptographic algorithms, secret keys should be generated randomly as the security of the system depends on the key and therefore generation of random sequences is vital. Randomness testing is done by means of statistical randomness tests. In this work, we show that the probabilities for the overlapping template matching test in the NIST test suite are only valid for a specific template and need to be recalculated for the other templates. We calculate the exact distribution for all 4-bit templates and propose new randomness tests, namely template matching tests. The new tests can be applied to any sequence of minimum length 5504 whereas the overlapping template matching test in the NIST test suite can only be applied to sequences of minimum length 10(6). Moreover, we apply the proposed tests to biased nonrandom data and observe that the new tests detect the nonrandom behavior of the generator even for a bias of 0.001, whereas the template matching tests in NIST cannot detect that bias.", "labels": [0, 10]}
{"id": "2847", "token": "Secure summation is one of the most applicable functions of secure multiparty computation (MPC) in which a group of users securely computes the summation value of their private inputs. The current solutions to this problem are basically on adding a random number to private inputs or splitting the inputs among users which need secure channel among members. Moreover, to be resistant against collusion of n - 2 players, they impose high communication cost. In this paper, we propose three cryptography-based protocols for secure sum that do not need secure channel and are secure against collusion of n - 2 players. Also, the communication cost of the proposed protocols is of complexity O(n). Based on the privacy requirements, the proposed protocols can provide the final result privacy as well as the private input privacy.", "labels": [0, 10]}
{"id": "2903", "token": "For multi-output Boolean functions (also called S-boxes), various measures of nonlinearity have been widely discussed in the literature but many problems are left open in this topic. The purpose of this paper is to present a new approach to estimating the nonlinearity of S-boxes. A more fine-grained view on the notion of nonlinearity of S-boxes is presented and new connections to some linear codes are established. More precisely, we mainly study the nonlinearity indicator (denoted by N-v) for S-boxes from a coding theory point of view. Such a cryptographic parameter N-v is more related to best affine approximation attacks on stream ciphers. We establish a direct link between Nv and the minimum distance of the corresponding linear code. We exploit that connection to derive the first general lower bounds on N-v of non-affine functions from F(2)n to F(2)m for m dividing n. Furthermore, we show that N-v can be determined directly by the weight distribution of the corresponding linear code.", "labels": [0, 10]}
{"id": "2972", "token": "A seamless and secure handover is always one of the important design goals of the cellular networks. The handover scheme of 4G Long Term Evolution (LTE) wireless networks is complex due to the presence of two possible different types of base stations. In LTE communication systems, a normal base station is referred to as an eNodeB (eNB). What increases the level of complexity of the system is the fact that the other kind of base stations, namely, Home eNodeB (HeNB), cannot directly communicate with eNB. In the LTE networks, the handover scenarios involving a HeNB could result in a complicated handover procedure. Besides, since key chains have been used in the handover processes, it is found to be lack of backward security. Therefore, in order to handle the handover involving a HeNB efficiently with security provisioning, in this paper, a proxy signature based handover scheme is proposed. The proposed scheme works based on the Elliptic Curve Cryptography (ECC) algorithm, which makes the computational cost of the handover process smaller compared to other handover schemes.", "labels": [0, 10]}
{"id": "3051", "token": "Field inversion in dominates the cost of modern software implementations of certain elliptic curve cryptographic operations, such as point encoding/hashing into elliptic curves (Brown et al. in: Submission to NIST, 2008; Brown in: IACR Cryptology ePrint Archive 2008:12, 2008; Aranha et al. in: Cryptology ePrint Archive, Report 2014/486, 2014) Itoh-Tsujii inversion using a polynomial basis and precomputed table-based multi-squaring has been demonstrated to be highly effective for software implementations (Taverne et al. in: CHES 2011, 2011; Oliveira et al. in: J Cryptogr Eng 4(1):3-17, 2014; Aranha et al. in: Cryptology ePrint Archive, Report 2014/486, 2014), but the performance and memory use depend critically on the choice of addition chain and multi-squaring tables, which in prior work have been determined only by suboptimal ad-hoc methods and manual selection. We thoroughly investigated the performance/memory tradeoff for table-based linear transforms used for efficient multi-squaring. Based upon the results of that investigation, we devised a comprehensive cost model for Itoh-Tsujii inversion and a corresponding optimization procedure that is empirically fast and provably finds globally-optimal solutions. We tested this method on eight binary fields commonly used for elliptic curve cryptography; our method found lower-cost solutions than the ad-hoc methods used previously, and for the first time enables a principled exploration of the time/memory tradeoff of inversion implementations.", "labels": [0, 10]}
{"id": "3124", "token": "This paper presents HAMSTER, the HeAlthy, Mobility and Security based data communication archiTEctuRe. HAMSTER is designed for Unmanned Vehicles and addresses mainly three types of communications: machine-to-machine, machine-to-infrastructure and internal machine communications. It is divided into three main versions: Flying HAMSTER (for aerial systems), Running HAMSTER (for terrestrial systems) and Swimming HAMSTER (for aquatic systems). Every version of such architecture is also equipped with Sphere and Nimble. Sphere deals with Safety & Security aspects regarding communication, components health and modules authentication. Nimble is aimed at increasing the overall mobility in such scenarios, strongly actuating with inherent communications of each application field. This paper details every aspect of HAMSTER and presents, as a plus at the end, two case studies: the first one consists of an evaluation of five communications schemes for internal communications in airplanes; the second one is a cryptographic evaluation of two Elliptic Curve Cryptography algorithms.", "labels": [0, 10]}
{"id": "3253", "token": "Two ring signature schemes over number theory research unit (NTRU) lattices are presented. The first scheme constructed in the random oracle model is an extension of Ducas, Lyubashevsky, and Prest's identity-based encryption scheme over NTRU lattices (in Asiacrypt 2014). Moreover, motivated by Boyen's lattice mixing and vanishing trapdoors (in PKC 2010), the second scheme in the standard model is achieved. Under the chosen-message attack, our new constructions are proved strongly existentially unforgeable, and the security can be reduced to the hardness of NTRU lattices. Compared with the existing lattice-based ring signatures, our schemes are more efficient and with shorter signature length. Copyright (c) 2016 John Wiley & Sons, Ltd.", "labels": [0, 10]}
{"id": "3310", "token": "Random number generators are essential in modern cryptography. The security of a cryptographic scheme can be achieved under the assumption that the system uses ideal random numbers to produce sensitive security parameters such as encryption keys and initial vectors. The weakness of the random number generator makes the entire cryptographic system insecure. In particular, the lack of entropy sources leads to predictable output random bits so that secret information can be guessed by malicious attackers. Therefore, it is important to collect sufficient entropy from physical noise sources. In this paper, we consider graphics processing units (GPUs) as an entropy source. From the race conditions in the parallel computations on a GPU, we can harvest sufficient entropy for cryptography. Using the entropy estimations in NIST SP 800-90B, the amount of entropy is estimated and compared with other physical sources.", "labels": [0, 10]}
{"id": "3495", "token": "Permutation polynomials over finite fields play important roles in finite fields theory. They also have wide applications in many areas of science and engineering such as coding theory, cryptography, combinatorial design, communication theory and so on. Permutation binomials and permutation trinomials attract people's interest due to their simple algebraic forms and additional extraordinary properties. In this paper, we find a new result about permutation binomials and construct several new classes of permutation trinomials. Some of them are generalizations of known ones. (C) 2016 Published by Elsevier Inc.", "labels": [0, 10]}
{"id": "19", "token": "Background: SmD1-amino-acid 83-119 peptide (SmD1(83-119)) is the major epitope of Smith (Sm) antigen, which is specific for adult systemic lupus erythematosus (SLE). The anti-SmD1(83-119) antibody has exhibited higher sensitivity and specificity than anti-Sm antibody in diagnosing adult SLE. However, the utility of anti-SmD1(83-119) antibodies remains unclear in children with SLE (cSLE). This study aimed to assess the characteristics of anti-SmD1(83-119) antibody in the diagnosis of cSLE. Methods: Samples from 242 children with different rheumatological and immunological disorders, including autoimmune diseases (SLE [n = 46] and ankylosing spondylitis [AS, n = 11]), nonautoimmune diseases (Henoch-Schonlein purpura [HSP, n = 60], idiopathic thrombocytopenia purpura [n = 27], hematuria [n = 59], and arthralgia [n = 39]) were collected from Shanghai Children's Medical Center from March 6, 2012 to February 27, 2014. Seventy age-and sex-matched patients were enrolled in this study as the negative controls. All the patients' sera were analyzed for the anti-SmD1(83-119), anti-Sm, anti-U1-nRNP, anti-double-stranded DNA (dsDNA), anti-nucleosome, anti-SSA/Ro60, anti-SSA/Ro52, anti-SSB, anti-Scl-70, and anti-histone antibodies using the immunoblotting assay. The differences in sensitivity and specificity between anti-SmD1(83-119) and anti-Sm antibodies were compared by Chi-square test. The correlations between anti-SmD1(83-119) and other auto-antibodies were analyzed using the Spearman's correlation analysis. A value of P < 0.05 was considered statistically significant. Results: Thirty-six out of 46 patients with cSLE were found to be positive for anti-SmD1(83-119), while 12 patients from the cSLE cohort were found to be positive for anti-Sm. Compared to cSLE, it has been shown that anti-SmD1(83-119) was only detected in 27.3% of patients with AS and 16.7% of patients with HSP. In comparison with anti-Sm, it has been demonstrated that anti-SmD1(83-119) had a higher sensitivity (78.3% vs. 26.1%, chi(2) = 25.1, P < 0.05) and a lower specificity (90.8% vs. 100%, chi(2) = 13.6, P < 0.05) in the diagnosis of cSLE. Further analysis revealed that anti-SmD1(83-119) antibodies were positively correlated with anti-dsDNA, anti-nucleosome, and anti-histone antibodies in cSLE. Moreover, it has been clearly shown that anti-SmD1(83-119) was more sensitive than anti-Sm in discriminating autoimmune diseases from nonautoimmune disorders in patients with arthralgia or hematuria. Conclusions: Measurement of anti-SmD1(83-119) in patients with cSLE has a higher sensitivity and a marginally lower specificity than anti-Sm. It has been suggested that inclusion of anti-SmD1(83-119) testing in the integrated laboratory diagnosis of cSLE may significantly improve the overall sensitivity in child populations.", "labels": [5, 33]}
{"id": "113", "token": "Objective We aimed to identify the association of carotid atherosclerosis with the traditional risk factors, disease features, cytokine profile, and calprotectin in patients with primary Sjogren's syndrome (pSS). Methods 63 primary pSS patients and 63 age- and sex-matched healthy controls underwent carotid ultrasound, clinical and laboratory examination. The presence of carotid plaques was taken as carotid atherosclerosis. The covariates of carotid atherosclerosis were identified in univariate and multivariate regressions. Results Patients with pSS had higher prevalence of carotid atherosclerosis (13% vs. 2%, p0.05). In univariate analyses, serum calprotectin, most traditional cardiovascular (age, male sex, metabolic syndrome, hypertension, hypertriglyceridaemia, and serum creatinine), and some disease-associated risk factors (glucocorticoid or saliva substitute use, constitutional domain of Enlar-Sjogren's syndrome disease activity index - EULAR) were associated with a higher risk for plaque. In a multivariate analysis, having pSS and higher serum calprotectin were associated with carotid atherosclerosis independent of traditional risk factors. Conclusion pSS have a higher prevalence of carotid atherosclerosis, which is associated with higher serum calprotectin level independent of traditional cardiovascular risk factors. Our findings suggest calprotectin as a biomarker of subclinical atherosclerosis in pSS.", "labels": [5, 33]}
{"id": "366", "token": "Introduction: Recent advances in the therapeutics of psoriatic arthritis (PsA) have provided more options to clinicians managing PsA. The purpose of this review is to update the reader on treatment options for PsA using conventional synthetic disease modifying agents (csDMARDs) and novel therapies including tumour necrosis factor alpha inhibitors, interleukin 12/23 inhibitor (ustekinumab), the interleukin 17 antagonists including secukinumab, brodalumab, ixekizumab, and the phosphodiesterase-4 inhibitor, apremilast.Areas covered: We reviewed published articles on the treatment of PsA. Our main sources of data included treatment recommendations, registry studies, systematic literature reviews, major randomised controlled trials for more recently approved drugs, and abstracts from the American College of Rheumatology and EULAR meetings.Expert commentary: An overview of the evidence for the use of various pharmacotherapeutic agents for treatment of this heterogeneous disease was compiled. Treatment options for the various domains of PsA are also discussed.", "labels": [5, 33]}
{"id": "438", "token": "Objective To assess symptomatic outcomes associated with flare after discontinuation of non-steroidal anti-inflammatory drugs (NSAIDs) in axial spondyloarthritis (axSpA). Methods Patients with NSAID-refractory axSpA discontinued NSAIDs, restarted if symptoms recurred, and self-recorded Bath Ankylosing Spondylitis Disease Activity Index (BASDAI). 75th percentiles were calculated for changes in BASDAI total and components from NSAID discontinuation to resumption. Results 75th percentiles for absolute/relative changes: BASDAI total (0-10)=1.5/28%; fatigue=2.0/25%; spinal pain=2.0/33%; joint pain/swelling=2.0/50%; enthesitis=2.0/43%; morning stiffness=1.5/27%. Conclusion No single score threshold applied but absolute change >= 2 or relative change >= 30% indicated symptomatic deterioration for most BASDAI components.", "labels": [5, 33]}
{"id": "538", "token": "Background: Radiographic sacroiliitis is the hallmark of ankylosing spondylitis (AS), and detection of acute sacroiliitis is pivotal for early diagnosis of AS. Although radiographic sacroiliitis is a distinguishing feature of AS, sacroiliitis can be seen in a variety of other disease entities. Case presentation: We present an interesting case of sacroiliitis in a patient with Paget disease; the patient presented with inflammatory back pain which was treated with bisphosphonate. This case demonstrates comorbidity with Paget disease and possible ankylosing spondylitis. We also present a review of the literature for other cases of Paget involvement of the sacroiliac joint. Conclusions: In addition, we review radiographic changes to the sacroiliac joint in classical ankylosing spondylitis as well as other common diseases. We compare and contrast features of other diseases that mimic sacroiliitis on a pelvic radiograph including Paget disease, osteitis condensans ilii, diffuse idiopathic skeletal hyperostosis, infections and sarcoid sacroiliitis. There are some features in the pelvic radiographic findings which help distinguish among mimics, however, one must also rely heavily on extra-pelvic radiographic lesions. In addition to the clinical presentation, various nuances may incline a clinician to the correct diagnosis; rheumatologists should be familiar with the imaging differences among these diseases and classic spondylitis findings.", "labels": [5, 33]}
{"id": "637", "token": "The aim of this study was to investigate possible association of a single nucleotide polymorphism (SNP) at position 9250 in exon 7 of the Osteopontin gehe (OPN gene 9250) with ankylosing spondylitis (AS). A case control association study was performed in 120 AS patients and 106 matched controls, consented to participate in the study. OPN gene 9250 polymorphism was detected by polymerase chain reaction (PCR) and direct sequencing. The frequency of the TC+CC genotype of the OPN gene 9250 was significantly higher (25.83% vs 12.26%, p < 0.05) and the frequency of C allele was significantly higher (17.50% vs 8.96%, p < 0.01) in AS patients than in controls. There were significant differences in OPN gene 9250 allele and phenotype frequencies between the AS patients and controls (p < 0.05). OPN gene 9250 polymorphism appears to be associated with susceptibility to AS in Chinese patients.", "labels": [5, 33]}
{"id": "825", "token": "The objective of the study was to analyze the impact of TNF antagonists (TNFa) on the total cholesterol and triglycerides on ankylosing spondylitis (AS) and psoriatic arthritis (PsA). In this single-centre observational study of AS and PsA patients, differences in triglyceride and total cholesterol levels and frequency of hypertriglyceridemia and hypercholesterolemia at 3 and 6 months were analysed in patients treated and not treated with TNFa. General estimation equations and linear regression analysis were used to investigate associations between disease activity and lipid levels and to identify predictors of change. One hundred fifty-seven patients treated, and 157 not treated with TNFa, were included in the study. A transient increase in cholesterol level from baseline to 3 months in TNFa-treated patients was the only statistically significant effect (P < 0.001). Persistent percentages of hypertriglyceridemia and hypercholesterolemia from baseline were significantly higher in not treated than in TNFa-treated patients (P = 0.009 and P = 0.001, respectively). Inverse associations between changes in cholesterol level and Bath Ankylosing Spondylitis Disease Activity Index (P = 0.011) and CRP (P < 0.001), but not Disease Activity Score in 28 Joints (P = 0.095) were found in the whole group. In AS and PsA patients treated with TNFa, mild and transient changes in cholesterol but not in triglyceride levels were associated with changes in disease activity.", "labels": [5, 33]}
{"id": "926", "token": "Objective: This study aimed to investigate whether there is a negative impact as a result of psoriatic arthritis disease of the inner ear function. Methods: Twenty-four successive patients and 38 healthy volunteers, younger than 60 years of age, who were followed up for at least for one year in the outpatient clinics of physical therapy and rehabilitation with the diagnosis of PsA according to CASPAR criteria (17) and who did not complain of any hearing impairment were included in the study. Distortion-product otoacoustic emission (DPOAE) values between 1 kHz and 4 kHz, tympanometric examination results, stapes reflex values, speech reception threshold (SRT) and speech discrimination (SD) values, pure-tone values between 250 and 8000 Hz and high-frequency values between 10,000, 12,500 and 16,000 Hz were analyzed. Statistical comparisons between both groups were performed using chi-square test and Mann-Whitney U test. p < 0.05 was accepted as the level of statistical significance. Results: Our study population consisted of 24 [9 male (37.5%) and 15 female (62.5%)] patients with a mean age of 47.21 +/- 11.28 (range, 28-59) years and 38 [16 male (42.1%) and 22 female (57.9%)] healthy volunteers with a mean age of 44.39 +/- 8.12 (range, 29-59) years as the control group. Mean duration of arthritis was 7.62 +/- 4.88 years. In the evaluation of hearing frequencies of the patients between 4000 and 6000 Hz, a statistically significant difference was found relative to the control group (p < 005). DPOAE values of the patients were analyzed within the 1000-4000 Hz interval. When compared with the control group, a statistically significant difference was found at 3000 and 4000 Hz (p < 005). Conclusion: Our study provides strong evidence suggesting the necessity of monitorization of these patients regarding sensorineural hearing loss so as to take measures against the development of hearing loss during early stage, which may be another disability in patients with PsA, which is itself a potential cause of severe disability. (C) 2016 Elsevier Ireland Ltd. All rights reserved.", "labels": [5, 33]}
{"id": "975", "token": "Colorectal cancer is one of the most common types of inflammation-based cancers and is occurred due to growth and spread of cancer cells in colon and/or rectum. Previously genetic association of cell cycle genes, both proto-oncogenes and the tumor suppressors has been proved. But there were few studies about association of immune related genes such as killer-cell immunoglobulin-like receptors (KIRs). Thus we intend to perform a meta-analysis to find the association of different genes of KIR and susceptibility to be affected by colorectal cancer. The overall population of the four studies investigated in ourmeta-analysis was 953 individuals (470 individuals with colorectal cancer and 483 individuals in control groups). After the analyses, we concluded that colorectal cancer is affected by KIR2DS5 and also there were no protecting gene. This result shows the inflammatory basis of this cancer. In other words, in contrast to leukemia and blood cancers, colorectal cancers seem to be affected by hyper activity of natural killer-cells (NKs). Whys and therefore of this paradox, is suggested to be investigated further. (C) 2016 Published by Elsevier Inc.", "labels": [5, 33]}
{"id": "1110", "token": "The use of anti-TNF agents is associated with an increased risk of tuberculosis (TB) and anti-TNF agents are stopped when active TB develops. However, discontinuation of treatment can result in flare of the underlying disease. The charts of 22 patients who developed active TB among a cohort of 2754 patients using anti-TNF agents between 2001 and 2013 were reviewed retrospectively. Patients restarting biologics during further follow-up were identified. One patient with miliary TB died within 1 month. A biologic agent was restarted in 16 of the remaining 21 patients (76 %). The most frequently re-initiated biologic agent was etanercept (n = 6) followed by rituximab (n = 5) and interferon-alpha (n = 3). Biologic treatment was re-initiated during anti-TB treatment in four patients and after completing TB treatment in 12 patients. The median follow-up after restarting biologics was 53 (IQR: 40-75) months. TB re-occurred in one patient with Beh double dagger et's syndrome, who initially received etanercept due to severe sight-threatening uveitis at the third month of anti-TB treatment followed by canakinumab 15 months later along with methotrexate, cyclosporine and corticosteroids. After a second course of 9 months TB therapy this patient is currently stable on interferon-alpha for 33 months. Restarting of anti-TNF agents and other biologic agents, even during TB treatment, seems to be possible among patients who had previously developed TB under anti-TNF treatment. However, the risk of re-development of TB infection mandates careful follow-up.", "labels": [5, 33]}
{"id": "1195", "token": "Background: Laboratory examination is a great value to confirm a diagnosis and estimate disease activity of Rheumatoid Arthritis (RA) and Ankylosing Spondylitis (AS). Since little research related to the diagnosis of RA and AS has been done in Iran, the aim of the present study was to evaluate the diagnosis markers in patients with RA and AS. Methods: This study was conducted among 104 patients with RA and 42 patients with AS in Iran during 2016. Inclusion criteria were according to the American College of Rheumatology (ACR) and European League against Rheumatism (EULAR) criteria. Five mL blood samples were collected from all patients. Laboratory studies consisted of ESR and anti-CCP tests and also determination of the presence of RF and CRP in these patients. Finally, the statistical analysis test was conducted using SPSS version 16.0. Results: The study patients with RA included 23 males (22.1%) and 81 females (77.9%) with the average age of 50.25 14.34. In RA patients, 82.7% were RF positive and 17.3% were negative. Also, 49% were CRP positive and 51% were negative. The mean ESR in RA patients was 27.76 +/- 20.17 mm/hour. The mean levels of anti-CCP were 109.15 +/- 90.55 IU/mL. The mean ages of 42 patients with AS, including 30 male (71.4%) and 12 females (28.6%), were 38.69 +/- 11.82 years. Among them, 24 patients (57.1%) were positive for CRP and 18 patients (42.9%) were negative. Only 2 patients (4.8%) were RF positive. 24 patients (57.1%) were positive for HLA-1127 and 18 patients (42.9%) were negative. The mean levels of ESR in AS patients were 30.30 +/- 26.98 mm/hour. Conclusions: Early diagnosis of the Rheumatoid arthritis and Ankylosing Spondylitis can help to prevent complications and its progression and help patients to recover more quickly.", "labels": [5, 33]}
{"id": "1268", "token": "Introduction: Early diagnosis, monitoring of disease activity, prediction of treatment response, and structural outcome remain major challenges in spondyloarthritis (SpA). Biomarkers could play a role in addressing these challenges, but in SpA there is a lack of suitable biomarkers.Areas covered: As SpA is clinically and pathophysiologically closely related to psoriasis and inflammatory bowel disease (IBD), we reviewed in literature, the value of serum biomarkers in these conditions with the aim to find potential candidates for assessing SpA.Expert commentary: Candidates of interest were antimicrobial peptides, including serum human beta defensin-2 (hBD-2) and lipocalin-2 (LCN-2), and class-1 MHC molecule beta2-microglobulin. Since these biomarkers are relevant in psoriasis and/or IBD from a pathophysiological point of view, and may play a role in the pathogenesis of SpA, we recommend further exploration of their value as biomarker in the diagnosis and prognosis of SpA.", "labels": [5, 33]}
{"id": "1342", "token": "Purpose of Review This publication updates an earlier review on the ever increasing knowledge about genetic polymorphism of HLA-B*27 and discusses its clinical relevance. Recent Findings As of January 1, 2017, there are 213 known alleles of HLA-B*27 at nucleotide sequence level, while at the translated protein level, there are 160 known subtypes based on one or more amino acid sequence differences. Some of these subtypes exhibit differential association with ankylosing spondylitis, and there may even be some level of hierarchy in this regard. On the other hand, HLA-B*27 has a protective effect against HCV, and this effect is also influenced by some of the subtypes of HLA-B*27. This may have important implications for designing anti-viral vaccines for global population and also for developing individualized treatments and vaccines. Summary Disease association and disease protective roles of HLA-B*27 suggest a common ground, i.e., promoting a more pronounced immune/inflammatory response for effective clearance of some pathogens, but that might, on the other hand, lead to autoimmunity and tissue injury in some circumstances.", "labels": [5, 33]}
{"id": "1612", "token": "Biosimilar infliximab (INX) was recently approved by the European Medicine Agency for the treatment of rheumatoid arthritis, ankylosing spondylitis (AS), Crohn's disease, ulcerative colitis, psoriatic arthritis (PsA), and psoriasis on the grounds that its pharmacokinetics, safety, and efficacy were comparable to those of innovator INX. The aim of this study was to investigate the real-life efficacy, safety, and immunogenicity of switching from innovator to biosimilar INX in patients with spondyloarthritis (SpA). Forty-one patients attending three Italian rheumatology centres with a previous diagnosis of SpA and clinically inactive or moderate disease activity (ASDAS-CRP < 2.1; 22 with AS, five with enteropathic arthritis, 10 with PsA, and four with undifferentiated SpA), who had been treated for more than 6 months with innovator INX in accordance with the ASAS/EULAR guidelines, were switched to biosimilar INX for pharmaco-economic reasons (Tuscany Law No. 450 of 7 April 2015) and followed up for 6 months. A record was kept of their BASDAI, BASFI, ASDAS-CRP, DAS28-CRP (in the presence of peripheral disease), MASES, VAS pain scores, the duration of morning stiffness, and adverse events (AEs). At the time of the switch, the patients had a median age of 50.9 years (range 23-80), a median disease duration of 124.5 months (range 14-372), and a median duration of treatment with innovator INX of 73.7 months (range 6-144). After 6 months of biosimilar INX therapy, there were no statistical differences in their median BASDAI (2.73 +/- 1.5 vs. 2.6 +/- 1.3, p = .27), BASFI (2.34 +/- 1.3 vs. 2.17 +/- 1.2, p = 0.051), ASDAS-CRP (1.35 +/- 0.3 vs. 1.28 +/- 0.2, p = 0.24), DAS28-CRP (2.66 +/- 0.67 vs. 2.67 +/- 0.35, p = 0.92), MASES (0.35 +/- 0.7 vs. 0.17 +/- 0.4, p = 0.08), or VAS pain scores (18 +/- 14.7 vs. 16.7 +/- 11.3, p = 0.55), whereas the median duration of morning stiffness had significantly decreased (7.2 +/- 6.9 vs. 5.8 +/- 6, p = 0.02). Furthermore, there was no change in circulating INX (4.22 +/- 2.89 vs 4.84 +/- 2.86 mu g/mL, p = 0.80) or anti-INX antibody levels (27.76 +/- 17.13 vs 27.27 +/- 17.28 ng/mL, p = 0.98). The switch from innovator to biosimilar INX in this Italian multicentre SpA cohort was not associated with any statistically significance differences in efficacy, adverse events or anti-drug antibody level.", "labels": [5, 33]}
{"id": "1728", "token": "Objective: Given the significant costs of reduced productivity (presenteeism) in comparison to absenteeism, and overall societal costs, presenteeism has a potentially important role to play in economic evaluations. However, these costs are often excluded. The objective of this study is to review applied cost of illness studies and economic evaluations to identify valuation methods used for, and impact of including presenteeism costs in practice. Methods: A structured systematic review was carried out to explore (i) the extent to which presenteeism has been applied in cost of illness studies and economic evaluations and (ii) the overall impact of including presenteeism on overall costs and outcomes. Potential articles were identified by searching Medline, PsycINFO and NHS EED databases. A standard template was developed and used to extract information from economic evaluations and cost of illness studies incorporating presenteeism costs. Results: A total of 28 studies were included in the systematic review which also demonstrated that presenteeism costs are rarely included in full economic evaluations. Estimation and monetisation methods differed between the instruments. The impact of disease on presenteeism whilst in paid work is high. Conclusions: The potential impact of presenteeism costs needs to be highlighted and greater consideration should be given to including these in economic evaluations and cost of illness studies. The importance of including presenteeism costs when conducting economic evaluation from a societal perspective should be emphasised in national economic guidelines and more methodological work is required to improve the practical application of presenteeism instruments to generate productivity cost estimates.", "labels": [5, 33]}
{"id": "1804", "token": "Background: According to international guidelines, treatment of inflammatory arthritis should be based on a shared decision between patient and rheumatologist. Furthermore, patients with inflammatory arthritis have high need of information and want to be more actively involved in medical decision-making. To facilitate shared decision-making and support patients in choosing between disease modifying anti-rheumatic drugs (DMARDs), a web-based patient decision aid (PtDA) was developed. This study evaluated use, appreciation and effect of this PtDA. Methods: A post-test only study with a historical comparison group was conducted. In a two-year period, all patients diagnosed with rheumatoid arthritis, psoriatic arthritis or ankylosing spondylitis, who were deciding whether to start a (different) DMARD were invited to participate. In the first year, patients received standard information (comparison group). In the second year, patients were referred to the PtDA (intervention group). In both groups, a questionnaire was sent four weeks after consulting the rheumatologist. Patient characteristics included sociodemographic, health-related and preference-related variables. Process measures were for use and appraisal of the PtDA (intervention group only). The primary outcome measure was patients' perceived role in medical decision-making. Secondary outcome measures comprised satisfaction with the decision-making process and the decision, beliefs about medication, adherence to medication and trust in the physician. Results: We received 158/232 questionnaires (68 %) from the comparison group and 123/200 (61 %) from the intervention group. The PtDA was used by 69/123 patients (57 %) in the intervention group. Patients who used the PtDA highly appreciated it and perceived it as easy to use and helpful. Relative to the comparison group, patients in the intervention group perceived a more active role in medical decision-making and decisions were more in line with patients' personal preferences. Other outcomes showed no significant difference between the two groups. Conclusion: The web-based PtDA was highly appreciated and perceived as helpful for decision-making. Implementation of the PtDA in rheumatology practice was associated with a significantly larger proportion of patients perceiving an active role in medical decision-making and decisions were more in line with patients' personal preferences. The PtDA can be a valuable aid in improving patient participation in decision-making about DMARDs.", "labels": [5, 33]}
{"id": "1857", "token": "Background: Rheumatoid arthritis (RA) and other rheumatic conditions not only fundamentally affect patients' quality of life and physiological needs but are also negatively associated with work ability. The costs of poor work ability, which, in sum, are more than treatment costs, pose an economic burden to society and patients. Work ability in RA appears to be multifactorial; symptoms such as pain, swelling, and stiffness play a major role, as these directly affect functional disability. Also, RA patients typically suffer from reduced muscle strength. Lower extremity function and grip strengths especially impair their quality of life. However, the role of muscle strength and disease activity as determinants of work ability have not yet been studied. Objective: The primary objective of this study is to compare work ability in working-age participants with seropositive RA and with high and low disease activity; the secondary objective is to evaluate the association of muscle strength, functional ability, and frailty with work ability. Methods: This monocentric cross-sectional study will be conducted at a rheumatologic outpatient clinic and day hospital with approximately 100 seropositive RA patients aged <65 years. A clinical disease activity index as a measure for rheumatoid disease activity will be assessed during the patients' routine visits at the clinic. Work ability, frailty, and functional disability will be evaluated with (self-reported) questionnaires as well as with physical tests (Work Ability Index/Score; Health Assessment Questionnaire Disability Index; Survey of Health, Ageing, and Retirement in Europe Frailty Instrument; Short Physical Performance Battery). Muscle strength will be determined with dynamometer measurements of isometric hand grip strength and quadriceps femoris muscle contraction strength. Sleep quality (Medical Outcomes Study Sleep Scale) and sexual functioning as physiological needs will additionally be determined with self-reported questionnaires. Results: For this study funding has already been awarded and enrollment has been completed. Data are currently being evaluated. Conclusions: This study will evaluate the association of work ability with modifiable parameters such as muscle strength and functional ability. It will provide further insights into work ability in RA and its associated risk factors. Any evidence of association will motivate further research, and the findings might encourage interventions focused specifically on improving muscle strength and lower extremity function to positively affect work ability.", "labels": [5, 33]}
{"id": "1959", "token": "OBJECTIVE. The purpose of this study is to characterize sacroiliac joints (SIJs) findings at CT of patients with diffuse idiopathic skeletal hyperostosis (DISH), a condition characterized (using the Resnick classification criteria) by ossification of at least four contiguous vertebrae in the thoracic spine and preserved disk space, but without radiographic evidence of intraarticular SIJ abnormalities. MATERIALS AND METHODS. Pelvic CT examinations of 104 patients with DISH (fulfilling the Resnick criteria on spinal CT) and 106 age-and sex-matched control subjects whose entire spine lacked CT evidence of DISH (total, 149 men and 61 women; mean [+/- SD] age, 72.3 +/- 8.7 years) were retrospectively evaluated for the presence of intra-and extraarticular bridging osteophytes, spurs, subchondral cystlike changes, erosions, and sclerosis of SIJs. Excluded were patients with known ankylosing spondylitis or inflammatory-related diseases. Data were analyzed using multivariate ANOVA to examine the degree of difference between patients with DISH and control subjects. Logistic regression analysis was used to generate odds ratios to examine their discriminatory ability. ROC analysis was then applied to examine the sensitivity and specificity of the results. RESULTS. The frequency of anterior bridging, posterior bridging, entheseal bridging, and joint ankylosis was significantly higher among patients with DISH compared with control subjects (48% vs 9%, 20% vs 1%, 34% vs 4%, and 23% vs 0%, respectively; p < 0.001 for all comparisons). CONCLUSION. Intraarticular ankylosis seen at CT, an entity not included in the Resnick classification criteria, is common among patients with DISH, which implies that the radiologic classification criteria for DISH need to be revised.", "labels": [5, 33]}
{"id": "2175", "token": "Objectives: The objectives of this study were to 1) describe and compare treatment persistence with first-and second-line subcutaneous tumor necrosis factor-alpha inhibitors (SC-TNFis) in patients with ankylosing spondylitis (AS), psoriatic arthritis (PsA), or rheumatoid arthritis (RA) (collectively immune-mediated rheumatic disease) in Sweden and 2) estimate and contrast health care costs in the two groups. Methods: Patients who initiated their first or second SC-TNFi between May 6 2010 and December 12 2012 were identified from the Prescribed Drug Register. Persistence was estimated using survival analysis. Costs comprised specialized outpatient care, inpatient care, and medication. The persistence analysis was stratified by immune-mediated rheumatic disease diagnosis. Results: A total of 4,903 patients treated with their first and 845 patients treated with their second SC-TNFi were identified. Baseline characteristics differed between the two groups. Therefore, propensity score matching analysis was implemented. Second-line patients were matched to first-line patients, and four cohort pairs (AS, PsA, RA, and all diagnoses combined) were generated. Patients treated with their first SC-TNFi had statistically significant higher persistence than patients treated with their second SC-TNFi in PsA (P=0.036), RA (P=0.048), and all diagnoses combined (P<0.001) but not in AS (P=0.741). Patients who were treated with their second SC-TNFi incurred higher costs than patients treated with their first SC-TNFi. Conclusion: Overall, persistence to the first SC-TNFi was higher than persistence to the second SC-TNFi. Furthermore, the second SC-TNFi was associated with higher costs than the first SC-TNFi. Therefore, prescribing the SC-TNFi with the best long-term persistence first may be beneficial.", "labels": [5, 33]}
{"id": "2294", "token": "Objectives: Multiple sclerosis (MS) is the common neurological disorders in young adults, which affects the central nervous system myelin or oligodendrocytes and results in disability. This study aimed to identify the key miRNAs in blood of patients in MS for better understanding the underlying mechanisms of MS. Methods: The publicly available Gene Expression Omnibus data-setsof MS were performed to integrated analysis. miRNA expression and mRNA expression were analyzed in whole blood samples from patients with MS and healthy controls by microarray analysis, Gene Ontology enrichment analyses, Kyoto Encyclopedia of Genes and Genomes pathway analyses, construction of miRNA-mRNA interaction network, and quantitative real-time polymerase reaction. Results: In patients with MS, microarray analysis identified 45 significantly dysregulated miRNAs and 621 significantly dysregulated mRNAs. 1165 negative correlation pairs of miRNA-mRNA were predicted and used to construct the interaction network. hsa-miR-30a, hsa-miR-93, hsa-miR-20b, and hsa-miR-20a occurred as central hubs regulating 87, 38, 34, and 34 genes. Dysregulated mRNAs were significantly enriched in ribosome, tuberculosis, and pathways in cancer. The verification of qRT-PCR displayed that hsa-miR-328-3p was significantly up-regulated in MS and its target genes RAC2 had the down-regulated tendency in MS. hsa-miR-20a-5p had the up-regulated tendency and the corresponding target gene EIF4EBP2 had the down-regulated tendency in MS compared to healthy controls. Discussion: hsa-miR-30a, hsa-miR-93, hsa-miR-20b, and hsa-miR-20a might be the key participant in the pathophysiology of MS involved in signaling pathways including ribosome, tuberculosis, and pathways in cancer.", "labels": [5, 33]}
{"id": "2363", "token": "Study Design. A prospective magnetic resonance imaging (MRI) study. Objective. To investigate the change in aortic traversing length in patients with thoracolumbar kyphosis secondary to ankylosing spondylitis (AS) after closing wedge osteotomy (CWO). Summary of Background Data. The CWO has been widely adopted for the correction of thoracolumbar kyphosis caused by AS. During this procedure, the aorta may be elongated in the instrumented area, which implies a potential risk of the aortic injury. To date, no reports have been specifically published using MRI to investigate the alteration in aortic traversing length in patients with AS undergoing CWO. Methods. From June 2013 to July 2015, 24 patients with AS with thoracolumbar kyphosis with a mean age of 38.1 years were recruited in the present study. All patients underwent single-level CWO. MRI examinations were performed before and 2 weeks after surgery. For each subject, the aortic diameter and length were measured on the MRI. Radiographic measurements included the global kyphosis, thoracic kyphosis, lumbar lordosis, local kyhosis, angle of fusion levels, and anterior height of the osteotomized vertebra. The height of these patients was also recorded. Results. The aortic traversing length significantly increased by an average of 2.0 cm after surgery. Significant changes in height, global kyphosis, lumbar lordosis, local kyphosis, and angle of fusion levels were observed (P0.05). In addition, the correlation analysis revealed a significant correlation between the aortic traversing length and changes in global kyphosis, lumbar lordosis, local kyphosis, angle of fusion levels, and height (P<0.01). Conclusion. The stretch of the aorta after CWO for the correction of thoracolumbar kyphosis was quantitatively verified by MRI investigation in the present study. Spine surgeons should be aware of the potential vulnerability of aortic injury in patients with AS undergoing CWO.", "labels": [5, 33]}
{"id": "2393", "token": "A new three-dimensional (3-D) Zn-based metal-organic framework with the formula of [Zn-2(L)(bpy)](CI) (1, H3L = 2,6-dihydroxypyridine-4-carboxylate, bpy = 4,4'-bipyridine), has been synthesized under hydrothermal condition. X-Ray diffraction analyse reveals that compound 1 exhibits the unique 3-D two-fold interpenetrated coordination framework with 3,4-connected fsx-3,4-C2 network topology, in which the L ligand adopts the mu(3)-bridging fashion. In addition, the experimental results of anti-inflammatory activity showed that compared with organic ligands H3L and bpy, the title compound 1 exerted rather potent activity.", "labels": [5, 33]}
{"id": "2529", "token": "Introduction: To date, there are no descriptions in the literature on gynecologic and sexual function evaluation in female patients with dermatomyositis (DM) and polymyositis (PM). Objective: To assess sexual function in female patients with DM/PM. Patients and methods: This is a monocentric, cross-sectional study in which 23 patients (16 DM and 7 PM), with ages between 18 and 40 years, were compared to 23 healthy women of the same age group. Characteristics on sexual function were obtained by applying the questionnaires Female Sexual Quotient (FSQ) and Female Sexual Function Index (FSFI) validated for the Brazilian Portuguese language. Results: The mean age of patients was comparable to controls (32.7 +/- 5.3 vs. 31.7 +/- 6.7 years), as well as the distribution of ethnicity and socioeconomic class. As for gynecological characteristics, patients and healthy controls did not differ with respect to age at menarche and percentages of dysmenorrhea, menorrhagia, premenstrual syndrome, pain at mid-cycle, mucocervical secretion, and vaginal discharge. The FSQ score, as well as all domains of the FSFI questionnaire (desire, arousal, lubrication, orgasm and satisfaction), were significantly decreased in patients versus controls, with 60.9% of patients showing some degree of sexual dysfunction. Conclusions: This was the first study to identify sexual dysfunction in patients with DM/PM. Therefore, a multidisciplinary approach is essential for patients with idiopathic inflammatory myopathies, in order to provide prevention and care for their sexual life, providing a better quality of life, both for patients and their partners. (C) 2016 Elsevier Editora Ltda.", "labels": [5, 33]}
{"id": "2623", "token": "Certain studies have suggested that the tumor necrosis factor-alpha (TNF-alpha) -857 C/T polymorphism is associated with risk of ankylosing spondylitis. However, the conclusions remain controversial. Therefore, we performed a meta-analysis to provide a more precise conclusion. Such databases as PubMed, Embase, CBM, CNKI, and Wanfang Data were searched to identify relevant studies up to August 26, 2015. Odds ratios (ORs) and 95% confidence intervals (CIs) were used to estimate the association between TNF-alpha -857 C/T polymorphism and ankylosing spondylitis susceptibility. A total of 10 studies were included in the meta-analysis. Overall, an elevated risk between TNF-alpha -857 C/T polymorphism and ankylosing spondylitis was observed in three genetic model (T vs. C: OR 1.86, 95% CI 1.19-2.92; CT vs. CC: OR 2.51, 95% CI 1.49-4.23; TT + CT vs. CC: OR 2.46, 95% CI 1.40-4.30), except in homozygote model (TT vs. CC: OR 2.41, 95% CI 0.96-6.06) and recessive model (TT vs. CT + CC: OR 1.54, 95% CI 0.71-3.35). Sensitivity analysis showed the overall results were robust. Subgroup analyses according to Hardy-Weinberg equilibrium and ethnicity showed that the increased risk of ankylosing spondylitis were predominant in Asian population. This meta-analysis indicated that TNF-alpha -857 C/T polymorphism might increase the susceptibility of ankylosing spondylitis, especially in Asians. Further studies were needed to verify the conclusion.", "labels": [5, 33]}
{"id": "2661", "token": "Background: Non-steroid anti-inflammatory drug (NSAID) usage is associated with kidney injury. Rise in serum creatinine (sCr) often represents irreversible process. Thus to assess the early effects of regular NSAID use, we studied sensitive serum and urine biomarkers of kidney injury. Methods: In a protocol-based intervention study, 103 subjects were enrolled in 3 mutually exclusive groups. Group 1 included 37 healthy controls having minimal baseline NSAID exposure as per a definition, and group 2 had 41 spondyloarthritis (SpA) patients on regular NSAID therapy for >3 months. Group 3 included 25 SpA patients having minimal NSAID exposure at baseline. Blood and urine samples were collected from all the 3 groups at baseline. Furthermore, group 3 was started on 6-week regular NSAID therapy, and blood and urine samples were re-collected at 1, 6, and 12 weeks. Baseline normal kidney function as per the definition was ensured in all the subjects. Creatinine, neutrophil gelatinase-associated lipocalin (NGAL), kidney injury molecule-1 (KIM-1), cystatin-C, and microalbumin were measured in urine and serum samples to assess kidney injury. Results: Kidney injury biomarkers were 2-3-fold higher in SpA patients using regular NSAID therapy compared to healthy controls and SpA patients having minimal NSAID exposure (uKIM-1 and uNGAL p < 0.0001, sKIM-1 and sNGAL p = 0.001). There was no difference in sCr and estimated glomerular filtration rate using Cockcroft Gault equation between the groups. In SpA patients started on 6 weeks of regular NSAID (group 3), biomarker levels started rising at week 1 and showed a significant rise at week 6. The levels in the patients that stopped NSAID use at 6 weeks showed reversibility at 12 weeks. Conclusions: Regular NSAID use in SpA patients induces subclinical kidney injury represented by rise in biomarkers. These levels start rising as early as 7 days of regular NSAID use and are reversible on stopping the drug. (C) 2017 S. Karger AG, Basel", "labels": [5, 33]}
{"id": "2750", "token": "Background: Long non-coding RNAs (lncRNAs) have been confirmed to play an important role in the development and progression of diseases. Ankylosing spondylitis (AS) is a chronic inflammatory systemic disease and it is hard to be found in early time. The purpose of this study was to investigate the role of lncRNA-AK001085 in the diagnosis of AS. Material/Methods: The expression of lncRNA-AK001085 was detected by quantitative real-time polymerase chain reaction (qRTPCR) analysis. The relationship between its expression and clinicopathologic characteristics was also analyzed. Meanwhile the correlation between lncRNA-AK001085 expression and diseases activity indexes was estimated. In addition, the value of it in the diagnosis of AS was explored through establishing receiver operating characteristic (ROC) curve. Results: Serum lncRNA-AK001085 expression was decreased in patients with AS compared with healthy individuals. And its expression was proved to be influenced by ever cigarette smoker, exercise level and occupational activity level. Besides, the correlation of the expression of lncRNA-AK001085 and disease activity indexes (BASDI, ASDAS, ESR, CRP) were all negative, which suggested that the lncRNA-AK001085 was significantly lower in patients with a high disease activity score. It might showed that the expression of lncRNA-AK001085 affected the activity of AS. Conclusions: LncRNA-AK001085 was down-regulated in AS patients and it could be an independent diagnostic indicator.", "labels": [5, 33]}
{"id": "2969", "token": "The term spondyloarthritis (SpA) is now increasingly used to classify and diagnose patients who are characterized by inflammation in the axial skeleton and peripheral manifestations (arthritis and enthesitis). The management of SpA should be tailored according to the current manifestations of the disease, the disease activity and functional impairment. The current article focuses on diagnosis and therapy in patients with axial SpA. Diagnostic procedures are discussed in light of diagnostic utility and feasibility in daily routine care. Cornerstones of treatment in patients with axial SpA are a combination of regular exercise and pharmacological treatment options aiming at anti-inflammatory strategies.", "labels": [5, 33]}
{"id": "2991", "token": "The purpose of the present review was to provide a comprehensive picture of the efficacy of the different tumor necrosis factor (TNF)-alpha inhibiting agents in the treatment of acute anterior uveitis (AAU), the most common extra-articular manifestation of ankylosing spondylitis (AS). AS related, AAU may lead to severe visual impairment, due to frequent flare recurrences, anterior, and posterior segment complications and traditional treatment side effects. Considerably higher levels of tumor necrosis factor (TNF) have been assessed in the aqueous humor and inflamed joints of patients with AS. Anti-TNF drugs have shown efficacy in preventing relapses of rheumatological manifestations of spondyloarthropathies. Several studies have underlined the sustained efficacy of the monoclonal anti-TNF antibodies also in reducing the recurrence of anterior chamber flares in patients with AS-related AAU. On the other hand, retrospective studies and observational reports have indicated lower effectiveness and some paradoxical occurrence of uveitis following treatment with the soluble receptor agent etanercept. Growing evidence suggests that a prophylactic strategy could be advocated in subjects with frequent and recalcitrant attacks of AS-AAU. In this regard, the administration of monoclonal anti-TNF antibodies such as adalimumab (ADA) has been shown to significantly reduce the rate of AAU recurrences. Indeed, during ADA treatment about 90 % of patients have shown to remain completely free of attacks for the entire follow-up period, in most studies. Further studies are needed to confirm the long-term efficacy of TNF inhibitors in AS related AAU and also their role in preventing ocular complications and visual impairment.", "labels": [5, 33]}
{"id": "3216", "token": "Study Design. A prospective multicenter cohort study for more than 10 years of outpatients with rheumatoid arthritis (RA). Objective. To identify predictive risk factors of cervical spine instabilities, which may induce compression myelopathy in patients with RA. Summary of Background Data. Many reports described the natural course of cervical spine involvement in RA. Only a few studies, however, conducted comprehensive evaluation of its prognostic factors. Methods. Cervical spine instability was radiographically defined as atlantoaxial subluxation with the atlantodental interval greater than 3 mm, vertical subluxation (VS) with the Ranawat value less than 13 mm, and subaxial subluxation with irreducible translation of 2mm or higher. The severe'' category of instability was defined as atlantoaxial subluxation with the atlantodental interval of 10mm or lower, vertical subluxation with the Ranawat value of 10mm or higher, and subaxial subluxation with translation of 4 mm or higher or at multiple levels. Of 503 definite'' or classical'' patients with RA without baseline severe'' instability, 143 were prospectively followed throughout for more than 10 years. The Cox proportional hazards regression analysis was performed to determine predictors for the development of severe'' instabilities. To exclude biases from the low follow-up rate, similar assessments were performed in 223 patients followed for more than 5 years from baseline. Results. The incidence of cervical spine instabilities and severe'' instabilities significantly increased during more than 10 years in both 143 and 223 cohorts (all P<0.01). Multivariable Cox proportional hazards models found that baseline mutilating changes (hazard ratio [HR] = 19.15, 95% confidence interval [95% CI] = 3.96-92.58, P< 0.01), corticosteroid administration (HR = 4.00, 95% CI = 1.76-9.11, P< 0.01), and previous joint surgery (HR = 1.99, 95% CI = 1.01-3.93, P = 0.048) correlated with the progression to severe'' instability in 143 cases and also in 223 cases (HR = 8.12, 95% CI = 2.22-29.64, P< 0.01; HR = 3.31, 95% CI = 1.68-6.53, P< 0.01; and HR = 2.07, 95% CI = 1.16-3.69, P = 0.014, respectively). Conclusion. Established mutilating changes, concomitant corticosteroid treatment, and previous joint surgery are relatively robust indicators for a poor prognosis of the cervical spine in patients with RA, based on the consistency in more than 10-year analysis of two different settings.", "labels": [5, 33]}
{"id": "3262", "token": "Ankylosing spondylitis (AS) is a chronic inflammatory condition that most commonly affects the axial skeleton. The most common cardiac manifestation in patients with AS is the aortic root and valve disease, followed by conduction and rhythm abnormalities, decreased coronary flow reserve, myocardial infarction, and diastolic dysfunction. However, the presence of systolic dysfunction has been less described in patients with AS. Herein we present two cases of idiopathic dilated cardiomyopathy in patients with AS. These patients were noted to have an improvement of their ejection fraction following treatment of AS. Clinical and echocardiographic improvement on anti-inflammatory treatment might be a clue to the inflammatory nature of this myocardial problem, and further investigations to study the issue is required.", "labels": [5, 33]}
{"id": "23", "token": "Nowadays, population growth, environmental constraints and climate change can adversely affect our water supply systems' ability to keep up with demand. Due to lack of unsuitable distribution and dispersion of water resources, precipitation, soil resources, etc., inter-basin transfers of water could be a solution in order to balancing between supply and demand water in different areas. In this study, the optimal designing of water conveyance from basin No-1 to basin No-2 is investigated. Water is transferred between these two dams by tunnel structure. Since the water flow through the tunnel is under pressure, increasing dam height will cause the decrease of tunnel diameter for constant water conveyance efficiency. The purpose of this study is transferring 95 % of water flow between two basins after supplying the agriculture consumption and environmental needs. Therefore, the mathematical program was developed first to solve the governing equations of water balance of reservoir and hydraulic of tunnel. Then, various strategies including different diameters of tunnel and dam height were considered and finally the best strategy from economic and technical viewpoint was proposed. The results showed that dam height of 151.2 m and tunnel diameter of 3.2 m are the economic options to convey of 95 % of the water.", "labels": [3, 21]}
{"id": "206", "token": "In order to reduce the accumulation of hydrogen and thus to mitigate the risk of combustion, many countries have installed passive autocatalytic recombiners (PARs) within light water reactor containments. The severe hydrogen combustion events of the recent Fukushima Daiichi accident are likely to incentivize an increased demand in upgrading nuclear power plants with PARs. Numerical simulation is an important tool for assessing PAR operation during a severe accident in terms of efficiency and proper installation. Advanced numerical PAR models are required for the challenging boundary conditions during a severe accident, for example, low oxygen amount, high steam amount, and presence of carbon monoxide. The REKO-DIREKT code has been developed in order to provide a PAR model capable of simulating complex PAR phenomena and at the same time being suitable for implementation in thermal-hydraulic codes. The development of REKO-DIREKT was supported by small-scale experiments performed at Forschungszentrum Juelich in the REKO facilities. These facilities allow the study of PAR-related single phenomena such as reaction kinetics under different conditions including variation of steam, oxygen, and carbon monoxide (REKO-3) and the chimney effect (REKO-4). Recently, the code has been validated against full-scale experiments performed in the Thermal-Hydraulics, Hydrogen, Aerosols, Iodine (THAI) facility at Eschborn, Germany, in the framework of the Organisation for Economic Co-operation and Development/ Nuclear Energy Agency THAI project. By this, the code has proven its applicability for different PAR designs and for a broad range of boundary conditions (pressure of up to 3 bars, steam amount up to 60 vol %, low-oxygen conditions). REKO-DIREKT has been successfully implemented in the commercial computational fluid dynamics code ANSYS-CFX as well as in the LP code COCOSYS [Gesellschaft for Anlag- und Reaktorsicherheit (GRS), Germany].", "labels": [3, 21]}
{"id": "342", "token": "After the accident at the Fukushima Daiichi nuclear power station in March 2011 (Fukushima accident), several investigation committees in Japan issued reports with lessons learned from the accident, including some recommendations on severe accident research. The review of specific severe accident research issues began after the Fukushima accident in the Atomic Energy Society of Japan (AESJ). AESJ has recently developed a new Thermal Hydraulics Safety Evaluation Fundamental Technology Enhancement Strategy Roadmap (TH-RM) for light water reactor safety improvement and development after the Fukushima accident by thoroughly revising the first version of the Roadmap (TH-RM-1) prepared in 2009. The revision was made by considering the lessons learned from the Fukushima accident. At the same time, the Research Expert Committee on Evaluation of Severe Accident, which was established by AESJ in 2012, has published phenomena identification and ranking tables (PIRTs) for both thermal hydraulics and source term issues in severe accidents based on findings from the Fukushima accident utilizing PIRT methodologies. The present paper reviews severe accident research before the Fukushima accident, lessons learned about severe accident research from the Fukushima accident, severe accident research issues reviewed after the Fukushima accident by AESJ, and current severe accident research activities mostly based on the two above-mentioned AESJ reviews after the Fukushima accident in Japan.", "labels": [3, 21]}
{"id": "456", "token": "The paper addresses some of the most relevant issues concerning the thermal hydraulics and radiation damage of the neutron generation target to be built at the European Spallation Source as recently approved after a critical design review. The target unit consists of a set of Tungsten blocks placed inside a wheel of 2.5 m diameter which rotates at some 0.5 Hz in order to distribute the heat generated from incoming protons which reach the target in the radial direction. The spallation material elements are composed of an array of Tungsten pieces which rest on a rotating steel support (the cassette) and are distributed in a cross-flow configuration. The thermal, mechanical and radiation effects resulting from the impact of a 2 GeV proton pulse are analysed in detail as well as an evaluation of the inventory of spallation products. The current design is found to conform to specifications and found to be robust enough to deal with several accident scenarios.", "labels": [3, 21]}
{"id": "570", "token": "Current scour estimation methods typically over-predict scour, resulting in uneconomical design. This tendency is partly due to the complexity of the scouring process, which indicates that some of its aspects are still not well understood, and can also be attributed to scale effects. Here, experiments are conducted to isolate the influence of relative coarseness (D/d(50)) and flow shallowness (h/D) on scour depth. For the range of D/d(50) in the present study, equilibrium scour depth (d(se)/D) decreases with increasing D/d(50) until a limiting value of D/d(50) = 175, after which d(se)/D approximate to 0.75. Furthermore, d(se)/D is found to depend on h/D when all other scour influencing parameters are held constant. A revised definition of the densimetric Froude number using the velocity along the separating streamline is shown to have an influential role in scour. An improved scour estimation method employing these parameters is presented and compared with current methods.", "labels": [3, 21]}
{"id": "649", "token": "The Water Cooled Ceramic Breeder blanket (WCCB) is being researched for Chinese Fusion Engineering Test Reactor (CFETR). The thermal-hydraulic analysis is essential because the blanket should remove the high heat flux from the plasma and the volumetric heat generated by neutrons. In this paper, the detailed three dimensional (3D) thermal hydraulic analysis on the whole module of WCCB blanket has been performed by Computational Fluid Dynamics (CFD) method, which is capable of solving conjugate heat transfer between solid structure and fluid. The main results, including temperature field, distribution of mass flow rate and coolant pressure drop, have been calculated simultaneously. These provides beneficial guidance data for the further structural optimization and for the design arrangement of primary and secondary circuit. Under the total heat source of 1.23 MW, the coolant mass flow rate of 5.457 kg/s is required to make coolant water corresponding to the Pressurized Water Reactor (PWR) condition (15.5 MPa, 285 degrees C-325 degrees C), generating the total coolant pressure drop (Delta P) of 0.467 MPa. The results show that the present structural design can make all the materials effectively cooled to the allowable temperature range, except for a few small modifications on the both sides of FW. The main components, including the first wall (FW), cooling plates (CPs), side wall (SWs)&stiffening plates (SPs) and the manifold(1-4), dominate 4.7%/41.7%/13%/40.6% of the total pressure drop, respectively. Additionally, the mass flow rate of each channel has been obtained, showing the peak relative deviation of 3.4% and 2% from the average for the paratactic channels and components separately. Generally, the results indicate that the present design of WCCB blanket can meet the requirements of thermal hydraulics. (C) 2016 Elsevier B.V. All rights reserved.", "labels": [3, 21]}
{"id": "719", "token": "Fluctuations in water surface elevation (WSE) along rivers have important implications for water resources, flood hazards, and biogeochemical cycling. However, current in situ and remote sensing methods exhibit key limitations in characterizing spatiotemporal hydraulics of many of the world's river systems. Here we analyze new measurements of river WSE and slope from AirSWOT, an airborne analogue to the Surface Water and Ocean Topography (SWOT) mission aimed at addressing limitations in current remotely sensed observations of surface water. To evaluate its capabilities, we compare AirSWOT WSEs and slopes to in situ measurements along the Tanana River, Alaska. Root-mean-square error is 9.0cm for WSEs averaged over 1km(2) areas and 1.0cm/km for slopes along 10km reaches. Results indicate that AirSWOT can accurately reproduce the spatial variations in slope critical for characterizing reach-scale hydraulics. AirSWOT's high-precision measurements are valuable for hydrologic analysis, flood modeling studies, and for validating future SWOT measurements.", "labels": [3, 21]}
{"id": "848", "token": "The product development process of hydraulic systems for construction machines is often supported by unidimensional simulations. They are used i.e. to define properties of new parts or to test system functions. More and more simulations are also used within the concept phase to define the best suited system layout for a certain purpose. But the usage of simulations in the concept phase is a difficult task. Because of the generally high number of different possible concepts and different customer usage profiles, the simulation effort is overwhelming without a proper process. Therefore, this paper shows an approach for a model based concept evaluation with respect to customer specific usage profiles. For this, a modular simulation model as well as downstream customer specific weighting procedure of the simulation results is used. The paper includes the general approach as well as its application on the hydraulic system of an excavator.", "labels": [3, 21]}
{"id": "1035", "token": "The thermal hydraulics of supercritical water under forced-, mixed convection and natural circulation conditions is not fully understood. In order to study the thermal hydraulic behaviour of this fluid under natural circulation conditions a small size, closed experimental loop has been designed and built. The thermal hydraulic phenomenon occurring in the loop can be measured by thermocouples mounted onto the outer surface of the heated tube wall, absolute and differential pressure transducers and a flow meter; moreover, simultaneously can be visualized by neutron radiography techniques. This paper describes the loop itself, the process of the experiment with the measurement techniques, the data acquisition system applied and the results got during the first measurement series. Based on the results of the first measurement series, it was found that the measured part of the steady state characteristic is independent from the system pressure. A slight dependence of steady state characteristic on the inlet temperature can be identified: the higher the inlet temperature the higher the mass flow rate. The total pressure drop and its components seem to be independent from the system pressure but strongly dependent on the inlet temperature due to the influence of bulk-fluid temperature on the relevant thermophysical properties (density and dynamic viscosity). The pressure drop due to acceleration of flow found to be negligible next to the two dominant components, the pressure drop due to frictional resistance and due to gravity, The coupled evaluation of the radiographic images and the thermophysical properties of wafer have shown that the main driving force behind the decrease of the neutron attenuation is the decreasing water density as the bulk-fluid temperature increases. The reverse of this relationship could be exploited during the validation of future Monte Carlo simulations. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [3, 21]}
{"id": "1095", "token": "Forward quantification of simulation (code) response uncertainties requires knowledge of physical model parameter uncertainties. Nuclear thermal-hydraulics codes, such as RELAP5 and TRACE, do not provide any information on uncertainties of physical model parameters. A framework is developed to quantify uncertainties of physical model parameters using Maximum Likelihood Estimation (MLE), Bayesian Maximum A Priori (MAP), and Markov Chain Monte Carlo (MCMC) algorithms. The objective of the present work is to perform the sensitivity analysis of the physical model parameters in code TRACE and calculate their uncertainties using MLE, MAP, and MCMC algorithms. The OECD/NEA BWR Full-size fine-mesh Bundle Test (BFBT) data is used to quantify uncertainty of selected physical models of TRACE code. The BFBT is based on a multi-rod assembly with measured data available for single or two-phase pressure drop, axial and radial void fraction distributions, and critical power for a wide range of system conditions. In this work, the steady-state cross-sectional averaged void fraction distribution is used as the input data for inverse uncertainty quantification (IUQ) algorithms, and the selected physical model's probability distribution function (PDF) is the desired output quantity. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [3, 21]}
{"id": "1235", "token": "The first wall (FW) of DEMO is a component with high thermal loads. The cooling of the FW has to comply with the material's upper and lower temperature limits and requirements from stress assessment, like low temperature gradients. Also, the cooling has to be integrated into the balance-of-plant, in a sense to deliver exergy to the power cycle and require a limited pumping power for coolant circulation. This paper deals with the basics of FW cooling and proposes optimization approaches. The effectiveness of several heat transfer enhancement techniques is investigated for the use in helium cooled FW designs for DEMO. Among these are wall-mounted ribs,. large scale mixing devices and modified hydraulic diameter. Their performance is assessed by computational fluid dynamics (CFD), and heat transfer coefficients and pressure drop are compared. Based on the results, an extrapolation to high heat fluxes is tried to estimate the higher limits of cooling capabilities. (C) 2016 Karlsruhe Institute of Technology. Published by Elsevier B.V. All rights reserved.", "labels": [3, 21]}
{"id": "1332", "token": "The Great East Japan Earthquake occurred on March 11, 2011 fatally damaged the Fukushima Daiichi Nuclear Power Plant (NPP), caused prolonged station blackout (SBO). Following the SBO, the reactor water level gradually dropped due to the increase in steam discharge from safety relief valves and eventually led to nuclear fuel melt down. Almost four years have passed since the accident, and official reports by the Japanese regulatory have given the general description of causes and progressions of the fatal accident. Even after the Fukushima accident, more than 430 nuclear power plants are currently operating and over 80 units are under construction worldwide. From this fact alone, it is extremely important to learn from the Fukushima accident and enhance the safety culture of the reactor operation to completely eliminate the possibilities of catastrophic accidents seen in 2011. In this study, the best estimate transient thermal-hydraulics code, RETRAN-03/MODO4 was utilized to focus on the effectiveness of the Isolation Condenser (IC) installed on Advanced Boiling Water Reactors (ABWR). The ICs turned out to be one of the very few operable safety systems during the Fukushima accident, and this simple yet reliable safety system should be utilized to secure ABWR from possible reactor core damages. In the present paper, several case studies conducted utilizing the ICs are presented and methods of countermeasures to improve light water reactor safety level in design and operation features are proposed. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [3, 21]}
{"id": "1479", "token": "This paper introduces current issues, challenges, and future directions of nuclear thermalhydraulic (T-H) safety research, viewed in close conjunction with new developments in advanced reactor systems and simulation tools and lessons learned from the Fukushima accident. Two technical concerns are introduced to illustrate some of the limitations in our current understanding of important T-H phenomena that are very relevant to nuclear safety. The first is reflood heat transfer, which has been an important safety issue for a long time, and the second is the multidimensional T-H phenomena appearing in nuclear reactor systems, which have rather recently drawn significant attention in the nuclear community. These concerns are discussed by taking some recent research examples and emphasizing their critical relevance to nuclear reactor safety. Then, some challenging issues for the advancement of nuclear T-H safety technologies are identified and briefly discussed in close conjunction with recent research efforts, and perspectives on advanced nuclear T-H safety research are presented.", "labels": [3, 21]}
{"id": "1575", "token": "Shoot apical meristems produce stem tissues, produce leaves, and produce flowers. Cell proliferation characteristics of meristems are dependent upon cell maturation processes and the functions of newly formed cells. Cells of stem terminals depend upon water availability from other plant portions. Inadequate moisture availability to stem terminals reduces shoot growth rates and leaf production rates. Xylem conductivity measurements of terminal shoot meristems and small leaves were approximated using the Hagen-Poiseuille equation to determine relationships between xylem contributions to leaves versus xylem conductivity within stems. Analyses of petiole and stem xylem conductivities for the 23 herbaceous plant species were confined to stem terminals that only had primary xylem cells in stems and only five leaves or leaf pairs. Among stem segments (10 mm to 64 mm in length) among species, the largest leaf areas ranged from 2.34 cm(2) to 54 cm(2), stem diameters ranged from 0.82 mm to 3.83 mm, and maximum leaf petiole and stem xylem conductivities were 0.12 g cm MPa-1 s(-1) and 0.35 g cm MPa-1 s(-1), respectively. For pooled samples, petiole xylem conductivity was well scaled with leaf area of largest leaves (r(2) = 0.76). For pooled samples, stem conductivity was well scaled with cumulative petiole conductivities (r(2) = 0.94). When the largest diameter stem sections from each species were considered, stem xylem conductivity was well scaled with mean radius of conduits (r(2) = 0.82). Overall, stem xylem conductivities were strongly linked to petiole conductivities as leaves developed. Petiole xylem conductivity was well scaled with stem conductivities for all 23 species with markedly different leaf areas.", "labels": [3, 21]}
{"id": "1642", "token": "As a consequence of its position and functions, the ITER blanket system will be subjected to significant heat loads under nominal reference conditions. Therefore, the design of its cooling system is particularly demanding. Coolant water is distributed individually to the 440 blanket modules (BMs) through manifold piping, which makes it a highly parallelized system. The mass flow rate distribution is finely tuned to meet all operation constraints: adequate margin to burn out in the plasma facing components, even distribution of water flow among the so-called plasma-facing fingers of the Blanket First Wall panels, high enough water flow rate to avoid excessive water temperature in the outlet pipes, maximum allowable water velocity lower than 7 m/s in manifold pipes. Furthermore the overall pressure drop and flow rate in each BM shall be within the fixed specified design limit to avoid an unduly unbalance of cooling among the 440 modules. Analyses have to be carried out following a computational fluid-dynamic (CFD) approach based on the finite volume method and adopting a CFD commercial code to assess the thermal-hydraulic behaviour of each single circuit of the ITER blanket cooling system. This paper describes the code benchmarking needed to determine the best method to get reliable and timely results. Since experimental tests are available in ITER Organization on full scale prototypes of Shield Blocks #08 and #14, CFD analyses have been performed to investigate their fluid-dynamic behaviour under steady state conditions and compare the numerical and experimental results. Results obtained are presented and critically discussed. (C) 2016 Elsevier B.V. All rights reserved.", "labels": [3, 21]}
{"id": "1723", "token": "VERA-CS (Virtual Environment for Reactor Applications, Core Simulator) is a coupled neutron transport and thermal-hydraulics code under development by the Conscirtium for Advanced Simulation of Light Water Reactors (CASL). An approach to uncertainty quantification and sensitivity analysis with VERA-CS was developed and a new toolkit was created to perform uncertainty quantification and sensitivity analysis. A 2 x 2 fuel assembly model was developed and Simulated by VERA-CS, and uncertainty quantification and Sensitivity analysis were performed with fourteen uncertain. input parameters. The minimum departure from nucleate boiling ratio (MDNBR), maximum fuel center-line temperature, and maximum outer clad surface temperature were chosen as the selected figures of merit. Pearson, Spearman, and partial correlation coefficients were considered for all of the figures of merit in sensitivity analysis and coolant inlet temperature was consistently the most influential parameter. Parameters used as inputs to the critical heat flux calculation with the W-3 correlation were shown to be the most influential on the MDNBR, maximum fuel center-line temperature, and maximum outer clad surface temperature. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [3, 21]}
{"id": "1848", "token": "The presence of micropollutants in the environment has triggered research on quantifying and predicting their fate in wastewater treatment plants (WWTPs). Since the removal of micropollutants is highly related to conventional pollutant removal and affected by hydraulics, aeration, biomass composition and solids concentration, the fate of these conventional pollutants and characteristics must be well predicted before tackling models to predict the fate of micropollutants. In light of this, the current paper presents the dynamic modelling of conventional pollutants undergoing activated sludge treatment using a limited set of additional daily composite data besides the routine data collected at a WWTP over one year. Results showed that as a basis for modelling, the removal of micropollutants, the Burger-Diehl settler model was found to capture the actual effluent total suspended solids (TSS) concentrations more efficiently than the Takacs model by explicitly modelling the overflow boundary. Results also demonstrated that particular attention must be given to characterizing incoming TSS to obtain a representative solids balance in the presence of a chemically enhanced primary treatment, which is key to predict the fate of micropollutants.", "labels": [3, 21]}
{"id": "1952", "token": "Modeling individual fish habitat selection in highly variable environments such as hydropeaking rivers is required for guiding efficient management decisions. We analyzed fish microhabitat selection in the heterogeneous hydraulic and thermal conditions (modeled in two-dimensions) of a reach of the large hydropeaking Rhone River locally warmed by the cooling system of a nuclear power plant. We used modern fixed acoustic telemetry techniques to survey 18 fish individuals (five barbels, six catfishes, seven chubs) signaling their position every 3 s over a three-month period. Fish habitat selection depended on combinations of current microhabitat hydraulics (e.g. velocity, depth), past microhabitat hydraulics (e.g. dewatering risk or maximum velocities during the past 15 days) and to a lesser extent substrate and temperature. Mixed-effects habitat selection models indicated that individual effects were often stronger than specific effects. In the Rhone, fish individuals appear to memorize spatial and temporal environmental changes and to adopt a least constraining habitat selection. Avoiding fast flowing midstream habitats, fish generally live along the banks in areas where the dewatering risk is high. When discharge decreases, however, they select higher velocities but avoid both dewatering areas and very fast-flowing midstream habitats. Although consistent with the available knowledge on static fish habitat selection, our quantitative results demonstrate temporal variations in habitat selection, depending on individual behavior and environmental history. Their generality could be further tested using comparative experiments in different environmental configurations. (C) 2016 Elsevier B.V. All rights reserved.", "labels": [3, 21]}
{"id": "2070", "token": "The effects of basin hydrology on hydraulic geometry of channels variability for incised streams were investigated using available field data sets and models of watershed hydrology and channel hydraulics for the Yazoo River basin, USA. The study presents the hydraulic geometry relations of bankfull discharge, channel width, mean depth, cross-sectional area, longitudinal slope, unit stream power, and mean velocity at bankfull discharge as a function of drainage area using simple linear regression. The hydraulic geometry relations were developed for 61 streams, 20 of them are classified as channel evolution model (CEM) Types IV and V and 41 of them are CEM streams Types II and III. These relationships are invaluable to hydraulic and water resources engineers, hydrologists, and geomorphologists involved in stream restoration and protection. These relations can be used to assist in field identification of bankfull stage and stream dimension in un-gauged watersheds as well as estimation of the comparative stability of a stream channel. A set of hydraulic geometry relations are presented in this study, these empirical relations describe physical correlations for stable and incised channels. Cross-sectional area, which combines the effects of channel width and mean channel depth, was found to be highly responsive to changes in drainage area and bankfull discharge. Analyses of cross-sectional area, channel width, mean channel depth, and mean velocity in conjunction with changes in drainage area and bankfull discharge indicated that the channel width is much more responsive to changes in both drainage area and bankfull discharge than are mean channel depth or mean velocity. (C) 2016 International Research and Training Centre on Erosion and Sedimentation/the World Association for Sedimentation and Erosion Research. Published by Elsevier B.V. All rights reserved.", "labels": [3, 21]}
{"id": "2207", "token": "Sediment concentration is fundamental for determining sediment transport in open channels. The Rouse equation, one of several methods for computing sediment concentration, has been derived using deterministic hydraulic principles. This study derives the Rouse equation using the Shannon entropy theory. The derivation requires a hypothesis on the cumulative probability distribution function of sediment concentration in terms of flow depth which is formulated in a general form and can specialize in several specific forms reported in the literature. The advantage of using the entropy theory is that it permits quantification of uncertainty associated with concentration and determination of parameters in terms of specified information, such as mean concentration. (C) 2016 Elsevier B.V. All rights reserved.", "labels": [3, 21]}
{"id": "2361", "token": "This experimental and analytical study investigates the double-averaged (DA) turbulent flow characteristics within an array of large gravel obstacles found atop a porous gravel bed. Analysis of the experimental data reveals that the DA streamwise velocity preserves the logarithmic law above the form-induced sublayer, while a linear law and a third-degree polynomial function apply within the form-induced and interfacial sublayers, respectively. The form-induced shear stress is 70% of the DA Reynolds shear stress (RSS) occurring at the virtual bed level. The DA turbulent kinetic energy (TKE) components, streamwise and vertical, attain their peak values at the obstacle crest level, while they diminish sharply below the virtual bed level. The fluxes of the TKE streamwise and vertical components, however, change their signs slightly below the crest level, indicating a changeover of the dominance of the bursting events. For the TKE budget, the TKE production, diffusion, and pressure energy diffusion rate terms attain their peak values at the crest level, while the TKE dissipation rate has its peak value at the virtual bed level. Third-order moments of velocity fluctuations follow the linear relationship, and their signs change slightly below the crest level. The quadrant analysis suggests that the sweep events are the governing mechanism at the near-bed flow region, while the ejection events become predominant with an increase in vertical distance. The quadrant plots of the form-induced velocity components display a pseudo-elliptical scatter within the interfacial sublayer and a small circular cluster above the form-induced sublayer.", "labels": [3, 21]}
{"id": "2465", "token": "Step-pool systems occur naturally in steep mountain streams and as man-made structures in steep channel sections where they serve as energy dissipating structures. Three different flow regimes may occur. The dominant flow regime is the cascading nappe flow regime. At higher discharges the skimming flow regime develops with an almost plane water surface. In between these flow regimes a transition flow regime occurs. A physical model was used to measure the pressure distribution around a single step for a particular step-pool geometry and for different flow regimes (nappe/transition/skimming). To achieve this, 14 simultaneously recording piezoresistive pressure transducers were distributed around the step. The results showed that the regime change from nappe to transition flow is associated with a discontinuity of the average Froude number of a step-pool unit as well as drops in pressures and water depth. Relative instantaneous drag forces reached a maximum for this regime change. This implies that the regime change from nappe to transition flow is a critical loading case with respect to the stability of the steps. On the other hand, the mean drag forces showed little systematic variation as the flow rate changed with a large spread in results for measurements repeated at the same flow. Thus, for the nappe and transition flow regimes, the mean drag force is not a good criterion to use to predict step stability. The occurrence of the different flow regimes could be related to the average Froude number of a step-pool unit. The results have practical implications for the design of step-pool systems.", "labels": [3, 21]}
{"id": "2577", "token": "This study numerically investigated the laminar mixed-convection heat transfer of different water copper nanofluids inside a microtube with curvature angle of 90 degrees using a finite volume method. The Reynolds number of modeling was 10, nanoparticles volume fractions were chosen from 0.0% to 6.0% and Richardson numbers varied from 0.1 to 10. The findings were depicted for dimensionless axial velocity, coefficient of friction and Nusselt number profiles as well as dimensionless temperature contours. The validity of model was excellent compared to former numerical and experimental studies. The results showed that the heat transfer and hydraulics behavior of nanofluids in curved geometries is to some extent different with other geometries and flat surfaces due to presence of buoyancy and centrifugal forces at the same time. Especially, in the regions near and after 45 degrees curvature angle, the behavior of heat transfer and nanofluid flow is unpredictable. In this region, increasing the nanoparticles volume concentration or transition from forced convection regime to free convection state, cause a decrease in Nusselt number and friction factor. That's while for the entrance region of microtube, the results are completely opposite; increasing the Richardson number or nanoparticle concentration enhances the heat transfer as well as friction factor. Also, the velocity profile variations in the vertical and horizontal diameter of microtube is significant in areas of 60 degrees (pi/3) and the heterogeneity of this profile increases by rising Rayleigh number and volume fraction of solid particles. (C) 2016 The Society of Powder Technology Japan. Published by Elsevier B.V. and The Society of Powder Technology Japan. All rights reserved.", "labels": [3, 21]}
{"id": "2674", "token": "A series of three-dimensional smoothed particle hydrodynamics (SPH) and finite-element (FE) models, with a domain in the form of a water tank, were undertaken to simulate tsunami-induced bore impact on a discrete onshore structure on a dry bed. The fluid motion was simulated using the SPH-based software DualSPHysics. The tsunami-like waves were represented by solitary waves with different characteristics generated by the numerical paddle wavemaker. Numerical probes were uniformly distributed on the structure's vertical surface providing detailed measures of the pressure distribution across the structure. The peak impact locations on the structure's surface were specifically determined and the associated peak pressures then compared with the prediction of existing commonly used design equations. Using the pressure-time histories from the SPH model, FE analysis was conducted with Abaqus to model the dynamic response of a representative timber structure. The results show that the equations used to estimate the associated pressure for design purposes can be highly non-conservative. By gaining a detailed insight into the impact pressures and structure response, engineers have the potential means to optimise the design of structures under tsunami impact loads and improve survivability.", "labels": [3, 21]}
{"id": "2710", "token": "This study presents the first attempt to link the multi-algorithm genetically adaptive search method (AMALGAM) with a groundwater model to define pumping rates within a well distributed set of Pareto solutions. The pumping rates along with three minimization objectives, i.e. minimizing shortage affected by the failure to supply, modified shortage index and minimization of extent of drawdown within prespecified regions, were chosen to define an optimal solution for groundwater drawdown and subsidence. Hydraulic conductivity, specific yield parameters of a modular threedimensional finite-difference (MODFLOW) groundwater model were first optimized using Cuckoo optimization algorithm (COA) by minimizing the sum of absolute deviation between the observed and simulated water table depths. These parameters were then applied in AMALGAM to optimize the pumping rate variables for an arid groundwater system in Iran. The Pareto parameter sets yielded satisfactory results when maximum and minimum drawdowns of the aquifer were defined in a range of -40 to +40 cm/year. Overall, 'Modelling - Optimization - Simulation' procedure was capable to compute a set of optimal solutions displayed on a Pareto front. The proposed optimal solution provides sustainable groundwater management alternatives to decision makers in arid region.", "labels": [3, 21]}
{"id": "2890", "token": "The application of best-estimate codes [coupled neutron kinetics (NK)/thermal hydraulics (TH)] for safety analyses of research reactors (RRs) has gained considerable momentum during the past decade. Application of these codes is largely facilitated by the high level of technological maturity and expertise that these codes allow as a safety technology in nuclear power plants, and it is largely driven by International Atomic Energy Agency activities. The present study belongs in this framework and presents the development and application of the coupled NK and TH code THERMO-T to the analysis of protected reactivity insertion accidents and loss-of-flow accidents in a typical RR with standard Materials Testing Reactor plate-type fuel elements. The coupling is realized by considering the neutronic reactivity feedbacks of the fuel and coolant temperatures and a heat generation model for the reactor power. The neutron flux in the reactor core is solved by applying point reactor kinetic equations and employing radial and axial power distributions calculated from a three-dimensional full-core model by the continuous-energy Monte Carlo reactor physics code Serpent. The evolution of temporal and spatial distributions of the fuel, cladding, and coolant temperatures is calculated for all fuel channels by using a finite volume time implicit numerical scheme for solving a three-conservation equation model. In this study, additional features, such as critical heat flux ratio prediction and decay heat model, are implemented for both highly enriched uranium and low-enriched uranium cores, and a comprehensive comparison of THERMO-T results is performed against other codes.", "labels": [3, 21]}
{"id": "3171", "token": "The present study investigates the accuracy of five different data-driven techniques in estimating oxygen transfer efficiency in baffled chutes: feedforward neural network (FFNN), radial basis neural network (RBNN), generalized regression neural network (GRNN), adaptive neuro fuzzy inference system with subtractive clustering (ANFIS-SC), and adaptive neuro fuzzy inference system with fuzzy c-means clustering (ANFIS-FCM). Baffled apron chutes or drops are used on channel structures to dissipate the energy in the flow. A baffled chute design is effective both in energy dissipation and in aerating the flow and reducing nitrogen supersaturation. There is a close relationship between energy dissipation and oxygen transfer efficiency. This study aims to determine the aeration efficiency of baffled chutes with stepped (S), wedge (W), trapezoidal (T), and T-shaped (T-S) baffle blocks. The performances of the FFNN, RBNN, GRNN, ANFIS-SC, and ANFIS-FCM models are compared with those of multilinear and nonlinear regression models. Based on the comparisons, it was observed that all data-driven models could be successfully employed in modeling the aeration efficiency of S, W, and T-S baffle blocks from the available experimental data. Among data-driven models, the FFNN model was found to be the best. (C) 2017 American Society of Civil Engineers.", "labels": [3, 21]}
{"id": "3364", "token": "We assessed whether diversity in plant hydraulic traits can explain the observed diversity in plant responses to water stress in seasonally dry tropical forests (SDTFs). The Ecosystem Demography model 2 (ED2) was updated with a trait-driven mechanistic plant hydraulic module, as well as novel drought-phenology and plant water stress schemes. Four plant functional types were parameterized on the basis of meta-analysis of plant hydraulic traits. Simulations from both the original and the updated ED2 were evaluated against 5yr of field data from a Costa Rican SDTF site and remote-sensing data over Central America. The updated model generated realistic plant hydraulic dynamics, such as leaf water potential and stem sap flow. Compared with the original ED2, predictions from our novel trait-driven model matched better with observed growth, phenology and their variations among functional groups. Most notably, the original ED2 produced unrealistically small leaf area index (LAI) and underestimated cumulative leaf litter. Both of these biases were corrected by the updated model. The updated model was also better able to simulate spatial patterns of LAI dynamics in Central America. Plant hydraulic traits are intercorrelated in SDTFs. Mechanistic incorporation of plant hydraulic traits is necessary for the simulation of spatiotemporal patterns of vegetation dynamics in SDTFs in vegetation models.", "labels": [3, 21]}
{"id": "3433", "token": "Restoration of an adequate water supply in spring is a prerequisite for survival of angiosperm trees in temperate regions. Trees must re-establish access to soil water and recover xylem functionality. We thus hypothesized that prolonged soil frost impairs recovery and affects hydraulics and phenology of Malus domestica var. 'Golden Delicious.' To test this hypothesis, over two consecutive winters the soil around some trees was insulated to prolong soil frosting, From mid-winter to early summer, the level of native embolism, the water and starch contents of wood, bark and buds were quantified at regular intervals and findings correlated with various phenological parameters, xylogenesis and fine root growth. The findings confirm that prolonged soil frost affects tree hydraulics and phenology but the severity of the effect depends on the climatic conditions. In both study years, percentage loss of hydraulic conductivity (PLC) decreased from about 70% at the end of winter to about 10% in May. Thereby, xylem refilling strongly coincided with a decrease of starch in wood and bark. Also treated trees were able to restore their hydraulic system by May but, in the warm spring of 2012, xylem refilling, the increases in water content and starch depolymerization were delayed. In contrast, in the cold spring of 2013 only small differences between control and treated trees were observed. Prolongation of soil frost also led to a delay in phenology, xylogenesis, and fine root growth. We conclude that reduced water uptake from frozen or cold soils impairs refilling and thus negatively impacts tree hydraulics and growth of apple trees in spring. Under unfavorable circumstances, this may cause severe winter damage or even dieback.", "labels": [3, 21]}
{"id": "3496", "token": "Steam injector (SI) is known as passive jet pump and heat exchanging device which operates without external power source or mechanical machineries. It utilizes direct contact condensation heat transfer between steam and water-jet as a driving mechanism of the operation and is capable of discharging sub cooled water at higher pressure than the inlet fluids pressure. In addition, it has an excellent heat transfer capability, more than 1000 times that of shell and tube heat exchanger. In the present study, thermal hydraulics characteristics of the water-jet-centered supersonic SI system were investigated from both experimental and analytical approaches. The SI body was manufactured with stainless steel equipped with overflow port. The water injection nozzle was designed with shaft-driving mechanism to freely adjust the axial location of the water nozzle and steam inlet cross sectional area. High pressure steam was supplied to the SI from once-through boiler, which is capable of supplying saturated steam at the maximum pressure of 0.63 MPa for the current test facility. Water jet was injected at mass flow rate of 0.4-0.8 kg/s. Pressure and temperature measurements were conducted at inlet and outlet of the steam injector system as well as at the overflow port to investigate the operation characteristics of the SI. Results showed the water-jet centered SI's promising functionality as a passive coolant injection in view of its quick-start up, operable condition limits, discharge pressure and heat transfer capabilities at current inlet conditions. In addition, obtained experimental results were compared with analytical model to assess the predictive capability of discharge pressure value and reasonable agreement was obtained. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [3, 21]}
{"id": "24", "token": "Load demand forecasting is a critical process in the planning of electric utilities. An ensemble method composed of Empirical Mode Decomposition (EMD) algorithm and deep learning approach is presented in this work. For this purpose, the load demand series were first decomposed into several intrinsic mode functions (IMFs). Then a Deep Belief Network (DBN) including two restricted Boltzmann machines (RBMs) was used to model each of the extracted IMFs, so that the tendencies of these IMFs can be accurately predicted. Finally, the prediction results of all IMFs can be combined by either unbiased or weighted summation to obtain an aggregated output for load demand. The electricity load demand data sets from Australian Energy Market Operator (AEMO) are used to test the effectiveness of the proposed EMD-based DBN approach. Simulation results demonstrated attractiveness of the proposed method compared with nine forecasting methods. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [1, 12]}
{"id": "72", "token": "We created a novel laminar-flow based microbial fuel cell (MFC) array to be an integrable and scalable power sourcefor portable lab-on-a-chip (LOC) devices. The microfluidic MFC enabled the laminar flow of anolyte and catholyte streams in a microchannel without any physical membranes while the device harvested electricity by utilizing ion transfers through the laminar interface which acts as a virtual membrane. The array prototype incorporated four series-connected fuel cells and was operated with two common inlets for the continuous introduction of the anolyte and catholyte. In the anodic flow region, microorganisms oxidized organic media and completed respiration by transferring the electrons to the anodes. The protons generated by the anodic reactions passed through the liquid-liquid interfaces and traveled to the cathodic streams. The electrons then moved across the external resistors to the cathodes where they combined with the protons and reduced oxidant (i.e. catholyte). The array generated a maximum power output of 60.5,W/cm(2) using a 100 kg(2) load, which outperformed a single laminar flow MFC unit by a factor of approximately 4. The series or parallel application of this array structure, using microfluidic MFCs integrated into a single LOC device, can offer the potential for on-chip power generation. (C) 2016 Elsevier B.V. All rights reserved.", "labels": [1, 12]}
{"id": "150", "token": "The United States Geological Survey estimates that over four trillion barrels of crude oil are currently trapped within U.S. oil shale reserves. However, no cost-effective, environmentally sustainable method for oil production from oil shale currently exists. Given the continuing demand for low-cost fossil-fuel production, alternative methods for shale-oil extraction are needed. Geothermic Fuel Cells (TM) (GFC) harness the heat generated by high-temperature solid oxide fuel cells during electricity generation to process oil shale into sweet crude oil. In this paper, a thermo-electrochemical model is exercised to simulate the performance of a 4.5 kW(e) (gross) Geothermic Fuel Cell module for in situ oil-shale processing. The GFC analyzed in this work is a prototype which contains three 1.5 kW(e) solid oxide fuel cell (SOFC) stack-and-combustor assemblies packaged within a 0.3 m diameter, 1.8 m tall, stainless-steel housing. The high-temperature process heat produced by the SOFCs during electricity generation is used to retort oil shale within underground geological formations into high-value shale oil and natural gas. A steady-state system model is developed in Aspen Plus (TM) using user-defined subroutines to predict the stack electrochemical performance and the heat-rejection from the module. The model is validated against empirical data from independent single-stack performance testing and full GFC-module experiments. Following model validation, further simulations are performed for different values of current, fuel and air utilization to study their influence on system electrical and heating performance. The model is used to explore a wider range of operating conditions than can be experimentally tested, and provides insight into the competing physical processes at play during Geothermic Fuel Cell operation. Results show that the operating conditions can be tuned to generate desired heat-flux conditions as needed across applications. (C) 2017 Elsevier Ltd. All rights reserved.", "labels": [1, 12]}
{"id": "314", "token": "Pressure-retarded osmosis is a renewable method of power production from salinity gradients which has generated significant academic and commercial interest but, to date, has not been successfully implemented on a large scale. In this work, we investigate lower bound cost scenarios for power generation with PRO to evaluate its economic viability. We build a comprehensive economic model for PRO with assumptions that minimize the cost of power production, thereby conclusively identifying the operating conditions that are not economically viable. With the current state-of-the art PRO membranes, we estimate the minimum levelized cost of electricity for PRO of US$1.2/kWh for seawater and river water pairing, $0.44/kWh for reverse osmosis brine and wastewater, and $0.066/kWh for nearly saturated water (26% wt) and river water, all for a 2 MW production system. Only a pairing of extremely high salinity (greater than 18%) water and freshwater has the potential to compete with wind power currently at $0.074/kWh. We show two methods for reducing this cost via economies of scale and reducing the membrane structural parameter. We find that the latter method reduces the levelized cost of electricity significantly more than increasing the membrane permeability coefficient. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [1, 12]}
{"id": "511", "token": "To response to the increasing demands for clean water, a large pressurized water reactor (PWR) with a desalination capability has been studied and demonstrated its potential so far. However, the electricity production of the large nuclear reactor decreases by 10% due to steam bypass for desalination. In this study, the authors evaluate the possibility of a large PWR with a capability of producing both electric power and clean water by using the supercritical CO2 (S-CO2) Brayton cycle technology. The S-CO2 power technology is adopted to minimize the decrease in the electricity production capacity due to desalination process. Two concepts which replace the existing steam based power conversion system with a S-CO2 Brayton cycle were proposed. The first concept is that the low pressure steam turbine section of the power conversion system is replaced with the S-CO2 Brayton cycle. The second concept is that the whole steam based power conversion system is replaced with the S-CO2 Brayton cycle. Several S -CO2 cycle options were considered in terms of power production and the desalination capacity and conducted a comparative analysis of selected layouts and the optimal operating conditions of the suggested layouts were identified. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [1, 12]}
{"id": "610", "token": "Electricity customers who install solar panels often are paid the prevailing retail price for the electricity they generate. We demonstrate that this rate of compensation typically is not optimal. A payment for distributed generation (w) that is below the retail price of electricity (r) often will induce the welfare-maximizing level of distributed generation (DG) when the fixed costs of centralized electricity production and the network management costs of accommodating intermittent solar DG are large, and when centralized generation and DG produce similar (pollution) externalities. w can optimally exceed r under alternative conditions. The optimal DG compensation policy varies considerably as industry conditions change. Furthermore, a requirement to equate w and r can reduce aggregate welfare substantially and can generate pronounced distributional effects.", "labels": [1, 12]}
{"id": "869", "token": "With the increasing concern about the serious global energy crisis and high energy consumption during high content solid wastes (HCSWs) treatment, microbial fuel cell (MFC) has been recognized as a promising resource utilization approach for HCSW stabilization with simultaneous electrical energy recovery. In contrast to the conventional HCSW stabilization processes, MFC has its unique advantages such as direct bio-energy conversion in a single step and mild reaction conditions (viz., ambient temperature, normal pressure, and neutral pH). This review mainly introduces some important aspects of electricity generation from HCSW and its stabilization in MFC, focusing on: (1) MFCs with different fundamentals and configurations designed and constructed to produce electricity from HCSW; (2) performance of wastes degradation and electricity generation; (3) prospect and deficiency posed by MFCs with HCSW as substrates. To date, the major drawback of MFCs fueled by HCSW is the lower power output than those using simple substrates. HCSW hydrolysis and decomposition would be a major tool to improve the performance of MFCs. The optimization of parameters is needed to push the progress of MFCs with HCSW as fuel. (C) Higher Education Press and Springer-Verlag Berlin Heidelberg 2017", "labels": [1, 12]}
{"id": "1027", "token": "As one of the most successfully commercialized distributed energy resources, the long-term effects of microturbines (MTs) on the distribution network has not been fully investigated due to the complex thermo-fluid-mechanical energy conversion processes. This is further complicated by the fact that the parameter and internal data of MTs are not always available to the electric utility, due to different ownerships and confidentiality concerns. To address this issue, a general modeling approach for MTs is proposed in this paper, which allows for the long-term simulation of the distribution network with multiple MTs. First, the feasibility of deriving a simplified MT model for long-term dynamic analysis of the distribution network is discussed, based on the physical underStanding of dynamic processes that occurred within MTs. Then a three-stage identification method is developed in order to obtain a piecewise MT model and predict electro-mechanical system behaviors with saturation. Next, assisted with the electric power flow calculation tool, a fast simulation methodology is proposed to evaluate the long-term impact of multiple MTs on the distribution network. Finally, the model is verified by using Capstone 00 micro turbine experiments, and further applied to the dynamic simulation of a modified IEEE 37-node test feeder with promising results. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [1, 12]}
{"id": "1192", "token": "The problem of inter-regional interchange scheduling in the presence of stochastic generation and load is considered. An interchange scheduling technique based on a two-stage stochastic minimization of expected operating cost is proposed. Because directly solving the stochastic optimization is intractable, an equivalent problem that maximizes the expected social welfare is formulated. The proposed technique leverages the operator's capability of forecasting locational marginal prices and obtains the optimal interchange schedule without iterations among operators. Several extensions of the proposed technique are also discussed.", "labels": [1, 12]}
{"id": "1333", "token": "Lignocellulosic biomass gasification followed by the Fischer-Tropsch (Fe) synthesis is becoming a promising pathway to produce synthetic biofuels, having the potential of being coupled with combined-cycle strategies in order to coproduce electricity. In this work, the thermodynamic performance of this type of bioenergy system is evaluated through exergy analysis. A base-case process combining biomass gasification, FT synthesis and a combined cycle is defined. Furthermore, two alternative configurations modifying the base-case process are considered: (i) autothermal reforming (ATR) of a fraction of the FT tail gas to increase the fuel yield, and (ii) combustion of a fraction of the conditioned biosyngas to increase electricity production. The biomass conversion plants are simulated using Aspen Plus (R) to obtain the data required for the assessment. The indirect gasifier and the gas combustor are identified as the main sources of irreversibility within the three process configurations, with exergy destruction ratios of 21% and 5-7%, respectively. The gasification subsystem is found to contribute over 50% to the overall exergy destruction, showing 68% efficiency. The power generation subsystem also shows a high contribution to the overall exergy destruction (19-28%) due to high fuel consumption and the significant thermodynamic irreversibility of the cycle. Depending on the plant configuration, overall exergetic efficiencies of 24-27% are attained. The ATR case leads to a higher yield of biofuels, at the expense of lower electricity production. This configuration enhances the exergetic efficiency of the system and thus its thermodynamic performance, in contrast to the alternative configuration for increased power generation. (C) 2017 Elsevier Ltd. All rights reserved.", "labels": [1, 12]}
{"id": "1370", "token": "The increase in installed capacity of renewable energy sources (RES) has a positive effect on the development of smart grids and demand side management (DSM). The reason for this is the intermittent nature of renewable energy, which is directly related to the problem of balancing the production and consumption of power within the power system. By using the DSM, the power consumption in the system comprising RES can be easier adjusted to the power production. The paper proposes an improved concept of DSM through the spatial and temporal DSM. The optimal spatial and temporal DSM aims at determining the power diagram of each individual load bus in order to achieve the optimal state in the whole system. The optimal state of the system can be quantified through the minimum daily energy losses or minimum daily operating costs. A mathematical definition of the optimal spatial and temporal DSM problem is presented as well as the algorithm for its solution. The proposed methodology has been tested by three test networks. The results confirm the overall system performance improvements that include: reduction of energy losses in the system, reduction of the operating costs and the increase of the voltage quality within the system. (C) 2017 Elsevier Ltd. All rights reserved.", "labels": [1, 12]}
{"id": "1475", "token": "The main focus of this paper is to select an economically suitable sustainable standalone power supply system for a remote off-grid town in Western Australia. Existing power systems of such remote towns in Australia have adverse environmental impacts and contribute to global warming due to the utilization of fossil fuels, especially diesel and gas. The possible electricity supply systems for such towns can vary from a diesel/gas generator towards a hybrid system composed of a generator, Wind turbine, photovoltaic system, and battery energy storage. In order to limit the cost of the system and to propose the most economically feasible solution, various combinations of supply systems are considered. These systems are analyzed in this paper by the help of HOMER software to determine the optimal architecture and the control strategy of the supply system. This study has used real demand data of the town, as well as the prices of different electrical components in the Australian market. The scenario which yields the minimum cost of energy is defined and suggested. Also, a decision-making based technique is proposed to help the local electricity utility in finding the suitable solution in the case of budget limits on the investment and annual operation and maintenance. Another aim of this analysis is to investigate and illustrate the impact of a small annual load growth on the size of the selected components for the selected power system, as well as the total net present cost and the cost of electricity. A sensitivity analysis is also performed to analyze the impact of uncertainties of some of the parameters in the outcome of the study to obtain the optimized cost of the selected system. (C) 2017 Elsevier Ltd. All rights reserved.", "labels": [1, 12]}
{"id": "1529", "token": "Outdoor industrial-scale microalgae cultivation is limited by several factors, among which a low efficiency of overall light energy conversion plays a key role, mainly due to photosaturation and photo inhibition under high irradiations. This work aims at improving the overall photoconversion efficiency in a microalgal production photobioreactor (PBRs), by exploiting an advanced photovoltaic (PV) technology. A semi-transparent dye sensitized solar cells module (DSC) is placed on the irradiated surface, thus absorbing part of the incident light to produce electricity, while transmitted photons are used by algal cells for photosynthesis. Experiments are carried out in a continuous laboratory scale flat-panel PBR, at different constant light intensities and under a day-night irradiation regime, to ascertain the performances of this combined PV-PBR system in terms of biomass productivity and overall photoconversion efficiency, compared to traditional transparent PBRs. The results obtained show that the configuration proposed, combining biomass production with innovative photovoltaics technology, could be a valuable way to improve light energy utilization and efficiency in microalgal production. (C) 2017 Elsevier Ltd. All rights reserved.", "labels": [1, 12]}
{"id": "1647", "token": "This study employed homogeneous and heterogeneous panel methods to examine the relationship between renewable and non-renewable electricity consumption and economic development in three transition economies in the Baltic region, namely, Estonia, Latvia and Lithuania, for the period of 1992-2011. The study put forward four hypotheses to examine the renewable electricity-development nexus. The findings indicated that there existed a unidirectional causality from the economic development to renewable electricity consumption. Thus, the results obtained from the statistical analyses have provided empirical evidence in support of the conservation hypothesis that postulates that economic development causes the expansion of renewable electricity consumption, but not vice versa.", "labels": [1, 12]}
{"id": "1822", "token": "This paper introduces a panel threshold model to empirically estimate the main drivers of electricity performance. The empirical analysis is based on a panel data set including 30 OECD countries over the period 1975-2013. We argue that effective regulatory reforms have positive interaction with the electricity generated leading to a higher capacity utilization and an increase in the level of labor productivity of the sector. The threshold analysis suggests that for already economically liberalised countries the level of economic freedom does not affect electricity generation and subsequently the level of electricity performance. Finally, the results do not drastically change when the Renewable Energy Sources (RES) are taken into account.", "labels": [1, 12]}
{"id": "1907", "token": "The rapid development of energy, electricity, and transportation industries has created a market for steel pipes; however, buried steel pipelines near high-voltage transmission lines and electrified railways often experience alternating current (AC) corrosion at the damaged coating of pipelines; such phenomenon is mostly due to the resistance between the capacitance and inductance coupling, especially for long-distance pipelines in parallel operation. AC corrosion can cause pipeline corrosion perforation and stress corrosion cracking (SCC) in some cases, which has been a vital threat to the pipeline safety. In this work, the influence of AC on corrosion behavior of X80 pipeline steel was investigated in NS4 near-neutral solution by data acquisition technique, electrochemical test, immersion tests and surface analysis techniques. Results show that with the increasing of AC density, corrosion morphology changed from uniform corrosion to localized corrosion with many pits. Under the full AC interference, X80 steel occurred cathodic and anodic polarization which resulted in iron dissolution and hydrogen precipitation. The negative half wave AC would lead to hydrogen evolution and hydrogen induced anodic dissolution, the pits in X80 steel surface present sharp. However, under disturbance of positive half-wave AC, only anodic dissolution occurred and the pitting appeared spill shape and smoothly. Under various AC waveform interference, the corrosion products of X80 steel surface were different. Under full AC wave and positive half-wave interference, the corrosion products were loose, had have no alpha-FeOOH and occurred cracks; however, under negative half-wave AC interference, the corrosion products were denser and contained alpha-FeOOH which has protective effect on substrates.", "labels": [1, 12]}
{"id": "2003", "token": "The optimal use of biomass from a global warming mitigation perspective depends upon numerous factors, including competition for land and other constraints. The goal of this study is identifying optimal uses of domestic biomass resources for the case of Denmark, with the objectives of minimizing global warming contribution and fossil energy resource consumption. For this purpose, consequential life cycle assessment of the different options for biomass was performed. Optimal solutions were identified, given specific national environmental targets, using linear programming. Results highlighted that utilizing the energy potential of manure and straw represents the primary opportunity for further global warming mitigation. For this purpose, co-digestion (for manure) and combustion with heat-and-power production (for straw) appear as the most promising technologies. The utilization of biomass (or biogas) for electricity/heat is generally preferred, as long as coal/oil is still used within the energy system. Yet, to fulfill environmental targets for renewable energy in the transport sector, the diversion of a significant share of biogas (and/or other biofuels) from these more beneficial uses is necessary. To completely phase out coal/oil, additional biomass (to current domestic resources) must be included, either through domestic energy crops cultivation or biomass/biofuel import; alternatively, natural gas could be used. (C) 2017 Elsevier Ltd. All rights reserved.", "labels": [1, 12]}
{"id": "2046", "token": "This paper pursues an inquiry into the relationship between ethnicity and development in the largest authoritarian country in the contemporary world, the People's Republic of China. It engages the theoretical literature on ethnic diversity and development in general, but also pays special attention to political economy logics unique to authoritarian systems. Focusing on the western part of China over a decade since the launch of China's Western Development Program (xibu da kaifa) in 2000, this paper utilizes the data from two censuses (2000 and 2010) together with nighttime streetlight imagery data to analyze the overall relationship between ethnicity and development provision. It also analyzes changes in such a relationship during this period. The paper finds that ethnic minority concentration negatively correlates with economic development in both the years 2000 and 2010 across the western provinces. It also finds that counties in non-autonomous provinces, which are historically more integrated with the rest of China than autonomous provinces, have a positive and systematic correlation between changes in ethnic minority concentration and changes in development during the 10-year period. The counties in autonomous provinces, on the other hand, show the opposite trend. Using three case studies of Tibet, Inner Mongolia, and Xinjiang, the paper concludes that although there is in general a tendency for ethnic minority concentrated areas to be less developed, ultimately which groups prosper more or less depends upon specific economic development and which political control logics the Chinese state implements. (C) 2017 The Authors. Published by Elsevier Ltd.", "labels": [1, 12]}
{"id": "2193", "token": "Here we present the technical and economical performances of a small scale trigeneration power plant based on solid oxide fuel cells and designed for a small residential cluster (i.e. 10 apartments). The energy system features a natural gas solid oxide fuel cell, a boiler, a refrigerator, and a thermal storage system. We compare different power plant configurations varying the size of the fuel cell and the refrigeration technology to satisfy the chilling demand (i.e. absorption or mechanical chiller). Given that the ability to meet the power demand is crucial in this kind of applications, the plant performances are assessed following an optimal control strategy, as a function of different energy demand profiles and electricity prices, and of rated and part load efficiencies of each energy converter. The optimization of the energy system operating strategy is performed through a graph theory-based methodology. Results are provided in terms of electrical and thermal efficiency, operating strategy, as well as economic saving, primary energy consumption reduction, and pay back period, considering different capital costs of the fuel cell. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [1, 12]}
{"id": "2223", "token": "In this study, a proton conducting solid oxide fuel cell (layered H+-SOFC) is prepared by introducing a La(2)NiO(4)perovskite oxide with a Ruddlesden-Popper structure as a catalyst layer onto a conventional Ni + BaZr(0.4)Ceo(0.4)Y(0.2)O(3-delta) (NiO + BZCY4) anode for in situ CO2 dry reforming of methane. The roles of the La2NiO4 catalyst layer on the reforming activity, coking tolerance, electrocatalytic activity and operational stability of the anodes are systematically studied. The La2NiO4 catalyst layer exhibits greater catalytic performance than the NiO + BZCY4 anode during the CO2 dry reforming of methane. An outstanding coking resistance capability is also demonstrated. The layered H+-SOFC consumes H-2 produced in situ at the anode and delivers a much higher power output than the conventional cell with the NiO + BZCY4 anode. The improved coking resistance of the layered H+-SOFC results in a steady output voltage of similar to 0.6 V under a constant current density of 200 mA cm(-2). In summary, the H+-SOFC with La2NiO4 perovskite oxide is a potential energy conversion device for CO2 conversion and utilization with cogeneration of electricity and syngas. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [1, 12]}
{"id": "2414", "token": "Cloud computing has recently emerged as a dominant Internet service computing model due to its payas-you-go and elastic service features. Cloud computing systems are usually composed of distributed datacenters, which leverage virtualization technology to provide a scalable and reliable service. Optical networks are recognized as promising next-generation core networks for connecting these distributed datacenters due to their characteristics such as high bandwidth provisioning, low latency, low bit error rate, etc. However, concern about the ever-increasing energy consumption of cloud computing systems together with core networks has been raised due to high electricity bills as well as environmental pollution. In this paper, we study the Energy-aware Provisioning in Optical Cloud Networks (EPOCN) problem for both dynamic and static cases. When traffic requests arrive in an online fashion, we propose a polynomial-time energy-aware routing algorithm to solve the dynamic EPOCN problem. Simulations show that our energy-aware routing algorithm brings more energy savings in comparison to a shortest path-based routing algorithm and a traffic grooming algorithm. On the other hand, we show that the EPOCN problem in the static case (the traffic matrix is known in advance) is NP-hard. We further divide this problem into (1) the Energy-Aware Routing (EAR) problem in optical networks and (2) the Energy-efficient Server and Switch Allocation (ESSA) problem in datacenter networks. Considering these two (sub)problems are still NP-hard, we present an exact Integer Linear Program (ILP) and a heuristic to solve each problem. We also conduct simulations to compare the proposed ILPs and heuristics in terms of energy consumption and running time. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [1, 12]}
{"id": "2485", "token": "The importance of the performance of frequency regulation has already been acknowledged by regulators and Independent System Operators (ISOs). A performance-based frequency regulation market model considering both regulation capacity and regulation mileage constraints is proposed in this paper. In the proposed market, high-performance regulation resources have higher priorities to be selected in the market. Market clearing prices are derived with Lagrange relaxation. The analysis of the components of market clearing prices accurately indicates the correlation between regulation capacity and regulation mileage. To accommodate the proposed regulation market design, AGC allocation algorithm is adjusted based on the market clearing results. The clearing procedure of the market model is demonstrated on an illustrative case. The proposed market design is tested and verified with market simulations and system dynamic simulations. Simulation results are discussed and compared to show the effectiveness of the proposed market design. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [1, 12]}
{"id": "2530", "token": "Gasification is a promising alternative for polymeric waste valorization when mechanical recycling is unfeasible on account of its heterogeneity or partial contamination, or simply when it yields a product of lower quality than what the market requires. Apart from its application for electricity generation, the waste-derived syngas shows a great potential for chemical waste recycling for the synthesis of hydrogen, methane, natural gas or methanol. In spite of the effort devoted so far to the experimental demonstration of these processes to enable this technology to access commercial stage, it is still necessary to develop detailed models of the process that allow a precise prediction of the resulting syngas composition, as well as tar formation and global efficiency of the process. This research work presents the development of a polyolefin gasification model for fluidized bed reactors. The model details the behaviour of primary pyrolysis and homogeneous reactions of oxidation, steam reforming, aromatization and thermal cracking. To accomplish this, it adopts new modelling strategies for the definition of primary tar species in order to reflect their twofold nature (aliphatic and aromatic), as well as to describe kinetics and stoichiometry involved in thermal cracking processes of tar species. The model is able to successfully predict the generation, volume composition and heating value of the syngas, final tar generation and global efficiency of the process. (C) 2017 Elsevier Ltd. All rights reserved.", "labels": [1, 12]}
{"id": "2665", "token": "As China's largest CO2 emission source, power sector has a large scale of power exchange, which results in the issue of interprovincial CO2 emissions transfer embodied in power transmission. Based on interprovincial detailed power exchange data, a bottom-up method which takes into account the fuel mix of exported electricity is developed to calculate provincial CO2 emissions embodied in power transmission. Provincial CO2 emissions from power sector associated in consumption perspective in 2007, 2010 and 2012 are analyzed and compared with those in production based perspective. The calculation shows that total CO2 emissions embodied in interprovincial power exchange is 532 Tg in 2012, accounting for 14% of total emissions from power sector. The embodied emissions have risen by 94% between 2007 and 2012. The general transfer pathway of embodied CO2 emissions is from eastern China to western China with long-range power transmission. The disparities between consumption and production based CO2 emissions are significant in some provinces. The production based CO2 emissions from power sector of Inner Mongolia are 195 Tg higher than those of the consumption based, while the consumption based emissions of Beijing are 484% larger than those of the production based. This study also reveals an increasing trend of CO2 emissions from both production and consumption principles for most provinces over the period 2007-2012. (C) 2016 Elsevier B.V. All rights reserved.", "labels": [1, 12]}
{"id": "2838", "token": "With the increasing installed capacity of wind power and the interdependencies among multiple energy sectors, optimal operation of integrated energy systems (IES) with combined cooling, heating and power (CCHP) is becoming more important. This paper proposes an optimal dispatch strategy for IES with CCHP and wind power. Natural gas system is modeled and its security constraints are integrated into the optimal dispatch model. The gas shift factor (GSF(gas)) matrix for natural gas system is derived to quantify the impact of gas supply and load at each node on the gas flow through the pipelines so that the pipeline flow equation is linearized. The objective function of the optimization model is to minimize the total operation cost of IES. Then the model is transformed into mixed integer linear programming (MILP) formulation to improve the computation efficiency. Numerical case studies conducted demonstrate the lower operation cost of the proposed model facilitating wind power integration. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [1, 12]}
{"id": "2922", "token": "Green energy has gained significant research attention across the globe due to its ability to reduce environmental damage. However, for complete acceptance of green energy, only government regulations are not enough; the willingness to use green energy and contribute to the wellbeing of the environment should spring from within consumers. Such willingness may be developed by enhancing consumers' perceived value of green energy. However, in order to do so, it is necessary to assess existing levels of consumers' perceived value towards green energy. The present study develops a multidimensional green perceived value scale to measure existing levels of consumers' perceived value. The scale considers green perceived value as a multidimensional second order construct comprising functional value, social value, conditional value and emotional value dimensions. Such an attempt has not been made before which highlights the originality value of the present study. The scale can be used to assess consumers' perception towards green energy. Such information would help in formulating strategies that encourage consumers to voluntarily adopt green energy. The study also reveals that it is not only the financial aspects that lead consumers to decide on adoption of green energy; consumers are also driven by emotional and social considerations. Thus, policy makers could formulate pro-green energy programmes and mass messages that appeal to consumers' sense of responsibility to voluntarily adopt green energy without having to rely on financial incentives. Researchers could examine the considered dimensions of the scale further with respect to other constructs related to consumer behaviour. (C) 2017 Elsevier Ltd. All rights reserved.", "labels": [1, 12]}
{"id": "3063", "token": "In order to optimize energy production in MFCs, a better understanding of anodic communities is essential. Our objective was to determine the taxonomic structure of the bacterial communities present at the surface of the anode during the formation and development of electro-active biofihns in MFCs inoculated with fresh primary clarifier overflow. Quantitative microbial community dynamics were evaluated as a function of time and electrical performance using 16S rRNA gene-based phylogenetic microarrays and flow cytometry. Results show that the bacterial community stabilized partially but not completely when voltage output was stable. Geobacter appeared to be the predominant genus, whose growth was associated with voltage, while some other genus still developed or declined after the voltage stabilization. Flow cytometry revealed that some genus showing a decreasing proportional fluorescence intensity over time were still actively respiring bacteria, and thus, active albeit minor members of the biofilm. Finally, this study shows that anodic biofilm selection and maturation is still occurring after more than 20 days of operation and over ten days after voltage is stabilized.", "labels": [1, 12]}
{"id": "3196", "token": "An echo state network (ESN)-based Q-learning method is developed for optimal energy management of an office, where the solar energy is introduced as the renewable source, and a battery is installed with a control unit. The energy consumption in the office, also considered as the energy demand, is separated into those from sockets, lights and air-conditioners. First, ESNs, well known for their excellent modelling performance for time series, are employed to model the time series of the real-time electricity rate, renewable energy and energy demand as periodic functions. Second, given the periodic models of the electricity rate, renewable energy and energy demand, an ESN-based Q-learning method with the Q-function approximated by an ESN is developed and implemented to determine the optimal charging/discharging/idle strategies for the battery in the office, so that the total cost of electricity from the grid can be reduced. Finally, numerical analysis is conducted to illustrate the performance of the developed method.", "labels": [1, 12]}
{"id": "3283", "token": "The current practice of discrete-time electricity pricing starts to fall short in providing an accurate economic signal reflecting the continuous-time variations of load and generation schedule in power systems. This paper introduces the fundamental mathematical theory of continuous-time marginal electricity pricing. We first formulate the continuous-time unit commitment problem as a constrained variational problem, and subsequently define the continuous-time economic dispatch (ED) problem where the binary commitment variables are fixed to their optimal values. We then prove that the continuous-time marginal electricity price equals to the Lagrange multiplier of the variational power balance constraint in the continuous-time ED problem. The proposed continuous-time marginal price is not only dependent to the incremental generation cost rate, but also to the incremental ramping cost rate of the units, thus embedding the ramping costs in calculation of the marginal electricity price. The numerical results demonstrate that the continuous-time marginal price manifests the behavior of the constantly varying load and generation schedule in power systems.", "labels": [1, 12]}
{"id": "3509", "token": "In this paper, a geothermal based multi-generation energy system, including organic Rankine cycle, domestic water heater, absorption refrigeration cycle and proton exchange membrane electrolyzer, is developed to generate electricity, heating, cooling and hydrogen. For this purpose, energetic, exergetic and exergoeconomic analysis are undertaken upon proposed system. Also, the effects of some important variables, i.e. geothermal water temperature, turbine inlet temperature and pressure, generator temperature, geothermal water mass flow rate and electrolyzer current density on the several parameters such as energy and exergy efficiencies of the proposed system, heating and cooling load, net electrical output power, hydrogen production, unit cost of each system products and total unit cost of the products are investigated. For specified conditions, the results show that energy and exergy efficiencies of the proposed multigeneration system are calculated about 34.98% and 49.17%, respectively. The highest and lowest total unit cost of the products estimated approximately 23.18 and 22.73 $/GJ, respectively, by considering that geothermal water temperature increases from 185 degrees C to 215 degrees C. (C) 2017 Published by Elsevier Ltd.", "labels": [1, 12]}
{"id": "25", "token": "Background: Amyotrophic lateral sclerosis (ALS) is a rapidly progressive disease of the nervous system involving both upper and lower motor neurons. The patterns of structural and metabolic brain alterations are still unclear. Several studies using anatomical MRI yielded a number of discrepancies in their results, and a few PET studies investigated the effect of ALS on cerebral glucose metabolism. The aim of this study was threefold: to highlight the patterns of grey matter (GM) atrophy, hypometabolism and hypermetabolism in patients with ALS, then to understand the neurobehavioral significance of hypermetabolism and, finally, to investigate the regional differences between the morphologic and functional changes in ALS patients, using a specially designed voxel-based method. Thirty-seven patients with ALS and 37 age-and sex-matched healthy individuals underwent both structural MRI and (18)[F]-fluorodeoxyglucose (FDG) PET examinations. PET data were corrected for partial volume effects. Structural and metabolic abnormalities were examined in ALS patients compared with control subjects using two-sample t tests in statistical parametric mapping (SPM). Then, we extracted the metabolic values of clusters presenting hypermetabolism to correlate with selected cognitive scores. Finally, GM atrophy and hypometabolism patterns were directly compared with a one-paired t test in SPM. Results: We found GM atrophy as well as hypometabolism in motor and extra motor regions and hypermetabolism in medial temporal lobe and cerebellum. We observed negative correlations between the metabolism of the right and left parahippocampal gyri and episodic memory and between the metabolism of right temporal pole and cognitive theory of mind. GM atrophy predominated in the temporal pole, left hippocampus and right thalamus, while hypometabolism predominated in a single cluster in the left frontal superior medial cortex. Conclusions: Our findings provide direct evidence of regional variations in the hierarchy and relationships between GM atrophy and hypometabolism in ALS. Moreover, the (18)FDG-PET investigation suggests that cerebral hypermetabolism is deleterious to cognitive function in ALS.", "labels": [2, 16]}
{"id": "147", "token": "Humans typically exhibit a tendency to follow the gaze of conspecifics, a social attention behaviour known as gaze cueing. Here, we addressed whether episodically learned social knowledge about the behaviours performed by the individual bearing the gaze can influence this phenomenon. In a learning phase, different faces were systematically associated with either positive or negative behaviours. The same faces were then used as stimuli in a gaze-cueing task. The results showed that faces associated with antisocial norm-violating behaviours triggered stronger gaze-cueing effects as compared to faces associated with sociable behaviours. Importantly, this was especially evident for participants who perceived the presented normviolating behaviours as far more negative as compared to positive behaviours. These findings suggest that reflexive attentional responses can be affected by our appraisal of the valence of the behaviours of individuals around us.", "labels": [2, 16]}
{"id": "246", "token": "Objective: There is considerable evidence that patients with schizophrenia have neurocognitive and social-cognitive deficits. It is unclear how such deficits in first-episode schizophrenia relate to current clinical symptoms. Method: Fifty-nine patients with first-episode schizophrenia (FES) were tested using the Danish version of NART (premorbid IQ), subtests from WAIS-III (current IQ), and global cognition using Brief Assessment of Cognition in Schizophrena (BACS), a neurocognitive test battery. Social perception was tested using film clips of everyday interactions (TASIT). Theory of mind (ToM) was tested using silent animations (Animated Triangles Task). The FES subjects had been experiencing psychotic symptoms for several years (mean duration 9.5 years 95% confidence interval (CI [7.6; 11.3]). The FES patients were divided into clinical subgroups based on their level of positive and negative symptoms (using SANS and SAPS). Healthy controls were matched to the patients. Results: High levels of negative symptoms were associated with low estimated functional IQ and poor neurocognition and social cognition. All SANS subscales, but Avolition-Apathy, had significant negative impact on social cognition. The effects of positive symptoms were complex. High levels of delusions were associated with higher premorbid IQ. In the presence of high levels of negative symptoms, high levels of positive symptoms were associated with the most comprehensive deficits in social perception, while, in the absence of negative symptoms, high levels of positive symptoms were not associated with such deficits. Conclusion: The results suggest that social-cognitive training will need to take account of the above mentioned effects of symptoms.", "labels": [2, 16]}
{"id": "422", "token": "Introduction: Being able to understand other people's emotions and intentions is crucial for social interactions and well-being. Deficits in theory of mind (ToM) functioning hamper this ability and have been observed in depression and other neuropsychiatric disorders. However, results of previous research in depression have been inconclusive, possibly due to the presence of comorbid disorders and the disregarding of other modulating factors. Methods: Thirty-eight patients with a major depressive disorder (MDD) and forty healthy matched controls were assessed with a ToM task using animated triangles. Results were correlated with attachment styles, empathy abilities and neurocognitive performance. Results: Our findings show that 1) healthy female controls performed significantly stronger on the ToM task than female MDD patients, 2) these performance differences were driven by attachment styles and 3) depression severity did not impact task performance. Limitations: The pharmacological treatment of the majority of patients might limit the generalizability of this study. Discussion: Results indicate a gender-specific impact of attachment styles on ToM performance. Future studies should investigate whether impairments in social cognitive tasks pose a risk factor for depression and/or interactional styles or vice versa. Moreover, with regard to remediation programs gender-specific needs should be taken into account.", "labels": [2, 16]}
{"id": "569", "token": "Understanding complex problems such as climate change is difficult for most nonaEuroscientists, with serious implications for decision making and policy support. Scientists generate complex computational models of climate systems to describe and understand those systems and to predict the future states of the systems. Non-scientists generate mental models of climate systems, perhaps with the same aims and perhaps with other aims too. Often, the predictions of computational models and of mental models do not correspond with important implications for human decision making, policy support, and behaviour change. Recent research has suggested non-scientists' poor appreciation of the simple foundations of system dynamics is at the root of the lack of correspondence between computational and mental models. We report here a study that uses a simple computational model to 'run' mental models to assess whether a system will evolve according to our aspirations when considering policy choices. We provide novel evidence of a dual-process model: how we believe the system works today is a function of ideology and worldviews; how we believe the system will look in the future is related to other, more general, expectations about the future. The mismatch between these different aspects of cognition may prevent establishing a coherent link between a mental model's assumptions and consequences, between the present and the future, thus potentially limiting decision making, policy support, and other behaviour changes.", "labels": [2, 16]}
{"id": "665", "token": "One of teenagers' key developmental tasks is to engage in new and meaningful relationships with peers and adults outside the family context. Attachment-derived expectations about the self and others in terms of internal attachment working models have the potential to shape such social reorientation processes critically and thereby influence adolescents' social-emotional development and social integration. Because the neural underpinnings of this developmental task remain largely unknown, we sought to investigate them by functional magnetic resonance imaging. We asked n = 44 adolescents (ages 12.01-18.84 years) to evaluate positive and negative adjectives regarding either themselves or a close other during an adapted version of the well-established self-other trait-evaluation task. As measures of attachment, we obtained scores reflecting participants' positive versus negative attachment-derived self- and other-models by means of the Relationship Questionnaire. We controlled for possible confounding factors by also obtaining scores reflecting internalizing/externalizing problems, schizotypy, and borderline symptomatology. Our results revealed that participants with a more negative attachment-derived self-model showed increased brain activity during positive and negative adjective evaluation regarding the self, but decreased brain activity during negative adjective evaluation regarding a close other, in bilateral amygdala/parahippocampus, bilateral anterior temporal pole/anterior superior temporal gyrus, and left dorsolateral prefrontal cortex. These findings suggest that a low positivity of the self-concept characteristic for the attachment anxiety dimension may influence neural information processing, but in opposite directions when it comes to self- versus (close) other-representations. We discuss our results in the framework of attachment theory and regarding their implications especially for adolescent social-emotional development and social integration.", "labels": [2, 16]}
{"id": "1005", "token": "Research has tried to identify risk factors that increase the likelihood of difficulties with externalizing behavior. The relations between individual or environmental factors and externalizing behavior have been especially documented. Child-oriented and parent-oriented interventions have been designed in order to decrease externalizing behavior in preschoolers. To date, however, research has largely been compartmentalized. It is therefore not known whether child-oriented or parent-oriented intervention is more effective in reducing externalizing behavior. The aim of the current study was to answer this question by comparing two 8-week child with two 8-week parent-oriented group programs sharing a common experimental design. This was done in a pseudo-randomized trial conducted with 73 3-6-year-old children displaying clinically relevant levels of externalizing behavior who were assigned to one of the four interventions and 20 control participants who were allocated to a waiting list. The results indicate that the four programs focusing on a specific target variable, i.e., social cognition, inhibition, parental self-efficacy beliefs, or parental verbal responsiveness, are all effective in reducing externalizing behavior among preschoolers. Their effectiveness was moderated neither by their orientation toward the child or the parent nor by their content, suggesting that several effective solutions exist to improve behavioral adaptation in preschoolers. A second important highlight of this study is that, thanks to comparable effect sizes, brief focused programs appear to be a reasonable alternative to long multimodal programs, and may be more cost-effective for children and their families.", "labels": [2, 16]}
{"id": "1180", "token": "Social cognitive deficits are common in neuropsychiatric disorders. Given the proximity of social cognition (SC) to everyday functioning, many intervention studies (including targeted, comprehensive, and broad-based approaches) have focussed on SC. The aim of this paper was to quantitatively meta-analyse the efficacy of SC interventions in adult neuropsychiatric patients. Databases Pubmed, PsycINFO, Web of Knowledge, and Embase were searched for controlled SC intervention studies published between 01-01-2003 and 01-01-2016. Forty-one studies, comprising 1,508 patients with schizophrenia, autism spectrum disorders, or acquired brain injury were included. Outcome measures evaluated emotion perception (EP), social perception (SP), Theory of Mind (ToM), and social functioning (SF). The meta-analyses showed that interventions were effective in improving SC (Cohen's d = .71). Interventions targeting one specific SC function were found to be most effective (d = .89), followed by broad-based interventions, targeting non-SC domains in addition to SC (d = .65), and comprehensive interventions, that target multiple SC processes (d = .61). Targeted interventions were especially effective in improving EP and ToM. Comprehensive interventions were able to ameliorate EP, ToM, and SF. Broad-based interventions were especially effective in improving SF, but also showed effects on EP and ToM.", "labels": [2, 16]}
{"id": "1262", "token": "Recent research has demonstrated impairments in social cognition associated with multiple sclerosis (MS). The present work asks whether these impairments are associated with atypical moral judgment. Specifically, we assessed whether MS patients are able to integrate information about intentions and outcomes for moral judgment (i.e., appropriateness and punishment judgments) in the case of third-party acts. We found a complex pattern of moral judgments in MS patients: although their moral judgments were comparable to controls' for specific types of acts (e.g., accidental or intentional harms), they nevertheless judged behaviors to be less appropriate and endorsed more severe punishment across the board, and they were also more likely to report that others' responses would be congruent with theirs. Further analyses suggested that elevated levels of externally oriented cognition in MS (due to co-occurring alexithymia) explain these effects. Additionally, we found that the distinction between appropriateness and punishment judgments, whereby harmful outcomes influence punishment judgments to a greater extent than appropriateness judgments, was preserved in MS despite the observed disruptions in the affective and motivational components of empathy. The current results inform the two-process model for intent-based moral judgments as well as possible strategies for improving the quality of life in MS patients.", "labels": [2, 16]}
{"id": "1424", "token": "Analogical reasoning is an important mechanism for social cognition in typically developing children, and recent evidence suggests that some forms of analogical reasoning may be preserved in autism spectrum disorder. An unanswered question is whether children with autism spectrum disorder can apply analogical reasoning to social information. In all, 92 children with autism spectrum disorder completed a social content analogical reasoning task presented via photographs of real-world social interactions. Autism spectrum disorder participants exhibited performance that was well above chance and was not significantly worse than age- and intelligence quotient-matched typically developing children. Investigating the relationship of social content analogical reasoning performance to age in this cross-sectional dataset indicated similar developmental trajectories in the autism spectrum disorder and typically developing children groups. These findings provide new support for intact analogical reasoning in autism spectrum disorder and have theoretical implications for analogy as a metacognitive skill that may be at least partially dissociable from general deficits in processing social content. As an initial study of social analogical reasoning in children with autism spectrum disorder, this study focused on a basic research question with limited ecological validity. Evidence that children with autism spectrum disorder can apply analogical reasoning ability to social content may have long-range applied implications for exploring how this capacity might be channeled to improve social cognition in daily life.", "labels": [2, 16]}
{"id": "1503", "token": "Purpose: A subgroup of individuals with anorexia nervosa (AN) displays social difficulties; however, it is not clear if individuals with comorbid autism spectrum disorders account for these difficulties. Methods: We compared social function using the Autism Diagnostic Observation Schedule in 43 young females with first-episode AN who did not have comorbid autism spectrum disorder, 28 individuals recovered from adolescent-onset AN, and 41 healthy comparison individuals (age range 14-22 years). We measured adaptive behavior with the Vineland-II parent questionnaire, and aspects of social cognition with psychological tests, such as the Reading-the-Mind-in-the-Eyes test, Profile of Nonverbal Sensitivity short version, The Awareness of Social Inference Test, Animated Triangles, and the CANTAB Affective Go/No-go task. Results: Participants with first-episode AN and those recovered from AN displayed difficulties in social function, which were not associated with body mass index or other state factors of the disorder in those with first-episode AN. Mood problems and anxiety were not associated with these difficulties. Parents rated participants with first-episode AN lower than recovered and control participants on the Socialization Domain of Vineland-II. Finally, only participants recovered from AN demonstrated deficits in specific domains of social cognition: perceiving nonverbal bodily gesture and vocal prosody. Conclusions: Young females with first-episode AN and those recovered from AN displayed impairments in social function, which may represent more stable traits of the disorder. Only participants recovered from AN demonstrated deficits in social cognition. (C) 2016 Society for Adolescent Health and Medicine. All rights reserved.", "labels": [2, 16]}
{"id": "1537", "token": "We outline an evolutionary-embodied-epistemological (EEE) account of intellectual arrogance (IA), proposing that people psychologically experience their important beliefs as valued possessions - mental materialism - that they must fight to keep - ideological territoriality - thereby disposing them toward IA. Nonetheless, IA should still vary, being higher among people taking a hostile and domineering epistemic stance (rejecting reality, resisting evidence) than among those taking an open and deferential one (embracing reality, respecting evidence). Such variations can be predicted from people's standing on the communion-agency circumplex at multiple levels of analysis (i.e. from their social inclusion and status; dispositional warmth and competence; and behavioral amiability and assertiveness). Using pre-validated indices of mental materialism and ideological territoriality, and an argument evaluation task permitting the quantification of rational objectivity and egotistical bias, we obtained consistent correlational evidence that, as hypothesized, IA is the highest when agency is high and communion low, validating the EEE account.", "labels": [2, 16]}
{"id": "1639", "token": "Psychiatric symptoms in patients with frontotemporal dementia (FTD) are highly prevalent and may complicate clinical management of these patients. Purpose of the present article is to present and discuss available data about the pharmacological treatment of psychiatric symptoms in patients with FTD. A research in the main database sources has been conducted to obtain an overview of the pharmacological management of psychiatric symptoms in patients with FTD. The search strategy included the following termsFTD and psychiatry, FTD and behavioural disturbances, and FTD and treatment. Pathophysiology of psychiatric symptoms in FTD is different from other types of dementia. Although drugs for Alzheimer disease appear to be ineffective for the treatment of psychiatric symptoms of FTD, preliminary evidence supports a possible usefulness of serotonergic antidepressants for these patients. Data are too scanty to draw definitive conclusions, but antidepressant treatment, particularly with serotonergic compounds, may improve psychiatric symptoms in patients with FTD. Large observational studies are needed to confirm this preliminary evidence, and a lot of effort and collaboration between neurologists and psychiatrists will be definitely crucial for future research of effective treatments for FTD.", "labels": [2, 16]}
{"id": "1750", "token": "People who are high in victim-sensitivity a personality trait characterized by a strong fear of being exploited by others are more likely to attend to social cues associated with untrustworthiness rather than to cues associated with trustworthiness compared with people who are low in victim-sensitivity. But how do these people react when an initial expectation regarding a target's trustworthiness turns out to be false? Results from two studies show that victim-sensitive compared with victim-insensitive individuals show enhanced source memory and greater change in person perception for negatively labeled targets that violated rather than confirmed negative expectations (the trustworthy trickster). These findings are in line with recent theorizing on schema inconsistency and expectancy violation effects in social cognition and with research on the different facets of justice sensitivity in personality psychology.", "labels": [2, 16]}
{"id": "1803", "token": "Most intranasal oxytocin research to date has been carried out in men, but recent studies indicate that females' responses can differ substantially from males'. This randomized, double-blind, placebo-controlled study involved an all-female sample of 28 women not using hormonal contraception. Participants viewed animations of geometric shapes depicting either random movement or social interactions such as playing, chasing, or fighting. Probe questions asked whether any shapes were friends or not friends. Social videos were preceded by cues to attend to either social relationships or physical size changes. All subjects received intranasal placebo spray at scan 1. While the experimenter was not blinded to nasal spray contents at Scan 1, the participants were. Scan 2 followed a randomized, double-blind design. At scan 2, half received a second placebo dose while the other half received 24 III of intranasal oxytocin. We measured neural responses to these animations at baseline, as well as the change in neural activity induced by oxytocin. Oxytocin reduced activation in early visual cortex and dorsal-stream motion processing regions for the social >size contrast, indicating reduced activity related to social attention. Oxytocin also reduced endorsements that shapes were friends or not friends, and this significantly correlated with reduction in neural activation. Furthermore, participants who perceived fewer social relationships at baseline were more likely to show oxytocin-induced increases in a broad network of regions involved in social perception and social cognition, suggesting that lower social processing at baseline may predict more positive neural responses to oxytocin.", "labels": [2, 16]}
{"id": "1925", "token": "Objective This study aimed to evaluate the efficacy of the Functional Independence Measure to assess preoperative frailty for elderly patients undergoing surgical aortic valve replacement. Methods Eighty-five patients >65 years who survived elective isolated aortic valve replacement from January 2008 to October 2015 were included. The mean age at the operation was 78 +/- 6 years old (n = 28 males, n = 57 females). The patients were divided into two groups according to their status at discharge: impossible to discharge home or hospitalization for >30 days (compromised group, n = 8), or unaffected (unaffected group, n = 77). Preoperative frailty was evaluated with the Functional Independence Measure, which comprises 18 items divided into six domains: self-care, sphincter control, mobility, locomotion, communication, and social cognition. Results The preoperative total Functional Independence Measure score was significantly lower in the compromised group (79 +/- 32) than in the unaffected group (120 +/- 9, p < 0.01). The preoperative motor Functional Independence Measure score was significantly lower in the compromised group (45 +/- 24) than in the unaffected group (85 +/- 9, p = < 0.01). The duration of postoperative intubation, intensive care unit stay, and postoperative hospitalization were significantly longer in the compromised group than in the unaffected group (48 +/- 67 vs 16 +/- 12 h, p < 0.01; 6.7 +/- 5.3 vs 3.4 +/- 2.0 days, p < 0.01; 34 +/- 27 vs 23 +/- 11 days, p = 0.02, respectively). Conclusions The preoperative Functional Independence Measure is effective for assessing preoperative frailty in elderly patients undergoing aortic valve replacement in terms of predicting operative morbidity.", "labels": [2, 16]}
{"id": "2246", "token": "Theories of neuroaesthetics assume, that looking at traces of actions used in creating artwork (e.g. brush marks) is associated with a simulation of these actions in the observer's sensorimotor-cortex. The aim of the current study is to dissociate the activation of the sensorimotor-cortex by the observation of action traces from associated visual processes. Twenty-eight participants observed handmade graphics (acrylic paint on paper) of different complexity (line, triangle, shape of a house) and computer-generated counterparts. Central mu-activity, as an index of sensorimotor-cortex activity, and occipital alpha-activity, as an index of visual cortex activity were recorded in the 8-13 Hz EEG-band. In line with the hyp5hesis, mu-activity at electrode C4 is sensitive for the complexity of handmade (p = 0.001), but not computer-generated graphics (p >0.500). In contrast, occipital alpha-activity is sensitive for the complexity of both handmade and computer-generated graphics (p <0.001). Furthermore, the more empathic the participants rated themselves, the stronger mu-suppression was induced by handmade graphics compared to computer-generated graphics (electrode C4; r=0.612, p = 0.001). These results support the involvement of the sensorimotor-cortex in the recognition of action traces and strengthen evidence that individuals scoring high in emotional empathy feature a particularly responsive mirror neuron system. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [2, 16]}
{"id": "2366", "token": "Background. The experience of 'sensed presence' a feeling or sense that another entity, individual or being is present despite no clear sensory or perceptual evidence is known to occur in the general population, appears more frequently in religious or spiritual contexts, and seems to be prominent in certain psychiatric or neurological conditions and may reflect specific functions of social cognition or body-image representation systems in the brain. Previous research has relied on ad-hoc measures of the experience and no specific psychometric scale to measure the experience exists to date. Methods. Based on phenomenological description in the literature, we created the 16-item Sensed Presence Questionnaire (SenPQ). We recruited participants from (i) a general population sample, and; (ii) a sample including specific selection for religious affiliation to complete the SenPQ and additional measures of well-being, schizotypy, social anxiety, social imagery, and spiritual experience. We completed an analysis to test internal reliability, the ability of the SenPQ to distinguish between religious.and non-religious participants,. and.whether. the SenPQ was specifically related to positive schizotypical experiences and social imagery. A factor analysis was also conducted.. examine underlying latent variables. Results, The SenPQ was found to be reliable and valid, with religious participants significantly endorsing.more items than non-religious participants, and the scale showing a selective relationship with construct relevant measures. Principal components analysis indicates two potential underlying factors interpreted as reflecting 'benign' and 'malign' ensed presence experiences. Discussion. The SenPQ appears to be a reliable and valid measure of sensed presence experience although further validation in neurological and psychiatric conditions is warranted.", "labels": [2, 16]}
{"id": "2423", "token": "The current study examined the cultural factors (i.e., religious background, religious participation, parents' views of prayer, and parents' concepts of God) that contribute to children's differentiation between the capabilities of human minds and God's mind. Protestant Christian, Roman Catholic, Muslim, and Religiously Non-Affiliated parents and their preschool-aged children were interviewed (N=272). Children of Muslim parents differentiated the most between God's mind and human minds (i.e., human minds are fallible but God's is not), and children who had greater differentiation between God's and humans' minds had parents who had the least anthropomorphic conceptions of God. Additionally, there was a unique effect of being raised in a Religiously Non-Affiliated home on the degree of children's differentiation between God's and human minds after religious context factors had been accounted for; in other words, children of Religious Non-Affiliates differentiated between humans and God the least and their differentiation was unrelated to religious context factors. These findings delineate the ways in which religious context differences influence concepts of God from the earliest formation.", "labels": [2, 16]}
{"id": "2514", "token": "Expectation of reward can be shaped by the observation of actions and expressions of other people in one's environment. A person's apparent confidence in the likely reward of an action, for instance, makes qualities of their evidence, not observed directly, socially accessible. This strategy is computationally distinguished from associative learning methods that rely on direct observation, by its use of inference from indirect evidence. In twenty-three healthy human subjects, we isolated effects of first-hand experience, other people's choices, and the mediating effect of their confidence, on decision-making and neural correlates of value within ventromedial prefrontal cortex (vmPFC). Value derived from first-hand experience and other people's choices (regardless of confidence) were indiscriminately represented across vmPFC. However, value computed from agent choices weighted by their associated confidence was represented with specificity for ventromedial area 10. This pattern corresponds to shifts of connectivity and overlapping cognitive processes along a posterior-anterior vmPFC axis. Task behavior and self-reported self-reliance for decision-making in other social contexts correlated. The tendency to conform in other social contexts corresponded to increased activation in cortical regions previously shown to respond to social conflict in proportion to subsequent conformity (Campbell-Meiklejohn et al., 2010). The tendency to self-monitor predicted a selectively enhanced response to accordance with others in the right temporoparietal junction (rTPJ). The findings anatomically decompose vmPFC value representations according to computational requirements and provide biological insight into the social transmission of preference and reassurance gained from the confidence of others.", "labels": [2, 16]}
{"id": "2564", "token": "Autism Spectrum Disorder (ASD) has been associated with reduced orienting to social stimuli such as eyes, but the results are inconsistent. It is not known whether atypicalities in phasic alerting could play a role in putative altered social orienting in ASD. Here, we show that in unisensory (visual) trials, children with ASD are slower to orient to eyes (among distractors) than controls matched for age, sex, and nonverbal IQ. However, in another condition where a brief spatially nonpredictive sound was presented just before the visual targets, this group effect was reversed. Our results indicate that orienting to social versus nonsocial stimuli is differently modulated by phasic alerting mechanisms in young children with ASD. Autism Res2017, 10: 246-250. (c) 2016 The Authors Autism Research published by Wiley Periodicals, Inc. on behalf of International Society for Autism Research.", "labels": [2, 16]}
{"id": "2749", "token": "Background: Up to 60% of patients with bipolar disorder (BD) have a history of traumatic events, which is associated with greater episode severity, higher risk of comorbidity and higher relapse rates. Trauma-focused treatment strategies for BD are thus necessary but studies are currently scarce. The aim of this study is to examine whether Eye Movement Desensitization and Reprocessing (EMDR) therapy focusing on adherence, insight, de-idealisation of manic symptoms, prodromal symptoms and mood stabilization can reduce episode severity and relapse rates and increase cognitive performance and functioning in patients with BD. Methods/ design: This is a single-blind, randomized controlled, multicentre trial in which 82 patients with BD and a history of traumatic events will be recruited and randomly allocated to one of two treatment arms: EMDR therapy or supportive therapy. Patients in both groups will receive 20 psychotherapeutic sessions, 60 min each, during 6 months. The primary outcome is a reduction of affective episodes after 12 and 24 months in favour of the EMDR group. As secondary outcome we postulate a greater reduction in affective symptoms in the EMDR group (as measured by the Bipolar Depression Rating Scale, the Young Mania Rating Scale and the Clinical Global Impression Scale modified for BD), and a better performance in cognitive state, social cognition and functioning (as measured by the Screen for Cognitive Impairment in Psychiatry, The Mayer-SaloveyCaruso Emotional Intelligence Test and the Functioning Assessment Short Test, respectively). Traumatic events will be evaluated by The Holmes-Rahe Life Stress Inventory, the Clinician-administered PTSD Scale and the Impact of Event Scale. Discussion: The results of this study will provide evidence whether a specific EMDR protocol for patients with BD is effective in reducing affective episodes, affective symptoms and functional, cognitive and trauma", "labels": [2, 16]}
{"id": "2930", "token": "A significant correlation exists between violence and schizophrenia (SCZ). Recent studies matched sonic cognitive deficits like strong risk factors for violence with interesting applications in terms of treatment. Our objective was to conduct a systematic review of the effectiveness of cognitive remediation (CR) and social cognitive training (SCT) in the management of violent and aggressive behaviors in SCZ. Methods: The electronic databases Pubmed, Web of Science, Cochrane Library and ScienceDirect were searched in, using combinations of terms relating to SCZ, CR and violence. Studies were selected and data were extracted using a PRISMA statement. Inclusion criteria were adults with SCZ and a documented collection of disruptive and violent behaviors, for whom researchers had used a CR or SCT program. Results: Eleven studies were identified, two related to non-specific CR intervention and nine to codified CR or SCT programs. Results showed that these programs had a positive impact on the control and reduction of global aggressive attitudes and physical assaults. Therapeutic targets were social cognition and executive functions through the improvement of interpersonal relationships and impulsivity feature respectively. Effectiveness was proved at various stages of the illness, in different types of patients and units, with effects persisting for up to 12 months after interruption of CR. Conclusions are limited by some methodological restrictions. Conclusion: Although current evidences need to be completed with further randomized studies, CR and SCI. appear to be promising approaches in the management of violence in SCZ.", "labels": [2, 16]}
{"id": "3032", "token": "There is extensive evidence that perceived and internally planned actions have a common representational basis: action observation can induce an automatic tendency to imitate others. If perceived and executed action, however, are based on shared representations, the question arises how we can distinguish self-related and other-related representations. It has been suggested that the control of shared representations involves a neural network centered on the temporo-parietal junction (TPJ). However, the specific role of the TPJ in controlling shared representations is still not clear. In a conflict situation where participants have to execute action A while observing action B, the TPJ might either facilitate the relevant action A or inhibit the irrelevant action B (mirror response). In the present study, we used transcranial Direct Current Stimulation (tDCS) to condition neural activity in the right temporo-parietal junction (TPJ). We then analyzed the corticospinal output as indexed by motor-evoked potentials (MEPs) induced by single-pulse TMS (spTMS) of the left primary motor cortex (M1) during action observation in the context of a conflict task. Results showed that tDCS-mediated increased control did not entail the attenuation of the task-irrelevant response activation: the effect of motor mirroring was not suppressed or reduced. Rather, facilitating TPJ activity via anodal tDCS selectively enhanced the instructed motor plan (self-related representation). This outcome supports the idea that TPJ plays a critical role in detecting the mismatch between self-related and other-related representations and is at work to enhance task relevant representations.", "labels": [2, 16]}
{"id": "3089", "token": "This paper argues that mind-reading hypotheses (MRHs), of any kind, are not needed to best describe or best explain basic acts of social cognition. It considers the two most popular MRHs: one-ToM and two-ToM theories. These MRHs face competition in the form of complementary behaviour reading hypotheses (CBRHs). Following Buckner (Mind Lang 29: 566-589, 2014), it is argued that the best strategy for putting CBRHs out of play is to appeal to theoretical considerations about the psychosemantics of basic acts of social cognition. In particular, need-based accounts that satisfy a teleological criterion have the ability to put CBRHs out of play. Yet, against this backdrop, a new competitor for MRHs is revealed: mind minding hypothesis (MMHs). MMHs are capable of explaining all the known facts about basic forms of social cognition and they also satisfy the teleological criterion. In conclusion, some objections concerning the theoretical tenability of MMHs are addressed and prospects for further research are canvassed.", "labels": [2, 16]}
{"id": "3248", "token": "Communication between cortical regions is necessary for optimal cognitive processing. Functional relationships between cortical regions can be inferred through measurements of temporal synchrony in spontaneous activity patterns. These relationships can be further elaborated by surveying effects of cortical lesions upon inter-regional connectivity. Lesions to cortical hubs and heteromodal association regions are expected to induce distributed connectivity changes and higher-order cognitive deficits, yet their functional consequences remain relatively unexplored. Here, we used resting-state fMRI to investigate intrinsic functional connectivity (FC) and graph theoretical metrics in 12 patients with circumscribed lesions of the medial prefrontal cortex (mPFC) portion of the Default Network (DN), and compared these metrics with those observed in healthy matched comparison participants and a sample of 1139 healthy individuals. Despite significant mPFC destruction, patients did not demonstrate weakened intrinsic FC among undamaged DN nodes. Instead, network-specific changes were manifested as weaker negative correlations between the DN and attentional and somatomotor networks. These findings conflict with the DN being a homogenous system functionally anchored at mPFC. Rather, they implicate a role for mPFC in mediating cross-network functional interactions. More broadly, our data suggest that lesions to association cortical hubs might induce clinical deficits by disrupting communication between interacting large-scale systems.", "labels": [2, 16]}
{"id": "3287", "token": "Group ownership is ubiquitous-property is owned by countries, corporations, families, and clubs. However, people cannot understand group ownership by simply relying on their conceptions of ownership by individuals, as group ownership is subject to complexities that do not arise when property is individually owned. We report 6 experiments investigating whether children ages 3 to 6 (N = 540) understand group ownership. In Experiments 1 and 2 children were asked who different objects belong to, and they appropriately judged that certain objects are more likely to belong to a group than to individual people. Experiments 3 and 4 investigated whether children understand the limits of group ownership. Children saw vignettes where agents modified or depleted property. Children ages 3 and older understood that individual members of a group should not deplete group-owned property, and children ages 5 and 6 understood that individual members should not modify group-owned property. Finally, Experiments 5 and 6 investigated whether children understand the benefits of group ownership. Children ages 5 and 6 judged that it is more acceptable for a group member to take group property than for a nonmember to do this, and children ages 4 to 6 judged that group members can take more group resources than can nonmembers. Together, these results are informative about how children conceive of group ownership rights, and about children's conceptions of groups.", "labels": [2, 16]}
{"id": "3381", "token": "Autism spectrum disorders (ASDs) are known to be characterized by restricted and repetitive behaviors and interests and by impairments in social communication and interactions mainly including theory of mind (ToM) processes. The cerebellum has emerged as one of the brain regions affected by ASDs. As the cerebellum is known to influence cerebral cortex activity via cerebello-thalamo-cortical (CTC) circuits, it has been proposed that cerebello-cortical disconnection could in part underlie autistic symptoms. We used resting-state (RS) functional magnetic resonance imaging (fMRI) to investigate the potential RS connectivity changes between the cerebellar dentate nucleus (DN) and the CTC circuit targets, that may contribute to ASD pathophysiology. When comparing ASD patients to controls, we found decreased connectivity between the left DN and cerebral regions known to be components of the ToM network and the default mode network, implicated in specific aspects of mentalizing, social cognition processing, and higher order emotional processes. Further, a pattern of overconnectivity was also detected between the left DN and the supramodal cerebellar lobules associated with the default mode network. The presented RS-fMRI data provide evidence that functional connectivity (FC) between the dentate nucleus and the cerebral cortex is altered in ASD patients. This suggests that the dysfunction reported within the cerebral cortical network, typically related to social features of ASDs, may be at least partially related to an impaired interaction between cerebellum and key cortical social brain regions.", "labels": [2, 16]}
{"id": "3494", "token": "Frontotemporal dementia is a neurodegenerative disease affecting cognition and behavior in multiple devastating ways. This article highlights diagnostic features helpful in differentiating frontotemporal dementia from other dementias, most commonly Alzheimer disease.", "labels": [2, 16]}
{"id": "3530", "token": "The formation of a coherent and unified self-concept represents a key developmental stage during adolescence. Imaging studies on self-referential processing in adolescents are rare, and it is not clear whether neural structures involved in self-reflection are also involved in reflections of familiar others. In the current study, 41 adolescents were asked to make judgments about trait adjectives during functional magnetic resonance imaging (fMRI): they had to indicate whether the word describes themselves, their friends, their teachers or politicians. Findings indicate a greater overlap in neural networks for responses to self- and friend-related judgments compared to teachers and politicians. In particular, classic self-reference structures such as the ventromedial prefrontal cortex and medial posterior parietal cortex also exhibited higher activation to judgments about friends. In contrast, brain responses towards judgments of teachers (familiar others) compared to politicians (unfamiliar others) did not significantly differ. Results support behavioral findings of a greater relevance of friends for the development of a self-concept during adolescence and indicate underlying functional brain processes. Hum Brain Mapp 38:987-996, 2017. (c) 2016 Wiley Periodicals, Inc.", "labels": [2, 16]}
{"id": "27", "token": "Bacillus thuringiensis (Bt) is known as the most successful microbial insecticide against different orders of insect pests in agriculture and medicine. Moreover, Bt toxin genes also have been efficiently used to enhance resistance to insect pests in genetically modified crops. In light of the scientific advantages of new molecular biology technologies, recently, some other new potentials of Bt have been explored. These new environmental features include the toxicity against nematodes, mites, and ticks, antagonistic effects against plant and animal pathogenic bacteria and fungi, plant growth-promoting activities (PGPR), bioremediation of different heavy metals and other pollutants, biosynthesis of metal nanoparticles, production of polyhydroxyalkanoate biopolymer, and anticancer activities (due to parasporins). This review comprehensively describes recent advances in the Bt whole-genome studies, the last updated known Bt toxins and their functions, and application of cry genes in plant genetic engineering. Moreover, the review thoroughly describes the new features of Bt which make it a suitable cell factory that might be used for production of different novel valuable bioproducts.", "labels": [6, 35]}
{"id": "116", "token": "We present a case of sarcoma occurring at a site of resected oligodendroglioma without preceding radiotherapy or chemotherapy. Oligosarcoma occurring at sites of resected oligodendroglioma or anaplastic oligodendroglioma with sarcomatous components are rare. Although meningioma or sarcoma-like lesions are sometimes reported after glioma-targeted radiotherapy, those without preceding radiotherapy are quite rare. Moreover, cases of sarcoma without oligodendroglial components occurring at a site of resected oligodendroglioma have never been reported. In this case, fluorescent in situ hybridization analysis revealed 1p/19q co-deletion in both the first tumor and second tumors. Additionally, immunohistochemistry revealed mutated isocitrate dehydrogenase 1 in both tumors. Taken together, these findings suggest a monoclonal tumor origin. Consequently, this case may indicate a new mechanism of development of sarcomatous lesions occurring at the site of a resected glioma.", "labels": [6, 35]}
{"id": "248", "token": "Positive-strand RNA genomes function as mRNA for viral protein synthesis which is fully reliant on host cell translation machinery. Competing with cellular protein translation apparatus needs to ensure the production of viral proteins, but this also stifles host innate defense. In the present study, we showed that porcine reproductive and respiratory syndrome virus (PRRSV), whose replication takes place in the cytoplasm, imprisoned host cell mRNA in the nucleus, which suggests a novel mechanism to enhance translation of PRRSV genome. PRRSV nonstructural protein (nsp) 1 beta was identified as the nuclear protein playing the role for host mRNA nuclear retention and subversion of host protein synthesis. A SAP (SAF-A/B, Acinus, and PIAS) motif was identified in nsp1 beta with the consensus sequence of (126)-LQxxLxxxGL-(135). In situ hybridization unveiled that SAP mutants were unable to cause nuclear retention of host cell mRNAS and did not suppress host protein synthesis. In addition, these SAP mutants reverted PRRSV-nsp1 beta-mediated suppression of interferon (IFN) production, IFN signaling, and TNF-alpha production pathway. Using reverse genetics, a series of SAP mutant PRRS viruses, vK124A, vL126A, vG134A, and vL135A were generated. No mRNA nuclear retention was observed during vL126A and vL135A infections. Importantly, vL126A and vL135A did not suppress IFN production. For other arteriviruses, mRNA nuclear accumulation was also observed for LDV-nsp1 beta and SHFV-nsp1 beta. EAV-nspl was exceptional and did not block the host mRNA nuclear export.", "labels": [6, 35]}
{"id": "281", "token": "Osmoprimed seeds increased the abundance of pGlcT proteins. Osmopriming together with heat shock increased the abundance of RBR proteins. NAD-ME increased when osmoprimed and heat-shocked seeds were imbibed at low temperature. The purpose of seed priming is to accelerate and synchronize germination and to increase stress tolerance through the activation of genes that function when seeds are exposed to unfavorable conditions. The objectives of this study were: (1) to evaluate the effects of osmopriming and heat-shock treatment on the germination of Eucalyptus urophylla seeds at different temperatures and (2) to analyze the seed proteome to elucidate the mechanisms of tolerance to thermal stress in primed and unprimed seeds. Untreated (control) seeds, osmoprimed (polyethylene glycol for 3 days) and redried seeds, and osmoprimed/heat-shocked (45 A degrees C for 1 h) and redried seeds were germinated for 14 days under constant light (2 x 40 W fluorescent daylight tubes) at 9, 16, 22, 24, or 31 A degrees C. Osmopriming, with or without heat-shock, led to a significant increase in the germination percentage at 9 A degrees C and induced the highest germination speed index at 31 A degrees C. According to proteomic analysis, osmoprimed seeds exhibited an increased abundance of several proteins, including sugar transport proteins, and this may have influenced the metabolic rate during germination. Osmopriming together with heat-shock treatment increased the abundance of proteins associated with regulation of the cell cycle suggesting that such proteins may be involved in protection against thermal stress. The Krebs cycle enzyme was increased when osmoprimed and heat-shocked seeds were imbibed at low temperature, possibly signifying increased synthesis of adenosine triphosphate. The results reported herein serve to explain some of the benefits of osmopriming/heat-shock treatment.", "labels": [6, 35]}
{"id": "415", "token": "Platinum drugs remain the backbone of many antineoplastic regimens. Among the numerous chemical or pharmacological effects of platinum drugs, some aspects tend to be under-reported. Thus, this perspective paper intends to stress some neglected properties of platinum drugs: first, the physico-chemical characteristics (aquation reaction kinetics) that determine site-specific toxicity; second, the impact on RNA molecules. Knowledge of the RNA world' has dramatically changed our understanding of cellular and molecular biology. The inherent RNA-crosslinking properties should make platinum-based drugs interact with coding and non-coding RNAs. Third, we will discuss the impact on the immune system, which is now recognized to substantially contribute to chemotherapy efficacy. Together, platinum drugs are in fact old drugs, but are worth re-focusing on. Many aspects are still mysterious but can pave the way to new drugs or an improved application of the already existing compounds.", "labels": [6, 35]}
{"id": "520", "token": "At a global level, with the increase in healthcare costs, there is a need to assess the economic impact of the incorporation of new technologies in different health disorders in different countries. There is scarce information regarding costs incurred with the use of current or new diagnostic tests for tuberculosis or from the vantage point of their incorporation within the healthcare systems of high-burden countries. The present study aimed to assess the mean cost and the activity based cost of the laboratory diagnosis for tuberculosis by means of conventional techniques and from the Detect TB (R) LabTest molecular test kit in a general high-complexity hospital of the public health system in Brazil. Cost analysis was performed by means of primary data, collected in the Mycobacteria and Molecular Biology Laboratory in 2013. The mean cost and activity based cost were, respectively, U$10.06/U$5.61 for centrifuged bacilloscopy by Ziehl Neelsen (ZN) and Auramine (AU); U$7.42/U$4.15 for direct bacilloscopy by ZN; U$27.38/U$16.50 for culture in a Loweinstein-Jensen solid medium; and U$115.74/U$73.46 for the Detect TB (R) LabTest Kit. The calculation of the ABC should be used in making decisions by administrators to be the best method of assessing the costs of conventional techniques and molecular method for providing the real value of the tests. So it is need to calculate the ABC, and not of the mean cost, in various scenarios before incorporating new technologies in health institutions.", "labels": [6, 35]}
{"id": "577", "token": "Aims: Recent evidence indicates that the defective ability to clear apoptotic cells by macrophages (efferocytosis) and the resultant apoptotic cells accumulation in atherosclerotic plaques play an important role during the progression of unstable plaques. The cannabinoid type 2 receptor (CB2), has recently been emerging as a new target to reduce vulnerability and promote stability of plaques, however, the underlying mechanisms have not been studied in detail. In the present study, we investigated whether selective activation of CB2 improves efferocytosis of macrophages. Main methods: RAW264.7 macrophage line and primary-isolated peritoneal lavage macrophages from C57bI/6J mice were cultured. The efferocytosis of macrophages was analyzed by using flow cytometry or confocal microscopy; and the possible mechanisms involved in regulation of efferocytosis were also explored by using molecular biology methods. Key findings: We found that JWH-133 and HU-308, selective agonists of CB2 receptor, concentration-dependently increased the phagocytosis of apoptotic cells in normal-cultured and oxidative low density lipoprotein (OxLDL) - loaded RAW264.7 and primary macrophages. JWH-133 and HU-308 also up-regulated expressions of tyrosine kinase family phagocytic receptors MerTK, Tyro3 and Axl, reduced levels of TNF-alpha and reactive oxygen species (ROS) induced by OxLDL, and inhibited activation of RhoA GTPase. Significance: The selective activation of CB2 improves efferosytosis of normal-cultured and OxLDL-loaded macrophages, which might provide a novel mechanism on how CB2 activation reduces vulnerability and promotes stability of atherosclerotic plaques. (C) 2016 Elsevier Inc All rights reserved.", "labels": [6, 35]}
{"id": "727", "token": "Background: Emergence of insecticide resistance in malaria vectors is a real threat to future goals of elimination and control of malaria. Therefore, the objective of this study was to assess research trend on insecticide resistance of Anopheles mosquito. In specific, number of publications, countries, institutions, and authors' research profile, citation analysis, international collaborations, and impact of journals publishing documents on insecticide resistance will be presented. It was conducted via Scopus search engine which was used to retrieve relevant data. Keywords used were based on literature available on this topic. The duration of study was set from 1996-2015. Results: A total of 616 documents, mainly as original research articles (n = 569; 92.37%) were retrieved. The average number of citations per article was 26.36. Poisson log-linear regression analysis indicated that there was a 6.00% increase in the number of publications for each extra article on pyrethroid resistance. A total of 82 different countries and 1922 authors participated in publishing retrieved articles. The United Kingdom (UK) ranked first in number of publications followed by the United States of America (USA) and France. The top ten productive countries included seven African countries. The UK had collaborations mostly with Benin (relative link strength = 46). A total of 1817 institution/ organizations participated in the publication of retrieved articles. The most active institution/ organization was Liverpool School of Tropical Medicine. Retrieved articles were published in 134 different scientific peer reviewed journals. The journal that published most on this topic was Malaria Journal (n = 101; 16.4%). Four of the top active authors were from South Africa and two were from the UK. Three of the top ten cited articles were published in Insect Molecular Biology journal. Six articles were about pyrethroid resistance and at least two were about DDT resistance. Conclusion: Publications on insecticide resistance in malaria vector has gained momentum in the past decade. International collaborations enhanced the knowledge about the situation of vector resistance in countries with endemic malaria. Molecular biology of insecticide resistance is the key issue in understanding and overcoming this emerging problems.", "labels": [6, 35]}
{"id": "789", "token": "The microbial populations in the activated sludge of two Polish wastewater treatment plants (WWTPs) were identified and quantified using Illumina sequencing of 16S ribosomal RNA amplicons over a 2-year period. Their dynamics over time were compared to Danish WWTPs (data collected in previous studies by Center for Microbial Communities, Aalborg University). The bacterial communities in Polish and Danish WWTPs were similar to each other, but the microbial diversity in Polish WWTPs was lower. The dominant genera in Polish WWTPs were more abundant than in Danish WWTPs; 30 of them constituted more than half the of activated sludge community. Polish WWTPs showed a higher abundance of bacteria involved in nitrogen and chemical oxygen demand removal (Proteobacteria and Bacteroidetes), while polyphosphate-acculumating bacteria were the dominant bacterial group in Danish plants. The microbial community structures in the examined Polish WWTPs were relatively similar to each other and showed strong seasonal variations which are not normally observed in Danish WWTPs.", "labels": [6, 35]}
{"id": "986", "token": "Concrete corrosion is one of the most significant problems affecting valuable sewer infrastructure on a global scale. This problem occurs in the aerobic zone of the sewer, where a layer of surface corrosion develops on the exposed concrete and the surface pH is typically lowered from around 11-10 (pristine concrete) to pH 2-4. Acidophilic microorganisms become established as biofilms within the concrete corrosion layer and enhance the loss of concrete mass. Until recently, the acidophilic community was considered to comprise relatively few species of microorganisms, however, the biodiversity of the corrosion community is now recognized as being extensive and varying from different sewer environmental conditions. The diversity of acidophiles in the corrosion communities includes chemolithoautotrophs, chemolithoheterotrophs, and chemoorganoheterotrophs. The activity of these microorganisms is strongly affected by H2S levels in the sewer gas phase, although CO2, organic matter, and iron in the corrosion layer influence this acidic ecosystem. This paper briefly presents the conditions within the sewer that lead to the development of concrete corrosion in that environment. The review focuses on the acidophilic microorganisms detected in sewer corrosion environments, and then summarizes their proposed functions and physiology, especially in relation to the corrosion process. To our knowledge, this is the first review of acidophilic corrosion microbial communities, in which, the ecology and the environmental conditions (when available) are considered. Ecological studies of sewer corrosion are limited, however, where possible, we summarize the important metabolic functions of the different acidophilic species detected in sewer concrete corrosion layers. It is evident that microbial functions in the acidic sewer corrosion environment can be linked to those occurring in the analogous acidic environments of acid mine drainage and bioleaching.", "labels": [6, 35]}
{"id": "1059", "token": "This review paper discusses the perspective of complex biological systems as applied to inheritance and ontogeny, focusing on the continuity of genetic, epigenetic (transgenerational) and microbiotic inheritance. The informational processuality within this continuity can be used as to exemplify the insufficiency of hierarchical concepts in grasping the complex and integrated nature of biological processes. The argument follows Bruni and Giorgi (Progress in Biophysics and Molecular Biology 119, 481-92, 2015) in emphasizing that while structures and substrates are organized hierarchically, communicational processes are organized heterarchically. The essay also argues the insufficiency of a single, basic, i.e. genetic level of description, which is the prevalent idea of twentieth century biology, to explain all phenotypic variation. I argue that inheritance and development cannot be fully explained by some sub- or super-ordination and that such descriptions are merely heuristic tools that do not reflect the nature of such processes.", "labels": [6, 35]}
{"id": "1226", "token": "Induced pluripotent stem cells (iPSCs) offer an unlimited resource of cells to be used for the study of underlying molecular biology of disease, therapeutic drug screening, and transplant-based regenerative medicine. However, methods for the directed differentiation of skeletal muscle for these purposes remain scarce and incomplete. Here, we present a novel, small molecule-based protocol for the generation of multinucleated skeletal myotubes using eight independent iPSC lines. Through combinatorial inhibition of phosphoinositide 3-kinase (PI3K) and glycogen synthase kinase 3 beta (GSK3 beta) with addition of bone morphogenic protein 4 (BMP4) and fibroblast growth factor 2 (FGF2), we report up to 64% conversion of iPSCs into the myogenic program by day 36 as indicated by MYOG(+) cell populations. These cells began to exhibit spontaneous contractions as early as 34 days in vitro in the presence of a serum-free medium formulation. We used this protocol to obtain iPSC-derived muscle cells from frontotemporal dementia (FTD) patients harboring C9orf72 hexanucleotide repeat expansions (rGGGGCC), sporadic FTD, and unaffected controls. iPSCs derived from rGGGGCC carriers contained RNA foci but did not vary in differentiation efficiency when compared to unaffected controls nor display mislocalized TDP-43 after as many as 120 days in vitro. This study presents a rapid, efficient, and transgene-free method for generating multinucleated skeletal myotubes from iPSCs and a resource for further modeling the role of skeletal muscle in amyotrophic lateral sclerosis and other motor neuron diseases.", "labels": [6, 35]}
{"id": "1270", "token": "Culture-based pathogen identification in skull base osteomyelitis, particularly for fungi, is often inaccurate. We report the case of patient with fungal skull base osteomyelitis cured by sustained antifungal therapy after 16 months of debilitating illness. Due to medical complications, a strong clinical rationale was needed to justify long-term antifungal therapy. The offending fungus was identified by experimental molecular technology (Ibis T5000 universal biosensor); invasive fungal disease was corroborated by biochemical assays. Our discussion will help familiarize the otolaryngologist with existing biochemical and molecular diagnostics for invasive fungal disease. We encourage future investigators to study their application in cases of skull base osteomyelitis.", "labels": [6, 35]}
{"id": "1453", "token": "Careful characterization and standardization of the composition of plant-derived food supplements is essential to establish a cause-effect relationship between the intake of that product and its health effect. In this review we follow a specific grape seed extract containing monomeric and oligomeric flavan-3-ols from its creation by Jack Masquelier in 1947 towards a botanical remedy and nutraceutical with proven health benefits. The preparation's research history parallels the advancing insights in the fields of molecular biology, medicine, plant and nutritional sciences during the last 70 years. Analysis of the extract's flavanol composition emerged from unspecific colorimetric assays to precise high performance liquid chromatography - mass spectrometry and proton nuclear magnetic resonance fingerprinting techniques. The early recognition of the preparation's auspicious effects on the permeability of vascular capillaries directed research to unravel the underlying cellular and molecular mechanisms. Recent clinical data revealed a multitude of favorable alterations in the vasculature upon an 8 weeks supplementation which summed up in a health benefit of the extract in healthy humans. Changes in gene expression of inflammatory pathways in the volunteers' leukocytes were suggested to be involved in this benefit. The historically grown scientific evidence for the preparation's health effects paves the way to further elucidate its metabolic fate and molecular action in humans.", "labels": [6, 35]}
{"id": "1506", "token": "Three genes, gnd, pgl, and fbp, relevant to the pentose phosphate pathway (PPP) were overexpressed in Corynebacterium glutamicum IWJ001, leading to increase of L-isoleucine production. The transcriptional levels of gnd, pgl, and fbp significantly increased in IWJ001/pDXW-8-gnd-fbp-pgl. Compared with the control strain IWJ001/pDXW-8, intracellular NADPH/NADP(+) ratios in IWJ001/pDXW-8-gnd and IWJ001/pDXW-8-gnd-fbp cells grown for 36 H increased threefold and fourfold, respectively, indicating that overexpression of gnd and fbp redirected the carbon flux to PPP. Intracellular NADPH/NADP(+) ratio in IWJ001/pDXW-8-gnd-fbp-pgl grown for 36 H was similar to IWJ001/pDXW-8, suggesting that the NADPH produced by PPP could be quickly consumed for L-isoleucine production. 10.9 and 28.96 g/L of L-isoleucine was produced in IWJ001/pDXW-8-gnd-fbp-pgl in shake flask cultivation and fed-batch fermentation, respectively. In addition, IWJ001/pDXW-8-gnd-fbp-pgl grew fast, its dry cell weight reached 49 g/L after 48 H, whereas the start strain IWJ001/pDXW-8 reached only 40 g/L. After 96 H fermentation, L-isoleucine yield on glucose in IWJ001/pDXW-8-gnd-fbp-pgl reached 0.138 g/g. The results demonstrate that carbon flux redirection to PPP is an efficient approach to enhance L-isoleucine production in C. glutamicum. (C) 2015 International Union of Biochemistry and Molecular Biology, Inc. Volume 63, Number 6, Pages 877-885, 2016", "labels": [6, 35]}
{"id": "1830", "token": "Gnathostomiasis is a foodborne zoonotic parasitosis caused by Gnathostoma nematodes. It has caused significant public problems worldwide, but its molecular biology is limited. The purpose of this study was to decode the complete mitochondrial (mt) genomes of Gnathostoma nipponicum and Gnathostoma sp., and compare their mt sequences with other Gnathostoma species. The complete mt genome sequences were amplified by long-range PCR and determined by subsequent primer walking. The complete mt genomes of G. nipponicum and Gnathostoma sp. were 14,093 bp and 14,391 bp, respectively. Both of the two mt genomes contain 12 protein-coding genes (PCGs), 2 ribosomal RNA genes and 22 transfer RNA genes. The gene order and transcription direction are the same as G. spinigerum and G. doloresi. The sequence difference across the entire mt genomes varied from 14.4% to 18.2% between G. nipponicum, Gnathostoma sp., G. spinigerum and G. doloresi of Japan and China isolates. Phylogenetic analyses by Bayesian inference (BI) using concatenated amino acid sequences of 12 PCGs showed that G. nipponicum and Gnathostoma sp. are two distinctive species of Gnathostoma, and G. nipponicum are more closely related to Gnathostoma sp. than to G. spinigerum. The mtDNA datasets provide abundant resources of novel markers, which can be used for the studies of molecular epidemiology and diagnosis of Gnathostoma spp. (C) 2016 Elsevier B.V. All rights reserved.", "labels": [6, 35]}
{"id": "1877", "token": "Cadmium (Cd) accumulation in rice and its subsequent transfer to food chain is a major environmental issue worldwide. Understanding of Cd transport processes and its management aiming to reduce Cd uptake and accumulation in rice may help to improve rice growth and grain quality. Moreover, a thorough understanding of the factors influencing Cd accumulation will be helpful to derive efficient strategies to minimize Cd in rice. In this article, we reviewed Cd transport mechanisms in rice, the factors affecting Cd uptake (including physicochemical characters of soil and ecophysiological features of rice) and discussed efficient measures to immobilize Cd in soil and reduce Cd uptake by rice (including agronomic practices, bioremediation and molecular biology techniques). These findings will contribute to ensuring food safety, and reducing Cd risk on human beings. (C) 2017 Elsevier Ltd. All rights reserved.", "labels": [6, 35]}
{"id": "1964", "token": "Rice stripe tenuivirus (RSV) is a filamentous, negative-strand RNA virus causing severe diseases on rice in Asian countries. The viral particle is composed predominantly of a nucleocapsid protein (NP) and genomic RNA. However, the molecular details of how the RSV NP interacts with genomic RNA during particle assembly remain largely unknown. Here, we modeled the NP-RNA complex and show that polar amino acids within a predicted groove of NP are critical for RNA binding and protecting the RNA from RNase digestion. RSV NP formed pentamers, hexamers, heptamers, and octamers. By modeling the higher-order structures, we found that oligomer formation was driven by the N-terminal amino arm of the NP. Deletion of this arm abolished oligomerization; the N-terminally truncated NP was less able to interact with RNA and protect RNA than was the wild type. These findings afford valuable new insights into molecular mechanism of RSV NPs interacting with genomic RNA.", "labels": [6, 35]}
{"id": "2073", "token": "Mesenchymal neoplasms of the thymus and mediastinum account for only 2 % of neoplasms of the mediastinum and are therefore very rare. With very few exceptions the histology, immunohistochemistry and (based on current knowledge) molecular biology of mediastinal soft tissue tumors are not different from their counterparts in other organs. Characteristic features are more concerned with clinical epidemiological and therapeutic aspects as well as the multitude of possible differential diagnoses. With the exception of organ-specific tumors, such as gastrointestinal stromal tumors (GIST), virtually all entities encountered in peripheral soft tissues can also arise in the mediastinum. Primary mediastinal soft tissue sarcomas (STS) must be distinguished from secondary radiation-induced STS after irradiation, e. g. for breast cancer and Hodgkin's lymphoma and from STS arising as somatic type malignancies in mediastinal germ cell tumors.", "labels": [6, 35]}
{"id": "2179", "token": "Brain-derived neurotrophic factor (BDNF) and its tyrosine kinase receptor TrkB have been reported to be associated with poor prognosis in neuroblastoma (NB) patients. Our previous studies indicated that BDNF activation of TrkB induces chemo-resistance through activation of phosphoinositide-3-kinase (PI3K)/Akt pathway. In this study, we investigated the role of BDNF/TrkB on metastasis in NB. A tetracycline-regulated TrkB-expressing NB cell line (TB3) was used. Scratch wound healing assay, Boyden chamber migration, and invasion assays were performed to study the migration and invasion of TB3 cells. A tumor xenograft model using SCID-Beige mice was utilized to detect the metastasis of NB tumors in vivo. Inhibitors of PI3K, MAPK, Akt, and mTOR were used. Western blotting was performed to study the expressions of P-Akt, P-Erk, and P-mTOR. Our results showed that in TrkB-expressing NB cells, BDNF treatment significantly increased gap closing (P < 0.01) in scratch wound healing assay, also significantly enhanced the numbers of migrating cells (P < 0.01) and invading cells (P < 0.01) in the Boyden chamber migration and invasion assays. In vivo, NB distant metastases were significantly increased in mice with TrkB-expressing xenograft tumors compared to those with non-TrkB-expressing tumors (P < 0.05). Pre-treatment with any of the inhibitors for PI3K (LY294002), MAPK (PD98059), Akt (perifosine), or mTOR (rapamycin) blocked the BDNF/TrkB-induced increases of cell migration and invasion in TB3 cells, and also blocked the BDNF/TrkB-induced expressions of P-Akt, P-Erk, and P-mTOR. These data indicated that BDNF/TrkB increased metastasis in NB via PI3K/Akt/mTOR and MAPK pathways, and BDNF/TrkB and the downstream targets may be potential targets for the treatment of NB metastasis.", "labels": [6, 35]}
{"id": "2202", "token": "The PLAGL1 gene encodes a homonymous zinc finger protein that promotes cell cycle arrest and apoptosis through multiple pathways. The protein has been implicated in metabolic, genetic, and neoplastic illnesses, but the molecular mechanisms by which the protein PLAGL1 participates in such diverse processes remains to be elucidated. In this review, we focus mainly on the molecular biology of PLAGL1 and the relevance of its abnormalities to several pathological processes.", "labels": [6, 35]}
{"id": "2291", "token": "In spite of excellent properties of supercritical CO2 in enzyme catalyzed reactions, destabilizing effects of CO2 molecules on the enzyme structure limits the industrial applications of this green solvent in the field of biocatalysis. Here, based on the substantial role of charged surface residues such as lysines in enzyme inactivation, we introduced for the first time, Post Translational Modifications (PTMs), a famous concept in molecular biology, as a protein stabilization strategy in supercritical condition. Lysine groups were modified using PTM templates to find out more about the exact mechanism of enzyme inactivation in supercritical CO2 and to explore a new way for protein stabilization in this solvent. We used MD simulation as common tool for in situ examining enzyme structure in supercritical fluids, for the investigation of structural consequence of modifications. Different modifications including acetylation, methylation, phosphorylation, and carboxylation have been applied on the model enzyme. For comparison to CALB structure in supercritical CO2, the acetylated enzyme was also simulated in aqueous solvent at 300 and 353 K. Interestingly, acetylation of lysine residues prevents enzyme from denaturation at high temperatures in water, which is in agreement with experimental observation in aqueous solution. However, acetylation is not so useful for stabilization of enzyme in supercritical CO2. In contrast, methylation and carboxylation efficiently stabilize enzyme in supercritical CO2. Phosphate groups in phosphorylated lysines destabilize enzyme by formation of excess hydrogen bonds by inappropriate groups and perturb enzyme conformation. Moreover, it was found that modification of surface arginine residues was not so satisfactory in stabilization of the enzyme. This finding supports the mechanism of lipase inactivation through direct interaction of CO2 molecules on lysine residues and formation of carbamates. We think this new exploration can open new window for developing enzyme catalyzed mechanism of enzyme inactivation in scCO(2). (C) 2016 Elsevier B.V. All rights reserved.", "labels": [6, 35]}
{"id": "2352", "token": "Construction of a random ssDNA sublibrary is an important step of the aptamer screening process. The available construction methods include asymmetric PCR, biotin-streptavidin separation, and lambda exonuclease digestions, in which PCR amplification is a key step. The main drawback of PCR amplification is overamplification increasing nonspecific hybridization among different products and by-products, which may cause the loss of potential high-quality aptamers, inefficient screening, and even screening failure. Cycle number optimization in PCR amplification is the main way to avoid overamplification but does not fundamentally eliminate the nonspecific hybridization, and the decreased cycle number may lead to insufficient product amounts. Here, we developed a new method, asymmetric emulsion PCR, which could overcome the shortcomings of conventional PCR. In asymmetric emulsion PCR, different templates were separated by emulsion particles, allowing single-molecule PCR, in which each template was separately amplified, and the nonspecific hybridization was avoided. Overamplification or formation of by-products was not observed. The method is so simple that direct amplification of 40 or more cycles can provide a high-quality ssDNA library. Therefore, the asymmetric emulsion PCR would improve the screening efficiency of systematic evolution of ligands by exponential enrichment. (C) 2015 The Authors. Biotechnology and Applied Biochemistry published by Wiley Periodicals, Inc. on behalf of the International Union of Biochemistry and Molecular Biology, Inc.", "labels": [6, 35]}
{"id": "2507", "token": "We explore the integration of societal issues in undergraduate training within the life sciences. Skills in thinking about science, scientific knowledge production and the place of science in society are crucial in the context of the idea of responsible research and innovation. This idea became institutionalized and it is currently well-present in the scientific agenda. Developing abilities in this regard seems particularly relevant to training in the life sciences, as new developments in this area somehow evoke the involvement of all of us citizens, our engagement to debate and take part in processes of change. The present analysis draws from the implementation of a curricular unit focused on science-society dialogue, an optional course included in the Biochemistry Degree study plan offered at the University of Porto. This curricular unit was designed to be mostly an exploratory activity for the students, enabling them to undertake in-depth study in areas/topics of their specific interest. Mapping topics from students' final papers provided a means of analysis and became a useful tool in the exploratory collaborative construction of the course. We discuss both the relevance and the opportunity of thinking and questioning the science-society dialogue. As part of undergraduate training, this pedagogical practice was deemed successful. (c) 2016 by The International Union of Biochemistry and Molecular Biology, 45(1):46-52, 2017.", "labels": [6, 35]}
{"id": "2617", "token": "Life is so remarkable, and so unlike any other physical system, that it is tempting to attribute special factors to it. Physics is founded on the assumption that universal laws and principles underlie all natural phenomena, but is it far from clear that there are 'laws of life' with serious descriptive or predictive power analogous to the laws of physics. Nor is there (yet) a 'theoretical biology' in the same sense as theoretical physics. Part of the obstacle in developing a universal theory of biological organization concerns the daunting complexity of living organisms. However, many attempts have been made to glimpse simplicity lurking within this complexity, and to capture this simplicity mathematically. In this paper we review a promising new line of inquiry to bring coherence and order to the realm of biology by focusing on 'information' as a unifying concept.", "labels": [6, 35]}
{"id": "2811", "token": "Viable bacterial cells and its genetic material can be stably maintained in Arctic permafrost for a long geological time. Because of the seasonal melting of permafrost strata, it cannot be excluded an access to the surface of ancient highly invasive species with increased pathogenicity. Mycoplasmas are very successful pathogens in humans, mammals, birds, insects, and plants, with high genome plasticity and ability to avoid immune response of host organism. The metagenomic approach allowed us to predict mycoplasma diversity in the Arctic permafrost. The number of mycoplasma DNA fragments in soil deposits of comparable age (similar to 30,000 years) and origin (the late Pleistocene Ice Complexes) is not so abundant compared with other microorganisms, but it is enough for a chance in the presence of living mycoplasmal cells in permafrost. DNA fragments of human, animal, insect, and plant pathogens were identified. The ubiquitous mycoplasma Acholeplasma laidlawii is the undisputed leader in the number of identified sequences in all three metagenomes. It may indicate a higher adaptive capacity and more powerful metabolic potential of A. laidlawii among Mollicutes.", "labels": [6, 35]}
{"id": "2964", "token": "The present study focuses on Cryptosporidium infections of foals in Brazil. A total of 92 animals of different breeds from 11 farms in the vicinity of Aracatuba in the state of Sao Paulo, were examined. According to PCR targeting the 18S rRNA gene, Cryptosporidium sp. DNA was detected in 21.7% (20/92) of foals. Good quality 18S rRNA, actin, HSP70 and gp60 genes nPCR amplicons were obtained from five fecal samples. PCR amplification and sequencing of a fragment of the GP60 sporozoite surface glycoprotein gene revealed C parvum genotypes IIaAl8G3R1, lIaAl5G2R1. Interestingly, we also detected in two foals a GP60 genotype related to the human parasite C. hominis. (C) 2016 Elsevier B.V. All rights reserved.", "labels": [6, 35]}
{"id": "3143", "token": "Background: Functionalized nanoparticles (NPs) are one promising tool for detecting specific molecular targets and combine molecular biology and nanotechnology aiming at modern imaging. We aimed at ligand-directed delivery with a suitable target-biomarker to detect early pancreatic ductal adenocarcinoma (PDAC). Promising targets are galectins (Gal), due to their strong expression in and on PDAC-cells and occurrence at early stages in cancer precursor lesions, but not in adjacent normal tissues. Results: Molecular probes (10-29 AA long peptides) derived from human tissue plasminogen activator (t-PA) were selected as binding partners to galectins. Affinity constants between the synthesized t-PA peptides and Gal were determined by microscale thermophoresis. The 29 AA-long t-PA-peptide-1 with a lactose-functionalized serine revealed the strongest binding properties to Gal-1 which was 25-fold higher in comparison with the native t-PA protein and showed additional strong binding to Gal-3 and Gal-4, both also over-expressed in PDAC. t-PA-peptide-1 was selected as vector moiety and linked covalently onto the surface of biodegradable iron oxide nanoparticles (NPs). In particular, CAN-doped maghemite NPs (CAN-Mag), promising as contrast agent for magnetic resonance imaging (MRI), were selected as magnetic core and coated with different biocompatible polymers, such as chitosan (CAN-Mag-Chitosan NPs) or polylactic co glycolic acid (PLGA) obtaining polymeric nanoparticles (CAN-Mag@PNPs), already approved for drug delivery applications. The binding efficacy of t-PA-vectorized NPs determined by exposure to different pancreatic cell lines was up to 90%, as assessed by flow cytometry. The in vivo targeting and imaging efficacy of the vectorized NPs were evaluated by applying murine pancreatic tumor models and assessed by 1.5 T magnetic resonance imaging (MRI). The t-PA-vectorized NPs as well as the protease-activated NPs with outer shell decoration (CAN-Mag@PNPs-PEG-REGAcp-PEG/tPA-pep1Lac) showed clearly detectable drop of subcutaneous and orthotopic tumor staining-intensity indicating a considerable uptake of the injected NPs. Post mortem NP deposition in tumors and organs was confirmed by Fe staining of histopathology tissue sections. Conclusions: The targeted NPs indicate a fast and enhanced deposition of NPs in the murine tumor models. The CAN-Mag@PNPs-PEG-REGAcp-PEG/tPA-pep1Lac interlocking steps strategy of NPs delivery and deposition in pancreatic tumor is promising.", "labels": [6, 35]}
{"id": "3242", "token": "BACKGROUNDWeeds can be a greater constraint to crop production than animal pests and pathogens. Pre-emergence herbicides are crucial in many cropping systems to control weeds that have evolved resistance to selective post-emergence herbicides. In this study we assessed the potential to evolve resistance to the pre-emergence herbicides prosulfocarb + S-metolachlor or pyroxasulfone in 50 individual field Lolium rigidum populations collected in a random survey in Western Australia prior to commercialisation of these pre-emergence herbicides. RESULTSThis study shows for the first time that in randomly collected L. rigidum field populations the selection with either prosulfocarb + S-metolachlor or pyroxasulfone can result in concomitant evolution of resistance to both prosulfocarb + S-metolachlor and pyroxasulfone after three generations. CONCLUSIONSIn the major weed L. rigidum, traits conferring resistance to new herbicides can be present before herbicide commercialisation. Proactive and multidisciplinary research (evolutionary ecology, modelling and molecular biology) is required to detect and analyse resistant populations before they can appear in the field. Several studies show that evolved cross-resistance in weeds is complex and often unpredictable. Thus, long-term management of cross-resistant weeds must be achieved through heterogeneity of selection by effective chemical, cultural and physical weed control strategies that can delay herbicide resistance evolution. (c) 2016 Society of Chemical Industry", "labels": [6, 35]}
{"id": "3404", "token": "Purpose: Combined modality therapy is a mainstay option for thoracic malignancies and head and neck cancers. The integration of different strategies is based on the multidisciplinary approach of modern clinical oncology. Radiation oncologists have to be educated, trained, and updated to provide state-of-the-art care to cancer patients and thus educational meetings are crucial. Methods: The Italian Association of Radiation Oncology Young Members Working Group (AIRO Giovani) organized its 8th national meeting, focused on combination therapy in lung, esophageal, and head and neck cancer (with a specific focus on larynx-preservation strategies for larynx/hypopharynx tumors), involving young professionals working in Italy. The meeting was addressed to young radiation oncologists, presenting state-of-the-art knowledge, based on the latest evidence in this field. We performed a review of the current literature based on the highlights of the Congress. Results: The multimodality approach of head and neck and thoracic malignancies includes surgery, chemotherapy, and radiotherapy, but also has to take into account new information and data coming from basic and translational research and including molecular biology, genetics, and immunology. All these aspects are crucial for the treatment of non-small-cell lung cancer and esophageal, esophagogastric junction, and larynx/hypopharynx malignancies. The integration of different treatments in the clinical decision-making process to combine therapies is crucial. Conclusions: Combination therapy has proved to be a consolidated approach in these specific oncologic settings, highlighting the importance of multimodality management in modern clinical oncology. Dedicated meetings on specific topics are helpful to improve knowledge and skills of young professionals in radiation oncology.", "labels": [6, 35]}
{"id": "29", "token": "Background: The presence of multiple allergies has been correlated with worse outcomes for patients undergoing hip and knee arthroplasty, but the effect of allergies has not yet been elucidated with respect to shoulder arthroplasty. Purpose/Hypothesis: The purpose of this study is to identify any discrepancies in shoulder arthroplasty outcomes with respect to reported drug allergies. We hypothesized that patients with multiple drug allergies would have inferior outcomes. Study Design: Cohort study; Level of evidence, 3. Methods: Included in the analysis were a single surgeon's cases between 2009 and 2014 of primary total shoulder arthroplasty with a minimum of 180 days of follow-up. Cases with fracture as the indication were excluded. Preoperative and postoperative metrics included visual analog scale (VAS) for pain, forward flexion range of motion, and Simple Shoulder Test (SST) results, and postoperative patient satisfaction scores were also collected. Chi-square and 1-way analysis of variance with Tukey post hoc analyses were performed when appropriate. Results: A total of 98 patients were included (no allergies, n = 51; single allergy, n = 21; multiple allergies, n = 26). The proportion of females was greater with increasing number of allergies (no allergies, 31%; single allergies, 47%; multiple allergies, 88%; Pearson chi(2) = 22.5; P <.0001). Both preoperatively and postoperatively, no difference was found between cohorts with respect to SST score, VAS score, or forward flexion. There was also no difference in postoperative satisfaction between cohorts. No difference between cohorts was identified when comparing the pre- to postoperative change in SST scores, VAS scores, or forward flexion. Conclusion: The presence of single or multiple allergies is not correlated with worse outcomes after primary anatomic total shoulder arthroplasty.", "labels": [5, 31]}
{"id": "83", "token": "Purpose of Review Galactose-alpha-1,3-galactose (alpha-gal) is a carbohydrate allergen with several unique characteristics. In this article, we discuss some recent advances in our understanding of the 'alpha-gal syndrome,' highlight data supporting the role of ticks in pathogenesis, and speculate on immune mechanisms that lead to sensitization. Recent Findings First described as the target of IgE in individuals suffering immediate hypersensitivity reactions to the novel anti-EGF monoclonal antibody cetuximab, it is now clear that a-gal sensitization is associated with mammalian meat allergy as well as reactions to other mammalian products. Unlike traditional IgE-mediated food allergies, reactions to a-gal often do not manifest until several hours following an exposure, although co-factors can influence the presentation. Multiple pieces of evidence, including recent work with a mouse model, point to the fact that sensitization is mediated by exposure to certain hard ticks and increasingly we are aware of its globally widespread impact. Summary The oligosaccharide a-gal represents a novel allergen with several unusual clinical features. It has been recognized now on multiple continents and its clinical presentation can be quite variable. Moreover, efforts to delineate the mechanisms leading to a-gal sensitization may have ramifications for our broader understanding of type 2 immunity.", "labels": [5, 31]}
{"id": "189", "token": "Background The clinical utility of serum IgG measurement in the diagnosis of allergy and food-induced hypersensitivity has been largely discredited. Recent studies, however, have shown that specific IgG can inhibit IgE mediated allergies, and may play a role in allergen specific desensitization. Accurate reference intervals for IgG specific allergens have not been widely established and are needed for better interpretation of serum antibody concentrations. In this study we established 64 IgG reference intervals for 48 common food allergens, 5 venoms, and 11 molds. Design Specific IgG concentrations were determined employing an automated fluorescent enzyme immunoassay on serum samples from 130 normal adults (65 males and 65 females), age range 1869 y, mean 37.3 y. Results The lower reference interval limit for all allergens tested (n=64) was <2 mcg/mL. The median upper reference interval value for all 64 allergens was 12.9 mcg/mL, with Tuna (f40) having the lowest upper interval limit at 3.8 mcg/mL, and the mold Setomelanomma rostrate (m8) demonstrating the highest upper interval limit at 131 mcg/L. Conclusions The considerable variation observed among the upper reference interval limits emphasizes the need for the establishment of allergen specific ranges for IgG. These newly established ranges should be a useful aid for clinicians in the interpretation of laboratory serum IgG results.", "labels": [5, 31]}
{"id": "270", "token": "Many species of insects are agricultural pests which cause not only economic losses but also allergies in humans. The subject of this study was to identify important antigens from the saw-toothed grain beetle - Oryzaephilus surinamensis [OS]. Sera of 30 patients from a suburban population of Upper Silesia (Southern Poland) were tested for the presence of IgE antibodies to antigens from particular active life stages of OS (larvae, pupae and adults of both sexes). The collected proteins were fractionated by SDS PAGE and identified by Western blot. The patient's antibodies against particular antigens were identified using anti-human anti-IgE monoclonal antibody. The conducted studies showed the existence of many protein fractions for each life stage of OS which give positive reactions with IgE antibodies. The largest number of allergenic potential fractions was shown in females (23 protein fractions) and pupae (22 protein fractions) while smaller amount was shown in larvae (18 protein fractions) and males (14 protein fractions). Majority of the sera (25/30) showed positive reactions to protein fractions 25-29 kDa and 30 -34 kDa from pupae of OS. The obtained results may indicate the existence of many protein fractions with an allergenic properties in OS. It also should be stressed that all life stages of this storage insect may provoke allergic reactions in exposed subjects. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [5, 31]}
{"id": "349", "token": "The disease progression of eosinophilic esophagitis (EoE) from childhood into adulthood is unclear. To determine the clinical outcome of patients who were diagnosed with EoE as children, and who now are young adults. Children (= 18 years old) were identified, and a structured telephone interview was conducted to obtain follow-up data on symptom prevalence (dysphagia to solids and liquids, nausea/vomiting, abdominal pain, and heartburn/regurgitation), food impaction, medication usage, health-care utilization, and resolution of atopy/food allergies. A favorable outcome was defined if EoE symptoms were resolved or improved by subjects' assessment. Unfavorable outcomes was defined as symptoms same or worse. Clinical variables that predicted a favorable outcome as an adult were examined. Mayo Dysphagia Scale (MDQ-30: scored 0-100) was administered to validate the outcome assessment. Mantel-Haenszel odds ratio and unpaired t-test were used. Fifty-eight subjects (64% male) who met study criteria were enrolled. Mean age at diagnosis was 12 years (range 4-17) and mean duration of follow-up was 8.3 years (2-16). As children, the most common presenting symptoms were abdominal pain (54%), dysphagia (33%), and vomiting (24%). As young adults, 47 subjects (81%) had a favorable outcome. Total MDQ-30 scores were 4.6 (0-30) and 14.1 (0-50) in subjects with favorable outcome and unfavorable outcome, respectively (P= 0.015). Two-thirds of subjects did not use steroids or proton pump inhibitors in the preceeding 12 months. Male children with EoE were four times more likely to have a favorable outcome as young adults compared with female children. Females were more likely to report nausea/vomiting as young adults (odds ratio 3.23, CI 0.97-10.60). Of all presenting symptoms in EoE children, dysphagia was the most likely to persist into adulthood (odds ratio 6.29, CI 1.85-21.38). Eighty one percent of EoE children had a favorable outcome as young adults. Most patients with symptom resolution did not require any form of steroid therapy or seek healthcare.", "labels": [5, 31]}
{"id": "676", "token": "Despite their nutritional value, population-level nut consumption remains low. Studies suggest that individuals would eat more nuts on their doctor's advice, making health professionals potentially important for promoting nut consumption. This cross-sectional study aimed to examine the perceptions and knowledge of nuts and the predictors of nut promotion among health professionals in New Zealand. Dietitians, general practitioners (GPs), and practice nurses were identified from the Electoral Roll and invited to complete a questionnaire (n = 318, 292, and 149 respondents respectively). Over one-fifth of GPs and practice nurses believed that eating nuts could increase blood cholesterol concentrations and cause weight gain. The most common perceptions overall were that nuts are healthy; high in protein, fat, and calories; and are satiating. Nut consumption was recommended for reasons relating to these perceptions and because of nuts' selenium content. Conversely, reasons for suggesting the consumption of fewer nuts included that they were high in calories and fat, would cause weight gain, and concerns regarding allergies and cost. All groups of health professionals were more likely to promote nut consumption if they perceived nuts to reduce the risk of diabetes (all p <= 0.034). Education could improve health professionals' knowledge regarding the effects of nut consumption on blood cholesterol and body weight, alongside other health benefits, which should improve the advice given to patients and may thereby increase nut consumption.", "labels": [5, 31]}
{"id": "770", "token": "Purpose of Review The purpose of this review is to summarize the evidence from recently published original studies investigating how glutathione S-transferase (GST) gene polymorphisms modify the impact of air pollution on asthma, allergic diseases, and lung function. Recent Findings Current studies in epidemiological and controlled human experiments found evidence to suggest that GSTs modify the impact of air pollution exposure on respiratory diseases and allergies. Of the nine articles included in this review, all except one identified at least one significant interaction with at least one of glutathione S-transferase pi 1 (GSTP1), glutathione S-transferase mu 1 (GSTM1), or glutathione S-transferase theta 1 (GSTT1) genes and air pollution exposure. The findings of these studies, however, are markedly different. This difference can be partially explained by regional variation in the exposure levels and oxidative potential of different pollutants and by other interactions involving a number of unaccounted environment exposures and multiple genes. Summary Although there is evidence of an interaction between GST genes and air pollution exposure for the risk of respiratory disease and allergies, results are not concordant. Further investigations are needed to explore the reasons behind the discordancy.", "labels": [5, 31]}
{"id": "816", "token": "Migraine is a common primary headache disorder. The mechanisms underlying the onset of a migraine attack are not completely understood. Environmental changes and a number of other factors could induce migraine attacks. The aim of this study was to investigate the relationship between the frequency of migraine attacks and allergens. Migraine patients without aura, and healthy individuals similar in age and gender without a history of headache and allergy were prospectively included in the study. The duration of migraine, the frequency of migraine attacks, the medication history, and the symptoms during attacks were questioned. Migraine disability assessment score (MIDAS) and visual analog scale (VAS) scores were obtained. Allergen extracts including dust, fungi, insect, animal epithelium, pollens, and food allergens were applied for allergy tests. 49 migraine patients and 49 healthy individuals were enrolled in the study. There was no significant difference in terms of age and gender. The median migraine disease duration, the number of attacks in a month, and the duration of attacks were, respectively, 5.5 years (1-44), 4 (1-10) day/month, and 24 (4-72) h. The mean MIDAS grade was 2.45 +/- 0.14 (1-4), and mean VAS score was 7.89 +/- 0.27 (4-10). The positivity of allergy tests was 55.1 % (27/49) in the migraine group and 32.7 % (16/49) in the control group (p < 0.05). The allergy tests were positive for house dust, red birch, hazel tree, olive tree, nettle, and wheat. The frequency of migraine attacks was higher in allergy-test-positive patients than in negative ones in the migraine group (p = 0.001). The migraine patients who had frequent attacks should be examined for allergies.", "labels": [5, 31]}
{"id": "917", "token": "Background: There is an increasing recognition of epidemics of primarily tubular-interstitial chronic kidney disease (CKD) clustering in agricultural communities in low-and middle-income countries (LMICs). Although it is currently unclear whether there is a unified underlying aetiology, these conditions have been collectively termed CKD of undetermined cause (CKDu). CKDu is estimated to have led to the premature deaths of tens to hundreds of thousands of young men and women over the last 2 decades. Thus, there is an urgent need to understand the aetiology and pathophysiology of these condition (s). International comparisons have provided the first steps in understanding many chronic diseases, but such comparisons rely on the availability of standardised tools to estimate disease prevalence. This is a particular problem with CKD, since the disease is asymptomatic until the late stages, and the biases inherent in the methods used to estimate the glomerular filtration rate (GFR) in population studies are highly variable across populations. Method: We therefore propose a simple standardised protocol to estimate the distribution of GFR in LMIC populations - The Disadvantaged Populations eGFR Epidemiology (DEGREE) Study. This involves the quantification of renal function in a representative adult population-based sample and a requirement for standardisation of serum creatinine measurements, along with storage of samples for future measurements of cystatin C and ascertainment of estimates of body composition, in order to obtain valid comparisons of estimated GFR (eGFR) within and between populations. Discussion: The methodology we present is potentially applicable anywhere, but our particular focus is on disadvantaged populations in LMICs, since these appear to be most susceptible to CKDu. Although the protocol could also be used in specific groups (e.g. occupational groups, thought to be at excess risk of CKDu) the primary aim of the DEGREE project is characterise the population distribution of eGFR in multiple regions so that international comparisons can be performed. It is only with a standardised approach that it will be possible to estimate the scale of, and variation in, impaired kidney function between affected areas. These data should then provide insights into important social, demographic and environmental risk factors for this increasingly recognised disease.", "labels": [5, 31]}
{"id": "1039", "token": "Mycotoxins, the secondary metabolites of fungal species, are the most frequently occurring natural food contaminants in human and animal diets. Risk assessment of mycotoxins focused as yet on their mutagenic, genotoxic and potential carcinogenic effects. Recently, there is an increasing awareness of the adverse effects of various mycotoxins on vulnerable structures in the intestines. In particular, an impairment of the barrier function of the epithelial lining cells and the sealing tight junction proteins has been noted, as this could result in an increased translocation of luminal antigens and pathogens and an excessive activation of the immune system. The current review aims to provide a summary of the available evidence regarding direct effects of various mycotoxins on the intestinal epithelial barrier. Available data, based on different cellular and animal studies, show that food-associated exposure to certain mycotoxins, especially trichothecenes and patulin, affects the intestinal barrier integrity and can result in an increased translocation of harmful stressors. It is therefore hypothesized that human exposure to certain mycotoxins, particularly deoxynivalenol, as the major trichothecene, may play an important role in etiology of various chronic intestinal inflammatory diseases, such as inflammatory bowel disease, and in the prevalence of food allergies, particularly in children.", "labels": [5, 31]}
{"id": "1164", "token": "Ethnopharmacological relevance: Traditional medicine has used Uvaria rufa Blume as an ethnomedicinal plant for treating fever, skin allergies, intestinal ulcers and prostate disorders including BPH. However, no scientific evidence supports the traditional use. Aim of the study: This study aimed to evaluate the therapeutic potential of U. rufa on BPH using in vitro and in vivo models. Materials and methods: In vitro studies screened the efficacy of a 5 alpha-reductase (5 alpha R) inhibition and antioxidant activity of petroleum ether, ethyl acetate, ethanol and aqueous extracts from the stem of U. rufa. Phytochemical screening was performed to determine the active compound using high-performance liquid chromatography (HPLC). Ethyl acetate extract (UR-EtOAc) of U. rufa was used to evaluate the therapeutic efficacy in vivo models. BPH was induced by subcutaneous injection of testosterone propionate (3 mg/kg) to male rats for 30 days. After 30 days of oral administration of UR-EtOAc at doses of 10 and 20 mg/kg and finasteride at a dose of 1 mg/kg, the prostate weight, prostate index (PI), testosterone and androgen receptor (AR) levels, and histopathological alteration of prostate gland were determined. Also, oxidative status and toxicity indices were assessed. Results: UR-EtOAc exhibited the highest potency of inhibition of 5 alpha R and possessed potent antioxidants rich in phenolics and flavonoids contents. The active compound analyzed by HPLC was beta-sitosterol. In vivo results show a significant reduction in prostate weight, PI, and AR in all treated groups when compared to the BPH model group (P < 0.001). Also, the UR-EtOAc and finasteride treated groups had increased prostatic and serum testosterone levels when compared to the BPH model group. A histopathological investigation of the prostate glands supported the above results. UR-EtOAc elevated the antioxidant enzymes and reduced the malondialdehyde level in BPH-induced rats. Moreover, treatment of UR-EtOAc at all doses had no toxic effects on the vital organs and serum biochemical indices. Conclusions: UR-EtOAc from the stem of Uvaria rufa Blume appears to have the potential as a phytotherapeutic agent in the management of BPH, which provides the scientific evidence for traditional use.", "labels": [5, 31]}
{"id": "1246", "token": "Objectives. Adherence to the allergic rhinitis clinical practice guideline is being considered as a potential focus for national performance metrics. To help inform this discussion, we assessed patient- and clinician-reported medication administration among nationally representative populations of patients with allergic rhinitis. Study Design. Cross-sectional analyses. Setting and Subjects. Home health assessments, ambulatory visits. Methods. Participants in the National Health and Nutrition Examination Survey and the National Ambulatory Medical Care Survey / National Hospital Ambulatory Medical Care Survey were assessed. The primary outcomes were the percentage of patients reporting receipt of antihistamines and/or nasal steroids among those with allergy-related symptoms and the percentage for whom a clinician administered these medications when diagnosing allergic rhinitis. Secondary outcomes included assessments of those with worse quality of life, confirmatory allergy testing, and leukotriene receptor antagonist use. Results. Within the National Health and Nutrition Examination Survey, an estimated 29.2 million patients were diagnosed with hay fever, while 92.2 million were diagnosed with allergies. Patients with symptoms of allergic rhinitis reported that antihistamines or nasal steroids were prescribed in 21.1% to 24.0% of cases. Leukotriene receptor antagonists were given to 1.7% of those without asthma or use of other allergy medications. Within the National Ambulatory Medical Care Survey / National Hospital Ambulatory Medical Care Survey, observations representing 149.5 million visits for allergic rhinitis demonstrated that nasal steroids were administered in 29.6% of cases, while nonsedating and sedating antihistamines were given in 22.4% and 17.2%, respectively. Conclusions. Despite a high prevalence of allergic rhinitis, per patient report and clinician entry, a substantial number of affected patients do not receive antihistamines and nasal steroids.", "labels": [5, 31]}
{"id": "1309", "token": "Microbial colonization of the gastrointestinal tract is an essential process that modulates host physiology and immunity. Recently, researchers have begun to understand how and when these microorganisms colonize the gut and the early-life factors that impact their natural ecological establishment. The vertical transmission of maternal microbes to the offspring is a critical factor for host immune and metabolic development. Increasing evidence also points to a role in the wiring of the gut-brain axis. This process may be altered by various factors such as mode of delivery, gestational age at birth, the use of antibiotics in early life, infant feeding, and hygiene practices. In fac(t), these early exposures that impact the intestinal microbiota have been associated with the development of diseases such as obesity, type 1 diabetes, asthma, allergies, and even neurodevelopmental disorders. The present review summarizes the impact of cesarean birth on the gut microbiome and the health status of the developing infant and discusses possible preventative and restorative strategies to compensate for early-life microbial perturbations.", "labels": [5, 31]}
{"id": "1386", "token": "IgE-mediated allergies, in particular allergic rhinoconjunctivitis and asthma, have reached epidemic proportions, affecting about one-third of the population in developed countries. The most effective treatment for allergies is specific immunotherapy (SIT), which involves the injection of increasing doses of an allergen extract to allergic individuals. The current form of SIT was first introduced in 1911 and recently celebrated its 100th birthday for the treatment of hay fever. The concept of this therapy at the time was straightforward, as it was believed that pollen contained toxins against which the patient could be vaccinated. However, the understanding became blurred with the discovery that IgE antibodies were the effector molecules of the allergic response. Subsequent research focused on the idea that SIT should induce tolerance keeping the IgE antibodies at bay. In this review, we will discuss the various hypotheses for the mechanism of SIT and we will put forward the concept that allergens may be viewed as protoxins' which need to be activated by IgE antibodies. Within this framework, protoxin-neutralizing antibodies are the key effector molecules while a shift to Th1 or Treg cells mainly contributes to the efficacy of SIT by helping B cells to produce neutralizing IgG antibodies.", "labels": [5, 31]}
{"id": "1429", "token": "Aim: Epigenetic mechanisms are critical for normal immune development and epigenetic alterations might therefore be possible contributors to immune diseases. To investigate if DNA methylation in whole blood is associated with total and allergen-specific IgE levels. Methods: We performed an epigenome-wide association study to investigate the association between DNA methylation and IgE level, allergen-specific IgE and self-reported immune diseases and allergies in 728 individuals. Results: We identified and replicated 15 CpG sites associated with IgE, mapping to biologically relevant genes, including ACOT7, ILR5A, KCNH2, PRG2 and EPX. A total of 331 loci were associated with allergen-specific IgE, but none of these CpG sites were associated with self-reported allergies and immune diseases. Conclusion: This study shows that IgE levels are associated with DNA methylation levels at numerous CpG sites, which might provide new leads for investigating the links between IgE and allergic inflammation.", "labels": [5, 31]}
{"id": "1548", "token": "PurposeThe aim of this study was to give an overview of the prevalence of contact allergy to active ingredients and excipients of topical medications across Europe. MethodsRetrospective analysis of data collected by the European Surveillance System on Contact Allergies () with substances applied to consecutively patch tested patients, 2009-2012, in 54 departments in 12 European countries. ResultsIn view of the varying composition of the baseline series used in the previously mentioned departments and countries, between 58833 (lanolin alcohols) and 16498 patients (sodium metabisulfite) were patch tested with the topical agents covered in this study. Among these, positive (allergic) reactions were most commonly observed to sodium metabisulfite (3.12% positive), followed by propolis (2.48%), Compositae mix (1.73%), lanolin alcohols (1.65%) and caine mix III (benzocaine, cinchocaine and tetracaine; 1.27%). ConclusionsSeveral of the substances warrant routine screening for contact allergy, i.e. patch testing in a baseline series. However, in view of a vast number of other topical agents, additional patch testing with the suspect topical drug preparations (including natural remedies and cosmetics) is warranted. In the event of a positive test to the (pharmaceutical) product, single ingredients should be tested individually to precisely identify the hapten(s). Copyright (c) 2016 John Wiley & Sons, Ltd.", "labels": [5, 31]}
{"id": "1590", "token": "Glycosylation of many proteins has been revealed to be closely related with food allergies, and screening and structural analysis of related glycoproteins and glycoallergens are essential for studies in this field. Herein, we describe detailed N-glycoform analysis of all glycoprotein fractions of soybean protein isolate (SPI) separated by sodium dodecyl sulfate polyacrylamide gel electrophoresis (SDS-PAGE) to disclose structural features of the glycan moieties of more soybean glycoproteins. SPI was fractionated by SDS-PAGE, and the generated protein bands were recovered and subjected to in-gel N-glycan release and labeling using a one-pot method newly developed by our group, followed by detailed analysis by electrospray ionization mass spectrometry (ESI-MS) and online hydrophilic interaction liquid chromatography coupled with electrospray ionization tandem mass spectrometry (HILIC-ESI-MS/MS). As a result, we found seven bands mainly containing oligomannose-type glycans; two mainly contain core alpha 1,3-facosylated glycans, and six have no glycans. This study is the first report that discovers core alpha 1,3-fucosylated N-glycans in bands 1, 2, and 6 and discloses bands 3, 4, 5, and 7 as glycoproteins and their N-glycoforms. Therefore, it can expand our knowledge about soybean protein glycosylation and provide significant structural reference for research of soybean allergens.", "labels": [5, 31]}
{"id": "1755", "token": "Pollen analyses of spider web samples, collected from the recently planted Tectona grandis (T. grandis, teak)-dominated tropical deciduous forest of Bhulsidih Village, Korba District (Chhattisgarh, central India), shed light on the relationship between the extant vegetation and pollen rain. The study revealed the dominance of pollen of herbs and trees, whereas shrubs, fern spores and algal remains are meagre. Among the tree taxa, Sapotaceae, Syzygium, Holoptelea, Lannea coromandelica, Shorea robusta and Grewia are dominating with moderate to low and intermittent presence of Madhuca indica, Terminalia, Mitragyna, Schleichera, Anacardiaceae, Diospyros, Emblica officinalis and Flacourtia. However, the rest of the forest constituents are either not represented at all despite their presence in the floristics, which could be attributed to their low pollen productivity owing to entomophily as well as their poor pollen preservation pattern. On the other hand, the ground vegetation is represented by the very high frequency of grasses (Poaceae) along with Tubuliflorae, Chenopodiaceae/Amaranthaceae and Cerealia, however, Artemisia, Xanthium, Malvaceae, Caryophyllaceae and Justicia in moderate to lower values. Ferns, which occur abundantly along the adjoining stream banks, are marked by the sporadic retrieval of trilete spores that could be ascribed to the prevailing damp condition around the sampling provenance. The study, in addition to understanding the pollen-vegetation relationship, could also be helpful in aerobiological study, especially in assessing the allergenicity of various pollen grains/spores in the area of investigation, causing bronchial asthma, hay fever (allergic rhinitis/pollinosis), naso-bronchial allergy and other respiratory disorders along with conjunctivitis, contact dermatitis, eczema, food allergies and other health disorders.", "labels": [5, 31]}
{"id": "1972", "token": "Background: Reports of frequent manifestation of allergic diseases in children with attention deficit hyperactivity disorder (ADHD) have been the subject of mounting clinical interest. However, evidence supporting the association between ADHD and allergies is inconsistent and has yet to be systematically reviewed. The objective of this study was to compile and assess available studies on the association between ADHD and allergic diseases in children. Methods: A comprehensive search using MEDLINE, EMBASE, the Cochrane library, and CINAHL databases was completed in 23 November 2015. The inclusion criteria for studies were that the research assessed allergic diseases in children, 18 years of age and younger, with a diagnosis of ADHD and that a distinct comparison group was incorporated. Any comparative studies, encompassing both randomized controlled trials and observational studies, were considered for inclusion. Two review authors independently assessed the quality of the selected studies by the use of validated assessment tools, performed data extraction and conducted meta-analysis according to Cochrane Collaboration guidelines. Results: Five eligible studies were included in this systematic review. Of these studies, three were case-control and two were cross sectional studies. A majority of information from the five studies was classified as having low or unclear risk of bias. The meta-analysis showed an association between children with ADHD and asthma compared with the control groups (OR: 1.80, 95% CI: 1.57 - 2.07; five studies, low quality of evidence), but did not indicate an association between food allergy and ADHD (OR: 1.13, 95% CI: 0.88 - 1.47; three studies very low quality of evidence). The odds of experiencing allergic rhinitis, atopic dermatitis, and allergic conjunctivitis were slightly higher in children with ADHD compared with control groups, though a substantial statistical heterogeneity was notable in the overall effect estimates. Conclusions: The findings from this review and meta-analysis show that children with ADHD are more likely to have asthma, allergic rhinitis, atopic dermatitis, and allergic conjunctivitis than their counterparts. Interventions including strategies for managing allergies in children with ADHD would be beneficial.", "labels": [5, 31]}
{"id": "2119", "token": "Objective. Hypersensitivity reactions (HSR) are frequently reported in patients rechallenged with carboplatin for recurrent ovarian cancer (ROC) and represent a critical issue, since discontinuation of the platinum-based therapy could affect prognosis. Several strategies to allow platinum rechallenge have been described, with controversial outcomes. The aim of this study is to illustrate a 10-year experience with cisplatin in patients with a previous HSR to carboplatin or at risk for allergy. Methods. A retrospective review of all patients with platinum sensitive ROC retreated with carboplatin was performed between January 2007 and May 2016 at the Istituto Nazionale Tumori, Fondazione G, Pascale, Naples. Results. Among 183 patients, 49 (26.8%) presented HSR to carboplatin, mainly during second line therapy. Mean number of cycles before HSR was 8 (range 3-17). G2, G3 and G4 reaction were detected in 83%, 15% and 2% of patients, respectively. In a multivariate analysis including age, hystotype, BRCA status, previous known HSR, and combination drug administered, only the type of carboplatin-based doublet used as 2nd line therapy was found to significantly affect HSR development, with a protective effect of PLD (pegylated liposomal doxorubicin) (p = 0.014, OR = 0.027). Thirty seven patients (77%) with a previous HSR to carboplatin were rechallenged with cisplatin. Treatment was generally well tolerated. 5 patients (13.1%) experienced mild HSR to cisplatin, successfully managed in all cases. 14 patients were treated with cisplatin even without a carboplatin-related HSR due to other allergies, Among these, only one developed HSR (7.1%), Conclusions. Cisplatin rechallenge is a feasible approach in patients experiencing I-JSR to carboplatin to maintain the beneficial effect of platinum while reducing hypersensitivity-related risks. (C) 2016 Elsevier Inc. All rights reserved.", "labels": [5, 31]}
{"id": "2224", "token": "Background: Most particulate matter (PM) and health studies in children with asthma use exposures averaged over the course of a day and do not take into account spatial/temporal variability that presumably occurs as children move from home, into transit and then school microenvironments. The objectives of this work were to identify increases in morning PM exposure occurring within home, transit and school microenvironments and determine their associations with asthma-related inflammation and rescue medication use. Methods: In 2007-2008, thirty Denver-area schoolchildren with asthma performed personal PM exposure monitoring using a real-time sensor integrated with a geographic information system (GIS) to apportion exposures to home, transit and school microenvironments. Concurrently, daily monitoring of the airway inflammatory biomarker urinary leukotriene E4 (uLTE(4)) and albuterol usage was performed. Results: Mean PM exposures each morning were relatively well correlated between microenvironments for subject samples (0.3 < r < 0.8), thus limiting use of this exposure metric to attribute health effects to PM exposure in specific microenvironments. Within-microenvironment increases in exposure, such as would be characterized by one or a series of transient spikes or a sustained increase in concentration (exposure event), however, were not strongly correlated between microenvironments (vertical bar r vertical bar= 5 mu g/m(3) exposure event during transit, they demonstrated a 24.0 % increase in uLTE(4) (95 % CI: 1.5 %, 51.5 %) and a 9.7 % (-5.9 %, 27.9 %) increase in albuterol usage compared to days without transit exposure events. Associations between exposure events and health outcomes in home and school microenvironments tended to be positive as well, but weaker than for transit. Conclusions: School children with asthma moving across morning microenvironments experience spatially heterogeneous PM exposures with potentially varying health effects.", "labels": [5, 31]}
{"id": "2301", "token": "Wine, and particularly red wine, is a beverage with a great chemical complexity that is in continuous evolution. Chemically, wine is a hydroalcoholic solution (similar to 78% water) that comprises a wide variety of chemical components, including aldehydes, esters, ketones, lipids, minerals, organic acids, phenolics, soluble proteins, sugars and vitamins. Flavonoids constitute a major group of polyphenolic compounds which are directly associated with the organoleptic and health-promoting properties of red wine. However, due to the insufficient epidemiological and in vivo evidences on this subject, the presence of a high number of variables such as human age, metabolism, the presence of alcohol, the complex wine chemistry, and the wide array of in vivo biological effects of these compounds suggest that only cautious conclusions may be drawn from studies focusing on the direct effect of wine and any specific health issue. Nevertheless, there are several reports on the health protective properties of wine phenolics for several diseases such as cardiovascular diseases, some cancers, obesity, neurodegenerative diseases, diabetes, allergies and osteoporosis. The different interactions that wine flavonoids may have with key biological targets are crucial for some of these health-promoting effects. The interaction between some wine flavonoids and some specific enzymes are one example. The way wine flavonoids may be absorbed and metabolized could interfere with their bioavailability and therefore in their health-promoting effect. Hence, some reports have focused on flavonoids absorption, metabolism, microbiota effect and overall on flavonoids bioavailability. This review summarizes some of these major issues which are directly related to the potential health-promoting effects of wine flavonoids. Reports related to flavonoids and health highlight some relevant scientific information. However, there is still a gap between the knowledge of wine flavonoids bioavailability and their health-promoting effects. More in vivo results as well as studies focused on flavonoid metabolites are still required. Moreover, it is also necessary to better understand how biological interactions (with microbiota and cells, enzymes or general biological systems) could interfere with flavonoid bioavailability.", "labels": [5, 31]}
{"id": "2450", "token": "Background To date, the effects of exclusive breastfeeding duration and timing of solid food introduction on allergy prevention are unclear. The aim of this study was to determine the effect of variable feeding practices on intestinal inflammation in infants using faecal eosinophil cationic protein as a surrogate marker and to assess whether faecal eosinophil cationic protein is associated with serum immunoglobulin E. Methods Subjects (n=206) were enrolled from the Prediction of Allergies in Taiwanese CHildren (PATCH) birth cohort study. Stool samples were collected at 6 and 12 months for determining eosinophil cationic protein, and blood was collected for determining total and allergen-specific immunoglobulin E at 12 months. We compared these biomarkers between infants with variable exclusive breastfeeding duration and infants introduced to solid foods at various periods. The association between faecal eosinophil cationic protein, total serum immunoglobulin E and specific immunoglobulin E was also analysed. Results Faecal eosinophil cationic protein was significantly higher in exclusively breastfed infants compared with formula-fed infants and infants who were not exclusively breastfed at 6 months of age (P6 months did not reduce serum immunoglobulin E, but rather increased intestinal inflammation. Faecal eosinophil cationic protein was not associated with total serum immunoglobulin E and specific immunoglobulin E and might not be a useful indictor of immunoglobulin E sensitization in infancy.", "labels": [5, 31]}
{"id": "2538", "token": "Glioma is a rare brain tumour with a very poor prognosis and the search for modifiable factors is intense. We reviewed the literature concerning risk factors for glioma obtained in case-control designed epidemiological studies in order to discuss the influence of this methodology on the observed results. When reviewing the association between three exposures, medical radiation, exogenous hormone use and allergy, we critically appraised the evidence from both case-control and cohort studies. For medical radiation and hormone replacement therapy (HRT), questionnaire-based case-control studies appeared to show an inverse association, whereas nested case-control and cohort studies showed no association. For allergies, the inverse association was observed irrespective of study design. We recommend that the questionnaire-based case-control design be placed lower in the hierarchy of studies for establishing cause-and-effect for diseases such as glioma. We suggest that a state-of-the-art case-control study should, as a minimum, be accompanied by extensive validation of the exposure assessment methods and the representativeness of the study sample with regard to the exposures of interest. Otherwise, such studies cannot be regarded as 'hypothesis testing' but only 'hypothesis generating'. We consider that this holds true for all questionnaire-based case-control studies on cancer and other chronic diseases, although perhaps not to the same extent for each exposure-outcome combination.", "labels": [5, 31]}
{"id": "2755", "token": "Atopic eczema (synonymous with atopic dermatitis) is a common heterogeneous phenotype with a wide spectrum of severity, from mild transient disease to a severe chronic disorder with atopic and non-atopic comorbidities. Eczema is a complex trait, resulting from the interaction of multiple genetic and environmental factors. The skin, as an organ that can be biopsied easily, provides opportunities for detailed molecular genetic analysis. Strategies applied to the investigation of atopic eczema include candidate gene and genome-wide studies, extreme phenotypes, and comparative analysis of inflammatory skin diseases. Genetic studies have identified a central role for skin barrier impairment in eczema predisposition and perpetuation; this has brought about a paradigm shift in understanding atopic disease, but specific molecular targets to improve skin barrier function remain elusive. The role of Th2-mediated immune dysfunction is also central to atopic inflammation, and has proved to be a powerful target for biological therapy in atopic eczema. Advances in understanding eczema pathogenesis have provided opportunities for patient stratification, primary prevention, and therapy development, but there remain considerable challenges in the application of this knowledge to optimize benefit for patients with atopic eczema in the era of personalized medicine. Copyright (C) 2016 Pathological Society of Great Britain and Ireland. Published by John Wiley & Sons, Ltd.", "labels": [5, 31]}
{"id": "2958", "token": "Objective. Behcet's disease (BD) is a systemic inflammatory disorder polarised to the Th1 and Th17 immune systems. Allergic diseases are polarised to the Th2 immune system. The aim of the present study is to investigate the prevalence of allergic diseases in patients who have BD. Methods. The study involved a large-scale interview survey of Japanese patients with BD at 21 institutes of ophthalmology; 353 patients (255 males and 98 females) were recruited for this study. We analysed the history of allergic diseases such as atopic dermatitis (AD), allergic rhinitis (AR), bronchial asthma (BA) and drug/food allergies (FA). Results. Oral aphthous ulcers, ocular lesions, skin lesions, genital ulcers, arthritis, neurological lesions, intestinal lesions, deep vein thrombosis and epididymitis were reported in 95.8%, 98.6%, 72.5%, 44.8%, 13.9%, 6.8%, 6.2%, 3.7% and 1.4% of the patients, respectively. It was also reported that 73 patients (20.7%) had histories of allergic diseases: AD (5 cases, 1.4%), AR (36 cases, 10.2%), BA (19 cases, 5.4%) and FA (30 cases, 8.5%). This percentage was significantly lower than in a survey that Japan's Ministry of Health, Labour and Welfare conducted for healthy population (47.6%) (odds ratio = 0.29, 95% confidence interval = 0.22-0.38, p=4.9 x 10(-22)). Frequencies of posterior/panuveitis, relatively severe ocular findings, and visual prognosis were not affected by a history of allergic diseases in BD. Conclusion. Patients with BD had fewer complications from allergic diseases than did the entire population of Japan.", "labels": [5, 31]}
{"id": "3030", "token": "Background: Prevalence of allergic diseases and impaired pulmonary function may be high in children born prematurely. This study aimed to assess pulmonary function and prevalence of asthma, atopic diseases and allergic sensitisation in these patients. Methods: A cross-sectional study was conducted with children aged 6-14 years who were born prematurely with birth weight <2000 g from January 2008 to May 2011. Exclusion criteria were: major malformations, or acute respiratory disorders. The International Study of Asthma and Allergies in Childhood questionnaire was applied followed by allergic skin prick test and spirometry. Results: The study included 84 children aged 9.3 +/- 2.3 years born at mean gestational age of 31.8 +/- 2.4 weeks. The prevalence of current asthma was 25%, more severe asthma was 15.5%; rhinitis was 38.1%; flexural eczema was 8.3%; and a positive skin-prick test was 69.6%. Frequencies of children with values <80% of predicted were: FVC (8.3%), FEV1 (22.6%), and FEV1/FVC ratio (16.7%). Prevalence of children with FEF25-75% <70% of the predicted value was 32.4%, positive bronchodilator response was observed in 20.5% of cases, and altered pulmonary function in 42.9%. Factors associated with altered pulmonary function were oxygen dependency at 28 days of life (OR: 4.213, p=0.021), the presence of wheezing in childhood (OR: 5.979, p=0.014) and infant's height (OR: 0.945, p=0.005). Conclusions: There was a high prevalence of severe asthma, allergic sensitisation, and altered pulmonary function among children and adolescents born prematurely. Bronchopulmonary dysplasia and a history of wheezing were risk factors for altered pulmonary function. (C) 2016 SEICAP. Published by Elsevier Espana, S.L.U. All rights reserved.", "labels": [5, 31]}
{"id": "3169", "token": "Aim: This study explored the under-researched area of whether preterm birth or bronchopulmonary dysplasia (BPD) affected hospitalisation rates, allergies or health-related quality of life (HRQoL). Methods: We studied 88 schoolchildren born preterm at a mean gestational age of 28.8 weeks (range 24.1-31.9) and matched term-born controls at the mean age of 11 years (range 8- 14). Hospitalisations after the first discharge were recorded, skin prick allergy tests were performed and HRQoL was assessed with a parental questionnaire. Results: Preterm children were hospitalised more than controls (64% versus 39%, p = 0.001), mostly before two years of age. The adjusted odds ratios (OR) for two-year-old preterm-born children being hospitalised for wheezing was 8.2 (95% CI 2.0-34.1). BPD affected 56% of the preterm children, but did not influence hospitalisations, and the positive skin prick rate was similar between the preterm and term-born children (35% versus 48%, p = 0.126). Preterm BPD children had fewer positive skin prick tests than those without BPD. HRQoL was lower in preterm than term children (81.25 +/- 10.84 versus 86.80 +/- 9.60, p = 0.001). Conclusion: Most health problems experienced by preterm-born schoolchildren occurred before two years of age and were mainly wheezing disorders. BPD decreased atopy but had no influence on hospitalisation rates.", "labels": [5, 31]}
{"id": "3353", "token": "Rhododendron anthopogon D. Don., a small compact Himalayan shrub growing in Nepal, is a known medicinal plant used to treat sore throat, colds, blood disorders, bone disease, potato allergies, and vomiting, and to relieve liver disorders, headaches and back pain. The present study investigated the chemical composition and bioactivities of the leaf essential oil from R. anthopogon from Dhankuta, Nepal. The essential oil from leaves was obtained by hydrodistillation and a detailed chemical analysis was conducted by gas chromatography mass spectrometry (GC-MS). The enantiomeric distribution of monoterpenoid components was determined using chiral gas chromatography and represents the first chiral examination of R. anthopogon essential oil. The essential oil was screened for antimicrobial activity using the microbroth dilution test, and for cytotoxic activity against MCF-7, MDA-MB-231, and 5637 using the MTT assay. A total of 70 volatile components were identified from the essential oil. The major components were alpha-pinene (21.5%), delta-cadinene (13.8%), beta-pinene (9.5%), limonene (5.9%), delta-amorphene (4.6%), alpha-muurolene (4.5%), and (E)-caryophyllene (3.2%) with other minor constituents (< 3%). The essential oil showed marginal antibacterial and cytotoxic activities, but no antifungal effects.", "labels": [5, 31]}
{"id": "3488", "token": "Background: Orally disintegrating tablets (ODTs) are a modern form of tablets that when placed in the oral cavity, disperses rapidly. These tablets have advantages, particularly good applications for children and old patients who have a complication in chewing or swallowing solid dosage forms. The aim of this study was to design, formulate, and evaluate the physicochemical properties of 5 mg montelukast ODTs for the prevention of asthma and seasonal allergies. Methods: Formulations were prepared with different amounts of super disintegrating agents and effervescent bases as disintegrant agents. Flowability and compressibility of mixed powders were evaluated. The prepared formulations were tested for hardness, thickness, friability, weight variation, drug content, wetting time, disintegration time, dissolution study, and moisture uptake studies. Results: The compressibility index and angle of repose were in the range of 15.87%-23.43% and 32.93-34.65, respectively. Hardness, thickness, friability, wetting time, and content uniformity of formulations were in the range of 33.7-37.1 N, 3.00-3.81 mm, 0.27%-0.43%, 31-50 s and 96.28%-99.90%, respectively. Disintegration time of the tablets prepared with super disintegrating agents, effervescent bases, and combination of two were in the range of 30-50, more than 60 and 20-36 s, respectively. Conclusions: Mixture of powders and tablets passed all the specified tests. The results showed formulations prepared by super disintegrating agents and super disintegrating agents with effervescent bases had shorter disintegration time compared to formulations with effervescent bases alone.", "labels": [5, 31]}
{"id": "30", "token": "Based on the qualitative research of elite interviews and narrative analysis of Hungarian documents, the main aim of this article is twofold: (1) to elucidate the transformation of Jobbik from a marginal extra-parliamentary youth focused movement to an influential parliamentary party; (2) to discuss the impact of Jobbik's ascension on the main centre right Fidesz only as a pre-conclusion. It argues that the rise of Jobbik is not a protest phenomenon that simply demonstrates a social disenchantment with the transitional economy. Jobbik's transformation is a unique post-Communist political development that is rooted in elements of Hungarian nationalism. These national elements include underlying social prejudice against Roma and Jews, a preference for paternalistic economic systems, and even attraction to the historical narrative of mythic Turanism in the debate over the origins of Hungarian national identity. Jobbik manipulates all of these national elements for the transformation of its own party identity, emerging as a main challenger to the Fidesz. (C) 2016 Published by Elsevier Ltd on behalf of The Regents of the University of California.", "labels": [2, 15]}
{"id": "111", "token": "This study presents an innovative field experiment exploring ethnic discrimination in contacts between local public officials and members of Swedish society. Using a correspondence study design, fictitious individuals with Arabic-and Swedish-sounding names contacted Swedish municipalities via email, asking questions about access to preschools. The findings indicate disadvantageous treatment of individuals with Arabic-sounding names in terms of the informal tone of the replies, as Swedish-sounding names were replied to in a friendlier, more welcoming way. Regarding the more formal aspects of the emails - i.e., whether they were replied to at all and the questions posed were directly answered - no statistically significant signs of discrimination emerge (although differences were of some substantial size, to the disadvantage of Arabic-sounding names). Still, informal disadvantageous treatment is sufficient cause for concern and noteworthy in the case of Sweden, considering its reputation as being egalitarian, immigration friendly and democratically well functioning.", "labels": [2, 15]}
{"id": "226", "token": "How do varying levels of inter-group contact affect voter preferences in connection with ethnically radical political candidates and parties? Two competing hypotheses have emerged in the last 60 years: the first, known as the group threat hypothesis, argues that voters from an ethnic or religious group in more ethnically or racially heterogeneous districts will exhibit stronger preferences for ethnically radical political candidates. The contact hypothesis argues that groups living in mixed localities are actually less likely to support ethnic radicals. Both perspectives have found empirical support, but no previous study has offered a theoretical explanation for two seemingly contradictory conclusions. We specify just such a theory, arguing that the effect of district level integration is conditioned by the direction of a group's share of the national population. We test this theory quantitatively using electoral data from Northern Ireland between 1983 and 2010.", "labels": [2, 15]}
{"id": "371", "token": "Poultry and pork farming are typical activities of small farms in southern Brazil. This production plays an important social and economic role in many of these areas as it is often the main income source. The swine compost has emerged as an alternative to reduce the volume of swine wastewater, which is transformed into a residue that can be easily transported and applied with less environment prejudice. However, there is no information in literature regarding the use of this compound as a source of nitrogen in grain crops. Therefore, the aim of this study was to evaluate poultry litter and swine compost as organic sources of nitrogen for the millet crop. The experiment was conducted in the years of 2013 and 2014 in southern Brazil, in no-tillage systems in a Hapludox soil. The treatments were: control (without nitrogen); poultry litter (PL), swine compost (SC) and mineral fertilization (NPK). The use of poultry litter resulted in better averages for almost all evaluated variables. Although the swine compost did not express results as good as the crop treated with poultry litter, the crop in which the swine compound was applied presented better results for some plant parameters than the chemical fertilizer treatment, which shows that these two residues can be viable alternatives for nitrogen fertilization in millet cultivations.", "labels": [2, 15]}
{"id": "544", "token": "Nonheterosexual individuals are half as likely as their heterosexual counterparts to report a religious identity. Gay, lesbian, bisexual, and queer (GLBQ) emerging adults who maintain a religious identity and affiliation throughout their adolescent and young adult years challenge dominant narratives of sexuality and religion (Pew, 2012, 2013). This study contextualizes these demographic findings and considers their impact on family life and sexual identity. The authors present data from 11 qualitative interviews with GLBQ individuals between the ages of 20 and 25. Results are presented in a model describing how participants constructed a GLBQ Christian identity, and how they perceive the acceptance of their identities in both their families and church communities.", "labels": [2, 15]}
{"id": "716", "token": "Objectives: The purpose of this study was to analyze the parenting experiences of mothers of children who stutter based on the grounded theory. Methods: The participants were six mothers of children who stutter. An in-depth interview was conducted, transcribed and analyzed according to the grounded theory method. Results: The data was analyzed into 172 concepts, 33 subcategories and 16 categories. The core phenomenon in the parenting experiences of mothers of children who stutter was a sense of 'Ultimate repression for normality'. The causal conditions of the core phenomenon were found to be an 'Apparent stuttering manifestation'. This phenomenon was found to be reinforced by the contextual conditions of 'Vague expectation,' 'Child's response' and 'Support from others'. 'Personality tendency', ' Personal values', and ' Putting on a front' were found to be the remedial factors with respect to the core phenomenon of a sense of Ultimate repression for normality'. Among the remedial strategies reported for 'Ultimate repression for normality' were ' Exploring methods', 'Compromise', 'Avoidance' and 'Badgering'. Those remedial strategies created 'Confidence,' 'Low self-esteem' and 'Remorse'. The parenting experiences of mothers of children who stutter were classified into four types. Conclusion: The results of this study indicated that any program intended to remedy a mother's sense of 'Ultimate repression for normality' should be managed not only by the clinicians themselves, but also by an academy or professional association. The study further concluded that societal prejudice against stuttering needs to be dealt with at the societal and governmental levels.", "labels": [2, 15]}
{"id": "810", "token": "Objective: This research focused on how race-based rejection sensitivity (RS-Race) and components of racial identity intensify negative psychological reactions to an incident of vicarious racism. We examined how these individual difference variables directly and/or indirectly predicted African American students' reactions to the trial of George Zimmerman in the killing of the African American teenager, Trayvon Martin. Method: In Study 1, 471 African American students completed measures of RS-Race, thought intrusions about the Zimmerman trial, and outcome variables (negative affect about the Zimmerman trial and forgiveness for Mr. Zimmerman). In Study 2, 304 African American students completed measures of racial identity (centrality, private regard, and public regard), thought intrusions about the Zimmerman trial, negative affect, and forgiveness. Results: In Study 1, higher RS-Race was either directly and/or indirectly (via thought intrusions) related to more negative affect and lower forgiveness. In Study 2, high racial centrality and low public regard either directly and/or indirectly (via thought intrusions) predicted more negative affect and lower forgiveness. Conclusions: RS-Race and specific components of racial identity are likely to sensitize African Americans to incidents of racism that happen to other African Americans, leading to negative psychological reactions when these events occur.", "labels": [2, 15]}
{"id": "877", "token": "This paper explores the extent to which people of different origins, natives and migrants, come together in everyday life in Europe. Instead of looking at overall perceptions' and stances', which are context-dependent and mediated through political-ideological currents and discourses as well as broader patterns of prejudice, we focus on sustained close contacts that suggest meaningful and organic relationships. Since it is most often people of migrant background who are blamed for leading parallel lives' and not integrating', we chose to focus on them and their interethnic friendships. Moreover, we seek to understand the relevance and role of the neighbourhood context in the development of those relationships. Despite the expressive fears in public discourses about the supposed negative impact of the presence of immigrants and ethnic minorities on social cohesion, our findings indicate that close interethnic relationships are not uncommon in diverse European cities. They further highlight that the neighbourhood context plays an important role in the first years of migrants' settlement. Relationships in the neighbourhood develop in less formal social settings and are also less demanding in terms of host-country cultural skills on the part of the migrants, thus giving the opportunity to newcomers to develop close interethnic relationships with natives. Finally, the analysis supports the positive role of diversity at the neighbourhood level in the development of interethnic friendships and stresses the importance of the neighbourhood's socio-spatial characteristics and its location in the wider urban net.", "labels": [2, 15]}
{"id": "932", "token": "For decades, increasing intergroup contact has been the preferred method for improving cooperation between groups. However, even proponents of this approach acknowledge that intergroup contact may not be effective in the context of intractable conflicts. One question is whether anything can be done to increase the impact of intergroup contact on cooperation. In the present study, we tested whether changing perceptions of group malleability in a pre-encounter intervention could increase the degree of cooperation during contact encounters. Jewish and Palestinian-Israeli adolescents (N = 141) were randomly assigned either to a condition that taught that groups are malleable or to a coping, control condition. During a subsequent intergroup encounter, we used two behavioral tasks to estimate the levels of cooperation. Results indicated that relative to controls, participants in the group malleability condition showed enhanced cooperation. These findings suggest new avenues for enhancing the impact of contact in the context of intractable conflicts.", "labels": [2, 15]}
{"id": "1320", "token": "Theorists and researchers have noted an overlap between individuals who are bisexually-identified and queer-identified. Although early definitions of bisexuality may have been predominantly binary (i.e., attracted to women and men), in recent years there has been a move toward a more queer understanding of bisexuality (e.g., attraction to more than one gender beyond women and men). The purpose of this study was to examine similarities and differences between adult women who were bisexually-identified and those who were queer-identified, ages 18 to 66 years, on sociodemographic characteristics, two dimensions of sexual orientation (sexual behaviors and attractions), fluidity in attractions and sexual orientation identity, and identity centrality and affirmation in an online sample (N = 489), which was mostly from the United States (73.5%). Results indicated that women who are bisexual and queer were similar in terms of sociodemographic characteristics, with the exception of education; women identifying as queer were more educated than women identifying as bisexual. Women identifying as queer were also more likely than women identifying as bisexual to report variability in their sexual behaviors and attractions and more fluidity in their sexual orientation identity. Additionally, women identifying as queer reported higher levels of identity centrality and affirmation than women identifying as bisexual. Considerations for sexual minority women's health research are discussed.", "labels": [2, 15]}
{"id": "1450", "token": "This study examines the factorial invariance of the Scale on Beliefs About Children's Adjustment in Same-Sex Families (SBCASSF) across countries in three samples: Chilean, Spanish, and Hispanic university students. The scale analyzes attitudes toward the consequences of the rearing and education of children by parents with a homosexual sexual orientation. The instrument consists of two subscales: Individual Opposition and Normative Opposition. The Spanish sample is composed of 199 university students, the Chilean sample is made up of 279 students, and the Hispanic sample consists of 114 students. The results provide empirical evidence for the reliability of the SBCASSF in the samples from the countries and its factorial invariance (strict invariance). Results are also provided about differences between countries and by sex. The SBCASSF could be a potentially useful measure for educators, psychologists, and other mental health professionals who wish to study beliefs about the child-rearing practices of same-sex parents.", "labels": [2, 15]}
{"id": "1507", "token": "For over a century, genetic arguments for the existence of racial inequality have been used to oppose policies that promote social equality. And, over that same time period, American biology textbooks have repeatedly discussed genetic differences between races. This experiment tests whether racial terminology in the biology curriculum causes adolescents to develop genetic beliefs about racial difference, thereby affecting prejudice. Individual students (N=135, grades 7-9) were randomly assigned within their classrooms to learn either from: (i) four text-based lessons discussing racial differences in skeletal structure and the prevalence of genetic disease (racial condition); or (ii) an identical curriculum lacking racial terminology (nonracial condition). Over 3-months that coincided with this learning, students in the racial condition grew significantly more in their perception of the amount of genetic variation between races relative to students in the nonracial condition. Furthermore, those in the racial condition grew in their belief that races differ in intelligence for genetic reasons significantly more than those in the nonracial condition. And, compared to the nonracial condition, students in the racial condition became significantly less interested in socializing across racial lines and less supportive of policies that reduce racial inequality in education. These findings show how biology education sustains racial inequality, and conversely, how human genetic variation education could be designed to reduce genetically based racism. (C) 2016 Wiley Periodicals, Inc.", "labels": [2, 15]}
{"id": "1700", "token": "Lesbian, gay, bisexual, transgender, and queer and questioning (LGBTQ) discrimination continues to be common on college campuses. While a number of studies have examined blatant victimization among students, little attention has been given to LGBTQ microaggressions. In this study, we examine both blatant victimization and microaggressions and their association with psychological distress among LGBTQ college students (N = 497) and look at whether gender identity moderates these relationships. Both forms of discrimination are associated with lower self-esteem and greater stress and anxiety. Victimization is more negatively associated with self-esteem among trans* students. Our findings emphasize the importance of addressing both blatant and subtle forms of discrimination targeting LGBTQ college students.", "labels": [2, 15]}
{"id": "1806", "token": "There is a rich literature on the nature of mental health-related stigma and the processes by which it severely affects the life chances of people with mental health problems. However, applying this knowledge to deliver and evaluate interventions to reduce discrimination and stigma in a lasting way is a complex and long-term challenge. We conducted a narrative synthesis of systematic reviews published since 2012, and supplemented this with papers published subsequently as examples of more recent work. There is evidence for small to moderate positive impacts of both mass media campaigns and interventions for target groups in terms of stigma-related knowledge, attitudes, and intended behaviour in terms of desire for contact. However, the limited evidence from longer follow-up times suggests that it is not clear whether short-term contact interventions have a lasting impact. The risk that short-term interventions may only have a short-term impact suggests a need to study longer term interventions and to use interim process and outcome data to improve interventions along the way. There is scope for more thorough application of intergroup contact theory whenever contact is used and of evidence-based teaching and assessment methods when skills training is used for target groups.", "labels": [2, 15]}
{"id": "1974", "token": "Using data collected in Canada, the United States, and the United Kingdom, this article examines the determinants of attitudes toward immigrants. In particular, we draw on the literature in social psychology to explore the role of locus of control in promoting more ethnocentric and restrictive attitudes towards immigration. We conceptualize control at three levels: (1) perceptions of individual locus of control (i.e., feeling that one can control one's own circumstances), (2) perceptions of societal control (i.e., feeling that one's country has control over immigration), and (3) perceptions of an outgroup's locus of control (i.e., feeling that an outgroup's social circumstances are attributable to dispositional rather than external factors). Results show that all three measures of control are important predictors of negative attitudes toward immigrants: Those who feel in control (personally or as a society) are less hostile towards immigrants, while those who attribute negative outcomes to immigrants' predispositions are also more hostile. Results also suggest that measures of control are related to, but distinct from, both partisanship and racial prejudice.", "labels": [2, 15]}
{"id": "2083", "token": "Past work suggested that dual identity was effective to reduce prejudice. This study extended research on dual identity and prejudice by identifying a boundary condition in this relationship, that is, group permeability. In Study 1, we replicated previous studies with Chinese individuals and found that inducing dual identity (emphasizing subgroup differences and a common nation identity), compared to the control condition, decreased the urban residents' prejudice against rural-to-urban migrants. In Study 2, we manipulated the group boundary permeability using the Hukou system reform, and found that when the group boundary was permeable, dual identity was effective in reducing prejudice against rural-to-urban migrants. However, this effect vanished in the condition where the group boundary was impermeable. These results point to the importance of inducing dual identity under specific conditions for research on decreasing prejudice. Some practical implications of the findings for urbanization and immigration are discussed.", "labels": [2, 15]}
{"id": "2226", "token": "The prevalence of developmentally vulnerable children living with parental mental illness has been well documented, however due to stigmatised attitudes and prejudice these children may be 'hidden' and not identified as requiring additional assistance in early childhood settings. The aim of the present study was to explore the experiences and workforce needs of centre-based child care staff working with families living with parental mental illness. Eight staff (four child care workers and four child care directors) who worked in centre-based child care were interviewed using a semi-structured interviews. The data were analysed using an Interpretative Phenomenology Analysis framework. The findings of the present study highlighted four central themes: child development issues, tension around referral and worker anxiety, inadequate knowledge and training about parental mental illness and sensitivity when working with families. While these participants knowingly prioritized the importance of working with families in their daily work, they described feeling stressed and anxious about discussing referral options with these parents, and often worried about 'making things worse' for the child and the parent. The present study has contributed knowledge in regard to an important segment of the early childhood workforce; such information can inform the development of tailored professional training and resources that provide information about referral procedures and support programs for these families. (C) 2017 Published by Elsevier Ltd.", "labels": [2, 15]}
{"id": "2338", "token": "Background: Implicit biases involve associations outside conscious awareness that lead to a negative evaluation of a person on the basis of irrelevant characteristics such as race or gender. This review examines the evidence that healthcare professionals display implicit biases towards patients. Methods: PubMed, PsychINFO, PsychARTICLE and CINAHL were searched for peer-reviewed articles published between 1st March 2003 and 31st March 2013. Two reviewers assessed the eligibility of the identified papers based on precise content and quality criteria. The references of eligible papers were examined to identify further eligible studies. Results: Forty two articles were identified as eligible. Seventeen used an implicit measure (Implicit Association Test in fifteen and subliminal priming in two), to test the biases of healthcare professionals. Twenty five articles employed a between-subjects design, using vignettes to examine the influence of patient characteristics on healthcare professionals' attitudes, diagnoses, and treatment decisions. The second method was included although it does not isolate implicit attitudes because it is recognised by psychologists who specialise in implicit cognition as a way of detecting the possible presence of implicit bias. Twenty seven studies examined racial/ ethnic biases; ten other biases were investigated, including gender, age and weight. Thirty five articles found evidence of implicit bias in healthcare professionals; all the studies that investigated correlations found a significant positive relationship between level of implicit bias and lower quality of care. Discussion: The evidence indicates that healthcare professionals exhibit the same levels of implicit bias as the wider population. The interactions between multiple patient characteristics and between healthcare professional and patient characteristics reveal the complexity of the phenomenon of implicit bias and its influence on clinician-patient interaction. The most convincing studies from our review are those that combine the IAT and a method measuring the quality of treatment in the actual world. Correlational evidence indicates that biases are likely to influence diagnosis and treatment decisions and levels of care in some circumstances and need to be further investigated. Our review also indicates that there may sometimes be a gap between the norm of impartiality and the extent to which it is embraced by healthcare professionals for some of the tested characteristics. Conclusions: Our findings highlight the need for the healthcare profession to address the role of implicit biases in disparities in healthcare. More research in actual care settings and a greater homogeneity in methods employed to test implicit biases in healthcare is needed.", "labels": [2, 15]}
{"id": "2373", "token": "Criminal-justice-involved clients often are a complicated population for students to consider through a lens of oppression. Nevertheless, it is critical that they do so given that many will serve clients with criminal records during their careers. An attempt to challenge students' prejudice toward criminal-justiceinvolved people was deployed using a teaching technique derived from intergroup contact theory. The authors invited Juan Melendez to share his story of incarceration on death row for more than 17 years for a crime he did not commit. This article is an examination of the impact of Mr. Melendez's story and the application of intergroup contact theory.", "labels": [2, 15]}
{"id": "2418", "token": "Positive intergroup contact with socially and economically advantaged national majorities has been shown to reduce ethnic identification among minorities, thereby undermining ethnic minority activism. This finding implies that ethnic identity is the relevant social identity driving ethnic minorities' struggle for equality. We argue that the study of the sedating effect of positive intergroup contact for minorities should be more nuanced. The existence of multiple and sometimes interplaying social identities can foster a reinterpretation of the meaning of ethnic activism. This study therefore examines how the interplay of ethnic and national identities shapes the sedating effect of contact on minority activism. We expect national identification to buffer the sedated activism resulting from reduced ethnic identification. That is, the mediation from intergroup contact to reduced ethnic activism through weakened ethnic identification is expected to be moderated by national identification. With survey data from Bulgaria, we investigated support for ethnic activism among Bulgarian Roma (N = 320) as a function of their contact with the national majority as well as their degree of ethnic and national identification. The predicted moderated mediation was revealed: a negative indirect relationship between contact and activism through decreased ethnic identification occurred among Roma with low national identification, whereas no sedating effect occurred among Roma identifying strongly as members of the Bulgarian nation. We discuss the meaning of national identification for the Roma minority, who experience harsh discrimination in countries where they have been historically settled, as well as convergence of these findings with work on dual identification. We highlight the role of interacting social identities in mobilizing resources for activism and the importance of adopting a critical view on ethnic discourse when studying activism in both traditional and immigrant minorities.", "labels": [2, 15]}
{"id": "2532", "token": "Theories of race relations have been shaped by the concept of a racial hierarchy along which Whites are the most advantaged and African Americans the most disadvantaged. However, the recent precipitated growth of Latinos and Asian Americans in the United States underscores the need for a framework that integrates more groups. The current work proposes that racial and ethnic minority groups are disadvantaged along 2 distinct dimensions of perceived inferiority and perceived cultural foreignness, such that the 4 largest groups in the United States are located in 4 discrete quadrants: Whites are perceived and treated as superior and American; African Americans as inferior and relatively American compared with Latinos and Asian Americans; Latinos as inferior and foreign; and Asian Americans as foreign and relatively superior compared to African Americans and Latinos. Support for this Racial Position Model is first obtained from targets' perspectives. Different groups experience distinct patterns of racial prejudice that are predicted by their 2-dimensional group positions (Studies 1 and 2). From perceivers' perspectives, these group positions are reflected in the content of racial stereotypes (Study 3), and are well-known and consensually recognized (Study 4). Implications of this new model for studying contemporary race relations (e.g., prejudice, threat, and interminority dynamics) are discussed.", "labels": [2, 15]}
{"id": "2598", "token": "Weight-related issues (including excess weight, disordered eating and body concerns) are often considered as comprising distinct domains of 'obesity' and 'eating disorders'. In this commentary we argue that the concept of weight bias is an important variable when considering wellbeing across the spectrum of weight-related issues. We make the following six points in support of this argument: i) weight bias is common and has adverse health consequences, ii) shaming individuals for their body weight does not motivate positive behaviour change, iii) internalized weight bias is particularly problematic, iv) public health interventions, if not carefully thought out, can perpetuate weight bias, v) weight bias is a manifestation of social inequity, and vi) action on weight bias requires an upstream, population-level approach. To achieve sustainable reductions in weight bias at a population level, substantive modifications and collaborative efforts in multiple settings must be initiated. We provide several examples of population-level interventions to reduce weight bias.", "labels": [2, 15]}
{"id": "2680", "token": "Community engagement of migrants has been identified as an important element in developing both individual well-being and cohesive multicultural receiving communities. Through 10 in-depth interviews, this study explores the profile of Moroccan migrant leaders in community organizations in the receiving context (south of Spain) and the reasons for which they engage. Moreover, it analyzes the relationship established between community engagement and their well-being. The results show that migrants commit for both intrinsic (e.g., support their compatriots) and extrinsic (e.g., increase their social connection) reasons. Their social action has a positive influence on their well-being because it activates the following paths: (1) improvement of bicultural competences; (2) development of social relationships with receiving members; (3) strengthening of social bonds with compatriots; (4) increase of abilities in dealing with unjust social conditions in the new environment; and (5) decrease of prejudice towards their own cultural group.", "labels": [2, 15]}
{"id": "2861", "token": "Scholars have been increasingly interested in how everyday interactions in various places with people from different ethnic/religious background impact inter-group relations. Drawing on representative surveys in Leeds and Warsaw (2012), we examine whether encounters with ethnic and religious minorities in different type of space are associated with more tolerance towards them. We find that in Leeds, more favourable affective attitudes are associated with contact in institutional spaces (workplace and study places) and socialisation spaces (social clubs, voluntary groups, religious meeting places); however, in case of behavioural intentions operationalised as willingness to be friendly to minority neighbours only encounters in socialisation spaces play a significant role in prejudice reduction. In Warsaw, people who have contacts with ethnic and religious minorities in public (streets, park, public services and transport) and consumption spaces (cafes, pubs, restaurants) express more positive affective attitudes towards them, but only encounters in consumption space translate into willingness to be friendly to minority neighbours. (C) 2016 The Authors. Published by Elsevier Inc.", "labels": [2, 15]}
{"id": "2888", "token": "An experiment (N=177) examined how user-generated comments on a crime news article, which attribute the reported crime to the local residents' predispositions, affect individuals' processing of the news and their reality perception. Participants who viewed the regionalism-invoking comments estimated the crime rates of the featured region to be higher than those exposed to regionalism-irrelevant or regionalism-counterbalancing comments, and such effects were more pronounced for those with a stronger regional self-identity. Moreover, those who read regionalism-related comments, either regionalism-invoking or regionalism-counterbalancing, (a) recalled better the locations featured in the focal and the subsequent, yet unrelated, news articles and (b) attributed greater responsibility to news media coverage for the persistence of regionalism, as compared to those who viewed regionalism-irrelevant comments.", "labels": [2, 15]}
{"id": "3028", "token": "In the Netherlands, as in most other western European countries, the desirability and the governability of a multicultural society are topics of debate. In the last decade, this debate has increasingly centred on second-generation migrants, focusing on their high rates of crime and school drop-out. In the Dutch context, however, little scholarly research has paid attention to second-generation migrants' own experiences. In this paper, I therefore focus on the perceptions of ethnic boundaries held by 12- to 19-year-old second-generation migrants and how they negotiate these boundaries in the low-income, multi-ethnic Feijenoord area of Rotterdam. The study shows that young people are used to living together with many different cultures and see themselves as being on both sides of the ethnic boundary between the Dutch-majority society and the culture of their parents. However, they also encounter prejudice and discrimination in their day-to-day lives, which calls into question the success of multiculturalism.", "labels": [2, 15]}
{"id": "3082", "token": "The present study examined legal perceptions of lesbian intimate partner violence (IPV) in an experimental context. Undergraduate women and men from the Southeastern United States (N = 217) read a trial summary in which the defendant was charged with physically assaulting her same-sex partner. The trial varied as to whether the victim and defendant were depicted via images as either feminine or masculine. Participants rendered verdicts and made judgments about the victim and defendant (e.g., credibility). Results indicated that the victim's and defendant's masculine or feminine appearance affected these judgments. Female participants viewed a masculine victim as more credible than a feminine victim when the defendant was masculine. When the victim was masculine, they viewed a masculine defendant as more responsible for the victim's injuries than a feminine defendant. Male participants had higher sympathy for a masculine versus feminine victim overall, but had more anger toward a masculine defendant versus a feminine defendant accused of assaulting a feminine victim. Finally, fewer participants mentioned the defendant's history of violence as a reason for a guilty of felony verdict for a feminine victim with a feminine defendant versus all other combinations of victim and defendant masculine/feminine appearance. Results are discussed in terms of gender stereotypes influencing legal decision-making in IPV cases among lesbian couples.", "labels": [2, 15]}
{"id": "3247", "token": "Does social influence exerted through role modeling of collective action impact social change in contexts that are not conducive to collective action, such as long-lasting violent conflicts? We examined this question in two field experiments in the Eastern Democratic Republic of Congo. We created two versions of an episode of an existing media intervention (a show aiming to promote positive social change), in which fictional characters either planned collective action (role modeling condition), or did not plan action (control condition) to address grievances. In Study 1, role modeling affected individual-level outcomes: it increased perceived collective efficacy and willingness to take action, but exacerbated intergroup attitudes and reduced tolerance. Study 2 tested the influence of role modeling on a group-level outcome (group discussions). Discussions following the role modeling show focused less on grievances, and included more positive lessons of the show, as well as more statements about collective efficacy and collective action. The findings highlight the influence of role modeling of collective action through media on efficacy and action for social change, but caution against unintended consequences on intergroup attitudes. (C) 2016 Elsevier Inc All rights reserved.", "labels": [2, 15]}
{"id": "3426", "token": "The American flag is a powerful symbol that campaigns seek to harness for electoral gain. But the flag's benefits may be more elusive than they appear. We begin by presenting content analysis of the flag's prevalence in 2012 U.S. presidential campaign ads, which suggests both candidates saw flags as advantageous. Then, in two experiments set during the 2012 campaign and a later study with prospective 2016 candidates, we find flag exposure provides modest but consistent benefits for Republican candidates among voters high in symbolic patriotism, racial prejudice, and Republican identification. These effects arise regardless of which candidate appears with the flag. Taken together, our results speak to both the power and limitations of the American flag in electioneering. Beyond practical implications for campaigns, these studies emphasize the heterogeneity of citizens' reactions to visual political symbols and highlight potent links between symbolic attitudes and a nation's flag.", "labels": [2, 15]}
{"id": "3562", "token": "This study was intended to analyze the intersection of experience of sexual stigma low-socioeconomic status, and suicide attempt amongst young Brazilians (11-24 years old). In each of the data collection periods (2004-2006: n = 7185; 2010-2012: n = 2734), participants completed a questionnaire-based instrument. Network analysis provided support for a Minority Stress Model, oriented around whether participants had experienced sexual stigma. Although suicide attempts decreased by 20% for participants who had not experienced sexual stigma, there was a 60% increase for those who had experienced sexual stigma. Of particular note were the increases in rates of reported community and familial physical assault, molestation, and rape for those who had experienced sexual stigma. An analysis of centrality statistics demonstrated that both experiences of this Minority Stress Model were fundamentally different, and that those disparities increased over the time frame observed in this study. At the center of this model, shortest paths statistics exhibited a direct conditioned connection between experiencing sexual stigma and suicide attempts. We discuss the social and historical contexts that contributed to these dynamics, and emphasize the need for policy change.", "labels": [2, 15]}
{"id": "31", "token": "This work numerically studies transient behaviour of particulate flows in a cylindrical-conical spouted bed in terms of comparative analysis of different models' predictions. Two approaches were used: a laminar flow model and a turbulent flow model. As a reference case, we consider experimental studies by He et al.,([ 14,15]) where the profiles of vertical particle velocities and the void fraction in the spout and the fountain of a full-column spout bed were measured. In this work we used the Euler-Euler unsteady multiphase model with the Syamlal-O'Brien, Gidaspow, and Wen-Yu drag models available in commercial CFD software Fluent 14.0. Analysis of results obtained by the use of laminar and turbulent flow models revealed almost identical solid and gas phase velocities and phase fractions within the spouted bed region. We found that the turbulence plays a significant role only in the gas phase above the spouted bed and it does not have any influence on the solid phase. Comparing our simulation results in the form of time-averaged vertical velocity of the solid phase against experimental data showed acceptable agreement in the spout and very good agreement in the fountain region. Numerical simulations with the Syamlal-O'Brien drag model gave better agreement with experimental data than results obtained using the Gidaspow and Wen-Yu drag models. To analyze the transient behaviour of the spouted bed, we use the volume-averaged particle velocity and gas phase velocity. The analysis of their time histories showed that the start up time is 2-3 s. The developed unsteady regime is reached after 4-5 s. Additionally we studied numerically the influence of different discretization schemes for convective terms on the final results. We found that the use of 1st order upwind scheme gives a steady state solution for both models, laminar and turbulent. Finally, we investigated the influence of the restitution coefficient on the transient characteristics of a cylindrical-conical spouted bed. A decrease in the value of the restitution coefficient leads to an increase in the period of oscillations of the volume-averaged velocities of the gas and solid phases.", "labels": [3, 24]}
{"id": "77", "token": "A combined experimental and computational study of the transfer of transparent index-matched silica-particle inks between two flat plates is presented for gravure printing applications. The influence of printing speed and initial ink droplet size on the ability to accurately transfer ink during the printing process is explored systematically. Smooth interface volume of fluid simulations show the same trends as the ink transfer observed in experiments over a wide range of printing speeds and for inks having different silica particle loadings. Our calculations indicate that for ink droplets with characteristic dimensions in the vicinity of 10 mu m, which are of particular interest for gravure printing applications, ink transfer improves significantly due to the diminishing effect of gravity, and the increased importance of capillary forces at small length scales. VC 2016 American Institute of Chemical Engineers AIChE J, 63: 1419-1429, 2017", "labels": [3, 24]}
{"id": "245", "token": "In this study, we present a high-order numerical method based on a combined compact integrated RBF (IRBF) approximation for viscous flow and fluid structure interaction (FSI) problems. In the method, the fluid variables are locally approximated by using the combined compact IRBF, and the incompressible Navier-Stokes equations are solved by using the velocity-pressure formulation in a direct fully coupled approach. The fluid solver is verified through various problems including heat, Burgers, convection-diffusion equations, Taylor-Green vortex and lid driven cavity flows. It is then applied to simulate some FSI problems in which an elastic structure is immersed in a viscous incompressible fluid. For FSI simulations, we employ the immersed boundary framework using a regular Eulerian computational grid for the fluid mechanics together with a Lagrangian representation of the immersed boundary. For the immersed fibre/membrane FSI problems, although the order of accuracy of the present scheme is generally similar to FDM approaches reported in the literature, the present approach is nonetheless more accurate than FDM approaches at comparable grid spacings. The numerical results obtained by the present scheme are highly accurate or in good agreement with those reported in earlier studies of the same problems. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [3, 24]}
{"id": "320", "token": "Benthic (streambed) biofilms metabolize a substantial fraction of particulate organic matter and nutrient inputs to streams. These microbial communities comprise a significant proportion of overall biomass in headwater streams, and they present a primary control on the transformation and export of labile organic carbon. Biofilm growth has been linked to enhanced fine particle deposition and retention, a feedback that confers a distinct advantage for the acquisition and utilization of energy sources. We quantified the influence of biofilm structure on fine particle deposition and resuspension in experimental stream mesocosms. Biofilms were grown in identical 3 m recirculating flumes over periods of 18-47 days to obtain a range of biofilm characteristics. Fluorescent, 8 mu m particles were introduced to each flume, and their concentrations in the water column were monitored over a 30 min period. We measured particle concentrations using a flow cytometer and mesoscale (10 mu m to 1 cm) biofilm structure using optical coherence tomography. Particle deposition-resuspension dynamics were determined by fitting results to a stochastic mobile-immobile model, which showed that retention timescales for particles within the biofilm-covered streambeds followed a power-law residence time distribution. Particle retention times increased with biofilm areal coverage, biofilm roughness, and mean biofilm height. Our findings suggest that biofilm structural parameters are key predictors of particle retention in streams and rivers.", "labels": [3, 24]}
{"id": "446", "token": "Whilst many vertebrates appear externally left-right symmetric, the arrangement of internal organs is asymmetric. In zebrafish, the breaking of left-right symmetry is organised by Kupffer's Vesicle (KV): an approximately spherical, fluid-filled structure that begins to form in the embryo 10 hours post fertilisation. A crucial component of zebrafish symmetry breaking is the establishment of a cilia-driven fluid flow within KV. However, it is still unclear (a) how dorsal, ventral and equatorial cilia contribute to the global vortical flow, and (b) if this flow breaks left-right symmetry through mechanical transduction or morphogen transport. Fully answering these questions requires knowledge of the three-dimensional flow patterns within KV, which have not been quantified in previous work. In this study, we calculate and analyse the three-dimensional flow in KV. We consider flow from both individual and groups of cilia, and (a) find anticlockwise flow can arise purely from excess of cilia on the dorsal roof over the ventral floor, showing how this vortical flow is stabilised by dorsal tilt of equatorial cilia, and (b) show that anterior clustering of dorsal cilia leads to around 40 % faster flow in the anterior over the posterior corner. We argue that these flow features are supportive of symmetry breaking through mechano-sensory cilia, and suggest a novel experiment to test this hypothesis. From our new understanding of the flow, we propose a further experiment to reverse the flow within KV to potentially induce situs inversus.", "labels": [3, 24]}
{"id": "593", "token": "Mechanical models for tumor growth have been used extensively in recent years for the analysis of medical observations and for the prediction of cancer evolution based on image analysis. This work deals with the numerical approximation of a mechanical model for tumor growth and the analysis of its dynamics. The system under investigation is given by a multi-phase flow model: The densities of the different cells are governed by a transport equation for the evolution of tumor cells, whereas the velocity field is given by a Brinkman regularization of the classical Darcy's law. An efficient finite difference scheme is proposed and shown to converge to a weak solution of the system. Our approach relies on convergence and compactness arguments in the spirit of Lions [P.-L. Lions, Mathematical topics in fluid mechanics. Vol. 2. Vol. 10 of Oxford Lecture Series Math. Appl. The Clarendon Press, Oxford University Press, New York (1998)].", "labels": [3, 24]}
{"id": "646", "token": "This paper analyzes the electromechanics of the spherical metal particles in AC gas-insulated lines (GIL) with a pragmatic test rig comprising coaxial cylindrical electrodes. Analysis on fluid resistance during the particle moving process is presented based on fluid mechanics as well as the kinetic parameters of the SF6/N-2 mixture. The interactive impacts between the particle and the conductor or the shell are also proposed based on collision theory of elastic mechanics considering random effects caused by the metal surface roughness. With the above aspects being included, a dynamic motion model for the spherical metal particles within AC GIL is established accordingly, and experimental studies are carried out to validate effectiveness and accuracy of the proposed model. Meanwhile, simulations are done regarding a real 220 kV AC GIL for further governance and verifications. The research observations indicate that, the applied voltage exerts an incremental effect on the maximum height of the moving particle, but won't affect the spread angle of the particle motion. Both the height and the spread angle of the particle's motion show inflection points with increased particle radius. On the contrary, the maximum height of the moving particle decreases with the increase of SF6 ratio and the gas pressure.", "labels": [3, 24]}
{"id": "723", "token": "The flow of viscous fluid in the cochlea induces shear forces, which could provide benefit in clinical practice, for example to guide cochlear implant insertion or produce static pressure to the cochlear partition or wall. From a research standpoint, studying the effects of a viscous fluid in the cochlea provides data for better understanding cochlear fluid mechanics. However, cochlear perfusion with a viscous fluid may damage the cochlea. In this work we studied the physiological and anatomical effects of perfusing the cochlea with a viscous fluid. Gerbil cochleae were perfused at a rate of 2.4 mu L/min with artificial perilymph (AP) and sodium hyaluronate (Healon, HA) in four different concentrations (0.0625%, 0.125%, 0.25%, 0.5%). The different HA concentrations were applied either sequentially in the same cochlea or individually in different cochleae. The perfusion fluid entered from the round window and was withdrawn from basal scala vestibuli, in order to perfuse the entire perilymphatic space. Compound action potentials (CAP) were measured after each perfusion. After perfusion with increasing concentrations of HA in the order of increasing viscosity, the CAP thresholds generally increased. The threshold elevation after AP and 0.0625% HA perfusion was small or almost zero, and the 0.125% HA was a borderline case, while the higher concentrations significantly elevated CAP thresholds. Histology of the cochleae perfused with the 0.0625% HA showed an intact Reissner's membrane (RM), while in cochleae perfused with 0.125% and 0.25% HA RM was torn. Thus, the CAP threshold elevation was likely due to the broken RM, likely caused by the shear stress produced by the flow of the viscous fluid. Our results and analysis indicate that the cochlea can sustain, without a significant CAP threshold shift, up to a 1.5 Pa shear stress. Beside these finding, in the 0.125% and 0.25% HA perfusion cases, a temporary CAP threshold shift was observed, perhaps due to the presence and then clearance of viscous fluid within the cochlea, or to a temporary position shift of the Organ of Corti. After 0.5% HA perfusion, a short latency positive peak (P0) appeared in the CAP waveform. This P0 might be due to a change in the cochlea's traveling-wave pattern, or distortion in the cochlear microphonic. (C) 2016 Elsevier B.V. All rights reserved.", "labels": [3, 24]}
{"id": "905", "token": "In this paper, we present a numerical solution method which is based on Taylor Matrix Method to give approximate solution of the Bagley-Torvik equation. Given method is transformed the Bagley-Torvik equation into a system of algebraic equations. This algebraic equations are solved through by assistance of Maple 13. Then, we have coefficients of the generalized Taylor series. So, we obtain the approximate solution with terms of the generalized Taylor series. Further some numerical examples are given to illustrate and establish the accuracy and reliability of the proposed algorithm.", "labels": [3, 24]}
{"id": "948", "token": "A numerical model is developed in the framework of OpenFOAM; an open source computational fluid dynamics (CFD) simulation code to simulate particle laden dense flows. The model uses discrete element method (DEM) for the discrete/particle phase and computational fluid dynamics approach (CFD) for the fluid/continuum phase. In current study, validation of the model is done in two steps. In first step the drag model is validated by comparing the results of settling velocity of spherical particle. In second step, spout fluidization test cases with different operating conditions are simulated and results of numerical simulation of spout-fluidized bed are compared against experimental and simulation results reported in literature. The isosurface plots of solid volume fraction show a good qualitative prediction of different flow regimes. The particle velocity profiles in the vertical direction for different test cases corresponding to different flow regimes are plotted and compared with the literature data. The predictions of the model are in good agreement with the experimental and numerical results reported in the literature. (C) 2016 Elsevier Inc. All rights reserved.", "labels": [3, 24]}
{"id": "1016", "token": "We have developed a new method for the efficient numerical simulation of colloidal suspensions. This method is designed and especially well-suited for parallel code execution, but it can also be applied to single-core programs. It combines the Stokesian Dynamics method with a variant of the widely used Barnes-Hut algorithm in order to reduce computational costs. This combination and the inherent parallelization of the method make simulations of large numbers of particles within days possible. The level of accuracy can be determined by the user and is limited by the truncation of the used multipole expansion. Compared to the original Stokesian Dynamics method the complexity can be reduced from 0(N2) to linear complexity for dilute suspensions of strongly clustered particles, N being the number of particles. In case of non-clustered particles in a dense suspension, the complexity depends on the particle configuration and is between O(N) and O(Pn(p, max)(2)), where P is the number of used processes and n(p, max) = inverted right perpendicularN/Pinverted left perpendicular, respectively. (C) 2016 Elsevier B.V. All rights reserved.", "labels": [3, 24]}
{"id": "1138", "token": "The purpose of this study is to carry out a thorough, critical analysis of the Morison equation as far as calculating wave action on large diameter piles like those used nowadays in offshore wind farms is concerned. The aim is to observe whether models currently used to estimate wave forces on piles are valid for large diameter piles apart from observing what the main forces in play in scouring are. This equation enables wave produced forces on a cylinder supported on the sea bed to be calculated. The study includes observations on the calculation model's sensitivity as to a variation in the cylinder's diameter, on the one hand and, on the other, as to temperature and salinity variation. With this in mind, specific software has been developed to simulate equations in fluid mechanics applied to solve the wave structure interaction problem in the separation, inertial and diffraction range. This software will enable an iterative calculation to be made for finding out the shape of the pressure wave caused when a wave passes over and will show the results for different pile diameters and water temperature.", "labels": [3, 24]}
{"id": "1201", "token": "Self-powered triboelectric nanosensor (TENS) has attracted increasing attention in recent years due to its independent and sustainable operations without external power source. In this paper, we demonstrate a newly designed fully packaged liquid-solid TENS based on the friction between polytetrafluoroethylene (PTFE) filtration membranes and water. The dependencies of output performance of water-based TENS on the water to-cylinder volume ratio, vibration frequency and amplitude using fluid mechanics analysis are demonstrated. By modifying PTFE filtration membrane with dopamine, this TENS can be used as dopamine sensor with high selectivity and sensitivity (detection limit of 0.1 mu M, a linear range from 10 mu M to 1 mM). Besides, by mixing with organics (such as ethanol) to decrease the water polarity, this TENS can be used as a sensor for the detection of ethanol concentration in water with fast response at room temperature. Compared with the existing solid-solid triboelectrication based TENS, this fully packaged liquid-solid triboelectrication based TENS is portable, easily fabricated, and has potential application for detecting toxic pollutants in water with higher sensitivity.", "labels": [3, 24]}
{"id": "1287", "token": "The present work proposes a novel method of detection and estimation of outliers in particle image velocimetry measurements by the modification of the temporal coefficients associated with a proper orthogonal decomposition of an experimental time series. Using synthetic outliers applied to two sequences of vector fields, the method is benchmarked against state-of-the-art approaches recently proposed to remove the influence of outliers. Compared with these methods, the proposed approach offers an increase in accuracy and robustness for the detection of outliers and comparable accuracy for their estimation.", "labels": [3, 24]}
{"id": "1420", "token": "High speed self-excited oscillation pulsed waterjet (SEOPW) offers many advantages over continuous jets or external-excited pulsed jets and has a large number of practical and industrial applications, In order to take better advantage of SEOPWs, effects of area discontinuity at nozzle inlet were analyzed based on the previous related research and then experimentally investigated with respect to the axial pressure oscillations. A jet-driven Helmholtz oscillator, which is capable of producing effective SEOPWs, was employed in the experiment. It was found that area discontinuity has a capacity of enhancing the peak, which largely depends on the inlet pressure and standoff distance. The enhancement decreases with increasing inlet pressure and only happens within small standoff distances. Compared with the continuous case, area enlargement enhances the peak by 25%, 21%, and 16%, corresponding to inlet pressures of 10, 15, and 20 MPa, respectively; while area contraction turns to be a better one by improving the peak by 8% at inlet pressure of 25 MPa. However, at inlet pressure of 30 MPa, both enlargement and contraction decrease the peak. Moreover, area discontinuity cannot influence the optimum standoff distance where the maximum peak appears. For the pressure oscillation amplitude, even both area discontinuities have the ability of increasing the amplitude regardless of inlet pressure and standoff distance, contraction enhances the amplitude much more than enlargement does at all the testing inlet pressures. In addition, area discontinuity has nearly no influence on the oscillating frequency and causes perturbations that may only affect the intensity of self-excitation by amplitude. (C) 2016 Elsevier Inc. All rights reserved.", "labels": [3, 24]}
{"id": "1610", "token": "We propose a framework for developing a comprehensive biophysical model that could predict and simulate realistic longitudinal MRIs of patients with Alzheimer's disease (AD). The framework includes three major building blocks: i) atrophy generation, ii) brain deformation, and iii) realistic MRI generation. Within this framework, this paper focuses on a detailed implementation of the brain deformation block with a carefully designed biomechanics-based tissue loss model. For a given baseline brain MRI, the model yields a deformation field imposing the desired atrophy at each voxel of the brain parenchyma while allowing the CSF to expand as required to globally compensate for the locally prescribed volume loss. Our approach is inspired by biomechanical principles and involves a system of equations similar to Stokes equations in fluid mechanics but with the presence of a non-zero mass source term. We use this model to simulate longitudinal MRIs by prescribing complex patterns of atrophy. We present experiments that provide an insight into the role of different biomechanical parameters in the model. The model allows simulating images with exactly the same tissue atrophy but with different underlying deformation fields in the image. We explore the influence of different spatial distributions of atrophy on the image appearance and on the measurements of atrophy reported by various global and local atrophy estimation algorithms. We also present a pipeline that allows evaluating atrophy estimation algorithms by simulating longitudinal MRIs from large number of real subject MRIs with complex subject-specific atrophy patterns. The proposed framework could help understand the implications of different model assumptions, regularization choices, and spatial priors for the detection and measurement of brain atrophy from longitudinal brain MRIs. (C) 2016 Elsevier Inc. All rights reserved.", "labels": [3, 24]}
{"id": "1754", "token": "Quantitative evaluation of the shear threshold on C. tinctorius L. cell growth is vital for bioreactor system design and optimization of scaled-up industrial cultivation. The present research focused on investigating the effects of shear force on C. tinctorius L cell growth by computational fluid dynamic (CFD) analysis in shaken flasks. The results revealed that specific cell growth rates were greatly inhibited as the shear force increased from 1.17 to 2.42 Pa. Recovery of viability and aggregation diameter to their normal levels could be implemented after a 4-day adaptation with large fluctuations in physiological state. With further correlation analysis on shear force and C. tinctorius L. growth rate, a threshold value was identified at an average and maximum shear stress of approximately 0.55 Pa (0.06 w/kg) and 4.00 Pa (0.93 w/kg) according to the influence on cell growth. Quantitative data on shear effects can facilitate the design of industrial processes and lead to more rational scale-up in industrial C. tinctorius L cultivation. (C) 2016 Elsevier B.V. All rights reserved.", "labels": [3, 24]}
{"id": "1887", "token": "In the present study, we address the development and application of an efficient tool for conversion of results obtained by an integrated computational fluid dynamics (CFD) and computational reaction dynamics (CRD) approach and their visualization in the Google Earth. We focus on results typical for environmental fluid mechanics studies at a city scale that include characteristic wind flow patterns and dispersion of reactive scalars. This is achieved by developing a code based on the Java language, which converts the typical four-dimensional structure (spatial and temporal dependency) of data results in the Keyhole Markup Language (KML) format. The visualization techniques most often used are revisited and implemented into the conversion tool. The potential of the tool is demonstrated in a case study of smog formation due to an intense traffic emission in Rotterdam (The Netherlands). It is shown that the Google Earth can provide a computationally efficient and user-friendly means of data representation. This feature can be very useful for visualization of pollution at street levels, which is of great importance for the city residents. Various meteorological and traffic emissions can be easily visualized and analyzed, providing a powerful, user-friendly tool for traffic regulations and urban climate adaptations.", "labels": [3, 24]}
{"id": "2022", "token": "The present article is focused on a 2D computational fluid mechanics study of local viscous flow dynamics and the formation character of rotary modes of deformation during Equal Channel Multiple Angular Extrusion (ECMAE) of a polymer workpiece fluid model through a U-shaped die with parallel slants in channel intersection zones. The present local flow problem was experimentally analyzed using physical simulation methods and theoretically studied with numerical fluid mechanics techniques. The computational approach has been grounded on the numerical finite difference solution of the boundary value problem for the Navier-Stokes equations in the curl transfer form for the local viscous flow of incompressible Newtonian fluid through a U-shaped rectangular die with parallel slants. The derived research results allow us to draw a conclusion that the implementation of a geometric design of parallel slants within a 2-turn U-shaped die results in localization of the maximum tangential stresses within the workpiece volume to the vicinity of these parallel slants during ECMAE.", "labels": [3, 24]}
{"id": "2118", "token": "We present a method for structural and fluid mechanics computations of ram-air parachutes. A ram-air parachute is a parafoil inflated by the airflow through the inlets at the leading edge. It has better control and gliding capability than round parachutes. Reliable analysis of ram-air parachutes requires accurate representation of the parafoil geometry, fabric porosity and the complex, multiscale flow behavior involved in this class of problems. The key components of the method are (i) the Space-Time Variational Multiscale (ST-VMS) method, (ii) the version of the ST Slip Interface (ST-SI) method where the SI is between a thin porous structure and the fluid on its two sides, (iii) the ST Isogeometric Analysis (ST-IGA), and (iv) special-purpose NURBS mesh generation techniques for the parachute structure and the flow field inside and outside the parafoil. The ST-VMS method is a stabilized formulation that also serves as a turbulence model and can deal effectively with the complex, multiscale flow behavior. With the STSI version for porosity modeling, we deal with the fabric porosity in a fashion consistent with how we deal with the standard SIs and how we enforce the Dirichlet boundary conditions weakly. The ST-IGA, with NURBS basis functions in space, gives us, with relatively few number of unknowns, accurate representation of the parafoil geometry and increased accuracy in the flow solution. The special-purpose mesh generation techniques enable NURBS representation of the structure and fluid domains with significant geometric complexity. The test computations we present are for building a starting parachute shape and a starting flow field associated with that parachute shape, which are the first two key steps in fluid-structure interaction analysis. The computations demonstrate the effectiveness of the method in this class of problems. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [3, 24]}
{"id": "2256", "token": "This work proposes a novel physics-based model for the fluid mechanics and heat transfer associated with slug flow boiling in horizontal circular microchannels to update the widely used three-zone model of Thome et al. (2004). The heat transfer model has a convective boiling nature and predicts the time dependent variation of the local heat transfer coefficient during the cyclic passage of a liquid slug, an evaporating elongated bubble and a vapor plug. The capillary flow theory, extended to incorporate evaporation effects, is applied to estimate the bubble velocity along the channel. A liquid film thickness prediction method also considering bubble proximity effects, which may limit the radial extension of the film, is included. The minimum liquid film thickness at dryout is set to the channel wall roughness. Theoretical heat transfer models accounting for the thermal inertia of the liquid film and for the recirculating flow within the liquid slug are utilized. The heat transfer model is compared to experimental data taken from three independent studies. The 833 slug flow boiling data points cover the fluids R134a, R245fa and R236fa, and channel diameters below 1 mm. The proposed evaporation model predicts more than 80% of the database to within +/- 30%. It demonstrates a stronger contribution to heat transfer by the liquid slugs and correspondingly less by the thin film evaporation process compared to the original three-zone model. This model represents a new step towards a complete physics-based modelling of the bubble dynamics and heat transfer within microchannels under evaporating flow conditions. (C) 2017 Elsevier Ltd. All rights reserved.", "labels": [3, 24]}
{"id": "2318", "token": "This case study trialled the introduction of a student-response system (Top Hat) in a third-year engineering Fluid Mechanics course (n=44) to improve student engagement, motivation and cognition. It was recognised that for the potential benefits of student-response systems (SRSs) to be fully realised, more time must be allocated for student engagement and the active learning components of the course. In order to allow sufficient time to fully engage with the SRSs and other classroom activities, traditional lectures were revised and the classroom format was flipped. This paper presents the initial case study results focusing on the use of SRSs. Overall, the new flipped lecture and SRS teaching format demonstrated a substantial increase in the level of student engagement, motivation, active learning and attendance compared to previous cohorts. However, the increased levels of engagement did not appear to reflect on any large increase in students' individual grades.", "labels": [3, 24]}
{"id": "2552", "token": "Polluted insulators frequently face flashover accident and it threatens the safety and stability of power system. In order to help to reduce the occurrence of flashover, it is necessary to study the contamination characteristics of insulators and its influence factors. In this study, the contamination of insulator is simulated by the Eulerian multiphase model in computational fluid dynamics. The flow field around insulators is calculated and the volume fraction of the particle phase is used to characterise the pollution degree on insulator surface. Results show that the pollution is mainly distributed on windward side and leeward side of insulator. The crosswind side of insulator is slightly contaminated. The four influence factors, wind velocity, particle concentration, particle diameter and flow angle have different effects on insulator contamination. Among these factors the particle concentration contributes most to the whole contamination degree of insulators. A wind tunnel contamination test on insulator is carried out to verify the feasibility of the numerical simulation. It can be found that simulated contamination distribution and variation of contamination degree with wind velocity well coincide with the results of wind tunnel test. The numerical simulation in this study is practical in studying the insulator contamination.", "labels": [3, 24]}
{"id": "2615", "token": "Based on fluid mechanics theories, this research focuses on numerical simulation and analysis of capillary flow under microgravity in fan-shaped asymmetric interior corner. We analyze the effect the contact angle has on rising height in a fan-shaped asymmetric interior corner, and get the Concus-Finn condition the calculation of capillary flow needs to satisfy in fan-shaped asymmetric interior corner. Then we study the effect that different parameters of experimental medium and container configuration has on capillary flow in fan-shaped asymmetric interior corner when Concus-Finn condition is fulfilled. The conclusions of this paper has an important role in guiding the analytic solution of flow in a fan-shaped asymmetric interior corner under microgravity. We can also chose the appropriate experimental medium and design a container based on this paper.", "labels": [3, 24]}
{"id": "2739", "token": "We derive the John-Sclavounos equations, describing the motion of a fluid particle on the sea surface, from first principles using Lagrangian and Hamiltonian formalisms applied to the motion of a frictionless particle constrained on an unsteady surface. This framework leads to a number of new insights into the particle kinematics. The main result is that vorticity generated on a stress-free surface vanishes at a wave crest when the horizontal particle velocity equals the crest propagation speed, which is the kinematic criterion for wave breaking. If this holds for the largest crest, then the symplectic two-form associated with the Hamiltonian dynamics reduces instantaneously to that associated with the motion of a particle in free flight, as if the surface did not exist. Further, exploiting the conservation of the Hamiltonian function for steady surfaces and travelling waves, we show that particle velocities remain bounded at all times, ruling out the possibility of the finite-time blowup of solutions.", "labels": [3, 24]}
{"id": "2946", "token": "In this paper we prove the existence and regularity of a solution to a two-dimensional system of evolutionary hemivariational inequalities which describes the Boussinesq model with nonmonotone friction and heat flux. We use the time retardation and regularization technique, combined with a regularized Galerkin method, and recent results from the theory of hemivariational inequalities. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [3, 24]}
{"id": "3068", "token": "Demand for green energy production is arising all over the world. A lot of emphasis is laid in making the buildings green. Even a small amount of energy savings made contribute to saving the environment. In this study, an idea is proposed and studied to extract power from the high head water in the pipelines of a building. A building of height 15 m is considered for this study. Water flowing in the pipe has sufficient energy to run a micro hydro turbine. The feasibility of producing electrical energy from the energy of pipe water is found. The motivation is to find the feasibility of generating power using a low-cost turbine. The experimental setup consists of micro turbine of 135 mm diameter coupled to a 12-V DC generator; LEDs and resistors are employed to validate the results. The theoretical calculations were presented using the fundamental equations of fluid mechanics. The theoretical results are validated using experimental and numerical results using CFD simulation. In addition, exergy analysis has been carried out to quantify the irreversibilities during the process in the system.", "labels": [3, 24]}
{"id": "3274", "token": "We present a preliminary examination of a new approach to a long-standing problem in non-Newtonian fluid mechanics. First, we summarize how a general implicit functional relation between stress and rate of strain of a continuum with memory is reduced to the well-known linear differential constitutive relations that account for relaxation and retardation. Then, we show that relaxation and retardation are asymptotically equivalent for small Deborah numbers, whence causal pure relaxation models necessarily correspond to ill-posed pure retardation models. We suggest that this dichotomy could be a possible way to reconcile the discrepancy between the theory of and certain experiments on viscoelastic liquids that are conjectured to exhibit only stress retardation. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [3, 24]}
{"id": "3382", "token": "Flow vectoring by a pair of synthetic jets is suitable for modification of the global flow characteristics with practical applications in active flow control and adaptive heat convection. The interaction of a pair of synthetic jets, with a separation distance s =3.3D, stroke length L-0 = 29D, and Reynolds number Re = 300, are investigated numerically using computational fluid dynamics (CFD) and experimentally using particle image velocimetry (PIV). To achieve the most realistic calculation- of the flow induced by synthetic jets, a full unsteady RANS simulation is performed of the internal flow in two cavities as well as the external jet flow using a dynamic mesh technique. The results for the intricate flow vectoring phenomenon show a reasonable quantitative agreement with PIV measurements, with a maximum deviation from PIV measurements of 14% for stream -wise centreline velocity in 10 < y/D < 20. The effect of phase difference between the pair of jets on the vectoring of the merged jet is investigated for delta phi = 0 degrees, 60 degrees and 130 degrees. The merged jet is vectored in the direction of the cavity that is leading in phase, with a similar trend shown by the experimental and numerical results of instantaneous and time -averaged vortical structures. This leads to a better physical understanding of the fluid mechanics of adjacent synthetic jets, and will enhance the theoretical basis needed to promote their practical application. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [3, 24]}
{"id": "3514", "token": "Endothelial cells (ECs) line the interior of blood and lymphatic vessels and experience spatially varying wall shear stress (WSS) as an intrinsic part of their physiological function. How ECs, and mammalian cells generally, sense spatially varying WSS remains poorly understood, due in part to a lack of convenient tools for exposing cells to spatially varying flow patterns. We built a multiplexed device, termed a 6-well impinging flow chamber, that imparts controlled WSS gradients to a six-well tissue culture plate. Using this device, we investigated the migratory response of lymphatic microvascular ECs, umbilical vein ECs, primary fibroblasts, and epithelial cells to WSS gradients on hours to days timescales. We observed that lymphatic microvascular ECs migrate upstream, against the direction of flow, a response that was unique among all the cells types investigated here. Time-lapse, live cell imaging revealed that the microtubule organizing center relocated to the upstream side of the nucleus in response to the applied WSS gradient. To further demonstrate the utility of our device, we screened for the involvement of canonical signaling pathways in mediating this upstream migratory response. These data highlight the importance of WSS magnitude and WSS spatial gradients in dictating the cellular response to fluid flow.", "labels": [3, 24]}
{"id": "32", "token": "Lactic Acid Bacteria (LAB) are ancient organisms that cannot biosynthesize functional cytochromes, and cannot get ATP from respiration. Besides sugar fermentation, they evolved electrogenic decarboxylations and ATP-forming deiminations. The right balance between sugar fermentation and decarboxylation/deimination ensures buffered environments thus enabling LAB to survive in human gastric trait and colonize gut. A complex molecular cross-talk between LAB and host exists. LAB moonlight proteins are made in response to gut stimuli and promote bacterial adhesion to mucosa and stimulate immune cells. Similarly, when LAB are present, human enterocytes activate specific gene expression of specific genes only. Furthermore, LAB antagonistic relationships with other microorganisms constitute the basis for their anti-infective role. Histamine and tyramine are LAB bioactive catabolites that act on the CNS, causing hypertension and allergies. Nevertheless, some LAB biosynthesize both gamma-amino-butyrate (GABA), that has relaxing effect on gut smooth muscles, and beta-phenylethylamine, that controls satiety and mood. Since LAB have reduced amino acid biosynthetic abilities, they developed a sophisticated proteolytic system, that is also involved in antihypertensive and opiod peptide generation from milk proteins. Short-chain fatty acids are glycolytic and phosphoketolase end-products, regulating epithelial cell proliferation and differentiation. Nevertheless, they constitute a supplementary energy source for the host, causing weight gain. Human metabolism can also be affected by anabolic LAB products such as conjugated linoleic acids (CLA). Some CLA isomers reduce cancer cell viability and ameliorate insulin resistance, while others lower the HDL/LDL ratio and modify eicosanoid production, with detrimental health effects. A further appreciated LAB feature is the ability to fix selenium into seleno-cysteine. Thus, opening interesting perspectives for their utilization as antioxidant nutraceutical vectors.", "labels": [6, 37]}
{"id": "80", "token": "In today's hectic lifestyle, health has been seriously hampered due to sedentary work. This paper represents an idea of walking based wearable piezoelectric device that provides an alternate means for powering mobile phone batteries. Moreover, it simultaneously serves another purpose of providing an emergency torch. Since, the mechanism of the device is based on walking; the device promotes human metabolism as well as physical fitness. Hence, it can be seen as an e-health gadget that encourages walking exercise as a means to power emergency torch and mobile phone batteries. The portable device comprises of a piezoelectric power generator, connectors for charging different mobile phone batteries and a Light Emitting Diode (LED) embedded in shoe for providing emergency torch. Piezoelectric circuit harvests energy from user's trotter movement. This energy is amplified, rectified by using a DC convertor and then regulated to 4.2 volts which is required by a Li ion mobile battery. By using this device, a man weighing 60 Kg can charge a 800mAh capacity battery in 2.6 hours by normal walking.", "labels": [6, 37]}
{"id": "138", "token": "High-throughput screening techniques that analyze the metabolic endpoints of biological processes can identify the contributions of genetic predisposition and environmental factors to the development of common diseases. Studies applying controlled physiological challenges can reveal dysregulation in metabolic responses that may be predictive for or associated with these diseases. However, large-scale epidemiological studies with well controlled physiological challenge conditions, such as extended fasting periods and defined food intake, pose logistic challenges. Culturally and religiously motivated behavioral patterns of life style changes provide a natural setting that can be used to enroll a large number of study volunteers. Here we report a proof of principle study conducted within a Muslim community, showing that a metabolomics study during the Holy Month of Ramadan can provide a unique opportunity to explore the pre-prandial and postprandial response of human metabolism to nutritional challenges. Up to five blood samples were obtained from eleven healthy male volunteers, taken directly before and two hours after consumption of a controlled meal in the evening on days 7 and 26 of Ramadan, and after an over-night fast several weeks after Ramadan. The observed increases in glucose, insulin and lactate levels at the postprandial time point confirm the expected physiological response to food intake. Targeted metabolomics further revealed significant and physiologically plausible responses to food intake by an increase in bile acid and amino acid levels and a decrease in long-chain acyl-carnitine and polyamine levels. A decrease in the concentrations of a number of phospholipids between samples taken on days 7 and 26 of Ramadan shows that the long-term response to extended fasting may differ from the response to short-term fasting. The present study design is scalable to larger populations and may be extended to the study of the metabolic response in defined patient groups such as individuals with type 2 diabetes.", "labels": [6, 37]}
{"id": "356", "token": "Objective: Adipocytes are robust protein secretors, most notably of adipokines, hormone-like polypeptides, which act in an endocrine and paracrine fashion to affect numerous physiological processes such as energy balance and insulin sensitivity. To understand how such proteins are assembled for secretion we describe the function of a novel endoplasmic reticulum oxidoreductase, adiporedoxin (Adrx). Methods: Adrx knockdown and overexpressing 3T3-L1 murine adipocyte cell lines and a knockout mouse model were used to assess the influence of Adrx on secreted proteins as well as the redox state of ER resident chaperones. The metabolic phenotypes of Adrx null mice were characterized and compared to WT mice. The correlation of Adrx levels BMI, adiponectin levels, and other inflammatory markers from adipose tissue of human subjects was also studied. Results: Adiporedoxin functions via a CXXC active site, and is upstream of protein disulfide isomerase whose direct function is disulfide bond formation, and ultimately protein secretion. Over and under expression of Adrx in vitro enhances and reduces, respectively, the secretion of the disulfide-bonded proteins including adiponectin and collagen isoforms. On a chow diet, Adrx null mice have normal body weights, and glucose tolerance, are moderately hyperinsulinemic, have reduced levels of circulating adiponectin and are virtually free of adipocyte fibrosis resulting in a complex phenotype tending towards insulin resistance. Adrx protein levels in human adipose tissue correlate positively with adiponectin levels and negatively with the inflammatory marker phospho-Jun kinase. Conclusion: These data support the notion that Adrx plays a critical role in adipocyte biology and in the regulation of mouse and human metabolism via its modulation of adipocyte protein secretion. (C) 2015 The Authors. Published by Elsevier GmbH.", "labels": [6, 37]}
{"id": "380", "token": "Purine derivatives play key role in human metabolism. Adenine, as a part of DNA, is constantly being attacked by many species which can form many different products, such as oxidized forms. Metyl group have been commonly observed in the case of DNA damage. Adenine can be methylated at different purine ring positions. There are so far few electrochemical studies describing oxidation processes in N-methylated adenines. We found out the possibility of measuring 3N-methyladenine (3N-mAde) on PeGE using electrode surface prereatment, due to unique surface morphology, followed by adsorption. we did not obtain signals at glassy acrbon electrode at same experimental conditions.", "labels": [6, 37]}
{"id": "436", "token": "Acrylamide (AA), a widely used industrial monomer which is categorised to be carcinogenic, was found to be generated in starch-containing foods during the heating process. This discovery has caused reasonable concern about possible health risks to humans due to dietary acrylamide uptake. In order to gain more information on human metabolism of acrylamide and to contribute to the assessment of the human carcinogenic risk due to AA uptake we measured the mercapturic acid of AA and its epoxide glycidamide (GA) i.e. N-acetyl-S-(2-carbamoylethyl)-L-cysteine (AAMA) and N-(RS)-acetyl-S-(2-carbamoyl2-hydroxyethyl)-L-cysteine (GAMA) in human urine. The relation between AAMA and GAMA is important in this context because GA is thought to be the ultimate carcinogenic metabolite of AA. The median levels in smokers (n = 13) were found to be about four times higher than in non-smokers (n = 16) with median levels of 127 mug/l versus 29 mug/l for AAMA and 19 mug/l versus 5 mug/l for GAMA. Therefore cigarette smoke proved to be an important source of acrylamide exposure. The level of AAMA in the occupationally non-exposed collective (n = 29) ranged from 3 to 338 mug/l, the level of GAMA from <LOD to 45 mug/l. The ratio of GAMA:AAMA varied from 0.03 to 0.53, median was 0.16 which is in reasonable agreement with results of different studies on rats. Thus the metabolic conversion of acrylamide to its genotoxic epoxide glycidarnide seems to occur to a comparable extent in rats and humans. Consequently, risk estimations by various authorities based on experimental data obtained in rats are supported by our findings. Besides we also measured the haemoglobin adducts of AA and GA in the blood of 26 participants. From these results compared to the mercapturic acids, we deduce a steady state for AA uptake, and we demonstrate a higher reactivity of GA in comparison to AA towards haemoglobin compared to glutathione in humans. (C) 2004 Elsevier B.V. All rights reserved.", "labels": [6, 37]}
{"id": "496", "token": "Aims/hypothesis: The adipokine adiponectin has insulin-sensitising, anti-atherogenic and anti-inflammatory properties. Recently, the genes for mouse and human adiponectin receptor-1 (ADIPOR1) and -2 (ADIPOR2) have been cloned. The aim of this study was to investigate whether genetic variants of the genes encoding ADIPOR1 and ADIPOR2 play a role in human metabolism. Materials and methods: We screened ADIPOR1 and ADIPOR2 for polymorphisms and determined their association with glucose metabolism, lipid metabolism, an atherogenic lipid profile and inflammatory markers in 502 non-diabetic subjects. A subgroup participated in a longitudinal study; these subjects received diet counselling and increased their physical activity. Results: We identified six variants of ADIPOR1 and seven variants of ADIPOR2. A single-nucleotide polymorphism (SNP) in the putative promoter region 8503 bp upstream of the translational start codon (-8503 G/A) of ADIPOR1 (frequency of allele A=0.31) was in almost complete linkage disequilibrium with another SNP (-1927 T/C) in intron 1. Subjects carrying the -8503 A and -1927 C alleles had lower insulin sensitivity, as estimated from a 75 g OGTT (p=0.04) and determined during a euglycaemic clamp (n=295, p=0.04); they also had higher HbA(1)c levels (p=0.02) and, although the difference was not statistically significant, higher liver fat (n=85, determined by proton magnetic resonance spectroscopy, p=0.056) (all p values are adjusted for age, sex and percentage of body fat). In the longitudinal study (n=45), the -8503 A and -1927 C alleles were associated with lower insulin sensitivity (p=0.03) and higher liver fat (p=0.02) at follow-up compared with the -8503 G and -1927 T alleles, independently of basal measurements, sex and baseline and follow-up percentage of body fat. Conclusions/interpretation: The present findings suggest that the -8503 G/A SNP in the promoter or the -1927 T/C SNP in intron 1 of ADIPOR1 may affect insulin sensitivity and liver fat in humans.", "labels": [6, 37]}
{"id": "592", "token": "The elucidation of the metabolism of new therapeutics is a major task for pharmaceutical companies and of great interest for drug testing Laboratories. The tatter in particular need to determine the presence or absence of drugs or their metabolic products in urine to test for a misuse of these compounds. Commonly, in vitro or animal models are used to mimic the human metabolism and produce potential targets in amounts allowing for method development. An alternative route based on electrochemical reactions of drugs was reported to allow for the generation of selected metabolites. The utility of this approach for doping control purposes was demonstrated with a novel class of anabolic agents termed selective androgen receptor modulators (SARMs). An arylpropionamide-derived drug candidate was subjected to etectrochemical metabolism and a major phase-I-metabolite, resulting from the elimination of a substituted phenol residue as identified in in vitro experiments, was generated and characterised using liquid chromatography/nuclear magnetic resonance spectroscopy and high resolution/high accuracy mass spectrometry. The metabolite was included in routine doping control procedures based on Liquid chromatography/tandem mass spectrometry and has served as a reference compound for 5000 doping control specimens.", "labels": [6, 37]}
{"id": "696", "token": "Human metabolism of di(2-ethylhexyl)phthalate (DEHP) was studied after a single oral dose of 48.1 mg to a male volunteer. To avoid interference by background exposure the D4-ring-labelled DEHP analogue was dosed. Excretion of three metabolites, mono(2-ethyl-5-hydroxyhexyl)phthalate (5OH-MEHP), mono(2-ethyl-5-oxohexyl)phthalate (5oxo-MEHP) and mono(2-ethylhexyl)phthalate (MEHP), was monitored for 44 h in urine and for 8 h in serum. Peak concentrations of all metabolites were found in serum after 2 h and in urine after 2 h (MEHP) and after 4 h (5OH-MEHP and 5oxo-MEHP). While the major metabolite in serum was MEHP, the major metabolite in urine was 5OH-MEHP, followed by 5oxo-MEHP and MEHP. Excretion in urine followed a multi-phase elimination model. After an absorption and distribution phase of 4 to 8 h, half-life times of excretion in the first elimination phase were approximately 2 h with slightly higher half-life times for 5OH- and 5oxo-MEHP. Half-life times in the second phase-beginning 14 to 18 h post dose-were 5 h for MEHP and 10 h for 5OH-MEHP and 5oxo-MEHP. In the time window 36 to 44 h, no decrease in excreted concentrations of 5OH- and 5oxo-MEHP was observed. In the first elimination phase (8 to 14 h post dose), mean excretion ratios of MEHP to 5oxo-MEHP and MEHP to 5OH-MEHP were 1 to 1.8 and 1 to 3.1. In the second elimination phase up to 24 h post dose mean excretion ratios of MEHP to 5oxo-MEHP to 5OH-MEHP were 1 to 5.0 to 9.3. The excretion ratio of 5OH-MEHP to 5oxo-MEHP remained constant through time at 1.7 in the mean. After 44 h, 47% of the DEHP dose was excreted in urine, comprising MEHP (7.3%), 5OH-MEHP (24.7%) and 5oxo-MEHP (14.9%).", "labels": [6, 37]}
{"id": "870", "token": "Direct research on gut microbiota for understanding its role as 'an important organ' in human individuals is difficult owing to its vast diversity and host specificity as well as ethical concerns. Transplantation of human gut microbiota into surrogate hosts can significantly facilitate the research of human gut ecology, metabolism and immunity but rodents-based model provides results with low relevance to humans. A new human flora-associated ( HFA) piglet model was hereby established taking advantage of the high similarity between pigs and humans with respect to the anatomy, physiology and metabolism of the digestive system. Piglets were delivered via cesarean section into a SPF-level barrier system and were inoculated orally with a whole fecal suspension from one healthy 10-year-old boy. The establishment and composition of the intestinal microbiota of the HFA piglets were analyzed and compared with that of the human donor using enterobacterial repetitive intergenic consensus sequence-PCR fingerprinting-based community DNA hybridization, group-specific PCR-temperature gradient gel electrophoresis and real-time PCR. Molecular profiling demonstrated that transplantation of gut microbiota from a human to germfree piglets produced a donor-like microbial community with minimal individual variation. And the microbial succession with aging of those ex-germfree piglets was also similar to that observed in humans. This HFA model provides a significantly improved system for research on gut ecology in human metabolism, nutrition and drug discovery.", "labels": [6, 37]}
{"id": "941", "token": "Introduction In the almost six decades of bariatric surgery, a variety of surgical approaches to treating morbid obesity have been developed. History and evolution Rather than prior techniques being continually superseded by new ones, a broad choice of surgical solutions based on restrictive, malabsorptive, humoral effects, or combinations thereof, is now available. In fact, in recent years, the advent of surgically modifying human metabolism promises new approaches to ameliorate traditionally medically treated metabolic entities, i.e., diabetes, even in the non-obese. The understanding of the various metabolic effects have led to a paradigm shift from bariatric surgery as a solely weight-reducing procedure to metabolic surgery affecting whole body metabolism. Conclusion The bariatric surgeon now faces the challenge and opportunity of selecting the most suitable technique for each individual case. To assist in such decision-making, this review, Metabolic surgery-principles and current concepts, is presented, tracing the historical development; describing the various surgical techniques; elucidating the mechanisms by which glycemic control can be achieved that involve favorable changes in insulin secretion and insulin sensitivity, gut hormones, adipokines, energy expenditure, appetite, and preference for low glycemic index foods; as well as exploring the fascinating future potential of this new interdisciplinary field.", "labels": [6, 37]}
{"id": "1085", "token": "The metabolic fate of the organophosphorothioate-type insecticide chlorpyrifos (CP) in an acutely intoxicated 59 years old female was investigated by liquid chromatography-electrospray ionisation-tandem mass spectrometry (LC-ESI-MS/MS) analysis of urine samples. Fifteen metabolites of CP and its bioactivated intermediate chlorpyrifos-oxon (CPO), respectively, of which only three have been described in man so far, were identified on the basis of characteristic MS/MS transitions, precursor/product ion and/or neutral loss scans, chlorine isotopomer patterns, and partly by synthesis of reference compounds and subsequent structure confirmation. Three distinct biotransformation routes of CP are proposed: (1) cleavage reactions at the aromatic phosphoester bond, (2) cleavage reactions at the alkyl phosphoester bonds, and (3) glutathione (GSH) dependent nucleophilic substitution of the 6-chlorine at the aromatic moiety. Route (2) has not been reported in humans before and (3) is a hitherto completely unknown scheme of CP metabolism. Urinary markers of the latter were chiefly cysteine S-conjugates of mono-dechlorinated CP, CPO, mono-O-deethyl CP, and mono-O-deethyl CPO as well as the 6-mercapturic acid conjugate of 3,5-dichloro-2-pyridinol. The presence of 3,5-dichloro-6-methylthio-2-pyridinol as well as its O-glucuronide suggests further a cysteine S-conjugate beta-lyase mediated degradation. In addition to the qualitative LC-MS/MS screening the renal elimination profiles of the primary products of scheme (1), i.e. diethyl thiophosphate (DETP), diethyl phosphate (DEP), and 3,5,6-trichloro-2-pyridinol (TCP), were monitored over 14 days (n = 21). A biphasic first-order excretion mechanism with half-lives of 21.5 h (initial fast excretion phase) and 119.5 h (terminal phase) for the Sum of free DETP and DEP was found. TCP was hardly eliminated in its free form (O-glucuronide identified as phase II conjugate) and half-lives calculated for the total amount of TCP (acidic hydrolysis of urine samples) were 40.8 and 150.7 h. The present study gives a more detailed view on the biotransformation of CP and together with the obtained kinetic data adds novel aspects to the limited knowledge of human metabolism of this xenobiotic, in particular at high dosage. (c) 2005 Elsevier Ireland Ltd. All rights reserved.", "labels": [6, 37]}
{"id": "1277", "token": "In pediatric age and particularly in newborn infants the drug efficacy and safety are influenced by the growth and development on drug Absorption, Distribution, Metabolism and Excretion (ADME). Thanks to the fast development of pharmacogenomics and pharmacogenetics, the drug therapy promises to be adapted to the genetic profile of the individual, reducing considerably the side effects of drugs and increasing their efficacy. Interindividual variability in drug response is well known in both adults and children. Such a variability is multifactorial considering both intrinsic and extrinsic factors. Drug distribution in the neonate is influenced by a variety of age-dependent factors as a total body water content and distribution variations, role of drug transporters, blood/tissue protein binding, blood and tissue pH and perfusion. The development of enzymes involved in human metabolism were classified in 3 categories: 1) those expressed during the whole or part of the fetal period, but silenced or expressed at low levels within 1-2 years after birth; 2) those expressed at relatively constant levels throughout fetal development, but increased to some extent postnatally; and 3) those whose onset of expression can occur in the third trimester, but substantial increase is noted in the first 1-2 years after birth. Besides this intrinsic aspects influencing pharmacokinetics during the neonatal period there are other important events such as inborn or acquired diseases, environment and finally pharmacogenetics and pharmacogenomics. Thousands of deaths every years are caused by fatal drug reactions; among the potential causes there are not only the severity of the disease being treated, drug interactions, nutritional status, renal and liver functions, but also the inherited differences in drug metabolism and genetic polymorphism. Adverse drug reactions (ADRs) among pediatric patients have been shown to be three times more frequent than in adults. On August 2010 The National Institute of Child Health and Human Development (NICHD) addressed patient safety issues in the NICU, recognizing that to understand and prevent adverse events, systematic research and education in safety issues needed. From all these concepts in terms of ADME, pharmacogenetics (relative to a single gene) and pharmacogenomics (relative to many genes) it is becoming more evident the perspective of the new concept of individualized medicine. The goal of this should be to identify which group of patients responds positively, which patients are nonresponders and who experiences adverse reaction for the same drug and dose. The interindividual variability in response to any drug is mostly dependent on DNA sequence variations across the human genome, the haplotype map (HAPMAP). At present there is still a big distance beween the knowledge in genetic and the practical application to model the drug profile to the genetic/genomic profile of the single patient. In the neonatal period the effects of growth in the pharmacodynamic, processes can help optimizing the dosage of neonatal frequently used medicines, thereby, minimizing their toxicity and increasing their efficacy. It should be useful to create accurate dosage adjustments according to the week of development.", "labels": [6, 37]}
{"id": "1381", "token": "Simple voltammetric determination of thiodiglycolic acid (TDGA) offers the possibility to follow individual deviations in metabolism of thiocompounds and one-carbon (1c) and two-carbon (2c) units, which take part in endogenous synthesis of creatine (CR). In three groups of young men the levels of TDGA in urine were followed after application of CR given as food supplement in 5 g daily doses. In the first group (7 men) it was found that the level of TDGA increased independently of the day time of application of CR. In the second group (9 men) the level of TDGA increased within an interval of 3-8.5 h after CR application and then dropped during 2 h to the normal level (20 mg L-1). In the third group (11 men), in 4 days' study the effects of CR were compared in alternation to vitamin B-12. Vitamin B-12 was given in the evening of the 1st and 3rd day and CR in the morning of the 3rd and 4th day. CR increased the excretion of TDGA in all men, while B-12 only in four men independently of CR application. (C) 2008 Elsevier Ltd. All rights reserved.", "labels": [6, 37]}
{"id": "1426", "token": "Bone remodelling, which maintains bone mass constant during adulthood, is an energy-demanding process. This, together with the observation that the adipocyte-derived hormone leptin is a major inhibitor of bone remodelling, led to the hypothesis that bone cells regulate energy metabolism through an endocrine mechanism. Studies to test this hypothesis identified osteocalcin, a hormone secreted by osteoblasts, as a positive regulator of insulin secretion, insulin resistance and energy expenditure. Remarkably, insulin signalling in osteoblasts is a positive regulator of osteocalcin production and activation via its ability to indirectly enhance bone resorption by osteoclasts. In contrast, leptin is a potent inhibitor of osteocalcin function through its effect on the sympathetic tone. Hence, osteocalcin is part of a complex signalling network between bone and the organs more classically associated with the regulation of energy homeostasis, such as the pancreas and adipose tissue. This review summarises the molecular and cellular bases of the present knowledge on osteocalcin biology and discusses the potential relevance of osteocalcin to human metabolism and pathology.", "labels": [6, 37]}
{"id": "1550", "token": "Low levels of pharmaceutical compounds have been detected in aquatic environments worldwide, but their human and ecological health risks associated with low dose environmental exposure is largely unknown due to the large number of these compounds and a lack of information. Therefore prioritization and ranking methods are needed for screening target compounds for research and risk assessment. Previous efforts to rank pharmaceutical compounds have often focused on occurrence data and have paid less attention to removal mechanisms such as human metabolism. This study proposes a simple prioritization approach based on number of prescriptions and toxicity information, accounting for metabolism and wastewater treatment removal, and can be applied to unmeasured compounds. The approach was performed on the 200 most-prescribed drugs in the US in 2009. Our results showed that under-studied compounds such as levothyroxine and montelukast sodium received the highest scores, suggesting the importance of removal mechanisms in influencing the ranking, and the need for future environmental research to include other less-studied but potentially harmful pharmaceutical compounds. (C) 2012 Published by Elsevier Inc.", "labels": [6, 37]}
{"id": "1701", "token": "Acetone is a good marker of metabolic stress as it is the most volatile and rapidly equilibrated of the ketone bodies produced by human metabolism. If the body utilizes predominately fat to meet its energy requirements, blood and breath acetone concentrations will increase. Elevated concentrations of breath acetone can indicate a normal response to caloric imbalances in the diet, or a diseased state such as untreated diabetes. This paper describes a novel method of acetone detection that uses a gas-solid chemical reaction of acetone with a hydroxylamine hydrochloride (HA) to produce an easily detectable chemical species, HCl. Breath samples are passed through a reactor filled with solid HA and the amount of HCl gas released is measured by sensitive near infrared diode laser spectroscopy. The breath acetone instrument described is compact, low power and portable.", "labels": [6, 37]}
{"id": "1788", "token": "Blue mussels (Mytilus edulis) accumulate and biotransform arsenic (As) to a larger variety of arsenicals than most seafood. Eight volunteers ingested a test meal consisting of 150 g blue mussel (680) mu g As), followed by 72 h with an identical, low As controlled diet and full urine sampling. We provide a complete speciation, with individual patterns, of urinary As excretion. Total As (tAs) urinary excretion was 328 +/- 47 mu g, whereof arsenobetaine (AB) and dimethylarsinate (DMA) accounted for 66% and 21%, respectively. Fifteen minor urinary arsenicals were quantified with inductively coupled plasma mass spectrometry (ICPMS) coupled to reverse-phase, anion and cation-exchange high performance liquid chromatography (HPLC). Thio-arsenicals and non-thio minor arsenicals (including inorganic As (iAs) and methylarsonate (MA)) contributed 10% and 7% of the total sum of species excretion, respectively, but there were large individual differences in the excretion patterns. Apparently, formation of thio-arsenicals was negatively correlated to AB formation and excretion, possibly indicating a metabolic interrelationship. The results may be of toxicological relevance since DMA and MA have been classified as possibly carcinogenic, and six of the excreted As species were thio-arsenicals which recently have been recognized as toxic, while iAs toxicity is well known. (c) 2012 Elsevier Ltd. All rights reserved.", "labels": [6, 37]}
{"id": "2103", "token": "PB-22 (1-pentyl-8-quinolinyl ester-1H-indole-3-carboxylic acid) and 5F-PB-22 (1-(5-fluoropentyl)-8-quinolinyl ester-1H-indole-3-carboxylic acid) are new synthetic cannabinoids with a quinoline substructure and the first marketed substances with an ester bond linkage. No human metabolism data are currently available, making it difficult to document PB-22 and 5F-PB-22 intake from urine analysis, and complicating assessment of the drugs' pharmacodynamic and toxicological properties. We incubated 10 mu mol/l PB-22 and 5F-PB-22 with pooled cryopreserved human hepatocytes up to 3 h and analyzed samples on a TripleTOF 5600+ high-resolution mass spectrometer. Data were acquired via TOF scan, followed by information-dependent acquisition triggered product ion scans with mass defect filtering (MDF). The accurate mass full scan MS and MS/MS metabolite datasets were analyzed with multiple data processing techniques, including MDF, neutral loss and product ion filtering. The predominant metabolic pathway for PB-22 and 5F-PB-22 was ester hydrolysis yielding a wide variety of (5-fluoro)pentylindole-3-carboxylic acid metabolites. Twenty metabolites for PB-22 and 22 metabolites for 5F-PB-22 were identified, with the majority generated by oxidation with or without glucuronidation. For 5F-PB-22, oxidative defluorination occurred forming PB-22 metabolites. Both compounds underwent epoxide formation followed by internal hydrolysis and also produced a cysteine conjugate. Human hepatic metabolic profiles were generated for PB-22 and 5F-PB-22. Pentylindole-3-carboxylic acid, hydroxypentyl-PB-22 and PB-22 pentanoic acid for PB-22, and 5'-fluoropentylindole-3-carboxylic acid, PB-22 pentanoic acid and the hydroxy-5F-PB-22 metabolite with oxidation at the quinoline system for 5F-PB-22 are likely the best targets to incorporate into analytical methods for urine to document PB-22 and 5F-PB-22 intake.", "labels": [6, 37]}
{"id": "2331", "token": "A huge number of genes within the human genome code for proteins that mediate and/or control nutritional processes. Although a large body of information on the number of genes, on chromosomal localisation, gene structure and function has been gathered, we are far from understanding the orchestrated way of how they make metabolism. Nevertheless, based on the genetic information emerging on a daily basis, we are offered fantastic new tools that allow us new insights into the molecular basis of human metabolism under normal as well as pathophysiological conditions. Recent technological advancements have made it possible to analyse simultaneously large sets of mRNA and/or proteins expressed in a biological sample or to define genetic heterogeneity that may be important for the individual response of an organism to changes in its nutritional environment. Applications of the new techniques of genome and proteome analysis are central for the development of nutritional sciences in the next decade and its integration into the rapidly developing era of functional genomics.", "labels": [6, 37]}
{"id": "2433", "token": "Background: In spite of its great promise, metabolomics has proven difficult to execute in an untargeted and generalizable manner. Liquid chromatography-mass spectrometry (LC-MS) has made it possible to gather data on thousands of cellular metabolites. However, matching metabolites to their spectral features continues to be a bottleneck, meaning that much of the collected information remains uninterpreted and that new metabolites are seldom discovered in untargeted studies. These challenges require new approaches that consider compounds beyond those available in curated biochemistry databases. Description: Here we present Metabolic In silico Network Expansions (MINEs), an extension of known metabolite databases to include molecules that have not been observed, but are likely to occur based on known metabolites and common biochemical reactions. We utilize an algorithm called the Biochemical Network Integrated Computational Explorer (BNICE) and expert-curated reaction rules based on the Enzyme Commission classification system to propose the novel chemical structures and reactions that comprise MINE databases. Starting from the Kyoto Encyclopedia of Genes and Genomes (KEGG) COMPOUND database, the MINE contains over 571,000 compounds, of which 93% are not present in the PubChem database. However, these MINE compounds have on average higher structural similarity to natural products than compounds from KEGG or PubChem. MINE databases were able to propose annotations for 98.6% of a set of 667 MassBank spectra, 14% more than KEGG alone and equivalent to PubChem while returning far fewer candidates per spectra than PubChem (46 vs. 1715 median candidates). Application of MINEs to LC-MS accurate mass data enabled the identity of an unknown peak to be confidently predicted. Conclusions: MINE databases are freely accessible for non-commercial use via user-friendly web-tools at http://minedatabase.mcs.anl.gov and developer-friendly APIs. MINEs improve metabolomics peak identification as compared to general chemical databases whose results include irrelevant synthetic compounds. Furthermore, MINEs complement and expand on previous in silico generated compound databases that focus on human metabolism. We are actively developing the database; future versions of this resource will incorporate transformation rules for spontaneous chemical reactions and more advanced filtering and prioritization of candidate structures.", "labels": [6, 37]}
{"id": "2562", "token": "The non-pathogenic Gram-positive soil bacterium Streptomyces davawensis synthesizes the riboflavin (vitamin B(2)) analogs roseoflavin (RoF) and 8-demethyl-8-amino-riboflavin (AF). Both compounds are antibiotics. Notably, a number of other riboflavin analogs are currently under investigation with regard to the development of novel antiinfectives. As a first step towards understanding the metabolism of riboflavin analogs in humans, the key enzymes flavokinase (EC 2.7.1.26) and FAD synthetase (EC 2.7.7.2) were studied. Human flavokinase efficiently converted RoF and AF to roseoflavin mononucleotide (RoFMN) and 8-demethyl-8-amino-riboflavin mononucleotide (AFMN), respectively. Human FAD synthetase accepted RoFMN but not AFMN as a substrate. Consequently, roseoflavin adenine dinucleotide (RoFAD) was synthesized by the latter enzyme but not 8-demethyl-8-amino-riboflavin adenine dinucleotide (AFAD). The cofactor analogs RoFMN, AFMN and RoFAD have different physicochemical properties as compared to FMN and FAD. Thus, the cofactor analogs have the potential to render flavoenzymes inactive, which may negatively affect human metabolism. RoF, but not AF, was found to inhibit human flavokinase. In summary, we suggest that AF has a lower toxic potential and may be better suited as a lead structure to develop antimicrobial compounds. (C) 2011 Elsevier Inc. All rights reserved.", "labels": [6, 37]}
{"id": "2759", "token": "Hallucinogenic tryptamine analogues, an important class of drugs of abuse, can be naturally occurring or chemically synthesized compounds. In Japan, psilocin and psilocybin (ingredients of magic mushrooms) and 5-methoxy-N,N-diisopropyltryptamine (5-MeO-DIPT; a synthetic tryptamine) seem to be particularly problematic due to their extensive abuse. This review is focused on human metabolism and forensic toxicological analyses of the above three tryptamine analogues. In humans, psilocybin is rapidly dephosphorylated to form psilocin, and most of the psilocin is eventually conjugated to form its glucuronide. On the other hand, 5-MeO-DIPT is mainly metabolized via O-demethylation, 6-hydroxylation, and N-deisopropylation, partly followed by conjugation to form their sulfates and glucuronides. Suitable hydrolysis should be, therefore, applied for sensitive and effective analysis of the metabolites. In analyzing psilocin and psilocybin by gas chromatography-mass spectrometry (GC-MS), derivatization is necessary for their discriminative identification. Although 5-MeO-DIPT and its three major metabolites can be analyzed by GC-MS without any derivatization, trimethylsilyl derivatization provides improvement of their peak shapes and intensities. In contrast to GC-MS, liquid chromatography-mass spectrometry and liquid chromatography-tandem mass spectrometry allow us not only to discriminate psilocin and psilocybin without derivatization, but also to directly analyze their conjugated metabolites.", "labels": [6, 37]}
{"id": "2897", "token": "There is considerable interest in coloured fruits and berries as sources of biologically active anthocyanins. To examine the relationship between the oral close and the amount excreted for anthocyanins from a food source across a physiological range of doses, volunteers were fed, in random order, four portions (100-400 g) of fresh strawberries as part of a standard breakfast. Urine was collected at 2 h intervals up to 8 h, and for the period 8-24 h. Fresh strawberries contained pelargonidin-3-glucoside as the major anthocyanin with smaller amounts of cyanidin-3-glucoside and pelargonidin-3-rutinoside. Anthocyanins were detected in the urine of all volunteers for all doses, predominantly as pelargonidin glucuronide and sulphate metabolites. There was a strong, linear relationship between oral dose and anthocyanin excretion (Pearson's product moment correlation coefficient = 0.692, p < 0.001, n = 40) which indicated that on an average, every additional unit of dose caused 0.0166 units of excretion. Within individuals, dose - excretion data fitted a linear regression model (median R-2 = 0.93) We conclude that strawberry anthocyanins are partially bioavailable in humans with a linear relationship between oral dose and urinary excretion for doses up to 400 g fresh fruit.", "labels": [6, 37]}
{"id": "3106", "token": "Pyruvate is a keystone molecule critical for numerous aspects of eukaryotic and human metabolism. Pyruvate is the end-product of glycolysis, is derived from additional sources in the cellular cytoplasm, and is ultimately destined for transport into mitochondria as a master fuel input undergirding citric acid cycle carbon flux. In mitochondria, pyruvate drives ATP production by oxidative phosphorylation and multiple biosynthetic pathways intersecting the citric acid cycle. Mitochondrial pyruvate metabolism is regulated by many enzymes, including the recently discovered mitochondria pyruvate carrier, pyruvate dehydrogenase, and pyruvate carboxylase, to modulate overall pyruvate carbon flux. Mutations in any of the genes encoding for proteins regulating pyruvate metabolism may lead to disease. Numerous cases have been described. Aberrant pyruvate metabolism plays an especially prominent role in cancer, heart failure, and neurodegeneration. Because most major diseases involve aberrant metabolism, understanding and exploiting pyruvate carbon flux may yield novel treatments that enhance human health.", "labels": [6, 37]}
{"id": "3164", "token": "After a coal mining accident, the key to the success of the coal mining emergency rescue is that the trapped miners are still alive before the rescue passage are made through. As new life-saving equipment, life-saving foods are used to maintain the viability and the self-saving ability of the front-line miners when they are trapped in the coal mining accident. The life-saving food will effectively extend the self-save time for the trapped miners and then essentially improve the rescued possibility of the trapped miners. The amount of human metabolism, which was measured under the hot and humid environment, determines salt targets and nutrition indexes of the life-saving food. According to the particularity of underground environment, the passage explores the method to store the life-saving food and how to reasonably select the storage locations. Reviewing the application of the mine life-saving food, we can conclude that the self-saving food will have a better future in the economic and social aspects. But it still needs to be demonstrated whether it is necessary to carry the food with the human body. When the life-saving food is exposed under the hot and humid environment, the deterioration cure is still unclear.", "labels": [6, 37]}
{"id": "3230", "token": "Among the food-related health issues, the presence of contaminants has a prominent role, due to the wide range of exogenous compounds that can occur in food commodities and to their large differences in structure and biological activity. A comprehensive assessment of the related risk is thus actually demanding in terms of time and facilities involved. In this context, the use of computational strategies can be an effective choice for supporting the hazard identification procedure at the early stage. In this work we focused on the food contaminant zearalenone by comparing the trans and cis isomers, respectively the well-known mycoestrogen and its still largely understudied isomer. We estimated the possible effects exerted by human metabolism on the xenoestrogenicity of cis-ZEN by using a validated in silica strategy based on docking simulations and rescoring procedures. Similarly, the exploitation of the most promising enzymatic detoxifying routes designed for trans-ZEN - which relies on the enzyme lactono hydrolase from Clonostachys rosea - has been assessed for the cis-isomer as well. Our results showed that both isomers can act as functional analogues with respect to xenoestrogenic activity, and several cis-ZEN metabolites with high biological potential have been identified. On the contrary, in spite of the high degree of structural analogy, the cis isomer showed a pattern of interaction with the degrading enzyme in stark contrast with that observed for trans-ZEN. For these reasons, the outcomes presented herein strongly support the inclusion of cis-ZEN in further studies of occurrence, metabolism and bioactivity assessment, and suggest the need for a dedicated handling for the cis isomer in risk assessment studies. (C) 2015 Elsevier Ltd. All rights reserved", "labels": [6, 37]}
{"id": "3268", "token": "Citric acid represents a class of carboxylic acids present in biological fluids and playing key roles in biochemical processes in bacteria and humans. Its ability to promote diverse coordination chemistries in aqueous media, in the presence of metal ions known to act as trace elements in human metabolism, earmarks its involvement in a number of physiological functions. Cobalt is known to be a central element of metabolically important biomolecules, such as B-12, and therefore its biospeciation in biological fluids constitutes a theme worthy of chemical and biological perusal. In an effort to unravel the aqueous chemistry of cobalt in the presence of a physiologically relevant ligand, citrate, the first aqueous, soluble, mononuclear complex has been synthesized and isolated from reaction mixtures containing Co(II) and citrate in a 1:2 molar ratio at pH similar to 8. The crystalline compound (NH4)(4)[CO(C6H5O7)(2)] (1) has been characterized spectroscopically (UV/vis, EPR) and crystallographically. Its X-ray structure consists of a distorted octahedral anion with two citrate ligands fulfilling the coordination requirements of the Co(II) ion. The magnetic susceptibility measurements of 1 in the range from 6 to 295 K are consistent with a high-spin complex containing Co(II) with a ground state S=3/2. Corroborating this result is the EPR spectrum of 1, which shows a signal consistent with the presence of a Co(II) system. The spectroscopic and structural properties of the complex signify its potential biological relevance and participation in speciation patterns arising under conditions consistent with those employed for its synthesis and isolation.", "labels": [6, 37]}
{"id": "3435", "token": "The objective of this project was to determine the factors associated with differences in butadiene (BD) inhalation uptake and the rate of metabolism for BID to epoxy butene by monitoring exhaled breath during and after a brief exposure to BID in human volunteers. A total of 133 subjects (equal males and females; four racial groups) provided final data. Volunteers gave informed consent and completed a questionnaire including diet and alcohol use. A venous blood sample was collected for genotyping CYP2E1. Subjects received a 20 min exposure to 2.0 ppm of BID, followed by a 40 min washout period. The total administered dose was 0.6 ppm*h. which is in the range of everyday exposures. Ten, 1 or 2 min exhaled breath samples (five during and five after exposure) were collected using an optimized strategy. BD was determined by GC-FID analysis. Breathing activity (minute ventilation, breath frequency and tidal volume) was measured to estimate alveolar ventilation. After the washout period, 250 mg of chlorzoxazone were administered and urine samples collected for 6 h to measure 2E1 phenotype. The total BID uptake during exposure (inhaled BID minus exhaled) was estimated. A three-compartment PBPK model was fitted to each subject's breath measurements to estimate personal and population model parameters. including in-vivo BD metabolic rate. A hierarchical Bayesian PBPK model was fit by Monte Carlo simulations to estimate model parameters. Regression and ANOVA analyses were performed. Earlier data analysis showed wide ranges for both total uptake BD and metabolic rate. Both varied significantly by sex and age, and showed suggestive differences by race, with Asians having the highest rates. The analyses reported here found no correlation between total BID uptake and metabolic rate. No significant differences were found for oxidation rates by 2E1 genotype or phenotype, but the rates showed trends consistent with reported differences by genotype and phenotype for chlorzoxazone metabolism. No effects on metabolic rate were observed for long-term alcohol consumption, or consumption in the past 24 h. Overall, neither dietary factors nor genetic differences explained much of the wide variability in metabolic rates. Population characteristics, age, sex, and race, were the most important explanatory variables, but a large fraction of the total variability in metabolism remains to be explained. (C) 2001 Elsevier Science Ireland Ltd. All rights reserved.", "labels": [6, 37]}
{"id": "3519", "token": "We discuss a human metabolism system using the theory of stochastic differential equations (SDEs) with reflecting boundary conditions. We investigate the distribution of the process determined by the SDEs. The relation between the deterministic model introduced by Nordberg and Kjellstrom and our stochastic model is considered. Numerical computations are also given.", "labels": [6, 37]}
{"id": "44", "token": "Extraction of road networks in urban areas from remotely sensed imagery plays an important role in many urban applications (e.g. road navigation, geometric correction of urban remote sensing images, updating geographic information systems, etc.). It is normally difficult to accurately differentiate road from its background due to the complex geometry of the buildings and the acquisition geometry of the sensor. In this paper, we present a new method for extracting roads from high-resolution imagery based on hierarchical graph-based image segmentation. The proposed method consists of: 1. Extracting features (e.g., using Gabor and morphological filtering) to enhance the contrast between road and non-road pixels, 2. Graph-based segmentation consisting of (i) Constructing a graph representation of the image based on initial segmentation and (ii) Hierarchical merging and splitting of image segments based on color and shape features, and 3. Post-processing to remove irregularities in the extracted road segments. Experiments are conducted on three challenging datasets of high-resolution images to demonstrate the proposed method and compare with other similar approaches. The results demonstrate the validity and superior performance of the proposed method for road extraction in urban areas. (C) 2017 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS). Published by Elsevier B.V. All rights reserved.", "labels": [4, 27]}
{"id": "168", "token": "Urban geological hazards involving ground instability can be costly, dangerous, and affect many people, yet there is little information about the extent or distribution of geohazards within Europe's urban areas. A reason for this is the impracticality of measuring ground instability associated with the many geohazard processes that are often hidden beneath buildings and are imperceptible to conventional geological survey detection techniques. Satellite radar interferometry, or InSAR, offers a remote sensing technique to map mm-scale grotind deformation over wide areas given an archive of suitable multi-temporal data. The EC FP7 Space project named PanGeo (2011-2014), used InSAR to map areas of unstable ground in 52 of Europe's cities, representing similar to 45% of the EU population. In partnership with Europe's national geological surveys, the PanGeo project developed a standardised geohazard-mapping methodology and recorded 1286 instances of 19 types of geohazard covering 18,000 km(2). Presented here is an analysis of the results of the PanGeo-project output data, which provides insights into the distribution of European urban geohazards, their frequency and probability of occurrence. Merging PanGeo data with Eurostat's GeoStat data provides a systematic estimate of population exposures. Satellite radar interferometry is shown to be as a valuable tool for the systematic detection and mapping of urban geohazard phenomena. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [4, 27]}
{"id": "285", "token": "The rapid and timely evaluation of urban environmental change is highly important for understanding urban sustainability in China. However, the comprehensive understanding of urban environmental change in China based on multi-source remote sensing data remains inadequate because current studies have mainly focused on a single aspect of the urban environment using a specific source of remote sensing data. In this study, we developed a comprehensive evaluation index (CEI) combining the remote sensing data of the fine particulate matter (PM2.5) concentration, land surface temperature (1ST) and vegetation cover (VC) to assess the urban environmental change in China at the national scale, among urban agglomerations and across the rapidly urbanized regions. We found a trend of environmental degradation in the urban areas of China between 2000 and 2012. Environmentally degraded and moderately degraded urban areas accounted for 48.14% of the total urban area in China. In particular, the expanded urban areas exhibited the most extensive environmental degradation, with 52.33% of the total expanded urban areas from 1992 to 2012 exhibiting environmental degradation or moderately environmental degradation. The increase in the PM2.5 concentration was one of the main manifestations of the environmental degradation in the expanded urban areas. We suggest that more attention should be paid to urban environmental issues during future urban development in China. (C) 2017 Elsevier Inc. All rights reserved.", "labels": [4, 27]}
{"id": "401", "token": "Light use efficiency (LUE) models offer an effective way for regional gross primary productivity (GPP) estimation. However, LUE is not easily determined at the landscape level due to its complexity and dependence on various environmental factors. One possible strategy to avoid the requirement for assessing environmental stressors is using the photochemical reflectance index (PRI) to determine LUE via the epoxidation state of the xanthophyll cycle. Integration of such measurements into GPP models could lead to more realistic GPP estimates of landscape level. Conventional, one-leaf LUE models, however, seem less suitable for integration of such remote sensing observations, as optically derived estimates are dependent on the shadow fraction viewed at a given time. Here, we utilize the two-leaf LUE (TL-LUE) model to parameterize LUE from multiangle PRI observations and compare it with MOD17 approach. Significant relationships were found between LUE (LUE, LUEsun, and LUEshaded) and PRI (PRI, PRIsun, and PRIshaded) over 8- and 16-day time steps. Similarly, R-2 values for the relationships between modeled GPP and observed GPP (EC derived measurements of GPP) were 0.87 (TL-LUE) and 0.81 (MOD17) at deciduous forest and 0.54 (TL-LUE) and 0.46 (MOD17) at evergreen forest for eight-day periods, as well as 0.84 (TL-LUE) and 0.74 (MOD17) at deciduous forest and 0.49 (TL-LUE) and 0.46 (MOD17) at evergreen forest for 16-day periods. Our results are relevant when planning potential future satellite missions to help constrain existing GPP models using remotely sensed data, as such observations will likely be affected by canopy shading effects at the time of observation.", "labels": [4, 27]}
{"id": "506", "token": "Utilizing remote sensing techniques to extract soil properties can facilitate several engineering applications for large-scale monitoring and modeling purposes such as earthen levees monitoring, landslide mapping, and off-road mobility modeling. This study presents results of statistical analyses to investigate potential correlations between multiple polarization radar backscatter and various physical soil properties. The study was conducted on an approximately 3 km long section of earthen levees along the lower Mississippi river as part of the development of remote levee monitoring methods. Polarimetric synthetic aperture radar imagery from UAVSAR was used along with an extensive set of in situ soil properties. The following properties were analyzed from the top 30-50 cm of soil: texture (sand and clay fraction), penetration resistance (sleeve friction and cone tip resistance), saturated hydraulic conductivity, field capacity, permanent wilting point, and porosity. The results showed some correlation between the cross-polarized (HV) radar backscatter coefficients and most of these properties. A few soil properties, like clay fraction, showed similar but weaker correlations with the co-polarized channels (HH and VV). The correlations between the soil properties and radar backscatter were analyzed separately for the river side and land side of the levee. It was found that the magnitude and direction of the correlation for most of the soil properties noticeably differed between the river and the land sides. The findings of this study can be a good starting point for scattering modelers in a pursuit of better models for radar scattering at cross polarizations which would include more diverse set of soil parameters. (C) 2016 Elsevier B.V. All rights reserved.", "labels": [4, 27]}
{"id": "612", "token": "The environmental challenges posed by global warming in the Himalayan region include early and rapid melting of snow and glaciers, creation of new lakes, and expansion of old ones posing a high risk of glacial lakes outburst flood (GLOF) hazard for downstream communities. According to various elevation ranges, 3044 lakes were analyzed basinwide in the Hindu Kush-Karakoram-Himalaya (HKH) ranges of Pakistan using multisensor remote sensing data of the 2001-2013 period. An overall increase in glacial lakes was observed at various altitudinal ranges between 2500 and 5500, m out of which noticeable-change by number was within the 4000-4500 m range. The analysis carried out by glacial-fediakes and nonglacial-fed lakes in different river basins indicated variable patterns depending on the geographic location in the HKH region. The correlation analysis of parameters like lake area, expansion, rate, and elevation was performed with 617 glacial lakes distributed in various river basins of the three HKH ranges. Lake area (2013) and elevation showed a negative relationship for all basins except Hunza, Shigar, and Shyok. The correlation between the expansion rate of lakes and elevation was on the positive side for Swat, Gilgit, Shigar, and Shingo basins a situation that may be attributed to the variable altitudinal pattern of temperature and precipitation. In order to explore such diverse patterns of lake behavior and relationship with influential factors in the HKH, detailed studies based on using high resolution image data coupled with in situ information are a prerequisite. Although an increase in lake area observed below 3500 m would be favorable for water resource management, but could be alarming in context of glacial flood hazards that need to be monitored critically on a long-term basis. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [4, 27]}
{"id": "827", "token": "To compensate for the limitations of optical remote sensing when restricted by cloud cover, it is worth exploring how to detect cyanobacterial blooms using synthetic aperture radar (SAR), which can penetrate clouds. A satellite-ground synchronous experiment was conducted in Lake Taihu, the third largest freshwater lake in China. A lipopeptide biosurfactant was detected in the algal scum layer, with an average content of 1.8 g/L. The viscosity (1.41 to 332 mPa. s) of the scum was significantly higher than that of scum-free water. The surface tension of the algal scum decreased by 12.5%, and the SAR microwave backscatter was reduced by 7.3 dB. This indicated that the cyanobacterial scum could effectively attenuate capillary waves and appear as dark patches in SAR images. SAR has the potential to be developed as a tool for the remote sensing of algal scum in lake waters. (C) 2017 Society of Photo-Optical Instrumentation Engineers (SPIE)", "labels": [4, 27]}
{"id": "989", "token": "Despite renewed efforts to better understand glacier change and recognize glacier change trends in the Andes, relatively large areas in the Andes of Argentina and Chile are still not investigated. In this study, we report on glacier elevation and mass changes in the outer region of the Northern and Southern Patagonian Icefields in the Southern Patagonian Andes. A newly-compiled Landsat ETM+ derived glacier inventory (consisting of 2253 glaciers and similar to 1314 +/- 66 km(2) of ice area) and differencing of the SRTM and SPOT5 DEMs were used to derive glacier-specific elevation changes over the 2000-12 period. The investigated glaciers showed a volume change of -0.71 +/- 0.55 km(3) a(-1), yielding a surface lowering of 0.52 +/- 0.35 m a(-1) on average and an overall mass loss of 0.46 +/- 0.37 m w.e. a(-1). Highly variable individual glacier responses were observed and interestingly, they were less negative than previously reported for the neighboring Patagonian Icefields.", "labels": [4, 27]}
{"id": "1123", "token": "Quantifying the contributions of climate change and human activities to ecosystem evapotranspiration (ET) and gross primary productivity (GPP) changes is important for adaptation assessment and sustainable development. Spatiotemporal patterns of ET and GPP were estimated from 2000 to 2014 over North China Plain (NCP) with a physical and remote sensing-based model. The contributions of climate change and human activities to ET and GPP trends were separated and quantified by the first difference de-trending method and multivariate regression. Results showed that annual ET and GPP increased weakly, with climate change and human activities contributing 0.188 mm yr(-2) and 0.466 mm yr(-2) to ET trend of 0.654 mm yr(-2), and-1.321 g C m(-2) yr(-2) and 7.542 g C m(-2) yr(-2) to GPP trend of 6.221 g C m(-2) yr(-2), respectively. In cropland, the increasing trends mainly occurred in wheat growing stage; the contributions of climate change to wheat and maize were both negative. Precipitation and sunshine duration were the major climatic factors regulating ET and GPP trends. It is concluded that human activities are the main drivers to the long term tendencies of water consumption and gross primary productivity in the NCP.", "labels": [4, 27]}
{"id": "1263", "token": "Glaciers' changes are an important indicator of global warming, and the interpretation of satellite images offers a good source of information for such a monitoring. It is important to select areas of interest for the detection of glaciers bodies and in particular to capture also the part covered with debris, which is an open issue in remote sensing of the glaciers. We use enhancing features with a physical meaning and we provide a coarse segmentation of the image of the Lys glacier belonging to the Monte Rosa district in the Alps. The image data correspond to electromagnetic sensing of sunlight as reflected in band of the visible red spectral range, T M3, and in two infrared bands T M4 and T M5, as operated from the thematic mapper (TM) sensor aboard the Landsat satellite in clear sunny days. (C) 2016 International Association for Mathematics and Computers in Simulation (IMACS). Published by Elsevier B.V. All rights reserved.", "labels": [4, 27]}
{"id": "1401", "token": "Integrating knowledge of environmental degradation, biodiversity change, and ecosystem processes across large spatial scales remains a key challenge to illuminating the resilience of earth's systems. There is now a growing realization that the manner in which communities will respond to anthropogenic impacts will ultimately control the ecosystem consequences. Here, we examine the response of freshwater fishes and their nutrient excretion -a key ecosystem process that can control aquatic productivity -to human land development across the contiguous United States. By linking a continental-scale dataset of 533 fish species from 8100 stream locations with species functional traits, nutrient excretion, and land remote sensing, we present four key findings. First, we provide the first geographic footprint of nutrient excretion by freshwater fishes across the United States and reveal distinct local-and continental-scale heterogeneity in community excretion rates. Second, fish species exhibited substantial response diversity in their sensitivity to land development; for native species, the more tolerant species were also the species contributing greater ecosystem function in terms of nutrient excretion. Third, by modeling increased land-use change and resultant shifts in fish community composition, land development is estimated to decrease fish nutrient excretion in the majority (63%) of ecoregions. Fourth, the loss of nutrient excretion would be 28% greater if biodiversity loss was random or 84% greater if there were no nonnative species. Thus, ecosystem processes are sensitive to increased anthropogenic degradation but biotic communities provide multiple pathways for resistance and this resistance varies across space.", "labels": [4, 27]}
{"id": "1447", "token": "New species discoveries or the rediscovery of species once considered extinct or extirpated is good news, and yet prospects for long-term survival may be bleak if remnant populations are small and isolated. Because (re)discovered species are commonly rare or cryptic, data to inform appropriate conservation actions are usually sparse. We demonstrate how to make the most of available data, using the recent rediscovery in Ghana of sitatunga Tragelaphus spekei as an illustrative case study. Sitatunga were thought extinct in Ghana for over 50years, but were rediscovered' by science in Avu Lagoon in 1998. Little is known about this species, especially West African populations, given its cryptic nature and inaccessible wetland habitat. Our approach to maximizing insights given limited data first paired observations of occurrence with landscape characteristics derived from open-access remote sensing data, creating the first ever habitat suitability model for sitatunga. This model then served to: (1) elucidate habitat preferences; (2) assess possible existence and connectivity of remnant populations elsewhere in Ghana; and (3) estimate maximum total and effective population size. Moreover, the timing of occurrence sightings provided insights into behavior. Sitatunga sightings were rare, heavily male-biased and mostly occurred between 6pm and 6am. Suitable habitat was limited, suggesting that habitat in and near Avu Lagoon is insufficient to ensure long-term population viability, and the existence of other, connected populations in Ghana is improbable. Without continued protection, and possibly additional interventions to augment population numbers or gene flow, the sitatunga in Avu Lagoon will likely go extinct. Our case study demonstrates the conservation challenges associated with the rediscovery of relict populations, and the utility of applying tools such as habitat suitability models to sparse data. Moreover, our research stresses the need to implement immediate conservation action upon species (re)discoveries to prevent (regional) extinction.", "labels": [4, 27]}
{"id": "1597", "token": "This paper examines the pattern and extent of energy development in steppe landscapes of northeast Colorado, United States. We compare the landscape disturbance created by oil and gas production to that of wind energy inside the Pawnee National Grasslands eastern side. This high-steppe landscape consists of a mosaic of federal, state, and private lands where dominant economic activities include ranching, agriculture, tourism, oil and gas extraction, and wind energy generation. Utilizing field surveys, remote sensing data and geographic information systems techniques, we quantify and map the footprint of energy development at the landscape level. Findings suggest that while oil and gas and wind energy development have resulted in a relatively small amount of habitat loss within the study area, the footprint stretches across the entire zone, fragmenting this mostly grassland habitat. Futhermore, a third feature of this landscape, the non-energy transportation network, was also found to have a significant impact. Combined, these three features fragment the entire Pawnee National Grasslands eastern side, leaving very few large intact core, or roadless areas. The primary objective of this ongoing work is to create a series of quantifiable and replicable surface disturbance indicators linked to energy production in semi-arid grassland environments. Based on these, and future results, we aim to work with industry and regulators to shape energy policy as it relates to environmental performance, with the aim of reducing the footprint and thus increasing the sustainability of these extractive activities.", "labels": [4, 27]}
{"id": "1673", "token": "Crop simulation models are commonly used to forecast the performance of cropping systems under different hypotheses of change. Their use on a regional scale is generally constrained, however, by a lack of information on the spatial and temporal variability of environment-related input variables (e.g., soil) and agricultural practices (e.g., sowing dates) that influence crop yields. Satellite remote sensing data can shed light on such variability by providing timely information on crop dynamics and conditions over large areas. This paper proposes a method for analyzing time series of MODIS satellite data in order to estimate the inter-annual variability of winter wheat sowing dates. A rule-based method was developed to automatically identify a reliable sample of winter wheat field time series, and to infer the corresponding sowing dates. The method was designed for a case study in the Camargue region (France), where winter wheat is characterized by vernalization, as in other temperate regions. The detection criteria were chosen on the grounds of agronomic expertise and by analyzing high-confidence time-series vegetation index profiles for winter wheat. This automatic method identified the target crop on more than 56% (four-year average) of the cultivated areas, with low commission errors (11%). It also captured the seasonal variability in sowing dates with errors of 8 and 16 days in 46% and 66% of cases, respectively. Extending the analysis to the years 2002-2012 showed that sowing in the Camargue was usually done on or around November 1st ( +/- 4 days). Comparing inter-annual sowing date variability with the main local agro-climatic drivers showed that the type of preceding crop and the weather conditions during the summer season before the wheat sowing had a prominent role in influencing winter wheat sowing dates. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [4, 27]}
{"id": "1739", "token": "Evapotranspiration (ET) is one of the most important components of the hydrological cycle, but it is often the most difficult variable to determine at basin scale. Traditionally, ET is estimated using pointbased measurements collected at meteorological stations, but the non-spatial nature of these measurements often leads to significant errors when utilized at watershed scale. In this study, the METRIC (mapping evapotranspiration at high resolution with internalized calibration) approach was evaluated using remotely sensed observations from the moderate resolution imaging spectroradiometer sensor and data from meteorological stations in the lower catchment of the Buyuk Menderes Basin in western Turkey in the form of actual ET maps at daily and monthly intervals between 1st April and 30th September 2010. The energy fluxes and daily ET maps resulting from METRIC were compared with ET data estimated with the help of meteorological parameters. These results were found to be compatible with the ground-based estimations which suggest considerable potential for the METRIC model for estimating spatially distributed actual ET values with little ground-based weather data.", "labels": [4, 27]}
{"id": "1797", "token": "Land use and land cover change (LULCC) is one of the main components of current anthropogenic global change. Unravelling the ecological response of biodiversity to the combined effect of land use change and other stressors is essential for effective conservation. For this purpose, we used co-inertia analysis to combine LULCC analysis of earth observation satellite data-derived maps and raptor data obtained from road censuses conducted in 2001 and 2014 at sampling unit level (10 km(2) spatial resolution), in northwestern Spain (province of Ourense, c. 7281 km(2)). In addition, habitat suitability models were also computed using ten widely used single-modelling techniques providing an ensemble of predictions at landscape level (four spatial resolutions: 500-m, 1-km, 2-km and 5-km radius around each sighting) for each year and raptor species to analyse the habitat suitability changes in the whole study area through three niche overlap indices. The models revealed an increase in occurrence and habitat suitability of forest raptor species coupled with a strong decrease in species associated with open habitats, mainly heaths and shrub formations. Open-habitat specialist species were negatively affected by the concomitant effects of intensive forest management and a long-lasting trend of rural abandonment coupled with an unusually high frequency of wildfires. Sustainable forest management and agricultural practices should be encouraged by both public and private sectors, through, e.g. policies related to European funds for rural and regional development (FEDER and FEADER programs) to effectively protect threatened habitats and species, and to comply with current environmental legislation. The combined use of satellite imagery and ground-level biodiversity data proved to be a cost-effective and systematic method for monitoring priority habitats and their species in highly dynamic landscapes.", "labels": [4, 27]}
{"id": "1853", "token": "This paper provides an overview of the surface waves investigation and monitoring (SWIM) instrument which will be one of the two payload instruments carried by China France Oceanography SATellite (CFOSAT) with a planned launch date in mid-2018. SWIM is a real aperture wave scatterometer operated at near-nadir incidence angles and dedicated to the measurement of directional spectra of ocean waves. The SWIM flight model is currently being assembled and tested, its performance is being assessed and its prototype data processing algorithm is being developed. The aim of this paper is to provide a complete overview on the motivations and scientific requirements of this mission, together with a description of the design and characteristics of the SWIM instrument, and the analysis of its expected performances based on a prelaunch study. An end-to-end simulator has been developed to evaluate the quality of the data products, thus allowing the overall performance of the instrument to be assessed. Simulations run with two subsets of full orbit subsets show that the performances of the instrument and the inversion algorithms will meet the scientific requirements for the mission.", "labels": [4, 27]}
{"id": "2066", "token": "We quantify the spatial and temporal aspects of the urban heat-island (UHI) effect for Kanpur, a major city in the humid sub-tropical monsoon climate of the Gangetic basin. Fixed station measurements are used to investigate the diurnality and inter-seasonality in the urban-rural differences in surface temperature () and air temperature () separately. The extent of the spatial variations of the nighttime and is investigated through mobile campaigns and satellite remote sensing respectively. Nighttime values dominate during both the pre-monsoon (maximum of 3.6 ) and the monsoon (maximum of 2.0 ). However, the diurnality in is different, with higher daytime values during the pre-monsoon, but very little diurnality during the monsoon. The nighttime value is mainly associated with differences in the urban-rural incoming longwave radiative flux ( during the pre-monsoon; 0.65 during the monsoon), which, in turn, causes a difference in the outgoing longwave radiative flux. This difference may modulate the nighttime value as suggested by significant correlations ( for the pre-monsoon; 0.50 for the monsoon). The magnitude of may also be modulated by advection, as it is inversely related with the urban wind speed. A combination of in situ, remotely sensed, and model simulation data were used to show that the inter-seasonality in , and, to a lesser extent, in , may be related to the change in the land use of the rural site between the pre-monsoon and the monsoon periods. Results suggest that the degree of coupling of and may be a strong function of land use and land cover.", "labels": [4, 27]}
{"id": "2257", "token": "Flood events cause substantial damage to urban and rural areas. Monitoring water extent during large-scale flooding is crucial in order to identify the area affected and to evaluate damage. During such events, spatial assessments of floodwater may be derived from satellite or airborne sensing platforms. Meanwhile, an increasing availability of smartphones is leading to documentation of flood events directly by individuals, with information shared in real-time using social media. Topographic data, which can be used to determine where floodwater can accumulate, are now often available from national mapping or governmental repositories. In this work, we present and evaluate a method for rapidly estimating flood inundation extent based on a model that fuses remote sensing, social media and topographic data sources. Using geotagged photographs sourced from social media, optical remote sensing and high-resolution terrain mapping, we develop a Bayesian statistical model to estimate the probability of flood inundation through weights-of-evidence analysis. Our experiments were conducted using data collected during the 2014 UK flood event and focus on the Oxford city and surrounding areas. Using the proposed technique, predictions of inundation were evaluated against ground-truth flood extent. The results report on the quantitative accuracy of the multisource mapping process, which obtained area under receiver operating curve values of 0.95 and 0.93 for model fitting and testing, respectively.", "labels": [4, 27]}
{"id": "2422", "token": "The reporting of ecological phenomena and environmental status routinely required point observations, collected with traditional sampling approaches to be extrapolated to larger reporting scales. This process encompasses difficulties that can quickly entrain significant errors. Remote sensing techniques offer insights and exceptional spatial coverage for observing the marine environment. This review provides guidance on (i) the structures and discontinuities inherent within the extrapolative process, (ii) how to extrapolate effectively across multiple spatial scales, and (iii) remote sensing techniques and data sets that can facilitate this process. This evaluation illustrates that remote sensing techniques are a critical component in extrapolation and likely to underpin the production of high-quality assessments of ecological phenomena and the regional reporting of environmental status. Ultimately, is it hoped that this guidance will aid the production of robust and consistent extrapolations that also make full use of the techniques and data sets that expedite this process. (C) 2017 Elsevier Ltd. All rights reserved.", "labels": [4, 27]}
{"id": "2573", "token": "Urbanization globally is consistently reshaping the natural landscape to accommodate the growing human population. Urban vegetation plays a key role in moderating environmental impacts caused by urbanization and is critically important for local economic, social and cultural development. The differing patterns of human population growth, varying urban structures and development stages, results in highly varied spatial and temporal vegetation patterns particularly in the pan-Pacific region which has some of the fastest urbanization rates globally. Yet spatially-explicit temporal information on the amount and change of urban vegetation is rarely documented particularly in less developed nations. Remote sensing offers an exceptional data source and a unique perspective to map urban vegetation and change due to its consistency and ubiquitous nature. In this research, we assess the vegetation fractions of 25 cities across 12 pan-Pacific countries using annual gap-free Landsat surface reflectance products acquired from 1984 to 2012, using sub-pixel, spectral unmixing approaches. Vegetation change trends were then analyzed using Mann-Kendall statistics and Theil-Sen slope estimators. Unmixing results successfully mapped urban vegetation for pixels located in urban parks, forested mountainous regions, as well as agricultural land (correlation coefficient ranging from 0.66 to 0.77). The greatest vegetation loss from 1984 to 2012 was found in Shanghai, Tianjin, and Dalian in China. In contrast, cities including Vancouver (Canada) and Seattle (USA) showed stable vegetation trends through time. Using temporal trend analysis, our results suggest that it is possible to reduce noise and outliers caused by phenological changes particularly in cropland using dense new Landsat time series approaches. We conclude that simple yet effective approaches of unmixing Landsat time series data for assessing spatial and temporal changes of urban vegetation at regional scales can provide critical information for urban planners and anthropogenic studies globally. (C) 2017 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS). Published by Elsevier B.V. All rights reserved.", "labels": [4, 27]}
{"id": "2719", "token": "Landsat data are increasingly used for ecological monitoring and research. These data often require preprocessing prior to analysis to account for sensor, solar, atmospheric, and topographic effects. However, ecologists using these data are faced with a literature containing inconsistent terminology, outdated methods, and a vast number of approaches with contradictory recommendations. These issues can, at best, make determining the correct preprocessing workflow a difficult and time-consuming task and, at worst, lead to erroneous results. We address these problems by providing a concise overview of the Landsat missions and sensors and by clarifying frequently conflated terms and methods. Preprocessing steps commonly applied to Landsat data are differentiated and explained, including georeferencing and co-registration, conversion to radiance, solar correction, atmospheric correction, topographic correction, and relative correction. We then synthesize this information by presenting workflows and a decision tree for determining the appropriate level of imagery preprocessing given an ecological research question, while emphasizing the need to tailor each workflow to the study site and question at hand. We recommend a parsimonious approach to Landsat preprocessing that avoids unnecessary steps and recommend approaches and data products that are well tested, easily available, and sufficiently documented. Our focus is specific to ecological applications of Landsat data, yet many of the concepts and recommendations discussed are also appropriate for other disciplines and remote sensing platforms.", "labels": [4, 27]}
{"id": "2771", "token": "Biocrusts are critical components of desert ecosystems, significantly modifying the surfaces they occupy. The mixture of biological components and soil particles that form the crust, in conjunction with moisture, determines the biocrusts' spectral signatures. Proximal and remote sensing in complemeritary spectral regions, namely the reflective region, and the thermal region, have been used to study biocrusts in a non-destructive manner, in the laboratory, in the field, and from space. The objectives of this review paper are to present the spectral characteristics of biocrusts across the optical domain, and to discuss significant developments in the application of proximal and remote sensing for biocrust studies in the last few years. The motivation for using proximal and remote sensing in biocrust studies is disttissed. Next, the application of reflectance spectroscopy to the study of biocrusts is presented followed by a review of the emergence of high spectral resolution thermal remote sensing, Which facilitates the application of thermal spectroscopy for biocrust studies. Four specific topics at the forefront of proximal and remote sensing of biocrusts are discussed: (1) The use of remote sensing in determining the role of biocrusts in global biogeochemical cycles; (2) Monitoring the inceptive establishment of biocrusts; (3) Identifying and characterizing biocrusts using Longwave infrared spectroscopy; and (4) Diurnal emissivity dynamics of biocrusts in a sand dune environment. The paper concludes by identifying innovative technologies such as low altitude and high resolution imagery that are increasingly used in remote sensing science, and are expected to be used in future biocrusts studies. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [4, 27]}
{"id": "2859", "token": "Rapid integration of global agricultural markets and subsequent cropland displacement in recent decades increased large-scale tropical deforestation in South America and Southeast Asia. Growing land scarcity and more stringent land use regulations in these regions could incentivize the offshoring of export-oriented commodity crops to sub-Saharan Africa (SSA). We assess the effects of domestic-and export-oriented agricultural expansion on deforestation in SSA in recent decades. Analyses were conducted at the global, regional and local scales. We found that commodity crops are expanding in SSA, increasing pressure on tropical forests. Four Congo Basin countries, Sierra Leone, Liberia, and Cte d ' Ivoire were most at risk in terms of exposure, vulnerability and pressures from agricultural expansion. These countries averaged the highest percent forest cover (58% +/- 17.93) and lowest proportions of potentially available cropland outside forest areas (1% +/- 0.89). Foreign investment in these countries was concentrated in oil palm production (81%), with a median investment area of 41 582 thousand ha. Cocoa, the fastest expanding export-oriented crop across SSA, accounted for 57% of global expansion in 2000-2013 at a rate of 132 thousand ha yr(-1). However, cocoa only amounted to 0.89% of foreign land investment. Commodity crop expansion in SSA appears largely driven by small-and mediumscale farmers rather than industrial plantations. Land-use changes associated with large-scale investments remain to be observed in many countries. Although domestic demand for commodity crops was associated with most agricultural expansion, we provide evidence of a growing influence of distant markets on land-use change in SSA.", "labels": [4, 27]}
{"id": "3020", "token": "Purpose of Review This review presents cutting- edge methods and current and forthcoming satellite remote sensing technologies to map aboveground biomass (AGB). Recent Findings The monitoring of carbon stored in living AGB of forest is of key importance to understand the global carbon cycle and for the functioning of international economic mechanisms aiming to protect and enhance forest carbon stocks. The main challenge of monitoring AGB lies in the difficulty of obtaining field measurements and allometric models in several parts of the world due to geographical remoteness, lack of capacity, data paucity or armed conflicts. Space- borne remote sensing in combination with ground measurements is the most cost-efficient technology to undertake the monitoring of AGB. Summary These approaches face several challenges: lack of ground data for calibration/validation purposes, signal saturation in high AGB, coverage of the sensor, cloud cover persistence or complex signal retrieval due to topography. New space-borne sensors to be launched in the coming years will allow accurate measurements of AGB in high biomass forests (>200 t ha(-1)) for the first time across large areas.", "labels": [4, 27]}
{"id": "3103", "token": "An erythromycin (ERY) detection method is proposed using the fiber optic core decorated with the coatings of silver and an over layer of ERY imprinted nanoparticles. Synthesis of ERY imprinted nanoparticles is carried out using miniemulsion method. The operating range of the sensor is observed to be from 1.62x10(-3) to 100 mu M while the sensor possesses the linear response for ERY concentration range from 0.1 to 5 mu M. The sensing method shows a maximum sensitivity of 205 nm/M near ERY concentration of 0.01 mu M. The detection limit and the quantification limit of the sensor are found to be 1.62x10(-3) mu M and 6.14x10(-3) mu M, respectively. The sensor's applicability in real samples is also examined and is found to be in good agreement for the industrial application. The sensor possesses numerous advantages like fast response time (< 15 s), simple, low cost, highly selective along with abilities towards online monitoring and remote sensing of analyte.", "labels": [4, 27]}
{"id": "3211", "token": "A forest fire started on August 8th, 2016 in several places on Madeira Island causing damage and casualties. As of August 10th the local media had reported the death of three people, over 200 people injured, over 950 habitants evacuated, and 50 houses damaged. This study presents the preliminary results of the assessment of several spectral indices to evaluate the burn severity of Madeira fires during August 2016. These spectral indices were calculated using the new European satellite Sentinel-2A launched in June 2015. The study confirmed the advantages of several spectral indices such as Normalized Difference Vegetation Index (NDVI), Green Normalized Difference Vegetation Index (GNDVI), Normalized Burn Ratio (NBR) and Normalized Difference Vegetation Index (NDVIreXn) using red-edge spectral bands to assess the post-fire conditions. Results showed high correlation between NDVI, GNDVI, NBR and NDVIreln spectral indices and the analysis performed by Copernicus Emergency Management Service (EMSR175), considered as the reference truth. Regarding the red-edge spectral indices, the NDVIreln (using band B5, 705 nm) presented better results compared with B6 (740 nm) and B7 (783 nm) bands. These preliminary results allow us to assume that Sentinel-2 will be a valuable tool for post-fire monitoring. In the future, the two twin Sentinel-2 satellites will offer global coverage of the Madeira Archipelago every five days, therefore allowing the simultaneous study of the evolution of the burnt area and reforestation information with high spatial (up to 10 m) and temporal resolution (5 days). (C) 2017 Elsevier B.V. All rights reserved.", "labels": [4, 27]}
{"id": "3302", "token": "Automatic change detection is one of the remote sensing applications that has received an increasing attention during the last years. However, fully automatic solutions reach their limitation; on the one hand, it is difficult to design general decision criteria able to select area of changes for images under various acquisition conditions, and on the other hand, the relevance of changes may differ from one user to another. In this letter, we introduce an alternative change detection method based on relevance feedback. The proposed algorithm is iterative and based on a query and answer model that: 1) asks the user questions about the relevance of his targeted changes and 2) according to these answers, updates change detection results. Our method is also based on a new formulation of canonical correlation analysis (CCA), referred to as context-aware CCA, that learns transformations, which map data from different input spaces (related to multitemporal satellite images) into a common latent space, which is sensitive to relevant changes while being resilient to irrelevant ones. These CCA transformations correspond to the optimum of a particular constrained maximization problem that mixes an alignment term with a context-based regularization criterion. The particularity of this novel CCA approach resides in its ability to exploit spatial geometric context resulting into better performances compared with other CCA approaches, as shown in experiments.", "labels": [4, 27]}
{"id": "3410", "token": "It is useful and challenging to analyze and select object features of very high resolution (VHR) remote sensing imagery. The overwhelming majority of existing feature selection methods always concatenate all of the features into a long feature vector and then select features from the vector, ignoring the homogeneity and heterogeneity of underlying feature subspaces. In this paper, we propose a supervised multiview feature selection (SMFS) method. Unlike the existing multiview methods, SMFS requires no prior knowledge of the number of views, and is independent of a prefixed classifier. By utilizing homogeneity and heterogeneity of the data, SMFS employs affinity propagation to automatically decompose features into multiple disjoint and meaningful feature groups or views without any prior knowledge. A group or view consists of homogeneous features, describing a unique data characteristic. Different views represent heterogeneous data characteristics. Then, features are evaluated and selected based on joint l(1,2)-norm minimization of a loss function and a regularization term. Different from the popular l(1,2)-norm, joint l(1,2)-norm enforces the intraview sparsity, instead of interview sparsity. Consequently, a view can be represented by a few representative features in each view, and the information of heterogeneous views can be well kept by the remaining representative features. The experimental results on four VHR satellite images attest to the effectiveness and practicability of SMFS in comparison with single-view algorithms. Furthermore, some discussions are conducted to give insights into homogeneity and heterogeneity of features.", "labels": [4, 27]}
{"id": "3454", "token": "The remote sensing image data is so vast that it requires compression by low-complexity algorithm on space-borne equipment. Binary tree coding with adaptive scanning order (BTCA) is an effective algorithm for the mission. However, for large-scale remote sensing images, BTCA requires a lot of memory, and does not provide random access property. In this paper, we propose a new coding method based on BTCA and optimize truncation. The wavelet image is first divided into several blocks which are encoded individually by BTCA. According the property of BTCA, we select the valid truncation points for each block carefully to optimize the ratio of rate-distortion, so that a higher compression ratio, lower memory requirement and random access property are attained. Without any entropy coding, the proposed method is simple and fast, which is very suitable for space-borne equipment. Experiments are conducted on three remote sensing image sets, and the results show that it can significantly improve PSNR, SSIM and VIF, as well as subjective visual experience. (C) 2017 Elsevier Inc. All rights reserved.", "labels": [4, 27]}
{"id": "45", "token": "ASP is located in a server-side scripting running environment, through this kind of environment, the user will be able to create and run dynamic interactive Web server application, such as interactive dynamic Web page, Web information processing, Web database access and so on. Analysis of the ASP technology and access the characteristics of WEB database, this paper introduces the working principle of ASP and ASP built-in objects and components, and emphasizes to discuss the ASP database access components ADO, based on this, gives the realization with ASP WEB database access to the application example in manufacturing engineering.", "labels": [3, 22]}
{"id": "90", "token": "One result of globalization is the rapid growth of offshoring, i.e., the outsourcing of functions and jobs to offshore locations. In the USA, offshoring has progressed to the point where it already affects everyday lives, from the cars we drive (of which a large portion of the work and components are outsourced) to computers (which are typically manufactured offshore and shipped back to the USA), to electronic diagnostics (where calls are answered overseas). This phenomenon has implications on our lives and on the jobs that engineers and scientists will assume both now and in the future. Further, it is something that all highly developed and even some lesser-developed countries must face. Consequently, the growth of outsourcing will have a major impact on the educational objectives of engineering programs and the resultant engineering curricula worldwide. This paper presents recent data on product and job offshore migrations and discusses the various dimensions of this phenomenon. In addition to the potential loss of engineering and other high-end technical jobs, sociological and cultural aspects, intellectual property issues, strategic planning concerns, and macro-economic issues are presented. For example, the effects of offshoring on the societal fabric of the countries that are recipients of manufacturing and service center outsourcing, such as China and India, are significant, rapid, and controversial. Offshoring has also begun to change the way that engineering programs in these countries educate their students. In addition, intellectual property issues create a major risk to companies considering outsourcing to certain less-developed countries. These issues can be broadly categorized into: the robustness and strength of intellectual property laws, and the degree to which these laws are implemented and enforced. Further, such factors as currency fluctuations and geo-political conditions can substantially impact outsourcing decisions and profitability. The phenomenon of offshoring, which is now affecting engineering careers, will play a major role in shaping engineering education worldwide. The next generation of engineers will need to possess the ability to work seamlessly across cultures, have outstanding communication skills and be familiar with the principles of project management, logistics, and systems integration. Some educational models that begin to address these requirements will be presented. (C) 2006 Elsevier Ltd. All rights reserved.", "labels": [3, 22]}
{"id": "167", "token": "The globalization trend has affected the tertiary education sector, resulting in an increased flow of both students and academics across borders. Economic pressures on universities and the emergence of new technologies have spurred the creation of new systems in engineering education. The recent advances in computer graphics have exposed great potential in education at all levels. The Virtual Reality (VR) is a promising technology which aims to assist the students in the visualization of concepts and to provide immediate graphical feedback during the learning process. This article presents a modular interactive teaching package, called Virtual Learning System (VLS), which can be used by people with little prior computer experience. VLS provides a comprehensive and conductive yet dynamic and interactive environment that can be incorporated into various courses in the field of Mechanical and Manufacturing Engineering. The evaluation of the learning process with the developed system has been done through laboratory reports, lab quizzes and questionnaires implemented with a tutorial monitoring application. (c) 2009 Wiley Periodicals, Inc. Comput Appl Eng Educ 19: 305-314, 2011; View this article online at wileyonlinelibrary.com; DOI 10.1002/cae.20312", "labels": [3, 22]}
{"id": "373", "token": "Particularly in the automotive industry, the combination of dissimilar materials presents manufacturing engineering with major challenges. Notably, the adapted use of plastic and metal opens up further potential for weight savings. Directly and firmly bonding the two materials together fails, however, on account of the chemical and physical dissimilarity of plastic and metal. Since joining of plastics and metals nowadays is based on adhesive bonding, the joint is weak and underlies ageing processes. A promising approach to overcome these problems is a laser based two-step process. In the first process step laser radiation is applied to generate microstructures on the surface of the metallic joining partner. In the subsequent laser joining process, the plastic is molten and interlocked into the microstructures after curing. The mechanical strength of the joint depends strongly on the load direction and can be influenced by the geometry and arrangement of microstructures. These influencing factors are investigated for three different load directions (tensile shear, tensile and peel) by experiments and by structural mechanics simulations.", "labels": [3, 22]}
{"id": "445", "token": "Friction stir welding is a novel joining process extensively used for welding of aluminum alloys. It is widely known that the process parameters involved in friction stir welding play a pivotal role in determining the final characteristics and microstructure of the joint. However, it is still unclear that what combination of process parameter values will lead to the optimum joint characteristics. Taguchi technique is a handy and efficient method that has been widely used for performing optimization in manufacturing engineering. In this paper, lap joint friction stir welding was performed on AA1100 and the process parameters were optimized using Taguchi L16 orthogonal design of experiments. Unlike previous studies on optimization of friction stir welding process in aluminum alloys, a more comprehensive approach has been taken towards the number of input and output parameters of the process. Process parameters considered in this study were tool rotational speed, tool traverse speed, tool tilt angle, and tool pin shape. The optimum design was obtained with reference to output parameters including hardness and grain size in the weld center zone, maximum working temperature, joint tensile strength, and elongation as well as the vertical and horizontal forces on the tool during the process. Analysis of variance was additionally performed to evaluate the significance of each design parameter on output parameters. Results gained from analysis of variance indicated that rotational speed and traverse speed were the most critical parameters in determining the weld mechanical properties as well as quality of the weld microstructure. Finally, to validate predicted optimum values based on Taguchi technique, confirmation tests were conducted, where an excellent agreement was observed between the predicted and experimental values, showing accuracy of the employed method and obtained results.", "labels": [3, 22]}
{"id": "645", "token": "The purposes of this study were to clarify the relationship between the force in tethered swimming (TS) and the power in semi-tethered swimming (STS), and to develop multiple regression models to estimate the force in the TS and the power in the STS using plural physical elements. To perform these purposes, the force in the TS and the power in the STS of 53 elite male high school and junior high school swimmers as subjects were measured. The force in the TS was measured by an electrical digital force gauge. The power in the STS was measured by the ergometer attachment improved a bicycle ergometer. Furthermore, height(163.2cm in average), weight (51.6kg), finger reach span (168.4cm), foot length (26.1cm), vertical jump (43.0cm) and its power of each subject was measured. The results of this study were summarized as follows; 1) The relationships between the force in the TS (X) and the power in the STS (Y) was Y=0.182X+16.35 (r=0.814). This relationship was highly significant statistically (p<0.001). 2) 49 of the multiple regression models to estimate the force in the TS were derived. The highest correlation coefficient model in theses was as follows; TS=0.16xweight+0.75xage+0.03xfinger reach span+1.10xfoot length+0.22xvertical jump-41.68 (r=0.787). 3) 59 of the multiple regression models to estimate the power in the STS were derived. The highest correlation coefficient model in these was as follows; STS=0.03xheight+0.45xweight+2.26xage+0.41xfinger reach span+0.27xvertical jump+0.01xvertical jump power-88.56 (r=0.866). (C) 2013 The Authors. Published by Elsevier Ltd. Selection and peer-review under responsibility of the School of Aerospace, Mechanical and Manufacturing Engineering, RMIT University", "labels": [3, 22]}
{"id": "806", "token": "A great deal of attention in manufacturing engineering has been focused on finishing operations of hard and brittle materials in recent years. This paper reports an experimental work on the analysis of surface roughness and material removal using design of experiment (DOE) method in magnetic abrasive finishing, (MAF) of flat surfaces. Change in surface roughness and material removal were found to increase with an increase in weight percentage of abrasive particles in magnetic abrasive brush, lubricant volume and decrease in working gap. Also, any decrease in the relative size of the abrasive particles vis-a-vis the iron particles would result into an increase of the surface roughness and decrease in material removal. It was observed that the work piece hardness had no considerable effect on the process results. The optimum parameter levels which lead into the best surface finish and highest material removal were also derived from these experimentations. Optimum levels included weight percentage of abrasive particles of 40%, Lubricant volume of 1 ml, working gap of 3 mm, relative size of abrasive particles vis-a-vis the iron particles of 0.22, and work piece hardness of 82-87 HBN. Disk type test pieces were selected from Al 7075 and their two side surfaces were under experiments. Experiments were made using a milling machine spindle as magnetic pole holder, and its table as fixture holder for work pieces.", "labels": [3, 22]}
{"id": "933", "token": "This paper describes a course that was redesigned to meet industry's need for a product life cycle management (PLM) literate workforce. The objective of this interdisciplinary course is to introduce students to manufacturing engineering theories coupled with an industry-sponsored project. Throughout the building of an assembly line simulation, students are exposed to topics including process design, process verification, and workspace ergonomics. Moreover, practices of project management along with the theory of critical chain are built into this course. The end goal is to prepare students with not only the knowledge of PLM but also the capability of problem solving, communication, self-motivated teamwork, and leadership.", "labels": [3, 22]}
{"id": "944", "token": "Current Product Lifecycle Management systems (PLM) have concentrated on product design, not on manufacturing engineering with its development of e.g. Material flows and layouts. This paper proposes an approach to describe how to represent the main required manufacturing process data using ontologies together with generic data standards. This approach makes it possible to develop translations between different software, and also providing users with the meaning of different concepts. It contributes to an efficient management of manufacturing information, with a focus on the material flow information as used in Discrete Event Simulation - DES.", "labels": [3, 22]}
{"id": "1102", "token": "Curriculum structure is responsible, largely, for the success of post-secondary Vocational Education. According to a survey among graduated students and local employers, the top skills required in students of CAD (short for Computer-aided Design) and CAM (short for Computer-aided Manufacturing) Engineering major are the abilities to use CAD applications in engineering design and production. Here we suggested a core-curriculum-based educational program aiming to enhance the employability and flexibility of students, thus promote china's post-secondary vocational education improvement.", "labels": [3, 22]}
{"id": "1136", "token": "The development of new products and manufacturing systems is usually performed in the form of projects. Frequently, the conduction of the project takes more time than planned due to inconsistency, incompleteness, and redundancy of data, which delays other project activities influencing the start of production (SOP). This paper proposes a semantic Web framework for cooperation and interoperability within product design and manufacturing engineering projects. Data and knowledge within the manufacturing domain are modelled within ontologies applying rule-based mapping. The framework facilitates the generation of new knowledge through rule based inference that enriches the ontology. This enables a high-level model completeness in the early phase of product design and manufacturing system development, which is a basic prerequisite for the realisation of a proper simulation study and analysis. The simulation results can be integrated into the ontologies as a knowledge that additionally extends the ontology.", "labels": [3, 22]}
{"id": "1216", "token": "Tolerances play an important role in modem manufacturing engineering and impact significantly the quality of a product and machining cost. In conventional methods, tolerances design is divided into two separate sequential stages i.e. product tolerance design and process tolerance design. This sequential tolerances design method would result in some problems in cooperation, continuity, and consistency between two separate design stages. A more rational approach in tolerance design is concurrent tolerancing which consolidate the two sequential design stages into one. In this paper, a genetic algorithm (GA) is used for concurrent tolerance design based on manufacturing cost and quality loss. A practical example is used to illustrate the design process. The calculation results by using CA are compared with those by conventional nonlinear optimization method.", "labels": [3, 22]}
{"id": "1354", "token": "Purpose - The purpose of this paper is to explore the robustness of the emerging body of knowledge about collaborative supply chains in the context of Engineered-to-Order (ETO) manufacturing engineering project systems. Design/methodology/approach - This paper uses an evolutionary classification technique to build an evolutionary history for an industry case study: the French ETO machine design industry. Findings - The evolutionary history shows that collaborative forms of governance have been used in this industry after an era of failed transactional market-based governance. The industry, however, has abandoned collaborative forms of governance to return to its historical roots towards more vertical integration. Research limitations/implications - Findings are only relevant in the context of the investigated industry. Practical implications - In certain industrial settings managers should consider the promise of collaboration and trust with cautious. Originality/value - The data set supports Williamson's (1993) rejection of trust as a mode of governance and calls for a more careful delineation of the conditions of recourse to trust in managerial situations.", "labels": [3, 22]}
{"id": "1512", "token": "The purpose of this work is to demonstrate that rapid prototyping can be effectively applied for fabricating test models to be used in aerodynamic experimental investigations. One of the most popular RP technology used worldwide is 3D printing (3DP). 3D printing technologies can be divided in the following groups: inkjet printing, fused deposition modelling and polyjet. The present work is focused on applications of polyjet technology for manufacturing of aerodynamic parts. This implicitly indicates the effectiveness of employing polyjet technology for fabricating wind tunnel test models. In the second part of the paper is presented a case study using EDEN 350 - 3D printing system by Objet, which is available at Transilvania University of Brasov, Department of Manufacturing Engineering.", "labels": [3, 22]}
{"id": "1565", "token": "This paper presents a novel hybrid ant colony optimization approach (ACO&VNS) to solve the permutation flow-shop scheduling problem (PFS) in manufacturing systems and industrial process. The main feature of this hybrid algorithm is to hybridize the solution construction mechanism of the ant colony optimization (ACO) with variable neighborhood search (VNS) which can also be embedded into the ACO algorithm as neighborhood search to improve solutions. Moreover, the hybrid algorithm considers both solution diversification and solution quality. Finally, the experimental results for benchmark PFS instances have shown that the hybrid algorithm is very efficient to solve the permutation flow-shop scheduling in manufacturing engineering compared with the best existing methods in terms of solution quality.", "labels": [3, 22]}
{"id": "1657", "token": "Technical advancements in manufacturing engineering have led to the development of advanced materials with improved mechanical properties. These materials are required to perform consistently in aggressive atmospheres without premature failure. To ensure reliable performance during their service life, materials are subjected to different nondestructive tests (NDT) to ensure that the materials are free from discontinuities and that their dimensions are less than critical discontinuity size. Though conventional film radiography is still used in the NDT industry, advanced radiologic techniques are being explored as an alternative to film radiography. Phosphor image plate based computed radiography is the latest development in this direction. The image produced using such a system is in a digital format, which can be processed to extract more information. This paper describes weld testing using an image plate based computed radiography system and the use of image processing for further evaluation.", "labels": [3, 22]}
{"id": "1714", "token": "As a pillar industry of the national economy, the logistics industry is a heavy responsibility in the low-carbon economy. Essentially from a logistics point of view, this paper proposed the concept of low-carbon logistics. A departure from the status quo of China's logistics industry energy consumption, and further pointed out that the cause of the problem facing China's logistics industry to achieve a low-carbon, and further propose a way to achieve low-carbon logistics. A new perspective for the study of low-carbon economy, and it proposed countermeasures effective way to promote the healthy growth of the logistics industry.", "labels": [3, 22]}
{"id": "1821", "token": "As a development country, Malaysia facing the challenge to develop their economic liked others. Economic changing from agriculture to manufacturing drastic change need people also adapt to that situation. Now days, changing become issues, such as changing of work life from agriculture to manufacturing, changing of technologies, changing of people thinking, etc. From previous studies found that major issues that majority graduate not enough employability skills. This is day by day issues and keep challenges all of Malaysian not only government also students and institutions. As previous study we found that PBL can be alternative to overcome this. Changing of delivery should be applied to applied subjects that taken by applied mathematics students to facing this problem. Applied mathematics students and subjects can be more attractive using PBL as alternative methodologies to facing now day and future issues. In this research, we study effectiveness of PBL as an alternative tool in enhancing employability skills among graduates. This study adopts a combination of qualitative and quantitative approaches. Data shall be collected using documents analysis. Students sample of the quasi-experimental study comprise manufacturing engineering undergraduates from several public institutions of higher learning in Malaysia. This result shows that student can be enhanced employability skills through PBL. Furthermore, student be more competitive and become more relevance with what industries need on employability skills. This is shown that applied mathematics with helping by PBL also valuable for become major function to catalyst employability skills. (C) 2010 Elsevier Ltd. All rights reserved.", "labels": [3, 22]}
{"id": "1962", "token": "Structural systems are subject to uncertainties due to variability in many hard-to-control noise factors, which include external loads, material properties, and construction workmanship. Traditional structural design methodologies, although clearly recognizing the presence of uncertainty, omit robustness against the effects of uncertainty in the design process. First, if the actual uncertainties in the design process are underestimated, the design may fail to satisfy safety requirements. Second, to guarantee safety in the presence of high variability of the system response, the structural designer may be forced to choose an overly conservative, thus inefficient and costly design. When robustness against uncertainty is not treated as one of the design objectives, the trade-off between over-design for safety and under-design for cost-savings is exacerbated. This manuscript demonstrates that safe and cost-effective structural engineering designs maybe achieved by implementing Robust Design concepts originally developed in manufacturing engineering to consider robustness against uncertainty. This manuscript presents an optimization-based methodology for the application of Robust Design principles to structural design and demonstrates its application on an academic problem involving design of a reinforced-concrete frame. (C) 2013 Elsevier Ltd. All rights reserved.", "labels": [3, 22]}
{"id": "2184", "token": "In recent years data mining has become a popular technique for extracting information from the databases of many types in different areas of commerce and industry. The strength of data mining comes from its flexibility of working on any kind of database and its ability to discover previously unknown and sometimes surprising results. Competitiveness increasingly depends on improving the quality of decision making from past information. Improved knowledge of engineering capabilities and products enables engineers to better target future production strategies. To move from quality control to quality assurance and reduced error occurrence, companies need to exploit their existing knowledge and previous experiences more effectively. Data mining analysis offers many potential benefits in this context. This paper briefly highlights the benefits that can be gained through the application of data mining technology in different sectors of Pakistan in general and in engineering sector in particular", "labels": [3, 22]}
{"id": "2295", "token": "In order to meet the development of advanced manufacturing technology, based on the requirement of engineering training in colleges in the new period, the advanced manufacturing engineering training platform is established. In this paper, the authors introduce in details the framework and function, analyze how to run the platform, and then, sum up its application of numerical control manufacturing in practice.", "labels": [3, 22]}
{"id": "2629", "token": "Industrial and Manufacturing Engineering (IME) 1020, Technical Communication, is a first-year technical communication course designed for first-year College of Engineering and Applied Sciences (CEAS) students at Western Michigan University (WMU). The course meets the university's General Education Writing Proficiency One requirement and is part of the core pre-engineering/pre-engineering technology program. Beginning with discussions amongst STEM faculty on how best to aid student retention while meeting course outcomes, the course coordinator has instituted a series of changes to the course syllabus and requirements including an emphasis on career exploration and development, research writing, and lifelong learning awareness. IME 1020 has also become an anchor course for the STEP (STEM Talent Enhancement Program) Learning Communities where interaction with faculty, and programs emphasizing early intervention and academic etiquette are contributing positively to an increase in first-year student retention rates.", "labels": [3, 22]}
{"id": "2648", "token": "Manufacturing engineering education is science & technology based subjects that are traditionally the hardest to teach online because of the need for providing practice & hands-on experiences at a distance. Therefore, this research aims to develop an e-leaming system to teach manufacturing technology and to enhance the quality, scale, and breadth of technological education. The major results of this research are; (1).Establish interactive on-line teaching material for the computer-aided manufacturing courses including CNC coding method, CNC simulation. (2).Propose the interactive teaching strategies for the students to learn machining process planning through web-based learning system. (3).Integrate multi-media and virtual laboratory in the developed interactive e-leaming system to enhance the effectiveness of machining education through web-based system. (4). Enhance students the ability to extract the manufacturing features from a mechanical drawing in either 2D or 3D. (5). Cultivate the principle of manufacturing process planning through the developed interactive web-based learning system. (6). Discipline CNC programming and CNC machining techniques through Internet.", "labels": [3, 22]}
{"id": "2724", "token": "The study of microstructure and texture deformation of the metallic materials necessitates detailed information of physical evidence about the plastic deformation mechanism, which involves a direct relationship between mechanical properties and their behaviours under the working conditions. Generally, the mechanical properties of materials are essentially the function of their structure and their compositions. So, the study of texture deformation of mechanical parts with an efficient way in manufacturing engineering is of considerable practical interest. The present paper entails the study of the deformation mechanism in microscopic scale-in situ observation of microstructure and texture deformation by using 'X-ray' computed tomography (CT) Medical Scanner installed in the CNAM-Paris, Industrial Materials Laboratory, for evaluating the plastic deformation mechanism. A tomographic inner-health analysis will be presented from 2D slices of the examined parts in the laboratory scale on the as-received and heat-treated aluminium specimens. (c) 2007 Elsevier B.V. All rights reserved.", "labels": [3, 22]}
{"id": "2940", "token": "Integrated engineering is a subject that many specialists are concerned with. The problem of integrated engineering depends on the way in which CAD and CAPP stages are solved and also on the way in which the information transfer between these phases is ensured. The present paper is focused on the phase of process planning and presents an innovative original CAPP system. The system is strongly related to product design (CAD) where the concept of constructive-technological entity is applied and facilitates CAPP stage. The present paper presents the system structure and working.", "labels": [3, 22]}
{"id": "2979", "token": "Flexibility, resource efficiency, and time-to-market are key success factors for industrial enterprises. Essential settings are set during early phases of product development as well as manufacturing. In later product lifecycle phases, the responses from the market (e.g. complains or the amount of damage cases) show the maturity stage of the products. Quality methods like TQM or EFQM pursue the goal to permanently learn from this information. Therefore it is necessary to have an adequate information supply. This article focuses on this problem in the context of maturity stage management in manufacturing engineering. The research therefore first identifies a huge gap between the theoretically discussed information supply, based on encompassing data bases, and the real existing heterogeneous IT landscapes, which have grown in history. On basis of empirical findings, industrial businesses lack in concepts that put them in a position of adequate information supply. Therefore, a generic Business Intelligence concept, developed through research activities, seems to be a promising approach. It is thus possible to combine information from product features and manufacturing information with the traditional dimensions of managerial analysis, in order to identify impacts of engineering decisions on the product lifecycle. (C) 2013 The Authors. Published by Elsevier B.V.", "labels": [3, 22]}
{"id": "3117", "token": "The development of computer aided resources in automation of generation of manufacturing routings and operations is being mainly accomplished through the search of similarities between existent ones, resulting standard process routings that are grouped by analysis of similarities between parts or routings. This article proposes the development of manufacturing routings and operations detailment using a methodology which steps will define the initial, intermediate and final operations, starting from the rough piece and going up to the final specifications, that must have binunivocal relationship with the part design specifications. Each step will use the so called rules of precedence to link and chain the routing operations. The rules of precedence order and prioritize the knowledge of various manufacturing processes, taking in account the theories of machining, forging, assembly,and heat treatments; also, utilizes the theories of accumulation of tolerances and process capabilities, between others. It is also reinforced the availability of manufacturing databases related to process tolerances, deviations of machine tool- cutting tool- fixturing devices - workpiece,and process capabilities. The statement and application of rules of precedence, linking and joining manufacturing concepts in a logical and structured way, and their application in the methodology steps will make viable the utilization of structured knowledge instead of tacit one currently available in the manufacturing engineering departments, in the generation of manufacturing routing and operations. Consequently, the development of Computer Aided in Process Planning will be facilitated, due to the structured knowledge applied with this methodology.", "labels": [3, 22]}
{"id": "3150", "token": "Project Based Learning techniques have given rise to other learning techniques as Research Works Based Learning (RWBL). This technique is especially interested in the teching-learning process of Materials Processing Technologies related disciplines. This work reports on the results of the application of RWBL techniques in a subject of the Cadiz University's Master in Manufacturing Engineering: Engineering of Non-Conventional Materials Removing Processes. Proposed research works have been designed on the basis of a classic research paper structure: Introduction, State of the Art, Experimental Procedure, Results, Discussion and Conclusions. These proposed works were focused on a comparative analysis of different machining processes, mainly, electro-discharge machining, abrasive waterjet machining and high speed machining. This experience can be considered highly successful because the 100% of the students reached the learning objectives of the subject.", "labels": [3, 22]}
{"id": "3270", "token": "This paper describes the use of a methodology for value stream mapping and analysis of Manufacturing Engineering New Product Introduction processes. The applicability and usefulness of the technique to process improvement in this domain is explored in a case study where the production system for a new component part is planned and proven. This analysis enables an improvement strategy for the Manufacturing Engineering process to be successfully outlined.", "labels": [3, 22]}
{"id": "3535", "token": "Icam (Institut Catholique d'Arts et Metiers) [1] was founded in 1898 in Lille. Today eight campuses offer engineering training in France and abroad: Lille, Nantes, Toulouse, La Roche-sur-Yon, Vannes, Pointe Noire / Douala (Central Africa) and Loyola Icam College of Engineering and Technology, in Chennai city, (capital of Tamil Nadu state, South India). Icam remains true to its Jesuit legacy, and strives to educate each student to become a person able to take responsibilities in the real world. With over 3000 students, Icam is a well-known engineering grande-ecole in France. Icam's pedagogy consists of a blend of theory and practice, and is based on an important collaboration with industry. After three years of basic courses in every engineering fields (Mechanical Engineering, Fluid Mechanics, Materials Engineering, Design and Manufacturing Engineering, Electrical Engineering, and Computer Sciences), the fourth year allows students to choose courses in the following areas : agrifood, construction and public works, transportation, energy, information and communication technologies. All these courses are taught by industry professionals, giving the students an accurate vision of their future jobs. The fifth year of training focuses on a one-semester internship (as an engineer), and a one-semester project, based on Research and Development activities, realised in collaboration with industry (over 1000 projects during the past five years); R&D projects are carried out by teams of 2 students working full time for one semester, and supervised by an Icam research fellow/lecturer (30 ECTS credits). All R&D projects are performed subcontracted by companies (from small and medium businesses to large companies), helping students to have a better understanding of industrial organisation and applications. This also helps each department to develop strong links with local industry. These collaborations school -industry offer several advantages from an educational point of view: student motivation, project management suited to customer expectations (deadlines, methodology), financial issues taken into account, hands-on approach (development of new materials, product and process design, process improvements, quality procedures.), etc. Projects examples: - LE RELAIS: development, characterisation, optimisation, and industrialisation of a new insulation material based on recycled textiles. -STAUB: support for environmental compliance of a foundry. -TOLES PERFOREES DE LA SAMBRE: development of an evanescent oil cleaning system based on luminous flux for perforated steel sheets. -RAILTECH: process modeling of rails aluminothermic welding.", "labels": [3, 22]}
{"id": "61", "token": "Background: Previous studies have suggested that fear memories can be updated when recalled, a process referred to as reconsolidation. Given the beneficial effects of model-based safety learning (i.e. vicarious extinction) in preventing the recovery of short-term fear memory, we examined whether consolidated long-term fear memories could be updated with safety learning accomplished through vicarious extinction learning initiated within the reconsolidation time-window. We assessed this in a final sample of 19 participants that underwent a three-day within-subject fear-conditioning design, using fear-potentiated startle as our primary index of fear learning. Methods: On day 1, two fear-relevant stimuli (reinforced CSs) were paired with shock (US) and a third stimulus served as a control (CS). On day 2, one of the two previously reinforced stimuli (the reminded CS) was presented once in order to reactivate the fear memory 10 min before vicarious extinction training was initiated for all CSs. The recovery of the fear memory was tested 24 h later. Results and conclusion: Vicarious extinction training conducted within the reconsolidation time window specifically prevented the recovery of the reactivated fear memory (p = 0.03), while leaving fear potentiated startle responses to the non-reactivated cue intact (p = 0.62). These findings are relevant to both basic and clinical research, suggesting that a safe, non-invasive model-based exposure technique has the potential to enhance the efficiency and durability of anxiolytic therapies. (C) 2017 Elsevier Ltd. All rights reserved.", "labels": [5, 34]}
{"id": "146", "token": "This article presents the use of a transdiagnostic, emotion-focused treatment with a young woman with nonsuicidal self-injury (NSSI), social anxiety disorder, and generalized anxiety disorder. The patient also presented with subclinical depressive, posttraumatic stress, and eating disorder symptoms. The Unified Protocol for Transdiagnostic Treatment of Emotional Disorders (Barlow et al., 2011), a cognitive-behavioral intervention designed to be applicable across anxiety, depressive, and related disorders with strong emotional components, was used to address the range of Laura's presenting concerns. After 16 individual treatment sessions, Laura experienced significant reductions in NSSI (and urges to engage in NSSI) as well as observable improvements in her self-reported ability to respond more adaptively to intense emotion. She also reported moderate reductions in her anxiety disorder symptoms. This case illustration demonstrates how a short-term, transdiagnostic treatment approach can be flexibly applied to a variety of problems maintained by aversive and avoidant reactions to intense emotion. (C) 2017 Wiley Periodicals, Inc.", "labels": [5, 34]}
{"id": "591", "token": "The psychological treatment of choice for obsessive-compulsive disorder (OCD) is exposure and response prevention (ERP). However, the training required for practitioners to be proficient in delivering ERP is not readily available, thereby rendering the treatment inaccessible to most patients. Self-directed ERP (sERP) programs designed to increase the accessibility of ERP have not proven effective, perhaps because patients find it difficult to comply with exposure exercises without the guidance of a clinician. Research on cognitive bias modification (CBM) suggests that CBM may help individuals approach feared situations. In this case study, a patient with OCD completed a 7-week treatment program that combines sERP with CBM. Treatment led to a significant decrease in OCD symptoms and functional impairment. Results suggest that this novel treatment, which requires only an initial couple of sessions with a clinician trained in ERP, has the potential to increase the accessibility of ERP for patients with OCD. (C) 2017 Wiley Periodicals, Inc.", "labels": [5, 34]}
{"id": "650", "token": "Background: Previous studies on patients diagnosed with social anxiety disorder (SAD) reported changed patterns of the resting-state functional connectivity network (rs-FCN) between the prefrontal cortices and other prefrontal, amygdalar or striatal regions. Using a graph theory approach, this study explored the modularity based community profile and patterns of inter-/intra-modular communication for the rs-FCN in SAD. Methods: In total, for 28 SAD patients and 27 healthy controls (HC), functional magnetic resonance imaging (fMRI) data were acquired in resting-state and subjected to a graph theory analysis. Results: The within-module degree z-score for a hub region [out of a total of 10 hub regions ranked using the participation coefficient] named left middle temporal gyms was impaired in SAD compared to HC, proportional to the severity of clinician-scored and patient-reported functional impairment in SAD. Limitations: Most of participants included in this study were undergraduate students in their early-to-mid 20's. Conclusions: This study showed the importance of functional communication from the left middle temporal gyros with other opercular-insular-subcortical regions for better objective functioning and lesser subjective disability in SAD.", "labels": [5, 34]}
{"id": "725", "token": "This study investigated the relationship between reading comprehension (RC), trait anxiety, and preoccupation with reading disability (RD) in 88 school children in Grades 3 through 5 and in their mothers. Children's trait anxiety had a significant direct negative relationship with RC and also mediated the association between preoccupation with RD and RC. Mothers' preoccupation with their children's RDs had a direct negative association with their children's RC. This association was also mediated through children's trait anxiety. No association was found between mothers' trait anxiety and children's RC. In a final model, RC was explained significantly by children's word reading fluency and trait anxiety as well as by their mothers' preoccupation with their children's RDs. This study extends our understanding of multicomponential models of RC by shedding light on the significant role played by anxiety- and preoccupation-related factors involving both children with RDs and their mothers.", "labels": [5, 34]}
{"id": "831", "token": "Response inhibition has been suggested to be dysfunctional in obsessive-compulsive disorder (OCD). However, this process involves intentional cognitive control, which does not correspond to the automatic emergence of stereotyped thoughts and behaviours usually reported by patients with OCD. In the present study, the excessive facilitation of unintentional processes was assessed in OCD by using the Computerized Mirror Pointing Task (CMPT). Seventy-six volunteers participated in this study, including 39 patients with OCD and 37 healthy controls. The CMPT was administered to all participants, and a score of appropriateness of the sensorimotor adaptation to the mirror inversion was computed from the initial deviation angle (IDA), that precedes the intentional readjustment of movement. Results showed that throughout the 40 trials of the CMPT, the IDA score remained significantly abnormal in patients with OCD in comparison with control participants. Further analyses of IDA scores in OCD revealed a clear tendency to keep a natural visuomotor processing that is rigid and unadapted to the mirror condition. Irrespective of the physical requirements of the environment, patients with OCD showed a strong tendency to initiate movements as per a previously consolidated - although unadapted- sensorimotor mapping. This suggests a tendency for an excessive facilitation of unintentional stereotyped processes. Further studies should be conducted on this question by using tasks sensitive to cognitive processes other than visuo-spatial abilities. (C) 2017 Elsevier Ltd. All rights reserved.", "labels": [5, 34]}
{"id": "883", "token": "Shyness has been linked to several distinct behavioral antecedents and biological correlates across development, including early behavioral inhibition and neuroendocrine dysregulation. In the present study, we examined whether self-reported history of childhood behavioral inhibition, concurrent cortisol output, and sex affected shyness levels in adults. Results revealed that a history of childhood social behavioral inhibition predicted higher shyness among female adults with high levels of cortisol output. Among women with low cortisol levels, there was no relation between childhood social behavioral inhibition and shyness levels. These associations were not consistent when examining a history of nonsocial behavioral inhibition, or among adult males. These findings highlight the importance of differentiating social versus nonsocial behavioral inhibition when examining relations between childhood temperament and adult shyness. Further, these findings raise the possibility that neuroendocrine dysregulation may have a unique role in predicting and maintaining social behaviors such as shyness depending on sex and individual differences in temperament. (C) 2017 Elsevier Ltd. All rights reserved.", "labels": [5, 34]}
{"id": "1169", "token": "Background: Nursing education programs in every state must meet specified NCLEX pass rate standards in order to maintain licensure and accreditation. These standards are a source of great anxiety for educators and students. There is wide variety of pass rate standards among the states. In addition, individual nursing program pass rates vary substantially from one year to the next. Objectives: Pass rate variation suggests the need for scrutiny of the accuracy of applying state pass rates as a standard for evaluating nursing education program. This study considers the implications of such variation. Design: The study computes 95% confidence intervals for nursing program pass rates from 2010 to 2014 to determine whether programs that failed to meet pass rate standards may have done so by accident and whether programs that met pass rate standards may have done so by accident. Data: The study data includes statutes and regulations that establish pass rate standards and NCLEX pass rates for 1792 nursing programs reflected in reports provided by state nursing boards. Findings: Almost 20% of nursing education programs violated the state pass rate standard at least once between 2010 and 2014. Among the programs that failed to meet pass rate standards, 28.4% had a 95% confidence interval that extended above the pass rate standard, A determination that these programs did not meet pass rate standards could well be erroneous. Approximately 17.4% of programs that met pass rate standards had confidence intervals that went below the pass rate standard. A finding that these programs complied with state pass rate standards might also be erroneous. Conclusions: Application of confidence intervals to nursing program pass rates suggests that use of pass rate standards to evaluate nursing program quality may not be appropriate. This suggests the need to rethink application of state pass rate standards when evaluating nursing education programs. (C) 2017 Elsevier Ltd. All rights reserved.", "labels": [5, 34]}
{"id": "1252", "token": "Background: Prenatal anxiety and depression are distressing for the expectant mother and can have adverse effects on her fetus and subsequently, her child. This study aimed to determine whether listening to specially composed songs would be an effective intervention for reducing symptoms of prenatal anxiety and depression. Methods: Pregnant women were recruited online and randomly assigned to one of two groups: the music group (daily listening to specially composed songs) or control group (daily relaxation) for 12 weeks each. Self-report questionnaires were used to assess symptoms of State and Trait anxiety (Spielberger) and depression (Edinburgh Postnatal Depression Scale (EPDS)). Trait anxiety was measured as the primary outcome, while State anxiety and depression were the secondary outcomes. 111 participants were randomised to each group. 20 participants in the intervention group and 16 participants in the active control group completed the study. Results: The music group demonstrated lower Trait Anxiety (p = .0001) (effect size 0.80), State Anxiety (p = .02) (effect size 0.64), and EPDS (p = .002) (effect size 0.92) scores at week 12 compared to baseline, by paired t test. There were no such changes in the control group. Conclusions: Though this pilot study had high levels of attrition, the results do suggest that regular listening to relaxing music should be explored further as an effective non-pharmacological means for reducing prenatal anxiety and depression.", "labels": [5, 34]}
{"id": "1266", "token": "Self-report inventories enable efficient assessment of mental attributes in large representative surveys. However, an inventory can be administered in several ways whose equivalence is largely untested. In the present study, we administered thirteen psychological questionnaires assessing positive and negative aspects of mental health. The questionnaires were administered by four different data collection methods: face-to-face interview, telephone interview, online questionnaire, and offline questionnaire. We found that twelve of the questionnaires differed in survey methods. Although, some studies showed that social desirability tends to be highest for telephone survey and lowest for web survey. Furthermore, the effects of social desirability should be the same for the online and offline samples. However, there were no statistically significant differences between the face-to-face and telephone samples for the anxiety scale, the stress scale, and the tradition scale. We also found that for eight scales, the online sample was statistically different from the offline sample in the respondent answers. Moreover, the survey method effects were only moderated by age. Finally, measurement invariance across the four survey methods was tested for each self-report measure. There was full strong measurement invariance established for nine of thirteen scales and partial strong measurement invariance for the remaining four scales across the four survey methods. These findings indicated that measurement invariance was affected by different survey methods. (C) 2017 Elsevier Ltd. All rights reserved.", "labels": [5, 34]}
{"id": "1350", "token": "The mental health impact of parental detention and deportation on citizen children is a topic of increasing concern. Forced parent-child separation and parental loss are potentially traumatic events (PTEs) with adverse effects on children's mental health. Objective: This study examines post-traumatic stress disorder (PTSD) symptoms and psychological distress among 91 Latino U.S.-born children (ages 6 to 12), living in mixed-status families with a least 1 undocumented parent at risk for detention or deportation. Method: Multiagent (child, parent, teacher, clinician) and standardized assessments were conducted at baseline to assess for child trauma and psychological distress. Results: Analyses indicate that PTSD symptoms as reported by parent were significantly higher for children of detained and deported parents compared to citizen children whose parents were either legal permanent residents or undocumented without prior contact with immigration enforcement. Similarly, findings revealed differences in child internalizing problems associated with parental detention and deportation as reported by parent as well as differences in overall child functioning as reported by clinician. In addition, teachers reported higher externalizing for children with more exposure to PTEs. Conclusions: These findings lend support to a reconsideration and revision of immigration enforcement practices to take into consideration the best interest of Latino citizen children. Trauma-informed assessments and interventions are recommended for this special population.", "labels": [5, 34]}
{"id": "1467", "token": "Background: There is considerable evidence that outcome expectations may predict psychotherapy outcomes. However, little is known about the long-term outcome expectations following the end of the treatment.Aims: The aim of this study was to evaluate patients' long-term outcome expectations after trauma-focused post-traumatic stress disorder (PTSD) psychotherapy in a single group effectiveness study.Methods: Twenty participants with various traumatic experiences who completed the Brief Eclectic Psychotherapy for Post-Traumatic Stress Disorder (BEPP) and all the assessments were included into the study. Self-report measures were used to evaluate the therapeutic outcomes: Impact of Event Scale-Revised (IES-R), Clinical Outcomes in Routine Evaluation-Outcome Measure (CORE-OM) at pre-treatment, post-treatment, and 6-month follow-up. Subjective Units of Distress Scale was used to measure long-term outcome expectations at post-treatment, asking participants to measure the expected distress in 6 months following the treatment. Assessments at 6-month follow-up were used to estimate the accuracy of patients' expectations of their distress at previous post-treatment assessment.Results: Significant decline of PTSD symptoms at post-treatment with large effect sizes was observed. At post-treatment assessment participants expected significant improvement of their condition in 6 months after the treatment. However, therapeutic effects remained stable at the 6-month follow-up.Conclusion: It is concluded that the PTSD patients, even after successful trauma-focused treatment, tend to expect further significant positive changes. However, therapeutic effects were stable half a year after the psychotherapy, and patients tend to have false expectations about further improvement of their condition.", "labels": [5, 34]}
{"id": "1722", "token": "This case features an adult male with moderate social anxiety disorder and mild depressive symptoms who showed an initial positive response to an earlier experience of cognitive behavior therapy, but then relapsed when he started avoiding social situations again because of continuing beliefs that experiencing anxiety was unacceptable. His treatment at our clinic focused on shifting unhelpful thinking about the likelihood and consequences of becoming anxious and reengaging in avoided social situations so he could learn to tolerate negative affect and uncertainty. The treatment approach draws from cognitive behavioral models of social anxiety and highlights advances in clinical science, especially recent work on the causal role of interpretation biases (the tendency to assign negative or threatening meaning to ambiguous situations) in the maintenance and reduction of anxiety. (C) 2017 Wiley Periodicals, Inc.", "labels": [5, 34]}
{"id": "1861", "token": "Today's disposable diapers are high-performance and well-tested products, designed to keep skin dry and healthy. They are primarily made of biologically inert polymers, commonly used in fabrics and other materials that are in contact with skin, and in foods and cosmetics. Still, product safety and ingredients in everyday products can be a source of anxiety for new parents. This article provides the facts behind some commonly asked questions from consumers about diaper ingredients and safety, including myths and facts related to chlorine, latex, dyes, and chemical additives.", "labels": [5, 34]}
{"id": "1943", "token": "A prior epidemiological study identified a reduction in opioid overdose deaths in US states that legalized medical cannabis (MC). One theory to explain this phenomenon is a potential substitution effect of MC for opioids. This study evaluated whether this substitution effect of MC for opioids also applies to other psychoactive medications. New England dispensary members (n = 1,513) completed an online survey about their medical history and MC experiences. Among respondents that regularly used opioids, over three-quarters (76.7%) indicated that they reduced their use since they started MC. This was significantly (p < 0.0001) greater than the patients that reduced their use of antidepressants (37.6%) or alcohol (42.0%). Approximately two-thirds of patients decreased their use of anti-anxiety (71.8%), migraine (66.7%), and sleep (65.2%) medications following MC which significantly (p < 0.0001) exceeded the reduction in antidepressants or alcohol use. The patient's spouse, family, and other friends were more likely to know about their MC use than was their primary care provider. In conclusion, a majority of patients reported using less opioids as well as fewer medications to treat anxiety, migraines, and sleep after initiating MC. A smaller portion used less antidepressants or alcohol. Additional research is needed to corroborate these self-reported, retrospective, cross-sectional findings using other data sources.", "labels": [5, 34]}
{"id": "2014", "token": "Although loving-kindness meditation (LKM) has shown some promise as a psychological intervention, little is known about the effectiveness of LKM for reducing one of the most prevalent mental health problems: anxiety. To build knowledge in this area, we conducted a randomized controlled trial, assigning non-clinical undergraduates to either a four-session, group-based LKM intervention (n = 38) or a waitlist control (n = 33). Self-reported anxiety, compassionate love, and self-compassion were assessed at pretreatment, posttreatment, and 8-week follow-up. Relative to control participants, participants in the LKM intervention reported higher compassionate love and self-compassion at posttreatment and higher self-kindness (a component of self-compassion) at follow-up. Anxiety ratings did not significantly differ between conditions at posttreatment or follow-up. Study limitations and directions for future research are discussed.", "labels": [5, 34]}
{"id": "2188", "token": "Telecare is a healthcare resource based on new technologies that, through the services offered, attempt to help elderly people to continue living in their homes. In this sense, first-generation telecare services have quickly developed in Europe. The aim of this work was to define the profile, pattern of medication consumption and disease frequencies of elderly users of a telecare service. The cross-sectional study involved 742 Spanish community-dwelling elders (85.3% of the total users aged 65 years and over who used a telecare service before the end of the data collection period). Data were collected between March and September 2012. Subjects' mean age was 83.3 (SD 6.6) years, and the majority lived alone (78.3%) and were female (85.8%). The mean Charlson comorbidity index score was 1.13 (SD 1.1), and the mean number of prescribed medications per day was 5.6 (SD 3.0). The most frequent diseases were hypertension (51.1%) and rheumatic disorders (44%); and the most consumed medications were those for the cardiovascular (75%) and nervous (65.2%) systems. For the total sample, the three main determinants of polymedication (five or more medications) were hypertension, anxiety-depressive symptoms and coronary heart disease. Regardless of the social elements contributing to the implementation of telecare services, specific health characteristics of potential users, such as morbidity and polypharmacy, should be carefully considered when implementing telecare services in the coming years.", "labels": [5, 34]}
{"id": "2267", "token": "Stimulant drugs produce reward but also activate stress-responsive systems. The corticotropin-releasing factor (CRF) and the related hypothalamus-pituitary-adrenal (HPA) axis stress-responsive systems are activated by stimulant drugs. However, their role in stimulant drug-induced reward remains poorly understood. Herein, we report that CRF1 receptor-deficient (CRF1-/-), but not wild-type, mice show conditioned place preference (CPP) responses to a relatively low cocaine dose (5 mg/kg, i.p.). Conversely, wild-type, but not CRF1-/-, mice display CPP responses to a relatively high cocaine dose (20 mg/kg, i.p.), indicating that CRF1 receptor-deficiency alters the rewarding effects of cocaine. Acute pharmacological antagonism of the CRF1 receptor by antalarmin also eliminates cocaine reward. Nevertheless, CRF1-/-mice display higher stereotypy responses to cocaine than wild-type mice. Despite the very low plasma corticosterone concentration, CRF1-/-mice show higher nuclear glucocorticoid receptor (GR) levels in the brain region of the hippocampus than wild-type mice. Full rescue of wild-type-like corticosterone and GR circadian rhythm and level in CRF1-/-mice by exogenous corticosterone does not affect CRF1 receptor dependent cocaine reward but induces stereotypy responses to cocaine. These results indicate a critical role for the CRF1 receptor in cocaine reward, independently of the closely related HPA axis activity. (C) 2017 Elsevier Ltd. All rights reserved.", "labels": [5, 34]}
{"id": "2542", "token": "This study attempted to examine the validity of the Italian version of the Career Factors Inventory (CFI), a psychometric tool widely used in the assessment of cognitive and personal-emotional dimensions of career indecision, among a sample of 2,060 Italian students attending high school and university. Recurring to both exploratory and confirmatory factor analyses, the original four-factor structure was confirmed and returned, in line with the literature, satisfactory reliability indices; moreover, CFI subscales showed intercorrelations consistent with previous studies, albeit lower in some cases. Subsequently, convergent validity between the four CFI subscales and other scales via zero-order correlation was tested, confirming previous evidence except for need for career information. In conclusion, consistent with previous studies, the Italian version of the CFI showed to be a valid and reliable instrument for the evaluation of dimensions of career indecision.", "labels": [5, 34]}
{"id": "2588", "token": "Structured, trauma-focused cognitive-behavioral therapy (CBT) techniques are widely considered an effective intervention for children who experienced sexual abuse. However, unstructured (i.e., nondirective) play/experiential techniques have a longer history of widespread promotion and are preferred by many practicing clinicians. No evidence is available, however, to determine how the integration of these techniques impacts treatment outcome. In this study, community-based clinicians who received training in a structured, trauma-focused cognitive-behavioral intervention administered pretreatment and posttreatment evaluations to 260 sexually abused children presenting with elevated posttraumatic stress. In addition, they completed a questionnaire describing the treatment techniques implemented with each child. Overall, significant improvement was observed for each of the six clinical outcomes. Regression analyses indicated that technique selection was a significant factor in posttreatment outcome for posttraumatic stress, dissociation, anxiety, and anger/aggression. In general, a greater utilization of the structured CBT techniques was related to lower posttreatment scores, whereas a higher frequency of play/experiential techniques was associated with higher posttreatment scores. However, no interaction effects were observed. The implication of these findings for clinical practice and future research are examined.", "labels": [5, 34]}
{"id": "2673", "token": "Background For prevention of sudden cardiac death, the transvenously implantable cardioverter-defibrillator therapy (tv-ICD) is well accepted. The subcutaneous system (S-ICD (R)) is promising in terms of reducing ICD complications. Nevertheless, the impact of the novel generator position on patients' quality of life (QoL) is yet unknown. Objective This study aimed at comparing QoL and posttraumatic stress with both systems. Methods 60 S-ICD (R) and 60 case-controlled tv single-chamber ICD patients were asked to respond to three standardized questionnaires. PDS [screening for posttraumatic stress disorders (PTSD)] and PHQ-D (detection of the most predominant psychological disorders) were used to screen for potential mental comorbidities. The SF-12 questionnaire was used to evaluate physical and mental well-being. Groups were compared in terms of QoL and PTSD. Results n = 42 (70%) pairs were analyzed (n = 30 male, mean age 44.6 +/- 12.2 years). Prior appropriate (p = 0.06) or inappropriate episodes (p = 0.24), ejection fraction (p = 0.28), or underlying cardiac disease did not differ significantly between groups. PDS revealed a PTSD in n = 6 tv-ICD and n = 6 S-ICD (R) patients (14.3%) equally. In the PHQ-D questionnaire, n = 4 tv-ICD and n = 2 S-ICD (R) patients fulfilled criteria for a major depression (p = 0.68). Panic disorders (n = 2 tv, n = 0 S-ICD (R), p = 0.5), and anxiety disorders (n = 3 S-ICD (R), n = 0 tv-ICD, p = 0.24) did not differ between groups. The physical well-being score was 39.9 +/- 12.5 in patients with a tv-ICD compared to 46.6 +/- 9.9 in S-ICD (R) patients (p = 0.01). The mental well-being score was comparable in both groups (tv-ICD 51.8 +/- 10.8 vs. S-ICD (R) 51.9 +/- 10.4, p = 0.95). Conclusions Our case-control study revealed equal or even better physical well-being of patients with the S-ICD (R). PTSD occurred in almost 15% of ICD patients irrespective of the type of system.", "labels": [5, 34]}
{"id": "2701", "token": "We examined the relationship between contact of police officers with citizens, their (meta-)stereotypes about citizens, and their work-related well-being. Ninety-three police officers from 4 police stations in low- and high-crime regions in France completed the questionnaire. As expected, negative well-being of police officers is predicted by negative contact with citizens and their belief that police officers are stereotyped negatively by citizens. Moreover, the relationship between negative contact and negative well-being was mediated by police officers' beliefs that police officers are perceived negatively by citizens, whereas their perceptions of citizens did not mediate this relationship. Interestingly, level of crime did not influence these relationships. Together, this research shows the important role of beliefs about how one's group is stereotyped when in contact with another group as it may have consequences for people's well-being.", "labels": [5, 34]}
{"id": "2758", "token": "The Differentiation of Self (DoS) is a key concept of Bowen's theory, indicating a process that begins in early infancy and progresses throughout childhood and adolescence, to reach a basic level in early adulthood. This study examined the psychometric properties of an Italian version of the Differentiation of Self Inventory-Revised (DSI-R) Skowron, Schmitt, Journal of Marital and Family Therapy 29:209-222, 2003), a multidimensional measure assessing DoS as conceptualized by Bowen. The sample comprised 671 subjects (age 19-69 year). Exploratory and confirmatory factor analyses showed that the Italian DSI-R possesses good psychometric properties. Internal consistencies were adequate. Correlations with the Dyadic Adjustment Scale, the Symptom Checklist 90-Revised, and the trait form of the State-Trait Anxiety Inventory were consistent with the theoretical relations among the constructs. The findings confirm the use of DSI-R as a psychometrically sound measure of the differentiation of self in the Italian context. Implications for future research and clinical practice are addressed.", "labels": [5, 34]}
{"id": "2900", "token": "The purpose of this study was to develop a scale in Urdu language for measuring different dimensions of afterlife belief. The scale was subjected to exploratory and confirmatory factor analysis on a sample of 504 individuals (235 men and 269 women) recruited from different cities in the Punjab, Pakistan. After exploratory and confirmatory factor analysis, 16 items were retained with three well-defined factor structures of afterlife belief: positive, negative, and extinction. The alpha coefficients of the subscales ranged from .65 to .78. Convergent and discriminant validity of the subscales of Afterlife Belief Scale was determined by finding its relationship with the Pleasant Afterlife Belief Scale, the Unpleasant Afterlife Belief Scale, the Anxiety Subscale of DASS, and the Belief in Equitable World Scale. The results support that the newly developed scale has promising validity.", "labels": [5, 34]}
{"id": "3070", "token": "Understanding the dynamics of mental health of recently resettled refugees is an essential component of any comprehensive resettlement program, yet establishing the components of a successful and acceptable mental health intervention is an elusive task. Semi-structured interviews were conducted with 30 resettled refugees from five countries who had received treatment for depression, post-traumatic stress symptoms, or anxiety. Themes generated from the interviews emphasized the need for strong group-based social support as well as a focus on practical needs such as acquiring and maintaining employment, language and literacy training, and access to care.", "labels": [5, 34]}
{"id": "3160", "token": "Older adults are prescribed sedative-hypnotic medications at higher rates than younger adults. These are not recommended for older adults due to risk of sedation, cognitive impairment, and falls. Severe generalized anxiety disorder (GAD) is a possibly appropriate use of these medications in older people, but little is available on use of sedative-hypnotic medications among older adults with GAD. This study examined the frequency and predictors of sedative-hypnotic medication use among older adults screening positive for anxiety. 25.88% (n=125) of participants reported taking sedative-hypnotics over the past 3 months; 16.36% (n=79) reported taking benzodiazepines, and 12.22% (n=59) reported taking hypnotic sleep medications. Depressive symptoms were more strongly associated with sedative-hypnotic use than insomnia or worry. Major depressive disorder and posttraumatic stress disorder, but not GAD, predicted sedative-hypnotic use. Other medications and treatments are more appropriate and efficacious for depression, anxiety, and insomnia in this population.", "labels": [5, 34]}
{"id": "3224", "token": "This paper investigates the dynamic relationship between Japanese Yen exchange rates and market anxiety during the period from January 5, 1998 to April 18, 2016. A quantitative technique of multifractal detrended cross-correlation analysis (MF-DCCA) is used to explore the multifractal features of the cross-correlations between USD/JPY, AUD/JPY exchange rates and the market anxiety gauge VIX. The investigation shows that the causal relationship between Japanese Yen exchange rates and VIX are bidirectional in general, and the cross-correlations between the two sets of time series are multifractal. Strong evidence suggests that the cross-correlation exponents tend to exhibit different volatility patterns in response to diverse external shocks such as financial distress and widening in interest rate spread, suggesting that the cross-correlated behavior between Japanese Yen exchange rates and VIX are susceptible to economic uncertainties and risks. In addition, the performances of two market anxiety gauges, the VIX and the TED spread, are compared and the sources of multifractality are also traced. Thus, this paper contributes to the literature by shedding light on the unique driving forces of the Yen exchange rate fluctuations in the international foreign exchange market. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [5, 34]}
{"id": "3325", "token": "This study investigates whether the augmentation of cognitive behavior therapy (CBT) with fluoxetine improves outcomes in anxious school refusing adolescents (11-16.5 years). Sixty-two participants were randomly allocated to CBT alone, CBT + fluoxetine or CBT + placebo. All treatments were well tolerated; with one suicide-attempt in the CBT + placebo group. All groups improved significantly on primary (school attendance) and secondary outcome measures (anxiety, depression, self-efficacy and clinician-rated global functioning); with gains largely maintained at 6-months and 1-year. Few participants were anxiety disorder free after acute treatment. During the follow-up period anxiety and depressive disorders continued to decline whilst school attendance remained stable, at around 54 %. The only significant between-group difference was greater adolescent-reported treatment satisfaction in the CBT + fluoxetine group than the CBT alone group. These results indicate the chronicity of school refusal, and the need for future research into how to best improve school attendance rates.", "labels": [5, 34]}
{"id": "3412", "token": "Stachys lavandulifolia Vahl is an herbaceous wild plant native to Iran which is traditionally used in Iranian folk medicine as a mild sedative tea for reducing anxiety and for treatment of gastrointestinal disorders. Our previous study on ethyl acetate extract of S. lavandulifolia proved anti-anxiolytic activity and so the present study was designed to determine chemical components of this biologically active fraction. The extract was prepared using maceration method. Column chromatography and medium pressure liquid chromatography (MPLC) was used respectively to separate the fractions. Finally, some evaluated fractions were used for high pressure liquid (HPLC) and peak shaving recycle technique to achieve more purification. Separated compounds were determined using NMR analysis and mass spectroscopy. Six compounds have been isolated from ethylacetate extract of aerial parts of S. lavandulifolia including four flavonoids (apigenin, kumatakenin, penduletin and 4 ', 7-dihyroxy-3, 5, 6-trimethoxy flavone), a labdan diterpenoid (labda-13-en-8, 15-diol), and an iridoid.", "labels": [5, 34]}
{"id": "3470", "token": "Background: mHealth (mobile health) services are becoming an increasingly important form of information and communication technology (ICT) enabled delivery for healthcare, especially in low-resource environments such as developing countries like Bangladesh. Despite widespread adoption of mobile phones and the acknowledged potential of using them to improve healthcare services, the adoption and acceptance of this technology among the elderly is significantly low. However, little research has been done to draw any systematic study of the elderly's intention to adopt mHealth services. Objective: The aim of this study was to develop a theoretical model based on the Unified Theory of Acceptance and Use of Technology (UTAUT) and then empirically test it for determining the key factors influencing elderly users' intention to adopt and use the mHealth services. Methods: A face-to-face structured questionnaire survey method was used to collect data from nearly 300 participants of age 60 years and above from the capital city of Bangladesh. The data were analyzed using the Partial Least Squares (PLS) method, a statistical analysis technique based upon Structural Equation Modeling (SEM). Results: The study determined that performance expectancy, effort expectancy, social influence, technology anxiety, and resistance to change (p0.05). Conclusions: This study confirms the applicability of UTAUT model in the context of mHealth services among the elderly in developing countries like Bangladesh. It provides valuable information for mHealth service providers and policy makers in understanding the adoption challenges and the issues and also provides practical guidance for the successful implementation of mHealth services. Additionally the empirical findings identify implications related to the design and development of mHealth services that influence potential users. Furthermore, due to a generic approach, the findings of this study could be easily modified to assist other developing countries in the planning and up-take of mHealth services. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [5, 34]}
{"id": "64", "token": "Bunch charge variations in Free Electron Lasers such as the Free Electron Laser in Hamburg (FLASH) or the European X-Ray Free Electron Laser (E-XFEL) impacts the longitudinal phase space distribution of the electrons resulting in different bunch peak currents, pulse duration and pulse shapes. The electron bunches are generated by short ultraviolet laser pulses impinging onto a photocathode inside a radio frequency (RF) accelerating cavity. At FLASH, bursts of bunches up to 800 pulses with an intra train repetition rate of 1 MHz are used and even higher repetition rates for the E-XFEL (up to 4.5 Mhz) are planned. Charge variations along these bunch-trains can be caused by variations of the laser pulse energies, instabilities of the accelerating fields in the RF cavity and time dependent effects in the photoemission process. To improve the intra bunch-train charge flatness and to compensate train-to-train fluctuations a dedicated digital control system, based on the Micro Telecommunication Computing Architecture (MicroTCA.4) standard, was designed, implemented and successfully tested at the FLASH. The system consists of a bunch charge detection module which analyzes data from toroid system and provides the input signal for the controller which drives a fast UV-Pockels Cell installed in the optical path of the photo-cathode laser. The Pockels cell alters the laser polarization and thus the transmission through a polarizer. The modulation of UV laser pulse energy with an iterative learning feed-forward minimizing the repetitive errors from bunch-train to bunch-train and a fast feedback algorithm implemented in a Field Programmable Gate Array (FPGA) allows for fast tuning of bunch charge inside the bunch-train. In this paper a detailed description of the system and first measurement results are presented.", "labels": [1, 14]}
{"id": "134", "token": "This paper deals with the problem of robust stability analysis of grid-connected converters with LCL filters controlled through a digital signal processor and subject to uncertain grid inductance. To model the uncertain continuous-time plant and the digital control gain, a discretization procedure, described in terms of a Taylor series expansion, is employed to determine an accurate discrete-timemodel. Then, a linear matrix inequality-based condition is proposed to assess the robust stability of the polynomial discrete-time augmented system that includes the filter state variables, the states of resonant controllers and the delay from the digital control implementation. By means of a parameterdependent Lyapunov function, the proposed strategy has as main advantage to provide theoretical certification of stability of the uncertain continuous-time closed-loop system, circumventing the main disadvantages of previous approaches that employ approximate discretized models, neglecting the errors. Numerical simulations illustrate the benefits of the discretization technique and experimental results validate the proposed approach.", "labels": [1, 14]}
{"id": "257", "token": "Wide bandgap semiconductors have been increasingly adopted to enhance the efficiency and reduce the volume of power converters, as these devices are able to switch at dozens of megahertz or even 100 megahertz with lower power losses. However, such a high frequency operation may impose a challenge to the digital control system, and the required clock frequency should be up to 100 gigahertz in high precision applications, which is difficult to realize in low-cost microprocessors such as field-programmable gate array (FPGA). Instead of using hardware-dependent high frequency clocks, an alternative solution is to utilize digital pulse-width-modulated (DPWM) dither techniques to enhance the DPWM resolution. Unfortunately, this is achieved at the expense of introducing low frequency harmonics, which may complicate the output filter and system controller design. In this paper, an optimal dither technique is proposed to enhance the resolution of DPWM power converters. The concepts of positive dither and negative dither are first proposed in this paper. Furthermore, vector diagram-based analysis indicates that with the combination of positive dithers, negative dithers and a carefully selected dither sequence, the lowest order harmonics can be completely eliminated when the dither period is multiples of six switching periods. In other cases, the proposed optimal dither technique can produce minimized lowest order harmonics. Finally, experimental results obtained from a synchronous buck converter validate the feasibility of the proposed technique.", "labels": [1, 14]}
{"id": "441", "token": "Fuel cell (FC)/lithium-ion battery hybrid power system (HPS) gradually becomes a powerful energy source in the future. This paper presents a digital boost converter for FC current regulation in the HPS with a dual-battery energy storage unit (ESU). The digital boost converter regulates the FC current in order to control the FC power generation. Simulations have been conducted in PSIM environment, and the digital controller is implemented with a Microchip dsPIC33FJ06GS202 16-bit microcontroller. Experimental results show that the efficiency of power conversion can reach to 85%.", "labels": [1, 14]}
{"id": "541", "token": "Second-order generalised integrator or resonant integrator (RI) has wide range of applications. Forward and backward Euler's approximation based two integrator realisation of RI is an easily implementable frequency adaptive method. However, it suffers from resonant frequency deviation due to discretisation. The discretisation methods that lead to accurate realisation of RI require online calculation or lookup table of trigonometric functions to accommodate frequency variation. In this study, multi-rate computation-based implementation of two integrator-based RI has been proposed to minimise resonant frequency deviation. In this method, no additional logic elements are consumed to achieve accurate resonant frequency location. This along with down-sampling leads to lesser phase lag of RI. The effect of quantisation on resonant frequency deviation has been analysed for proper choice of calculation time. It is also shown that appropriate choice of down-sampling instants give a range of phase response characteristics around the nominal continuous time RI phase response. The accuracy of resonant frequency emulation has been experimentally verified by implementing a proportional-resonant controller as current controller.", "labels": [1, 14]}
{"id": "633", "token": "The advertising as a form of business promotion has more and more widely in different applications, and the lighting lamps is one of the key equipments in the entire outdoor advertising facilities. In order to improve advertising effectiveness and facilities security, especially for the outdoor advertising lighting applications in some remote areas, occasionally occur the advertising lamps stolen and damaged. A novel advertising lighting anti-thefts security system based on digital control technologies is designed and implementation in this paper. The designed system can achieve the real-time online status monitoring of advertising lighting lamps, once the abnormal situation the system can be issued on-site sound and light alarms and remote on-line notification, etc., which greatly improving the anti-theft security performance of outdoor advertising lighting.", "labels": [1, 14]}
{"id": "652", "token": "We developed a 2.5x6.6 mm(2) 2-D array transducer with integrated transmit/receive application-specific integrated circuit (ASIC) for real-time 3-D intracardiac echocardiography (4-D ICE) applications. The ASIC and transducer design were optimized so that the high-voltage transmit, low-voltage time-gain control and preamp, subaperture beamformer, and digital control circuits for each transducer element all fit within the 0.019-mm(2) area of the element. The transducer assembly was deployed in a 10-Fr (3.3-mm diameter) catheter, integrated with a GE Vivid E9 ultrasound imaging system, and evaluated in three preclinical studies. The 2-D image quality and imaging modes were comparable to commercial 2-D ICE catheters. The 4-D field of view was at least 90 degrees x 60 degrees x 8 cm and could be imaged at 30 vol/s, sufficient to visualize cardiac anatomy and other diagnostic and therapy catheters. 4-D ICE should significantly reduce X-ray fluoroscopy use and dose during electrophysiology ablation procedures. 4-D ICE may be able to replace transesophageal echocardiography (TEE), and the associated risks and costs of general anesthesia, for guidance of some structural heart procedures.", "labels": [1, 14]}
{"id": "741", "token": "The efforts for more reliable power conversion systems have been gaining momentum in recent years. The majority of the studies concerning reliability of power switches focus on the package-related failures, mainly caused by the cyclic thermal stress. The basic failure precursor for this type of stress has been identified as increased on-state resistance for power MOSFETs in the recent literature. On-state resistance monitoring during converter operation is a challenging and costly task as it requires current and voltage sensing circuits, which can block the high voltage across the switch during off-state to protect the measurement or control unit. This paper proposes a software frequency response analysis method to determine the health status of high-voltage power MOSFETs with high on-state resistance. This is achieved by analyzing and evaluating the variation in the plant model at double pole frequency using the same DSP that is used for control purposes. The proposed concept is analyzed for boost converter; however, it can be used to detect the on-state resistance variation in other types of converters operating in continuous condition mode (CCM). The proposed algorithm is embedded in a low cost DSP and experimentally verified on a dc/dc boost converter.", "labels": [1, 14]}
{"id": "886", "token": "This paper presents the stability analysis of dc distributed power systems with multiple converter-controlled loads. The load converters are tightly controlled, behaving as constant power loads with low-damped LC filters. The dynamic behavior of the system in high frequency range is often not studied with the classical tools based on conventional averaging techniques. However, dc power systems with the reduced size filter, and consequently, the high resonant frequency, are widely used in transportation applications. In this paper, the stability analysis of the system is established based on a discrete-time model of the system, taking into account the switching frequency and intrinsic nonlinearities of the system model. The impacts of the filter parameters and interactions among the constant power loads are investigated with the proposed discrete-time method. Moreover, an active stabilizer is developed and included in the dynamic model of the system, in order to extend the stability margin. The theoretical observations are then validated experimentally on a laboratory hardware prototype.", "labels": [1, 14]}
{"id": "1056", "token": "This paper presents a demodulation algorithm based on the synchronous integrator circuit for the MEMS tuning fork gyroscope utilizing the digital processing technology. The synchronous integral demodulator (SID) is adopted to demodulate the drive-detection signal and sense-axis output signal separately. Combining with automatic gain control and phase-locked loop technology, the closed-loop control of drive mode has been implemented, and high precision output of the gyroscope has been achieved. The simulation results have verified the effectiveness of the synchronous integrator circuit, which is in good agreement with the theoretical analysis. Compared with other demodulation algorithms, the SID has the advantages of the lower noise level, a better ability to attenuate the harmonics, and the best hardware efficiency. The frequency characteristic of the synchronous integrator is also analyzed, which is vital to the bandwidth of gyroscope. The print circuit board based on field-programmable gate array digital circuit is manufactured and the corresponding experiment is carried out. The experimental results show that the SID algorithm of digital control system for the gyroscope developed in our laboratory has achieved a good performance. The bias instability of tested gyroscope is measured to be 0.2 degrees l/h with the angle random walk of 0.14 degrees/root h and the nonlinearity of the scale factor is < 60 ppm with the measurement range of +/- 100 degrees/s.", "labels": [1, 14]}
{"id": "1148", "token": "Recently, there has been an increase in the use of finite control set model predictive control (FCS-MPC) for power converters. Model predictive control (MPC) uses the discrete-time model of the system to predict future values of control variables for all possible control actions and computes a cost function related to control objectives. This control technique can provide fast dynamic response. However, MPC method implementation imposes a very high computational burden and causes significant hardware requirements for real-time implementation. In this paper, a fully field-programmable gate array (FPGA)-based real-time implementation of MPC is proposed for direct matrix converter (DMC). In the proposed method, all control calculations and the safe commutation scheme for DMC are fully implemented in the FPGA and the need for another digital control platform, such as digital signal processors (DSP) or dSPACE, is eliminated. The proposed scheme takes full advantages of the parallel computation capability of FPGAs.", "labels": [1, 14]}
{"id": "1244", "token": "Experimental self-driving cars are being tested on public roads, and will at some point be commercially sold or made otherwise available to the public. A self-driving car and its digital control systems take over control tasks previously performed by the human driver. This places high demands on this control system which has to perform the highly complex task of driving the car through traffic. When this system does not perform its task adequately and damage ensues the failure of the control system may be used as a stepping stone to claim liability of the manufacturer of the car or the control system. Uncertainties about the application of (product) liability law may slow down the uptake of self-driving cars more than is warranted on the basis of technical progress. This article examines how the decision about the timing of a market introduction can be approached and how possible chilling effects of liability law can be redressed with an adequate system of obligatory insurance. (C) 2015 Maurice Schellekens. Published by Elsevier Ltd. All rights reserved.", "labels": [1, 14]}
{"id": "1372", "token": "The current controller with fast transient response and satisfactory steady state characteristics is required in PMSM Servo System. In this paper, the application of active disturbance rejection control (ADRC) for current loop is proposed and the design proceeding of a first-order ADRC controller in the current loop is elaborated. Then, by taking use of the ADRC controller and the analysis of the digital control delay effect, an improved method focusing on delay effects is presented. By taking these measures, the current regulation can achieve high performance. Simulation and experimental results verify the correctness and feasibility of the proposed method.", "labels": [1, 14]}
{"id": "1441", "token": "Bearingless permanent magnet synchronous motors (BPMSMs) have been received more and more attention during the past few decades. To realize the high-performance control for rotation and levitation, we will first need to obtain the accurate suspension force model of a BPMSM. In this work, different from conventional suspension force models, a modeling scheme for the suspension force of a BPMSM is presented by taking into account rotor eccentricity with the Maxwell stress tensor modeling scheme. The theoretical value of a suspension force model is compared by the two-dimensional finite element (FE) analysis, and calculation results reveal that the theoretical value closely agree with the FE computed one. Furthermore, the digital control system is devised by taking advantage of TMS320F2812, and a test platform for experiments is then set up. In accordance with the corresponding findings of the experiments, the rotor stabilization with magnetic levitation can be achieved. The results lay a theoretical and experimental foundation for further study of the BPMSM.", "labels": [1, 14]}
{"id": "1486", "token": "In this paper, a unified averaged modeling method is proposed to investigate the fast-scale period-doubling bifurcation of a full-bridge integrated buck-boost inverter with peak current control. In order to increase the resolution of the conventional classic averaged model to half the switching frequency, sample-and-hold effect of inductor current is absorbed into the averaged model, i.e. the proposed unified averaged model can capture the high-frequency dynamical characteristics of the buck-boost inverter, which is both an extension and a modification of conventional averaged model. Based on the unified mode, fast-scale bifurcation is identified, and the corresponding bifurcation point is predicted with the help of the locus movement of all the poles, and their underlying mechanisms are revealed. Detailed analysis shows that the occurrence of high-frequency oscillation means fast-scale bifurcation, while the occurrence of low-frequency oscillation leads to slow-scale bifurcation. Finally, it is demonstrated that the unified averaged model can provide not only a general method to investigate both the slow-and fast-scale bifurcations in a unified framework but also a quite straightforward design-oriented method which can be directly applicable.", "labels": [1, 14]}
{"id": "1558", "token": "In digitally controlled circuits for power electronic circuits, sampling data are important because the digital control circuit is operated on the basis of these data. If the sampled values have been affected by switching noise from the power circuit, the control stability of the circuit would be disturbed. This paper proposes a noiseless sampling method that can sample a value without being affected by the switching noise. The synchronous sampling method may be affected by the switching noise depending on the duty ratio of the circuit. The noiseless sampling method does not obtain data immediately after turn-on and turn-off switching. The control circuit can avoid the switching noise by using noiseless sampling, which leads to a disturbance in the control circuit and enhances the robustness of the circuit when applying the multisampling method. Experimental results are presented to verify that the current control of the proposed sampling method is not disturbed by the switching noise even in the absence of a noise filter.", "labels": [1, 14]}
{"id": "1631", "token": "In a distributed generation system, the stability of grid-connected inverters is directly related to the reliable operation of the grid-connected system. The impedance-based analysis method can be employed to effectively study the interaction stability between grid-connected inverters and grid, which means that it is necessary to obtain the impedance modeling of grid-connected inverters for the analysis of impedance stability. Based on the three-phase LCL-type grid-connected inverter, the harmonic linearization method was adopted in this paper to analyze the frequency characteristic of Phase-Locked Loop (PLL), and a design approach of PLL regulator parameters was proposed. Meanwhile, the impacts of the factors that include PLL and digital control delay on the impedance characteristic were considered, and the positive-sequence and negative-sequence impedance model of the gridconnected inverter was built by combining the harmonic linearization and symmetrical component methods. Then, the frequency characteristic of PLL was verified by the simulation results and the output impedance model of the grid-connected inverter was verified by the experimental results, which effectively proved the correctness of the theoretical analysis. Finally, based on the output impedance model of the grid-connected inverter, the impedance-based analysis method was adopted to make a theoretical analysis and experiment validation of the interaction stability of the grid-connected system.", "labels": [1, 14]}
{"id": "1707", "token": "Inspiring by the advantages of digital peak voltage (DPV) control and digital average current (DAC) control, the digital average voltage (DAV) control for switching DC-DC converter is proposed and investigated. Taking buck converter as an example, DAV control algorithm is analyzed in detail. In order to explore the stability of system, the z-domain transfer function is deduced, by which the critical equivalent series resistance (ESR) of output capacitor is obtained. Finally, DAV controlled, DPV controlled and DAC controlled buck converter are compared by time-domain simulation. Results indicate that DAV control possesses better steady accuracy as well as DAC control. In addition, DAV controlled buck converter is in stable state during the whole duty ratio. Moreover, DAV control and DPV control have similar load transient performance but DAV control behaves lower overshoot voltage with load variation.", "labels": [1, 14]}
{"id": "1912", "token": "This work describes the practical implementation of a Floating-Interleaving Boost Converter (FIBC) for fuel cell applications. The paper aims to validate the concept of digitally-controlled from four-phases-FIBC for fuel cell applications. FIBC exhibits interesting performance in terms of magnetics, input, and output current ripple, part count and distributed power losses. A potential field of application is indeed medium and higher power fuel cell front-end converters, where minimizing input current ripple is significant but also redundancy and reliability are crucial. Actually, this approach covers all these aspects since provide module and device redundancy with real-time and flexible digital control reconfiguration. Relevant aspects related to design; modeling, simulation and experimental verification of 100W, Arduino-controlled, 4-phases-FIBC are treated in this paper.", "labels": [1, 14]}
{"id": "1991", "token": "PID controller has been widely used in many different areas such as power systems, drives control, automotive mechatronics, aerospace, process control, and robotics. Recently, FPGA (field programmable gate array) has become an alternative solution for the realization of digital control algorithm systems. In this paper FPGA-based incremental PID (Proportional, Integral, Derivative) controller is designed and simulated. After the analysis of PID control algorithm, VerilogHDL language is used to design the software programs. Simulation results show the effectiveness and feasibility of the proposed method.", "labels": [1, 14]}
{"id": "2180", "token": "This paper focuses on dynamic modeling, simulation and control of Advanced Automatic Pumping Station with Canal Level Remote Control System using ABB PLC (Programmable Logical Controller) based Fuzzy Logic Controller. The system is designed for the agricultural land where the water level (i.e. canals or rivers) is low and traditional system of irrigation is not working well. System is automated through two different controllers, first controller automate the water reservoir gate according to the upper and lower limits of reservoir level and second controller dealt with speed of two pumps with respect to the set point of water level in canal. For controlling, monitoring and real time visualization of a system, HMI (Humane Interface Machine -CP 405) is connected. The applied control method is based on Fuzzy Logic System, designed in MATLAB Simulink, which can communicate with PLC through OPC server by using gateway. Through GPRS based system communication is done between PLC and canal water level meter. A digital control unit PLC (AC500 PM556-ETH) gets data from the system, take the require actions and make decision to operate the pumping station. Simulation results show that system can effectively operate in both, automatic as well as manual conditions depending on selection switch.", "labels": [1, 14]}
{"id": "2251", "token": "The voltage source converters (VSC) are the key power interfaces between the individual ac grids and dc grids in the hybrid power system. When the ac grid is unbalanced, the grid currents are distorted and the harmonic is induced. Meanwhile, the oscillations in the active and reactive power are also increased, which may damage these interfaces. In order to ensure the safety of the converters and the grid facility, a flexible control strategy is proposed for the ac/dc hybrid grid in this paper. At first, the current harmonic for the VSC is theoretically analyzed under unbalanced conditions. Furthermore, the methods to separate the positive- and negative-sequence components of the ac grid voltages are summed up and analyzed. Based on the theoretical analysis, different protected control methods are compared. A new control method, which can flexibly control oscillations of the active and reactive power by introducing a parameter k, has been proposed. The estimation of maximum current in each phase is discussed; meanwhile, the relationship between the voltage ripple on dc link and the parameter k is given. Finally, the validity and advantages of the proposed method are verified by the simulating and experimental results.", "labels": [1, 14]}
{"id": "2457", "token": "A design of a new hybrid-type digital pulsewidth modulator (DPWM) with a wide frequency range of 1000 : 1, from 10 kHz to 10 MHz, is presented. The proposed DPWM has the maximum duty-cycle resolution of 11 bits and consumes the power of 17.5 mu W at 10 kHz and 2.36 mW at 10 MHz, respectively. The proposed DPWM realizes the upper 5-bit resolution using a programmable digital counter and the lower 6-bit resolution using a current-integrating-type phase interpolator, employing an M2M-ladder current-steering digital-to-analog converter for low power consumption. The operating clock is generated in on-chip using a relaxation oscillator. The prototype integrated circuit fabricated in a 0.25-mu m high-voltage complementary metal-oxide-semiconductor demonstrates that the proposed DPWM maintains a good linearity across the entire operating range.", "labels": [1, 14]}
{"id": "2708", "token": "A switched-current (SI) based beamformer, suitable for low-power and low-area applications, is presented. The most important feature of the proposed beamformer is that the current consumption does not increase linearly with memory size. This is achieved by employing external capacitors for memory storage unlike a conventional SI memory. This is a fully differential design implemented using delay and sum approach. An Analog RAM (ARAM) has been used to implement the delay and each memory cell in the ARAM has been implemented using an SI circuits. There are 16 memory cells in each ARAM consuming 35.15 mu A/cell. The signal-to-noise ratio (SNR) of 63 dB is measured after summation of 16 channels. The total current consumption of beamformer including the bias, and digital control is 9 mA and area is 1.27 mm(2). (C) 2015 Elsevier Ltd. All rights reserved.", "labels": [1, 14]}
{"id": "2875", "token": "In a digital control system, the dependency model between the actions of operators differs from that in a conventional control room because information sharing and the main control room (MCR) operations are team operations. Dependencies between the actions of operators are more common in a digital control system compared with a conventional control room because operators share the same information and MCR operations are directed by team decisions. Therefore, assessing the dependencies between operators is an important aspect of human reliability analysis. In this study, we use a fuzzy logic-based approach to evaluate the dependencies among the actions of operators in the present study. First, the factors that influence the dependency levels among the actions of operators are identified by analyzing the characteristic human factors in a digital control system and an analytical model of the dependencies is then constructed. Second, a method for analyzing the dependencies between the actions of operators is established based on a fuzzy logic approach. This method can simulate vague and uncertain knowledge, but it also provides a clear explanation of the origins of results and their reasoning process by tracing the steps in reasoning. Therefore, traceability and repeatability are characteristics of the proposed method. Third, we present a case study to demonstrate the proposed approach. Finally, we demonstrate that the results obtained are reasonable and that the established model is stable based on validations that involve data comparisons and a sensitivity analysis of the model. (C) 2015 Elsevier B.V. All rights reserved.", "labels": [1, 14]}
{"id": "2937", "token": "Actuated by spatial universal rotating magnetic vector through digital control, the steering navigation of the spiral-type capsule robot in the gastrointestinal (GI) tract becomes possible. However, as a potential risk, the fluid resistance torsion moment generated by the rotating spiral-type capsule robot would distort the GI tract with insufficient fluid. It is difficult to investigate the fluid distorting effect on the GI tract, because online measurement of the fluid resistance torsion moment still remains unsolved. In this paper, an innovative method employing critical coupling magnetic moment for indirectly detecting the fluid resistance torsion moment is proposed. To reduce fluid distorting effect, a petal-shaped capsule robot, whose surface is composed of four petal-shaped tiles, is proposed, and fluid resistance torsion moment-weaken effect of the petal-shaped capsule robot is discovered and investigated, which happens to the fluid when it travels through a convergent wedge-like gap between the surface of each of the four petal-shaped tiles and the inner pipe wall. Simulations and experiments have demonstrated that the twist impact on the GI tract by the petal-shaped capsule robot is reduced, while the non-contact driving performance in the GI tract is improved greatly isolated by fluid membrane with high dynamic pressure.", "labels": [1, 14]}
{"id": "3062", "token": "This article described a novel digital multi-mode control strategy for primary-side controlled flyback converter to improve the efficiency within full-load range. The working modes of different load ranges were chosen according to the main power losses analysis and other constraint. Especially, a novel pulse skip mode control method which could reduce the number of actual switching cycles was proposed to improve the light load efficiency. A prototype with field-programmable gate array control has been made to verify the proposed digital multi-mode control strategy.", "labels": [1, 14]}
{"id": "3198", "token": "This paper presents the simulation results of a linear, fully integrated, two-stage digitally programmable 130 nm CMOS power amplifier (PA) operating at 2.4 GHz. Its power stage is composed of a set of amplifying cells which can be enabled or disabled independently by a digital control circuit. All seven operational modes are univocal in terms of 1 dB output compression point (OCP1dB), saturated output power (P-SAT) and power gain at 2.4 GHz. The lowest power mode achieves an 8.1 dBm P-SAT, a 13.5 dB power gain and consumes 171 mW DC power (P-DC) at an OCP1dB of 6 dBm, whereas the highest power mode reaches an 18.9 dBm P-SAT and a 21.1 dB power gain and consumes 415 mW P-DC at an OCP1dB of 18.2 dBm.", "labels": [1, 14]}
{"id": "3251", "token": "This paper presents an experimental investigation on specimens manufactured by Selective Laser Sintering (SLS), with the purposes of giving designers advice when designing 3D printed parts, and laying the basis for a step forward in the field of fracture mechanics of 3D complex parts. The aim is to investigate the effect of building direction in Polyamide (PA) 3D printed samples and to assess whether a crack can be initiated directly from the sintering process for fracture mechanics study purposes. Six different configurations of Mode I Compact Tension (CT) specimens were manufactured and tested; the experiments were monitored by Digital Image Correlation (DIC) and fractured surfaces were analyzed using microscopy. Results showed that samples with better mechanical performance are those in which all the layers contain a portion of the crack. On the other hand, those with layers parallel to the crack plan offer a preferential pathway for the crack to propagate. DIC and fractography investigations showed that, under certain conditions, small-radius geometries, or too-close surfaces may bond together depending on printer resolution. Experiments also showed that SLS is capable of printing specimens with internal cracks that can be used to study fracture mechanics of complex parts or parts with internal cracks. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [1, 14]}
{"id": "3395", "token": "The extraction of molten iron and slag in the liquid phase from the lower part of a blast furnace (hearth) is usually accomplished according to operational experience and involves a high degree of uncertainty, mainly because the liquid level cannot be directly measured. This study presents a methodology for obtaining multistep models to forecast the hearth liquid level by measuring a voltage generated on the blast furnace shell, which is strongly correlated with the hearth liquid level. The results show that this electrical signal is a nonstationary and nonlinear time-series that, after appropriate treatment, can be represented by a time-delay neural network (TDNN) model. Some comparisons are made with linear time-series models represented by an autoregressive moving average model and a seasonal autoregressive integrated moving average model, and the results indicate that the TDNN model provides better forecasting performance up to one hour ahead. Note to Practitioners-This work was motivated by the need for better knowledge regarding the liquid level in a blast furnace hearth because this information affects the strategy of the opening and closing of tapholes in the blast furnace and, consequently, the production control and operational quality. Due to the difficulties of measuring the liquid level in the hearth directly, a system was installed that uses a voltage generated in the hearth shell as a liquid-level sensor in the hearth. In this study, the analysis and treatment of this signal is performed by achieving a stationary, nonlinear signal strongly correlated with the level of molten iron and slag inside the blast furnace hearth. A mathematical model that represents this signal was developed and implemented online in the blast furnace digital control system to enable forecasting of the liquid level up to one hour ahead. This computational tool aids operators and engineers in deciding in advance the instants to open or close the tapholes, thereby increasing safety and financial gains.", "labels": [1, 14]}
{"id": "66", "token": "The relationship between contaminated drinking water with trace elements and thyroid diseases hypertension, liver functions disorder and kidney functions disorder was studied in this research. The thyroid diseases hypertension, liver functions disorder and kidney functions disorder are due to contaminant drinking water with trace elements. The present study concerned with water toxicity. The heavy metals belonging to the most important pollutants. A strong relationship between contaminated drinking water with heavy metals from some of the stations of water shopping in Hail, KSA and thyroid diseases hypertension, liver functions disorder and kidney functions disorder has been identified in this study. These diseases are apparently related to contaminant drinking water with heavy metals such as Pb, Cd, Cu, Mo, Zn, Ni, Mn, Co and Cr. kidney functions disorder is related to contaminate drinking water with lead and cadmium, liver functions disorder to copper and molybdenum, and thyroid functions disorder to iodide, copper, and cadmium. Long-term exposure to lead, cadmium, zinc, iron, and arsenic in drinking-water is mainly related to primarily in the form of thyroid, liver, and kidney functions disorder. Studies of these diseases suggest that abnormal incidence in specific areas is related to toxic materials in the groundwater and thereby led to the contamination of drinking water in these areas. The result of this study showed that increase in the thyroid hormones, and liver functions test as AST and ALT enzymes. Also, there were increase in the hypertension and kidney functions test as creatinine and uric acid. These increases due to the pollution of drinking water by heavy metals.", "labels": [4, 29]}
{"id": "153", "token": "Ditch cleaning in drained peatland forests increases sediment loads and degrades water quality in headwater streams and lakes. A better understanding of the processes controlling ditch erosion and sediment transport in such systems is a prerequisite for proper peatland management. In order to relate hydrological observations to key erosion processes in headwater peatlands drained for forestry, a two-year study was conducted in a nested sub-catchment system (treated with ditch cleaning) and at two reference sites. The treated catchment was instrumented for continuous discharge and turbidity monitoring, erosion pin measurements of changes in ditch bed and banks and time-integrated sampling of suspended sediment (SS) composition. The results showed that ditch cleaning clearly increased transient suspended sediment concentrations (SSCs) and suspended sediment yields (SSYs), and resulted in temporary storage of loosely deposited organic sediment in the ditch network. After exhaustion of this sediment storage, subaerial processes and erosion from ditch banks became dominant in producing sediment for transport. Recorded SSCs were higher on the rising limbs of event hydrographs throughout the study period, indicating that SS transport was limited by availability of erosion-prone sediment. A strong positive correlation (R-2=0.84, p<0.001) between rainfall intensity (above a threshold of 1mmh(-1)) and average SSC obtained on the rising limb of hydrographs for the sub-catchment showed that soil detachment from ditch banks by raindrop impact can directly increase SSC in runoff. At the main catchment outlet, variation in SSC was best explained (R-2=0.67, p<0.05) by the linear combination of initial discharge (-), peak discharge (+) and the lag time from initial to peak discharge (-). Based on these factors, ditch cleaning slightly increased peak discharges and decreased transit times in the study catchment. The implications of the results for water pollution management in peatland forests are discussed. Copyright (c) 2016 John Wiley & Sons, Ltd.", "labels": [4, 29]}
{"id": "266", "token": "An approximately 59-year (1955-2014) sedimentary record of metal elements (Cu, Pb, Zn, Ni, Co, Mn, and Fe) in a sediment core, collected from the Huaihe River, Huainan City, Anhui Province, China, was reconstructed by using Pb-210 geochronology. Copper, Zn, Ni, Co, and Mn evaluated by enrichment factor (EF) indicated minor contamination due to water pollution accidents of the Huaihe River that occurred in 1990s and 2004. Lead presented the most severe pollution among the metals studied, especially during 1957-1974. The use of leaded petrol and atmospheric deposition of coal combustion flue gases could have contributed to Pb contamination. In spite of the general good quality (mean sediment pollution index (SPI) 35.69) of the sediment core evaluated by SPI based on the principal component analysis, worse sediment qualities in the upper section (<6 cm, 2004) were still observed, suggesting intensive human activities causing the increasing concentrations of metals in recent decades.", "labels": [4, 29]}
{"id": "360", "token": "The most important environmental processes in riparian zones are the release of carbon, nitrogen, and phosphorus from various organic compounds. The extracellular enzymes of soil microorganisms are involved in the bio-geochemical cycling of organic matter nutrients and may be important for regulating water quality. The objectives of the present study were to determine whether the activities of soil enzymes were affected by different inundation periods in the riparian zone and to identify major factors that influence soil enzyme activity. We subjected three study plots to different inundation conditions (long inundation, moderate inundation, and rare inundation) within the transects perpendicular to the river flow at three sites (Weijiadu, Lijiaocun, and Daxu) in Lijiang, Guilin City, China. Soil physicochemical properties, dissolved nutrient composition, and soil enzyme activities were analyzed. The activity of acid phosphatase, alkaline phosphatase, and arylsulfatase significantly increased as the inundation frequency decreased, whereas the activity of glucosidase, beta-N-acetylglucosaminidase, glycine aminopeptidase, L-leucine aminopeptidase, and dehydrogenase were significantly higher in study plots that received long inundation than in those subjected to moderate or rare inundation. Linear regression indicated that most hydrolase and dehydrogenase activities were affected by soil clay content, soil organic matter, and soil water content, among other factors. NO3--N limited the activity of acid phosphatase, L-leucine aminopeptidase, and glycine aminopeptidase. Polyphenol oxidase activity was constrained by soil water content and available potassium but promoted by NO3--N. Our study demonstrated that imposing longer inundation periods can increase soil enzyme activities. To maintain microbial activity and to minimize water pollution, it is important to reduce high NO3--N loads. (C) 2016 Elsevier B.V. All rights reserved.", "labels": [4, 29]}
{"id": "606", "token": "The U.S. is experiencing unprecedented movement away from coal and, to a lesser degree, oil. Burdened low-income communities and people of color could experience health benefits from reductions in air and water pollution, yet these same groups could suffer harm if transitions lack broad public input or if policies prioritize elite or corporate interests. This paper highlights how U.S. energy transitions build from, and contribute to, environmental injustices. Energy justice requires not only ending disproportionate harm, it also entails involvement in the design of solutions and fair distribution of benefits, such as green jobs and clean air. To what extent does the confluence of state, civic, and market processes assure just transitions to clean, low-carbon energy production involving equitable distribution of costs, benefits, and decision-making power? To explore this question we assess trends with (1) fossil fuel divestment; (2) carbon taxes and social cost of carbon measurements; (3) cap-and-trade; (4) renewable energy; and (5) energy efficiency. Current research demonstrates opportunities and pitfalls in each area with mixed or partial energy justice consequences, leading to our call for greater attention to the specifics of distributive justice, procedural justice, and recognition justice in research, policy, and action. Illustrative energy transition case studies suggest the feasibility and benefit of empowering approaches, but also indicate there can be conflict between green and just, as evident though stark inequities in clean energy initiatives. To identify positive pathways forward, we compile priorities for an energy justice research agenda based on interactive and participatory practices aligning advocacy, activism, and academics.", "labels": [4, 29]}
{"id": "734", "token": "Theories that explain the governance of water, such as integrated river basin management and multilevel water governance, point to scalar configurations of power as critical determinants of success (or failure). This article explains how the scalar configurations of power in water governance mirror those of the Chinese State, and influence water governance in powerful ways. We use the case of the Yangtze River and Shanghai, a megacity in the Yangtze estuary, as examples, showing how a local jurisdiction exercises its regulatory measures against different types of transjurisdictional water pollution and how these regulatory measures mirror the fluidity (or rigidity) of power configurations in hydropolitics in China. China's evolving water resource management institutions are as yet unable to address the scalar configurations of power in water governance.", "labels": [4, 29]}
{"id": "837", "token": "Large-scale open storage of wood mulch is common practice at wood recycling facilities. During rain and snow melt, leachate with soluble compounds and suspended particles is released from mulch stockpiles. The objective of this study was to determine the quality of leachate/runoff from wood recycling facilities to evaluate its potential to contaminate receiving waterbodies. Wood mulch (n = 30) and leachate/runoff (n = 26) samples were collected over 1.5 years from three wood recycling facilities in New Jersey, USA. Differences by site were found (p < 0.05) for most of the 21 constituents tested in the solid wood mulch samples. Biochemical oxygen demand (range <20-3000 mg/L), chemical oxygen demand (134-6000 mg/L) and total suspended solids (69-401 mg/L) median concentrations of the leachate/runoff samples were comparable to those of untreated domestic wastewater. Total Kjeldahl N, total P and fecal coliform median values were slightly lower than typical wastewater values. Dose-response studies with leachate/runoff samples using zebrafish (Danio rerio) embryos showed that mortality and developmental defects typically did not occur even at the highest concentration tested, indicating low toxicity, although delayed development did occur. Based on this study, leachate/runoff from wood recycling facilities should not be released to surface waters as it is a potential source of organic contamination and low levels of nutrients. A study in which runoff from a controlled drainage area containing wood mulch of known properties is monitored would allow for better assessment of the potential impact of stormwater runoff from wood recycling facilities. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [4, 29]}
{"id": "940", "token": "Water pipes are considered to be one of responsible sources for the water pollution. Among these sources of water supply, the water pipes are the only source of carrying out fresh or processed water into lakes, ponds and streams etc. In Pakistan, knowledge on the condition of water pipes is scarce as deterioration of water pipes are hardly inspected due to high cost. The aim of the current research was to examine the quality of water pipelines of eight districts of South-Punjab, namely, Mianwali, Khushab, Layyah, Bhakkar, Dera Ghazi Khan, Muzaffargarh, Rajanpur and Rahim Yar Khan. Selected sampling stations were analyzed for physio-chemical parameters such as pH, Total Dissolve Solids (TDS), Sulfate (SO4), Chlorine (Cl), Calcium (Ca), Magnesium (Mg), Hardness, Nitrate (NO3), Fluoride (F) and Iron (Fe). The data pertaining water monitoring contain different parameters and seem difficult work for the interpretation of water quality by managing different parameters separately. For this purpose, National Sanitation Foundation Water Quality Index (NSF-WQI) was determined to communicate the quality of water in a simple form. Besides this, groups comprising of similar sampling sites based on water quality characteristics were identified using unsupervised technique. Factor Analysis (FA) has been performed for extracting the latent pollution sources that may cause the more variance in large and complex data. The calculated values of WQI from 1600 sampling stations ranging from 20.73 to 223.74 are divided into five groups; Excellent to Unsuitable class of waters with the average value 62.09 described as good limit for drinking water. Further sampling stations are divided into five optimal clusters selected with suitable k value obtained from Silhouette coefficient. Results of k-means clustering are also verified with natural groups made by WQI. Analysis of multivariate techniques showed several factors to be responsible for the water quality deterioration. It is found out from the FA that three latent factors such as organic pollution, agriculture run-off and urban land use caused 83.30 % of the total variation. Hence, water quality management and control of these latent factors are strongly recommended.", "labels": [4, 29]}
{"id": "1031", "token": "Food supply and consumption are critical for sustaining, urban system functions, and are key determinants of the quantity and pathways of nutrient flow in cities. Nutrient elements from urban food consumption are becoming major pollutant sources in urban environments. Therefore, understanding flow magnitude and pathways, the role of a growing population, and changing dietary structure and technology in future nutrient metabolism are essential to understand cities as ecosystems and urban environmental management. Taking the city of Xiamen, a rapid urbanizing area of Southeast China as a case study, we simulated urban metabolism of three major food-sourced nutrient elements (carbon, nitrogen, and phosphorus or CNP) over 1991-2010 and environmental emissions. Impacts of future population growth, dietary habit change, and waste treatment improvement on various environments were forecast by scenario analysis. A sensitivity analysis was conducted to test how different waste treatment technologies affect environmental emissions from food-sourced nutrients. Our results show that the food-sourced CNP had various metabolic fluxes through urban systems, with carbon mostly emitted into the air and nitrogen and phosphorus mostly discharged into landfills and water. Population growth and dietary structure change will accelerate increases of nutrient emissions to the environment, whereas enhancing current waste treatment technology can just alter emissions to different environments. Based on the results, we discuss how food-sourced nutrient metabolism can be better managed, to enhance connectivity between cities and their hinterlands and maintain environmental emissions within the carrying capacity of the cities. (C) 2016 Published by Elsevier Ltd.", "labels": [4, 29]}
{"id": "1132", "token": "Globally, water pollution is mainly caused by the presence of heavy metals and metalloids such as arsenic. The majority of the techniques employed in the removal are of low efficiency and high cost. Therefore, in this work it is presented the adsorption processes of arsenic (As III and V) ions employing magnetite nanoparticles (MNPs) synthesized by the aerosol assisted chemical vapor deposition (AACVD) process. The adsorption efficiency was determined at different times and concentrations. The remaining As concentration in the solutions was analyzed by atomic absorption spectroscopy. The adsorbed As ions on the surface of the NMPs was analyzed by high resolution transmission electron microscopy. The results showed an overall removal efficiency of 87% for As+3 and 98% for As+5, in a contact time of 15 minutes. Results suggested the use of NMPs as a promising alternative in the removal of As ions in water.", "labels": [4, 29]}
{"id": "1183", "token": "This paper evaluates the existing policy frameworks for mitigation of diffuse water pollution from agriculture (DWPA) in England and China. With reference to a conceptual model of the process of policy transfer or international lesson drawing, and possible constraints to this, it assesses whether and how China can draw lessons to improve current policy from the supra-national and national provisions of the EU and a member state that by 2016 had comprehensively implemented EU agricultural and environmental policy. DWPA is first analysed as a public policy challenge to inform specification of a generic framework for its mitigation. The current policy frameworks for mitigation of DWPA in England and China are evaluated, and their potential for improvement is assessed. A number of barriers to lesson drawing for regulation, incentive payments schemes and advice provision are diagnosed. These barriers are potentially least in relation to advice provision and its use to promote voluntary action by farmers. Given its structure and capabilities the public agricultural extension system in China is also recognised as a key resource. A focus on three policy approaches to mitigate DWPA in China is recommended: i) targeted regulation to a 'reference level' of large intensive livestock, and ultimately other large commercial farms; ii) strategic use of incentive payment schemes to protect water resources from DWPA; and iii) re-orientation of the ethos and modalities of operation of the extension system, informed by international lesson drawing, with the aim of rebalancing farm productivity and environmental protection. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [4, 29]}
{"id": "1272", "token": "The grey water footprint refers to the volume of water that is required to assimilate polluted water. It reflects the intensity of water pollution caused by water use for human activities. This study aims to address some major shortcomings associated with grey water footprint accounting in the literature and discuss several ways towards its improvement. Global maize production is used for illustration. The study specifically tackles three issues: the appropriate water quality standards for grey water footprint assessment; grey water footprint for multiple pollutants; and the influence of spatial resolution of the assessment on the level of grey water stress. A biophysical crop model is applied to quantify nitrogen and phosphorus losses to water in maize production on a global scale with a 0.5-degree spatial resolution. The study shows that the grey water footprint calculation is highly Sensitive to the water standards applied. The results also suggest that the grey water footprint relating to nitrogen and phosphorus pollution caused by maize production alone has already exceeded their local water availability in many parts of the world. Grey water stress shows a more critical situation at the grid level than at the watershed level for maize cultivation because the former represents the local concentration whereas the latter gives the average situation of the whole watershed. This study highlights the need for standardizing the setting of water quality standards for a consistent grey water footprint assessment taking into consideration the diverse aquatic ecosystems and ambient water quality requirements across regions, as well as the presence of multiple pollutants in water bodies. (C) 2017 Elsevier Ltd. All rights reserved.", "labels": [4, 29]}
{"id": "1389", "token": "Continental-scale water quality modeling is a new scientific approach concerned with computing the level of water pollution for several river basins at once. Uncertainties in these models, and in models of smaller scale, arise especially from the specification of model parameters. To identify and analyze these uncertainties we perform a global sensitivity and uncertainty analysis using Latin Hypercube Sampling on the WorldQual water quality model. The focus of the analysis is the river pathogen model of WorldQual as applied to rivers in Africa. This is the first uncertainty and sensitivity analysis performed on a continental-scale pathogen river pollution model. The median output uncertainty of the model (coefficient of variation, based on log-transformed data), assuming plausible estimates of 42 parameter uncertainties, was 10.7%; 90% of grid cells had output uncertainties below 23%. The parameters making the largest contribution to this uncertainty (in order of importance) are the pathogen waste loading per capita, the in-stream settling velocity of pathogens, the percentage of population in a river basin connected to a sewer system, and the raw effluent concentration from the manufacturing sector. Over the continental study area, model output uncertainty and the most sensitive parameters were found to have a highly irregular spatial pattern. This finding suggests that model performance is a strong function of local and regional conditions and that reducing the uncertainty of a single parameter may not lead to large improvements in model performance over the entire continent. A more efficient approach would be to improve model performance region-by-region and improve the estimation of specific parameters known to have a large influence on model uncertainty in those regions. The analysis showed that only four parameters dominate output uncertainty over 93% of the study area, implying that model performance can be substantially improved by reducing the uncertainty of a small number of parameters. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [4, 29]}
{"id": "1579", "token": "The degradation of urban river ecosystems presents a serious threat to sustainable urban development. Consequently, extensive efforts have been devoted to the ecological restoration of urban rivers worldwide. This study evaluates the environmental externalities associated with water pollution and river restoration in Guangzhou in southern China. A basic hedonic pricing model is applied to test hypotheses using a sample of 968 apartment transaction records during July-December 2013. Results show that river restoration could reverse negative externalities of polluted watercourses to positive externalities, especially for those apartments located on the 10th floor or lower. Water quality improvement from polluted non-recreational water (Grade V or worse) to non-body contact recreational water (Grade IV) could increase apartment values by 0.9%. River restoration (including river bank greening and water quality improvement) could increase property values by 4.61%, demonstrating a preference of Guangzhou residents for greening riverscapes. This study could hopefully provide a scientific basis for urban river governance for communities and decision-makers, and serve as a reference case to elucidate human preferences about river restoration in rapidly developing countries. (C) 2016 Elsevier B.V. All rights reserved.", "labels": [4, 29]}
{"id": "1609", "token": "Enzymatic treatments in textile are remarkable because of their environmentally friendly properties, such as less energy, water and chemical need, low waste water pollution. In this paper combined use of amylase, pectinase and cellulase in the same bath was studied in different parts. In the first part of the experiment, raw cotton woven fabrics were treated with amylase, pectinase and cellulase enzymes in the same bath at different process conditions to desize, scour and polish. Results showed that one-bath triple enzymatic mixture process could be done successfully. Therefore, it could be used instead of conventional processes. Moreover, the enzymatic process was completed almost in half of the conventional treatments' durations and temperatures. In the second part, effects of enzymes' dosages were analyzed by using enzymes in pairwise combinations. By this way, not only the effects of the amount of enzymes but also the effects of each enzyme on each fabric property were seen more distinctly. The increases of enzymes' concentrations led to an increase in every tested value except tear strength. Pectinase + cellulase combination resulted in minimum tear strength and whiteness, but maximum absorbency. Usage of enzymes one-by-one constituted the final part of the study. It had been found that amylase affected whiteness and absorbency, cellulase affected tear strength particularly. Although combined enzymatic treatments were conducted at more moderate conditions than conventional processes, comparable results were observed.", "labels": [4, 29]}
{"id": "1663", "token": "The El Sancho reservoir is located in the Odiel River basin, which crosses the Iberian Pyrite Belt. The reservoir receives acid mine drainage (AMD) from the Meca River, a tributary of the Odiel River. Two multi-parameter probes, one placed at the tail (up-gradient) end of the reservoir, where the contaminants enter, and another close to the reservoir dam were used to characterize acidity migration through the Sancho reservoir. The probes both measured pH and conductivity every 30 min. Two different levels of contamination were found, due to dilution that takes place within the reservoir and changes in the AMD composition. The cross-correlation function allowed quantification of the migration process from tail to dam. For both pH and conductivity, the maximum correlation occurred 17 days after sampling, indicating a mean transit time of 17 days. Since the distance between the two sampling points was 14,500 m, the contaminant transit speed was 0.0098 m/s.", "labels": [4, 29]}
{"id": "1776", "token": "Clogging refers to a reduction of riverbed hydraulic conductivity. Due to difficulties in determining the thickness of the clogging layer, the leakage coefficient (L) is introduced and used to quantify the recoverable portion of bank filtrate. L was determined at several riverbank filtration (RBF) sites in field tests and using an analytical solution. Results were compared with data from similar experiments in the early 1970s and 1991-1993. In the 1980s, severe river water pollution in conjunction with high water abstraction led to partly unsaturated conditions beneath the riverbed. A leakage coefficient L of 5 x 10(-7) s(-1) was determined. After water quality improvement, L increased to 1-1.5 x 10(-6) s(-1). An alternative, cost and time efficient method is presented to estimate accurate leakage coefficients. The analytical solution is based on groundwater level monitoring data from observation wells next to the river, which can later feed into numerical models. The analytical approach was able to reflect long-term changes as well as seasonal variations. Recommendations for its application are given based on experience.", "labels": [4, 29]}
{"id": "1924", "token": "Mineralization of sulfidic minerals including realgar, orpiment and pyrite occurs in argillic alteration zones in northeastern Iran, which affects water quality and health in these semi-arid localities. Geochemical source of ions in surface and ground waters was examined to evaluate potential effects of sulfidic mineralization on water quality. The surface and groundwater samples were analyzed to determine the major ions (Na+, Ca2+, Mg2+, K+, HCO3-, SO42-, Cl-) and trace elements (such as As, B, Br). Water-rock interactions and evaporation defined as the key phenomena on groundwater chemistry using Gibbs diagram. Concentrations of arsenic (As) varied from 16 to 606 mu g/L, which was higher than the WHO (2011). Calculated ionic ratios revealed that anions and cations in surface and ground waters originated from partial leaching through ion exchange in alteration zones. We postulate that the primary source of As resulted from oxidation of As-bearing sulfide minerals such as orpiment, realgar and arsenopyrite in argillic-pyrite alteration zone. High pH (>8) could provide the alkalinity to increase sulfide oxidation and release As into the water. The stable isotope data (delta O-18 and delta H-2) indicated the origin of the waters, which is mainly meteoric precipitation with partial effects from evaporation processes and exchanging ions with surrounding rocks. This confirms the notion that the source of all analyzed ions including the toxic As is geogenic. Hydrogeochemical process, which affected the water chemistry and thus environmental public health are likely to be water-rock interactions and evaporation. (C) 2016 Elsevier B.V. All rights reserved.", "labels": [4, 29]}
{"id": "2026", "token": "Fly ash has been recognized as hazardous material causing air, soil and water pollution. Fly ash a 'waste by-product' of electricity generation from power plants (coal-based thermal) has an estimated annual production of approximately two hundred million tons. In-spite of many problems associated (like land requirement for disposal, toxicity to groundwater, handling issues etc.); we have started treating fly ash as a resource material. Present research addresses usage of fly ash in roads & bridges and embankments. In the present study, an attempt has been made to recognize and analyze comprehensively key elements and sub-elements of program implementation of fly ash usage and further to segregate Critical factors (CFs) of usage of fly ash in roads & bridges and embankments. Eight relevant CFs have been recognized for usage of fly ash in roads & bridges; and ten CFs for the usage of fly ash in embankments. Thereafter, Interpretive Structural Modeling (ISM) approach has been applied on these CFs and two models of driver CFs, linkage CFs and driven CFs have been obtained. Appropriate discussions along-with MICMAC analysis in the light of important elements and sub-elements have helped to present managerial implications useful for stakeholders. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [4, 29]}
{"id": "2125", "token": "Due to their harmful effects on human's life and aquatic environments, designing easy and swift yet efficient methodologies to remove pollutants from water stream is one of the important tasks of the scientific community. Among the pollutants, dyes have a significant role on water pollution, because their presence, even in low concentration, impacts the aquatic life by preventing the photosynthesis process and it can be considered as toxic chemicals endangering the human's health. In this study three newly synthesized Task Specific Ionic Liquids (TSILs) incorporating different types of aromatic group on imidazolium ring namely, 1-Butyl-3-Benzoimidazolium bis(trifluoromethylsulfonyl)imide [BzBIm][NTf2]; 1-Butyl-2-Phenyl-imidazolium bis(trifluoromethylsulfonyl)imide [BPhIrn][NTf2]; and 1-Benzyl-3-butyl. imidazolum bis(trifluoromethylsulfonyl)imide [BnBlm][NTf2] have been employed to remove swiftly heavy loads (up to 1,500 ppm) of cationic Methylene Blue dye (MB) from aqueous solution without pH adjustment The results showed that the presence of additional aromatic groups has a significant effect on the extraction efficiency of MB removal through enhancement of the pi-pi interactions between ILs and the aromatic structure of MB. Conductor-like Screening Model for Real Solvent (COSMO-RS) was used to analyse the IL-MB interaction in the studied systems. Finally, an original microbiological method has been designed not only to assess the toxicity of aqueous solution before and after the extraction process to reveal the industrial potential of this methodology but also to highlight the high hydrophobicity of these new TSILs. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [4, 29]}
{"id": "2240", "token": "While rising air and water pollution have become issues of widespread public concern in India, the relationship between spatial distribution of environmental pollution and social disadvantage has received less attention. This lack of attention becomes particularly relevant in the context of industrial pollution, as India continues to pursue industrial development policies without sufficient regard to its adverse social impacts. This letter examines industrial pollution in India from an environmental justice (EJ) perspective by presenting a national scale study of social inequities in the distribution of industrial hazardous waste generation. Our analysis connects district-level data from the 2009 National Inventory of Hazardous Waste Generating Industries with variables representing urbanization, social disadvantage, and socioeconomic status from the 2011 Census of India. Our results indicate that more urbanized and densely populated districts with a higher proportion of socially and economically disadvantaged residents are significantly more likely to generate hazardous waste. The quantity of hazardous waste generated is significantly higher in more urbanized but sparsely populated districts with a higher proportion of economically disadvantaged households, after accounting for other relevant explanatory factors such as literacy and social disadvantage. These findings underscore the growing need to incorporate EJ considerations in future industrial development and waste management in India.", "labels": [4, 29]}
{"id": "2463", "token": "The eastern coastal areas of China have high-density population, developed society and economy, and large water pollution emissions. How to reduce water pollution and realize the coordinated development of the economy and environment has become the national focus. Effective environmental policies should consider regional differences in development stage and sustainability performance. Here, we first analyzed the water pollution emissions intensity of the eastern coastal areas of China and the urgency of emissions reduction using 8-year environmental statistics from 2003 to 2010. We characterized development stages of the eastern coastal areas based on the relationships between water pollution emissions intensity and economic development. Further, we built a coordination degree index of economic development and water environment protection as a measure of sustainability. Results show that water pollution emissions intensity decreases as the economy grows from 2003 to 2010. The less-developed regions have a better coordination degree than some more-developed regions, especially those most-developed ones (e.g., Shanghai show more pressures on long-term sustainability than Hebei). The less-developed regions should take advantage of economic growth to invest more advanced environment protection technologies. The more-developed regions need to upgrade its economic structures and municipal infrastructures. Overall, the study provided a comprehensive approach to understand regional difference in development stage and sustainability performance in the eastern coastal region of China as well as the need of different environmental policies to reduce water pollution emissions. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [4, 29]}
{"id": "2672", "token": "In zooplankton communities, morphological changes in Cladocera (Crustacea: Branchiopoda) may be resulting from water pollution by anthropogenic activities and/or natural events. The removal of vegetation cover, urbanization, agriculture and sewage release accelerate the eutrophication process in the aquatic environment. The present study seeks to demonstrate the occurrence of morphological abnormalities in cladocerans and relate the changes in the morphology and species composition to the physical and chemical parameters of the water. Samplings were made monthly in five stations on the Sapucai River compartment of Furnas Reservoir, located in the state of Minas Gerais, Brazil, from July 2013 to February 2014. The Furnas Reservoir has intense occupation of the surrounding areas by agriculture, urban and industrial activities and the installation of net cage fish cultures, which contribute to the water quality deterioration. Cladocerans samples were collected using a suction pump and plankton net (68 mu m mesh size) and concentrated from a volume of 400 L. The measures of physical and chemical parameters of the water were obtained by a Horiba U-50 multi-sensor on the surface of water column and the density and morphology of Cladocera were made by microscopy. Twenty-three species of Cladocera were recorded with high organism densities of Chydoridae family species. Morphological abnormalities were observed in Daphnia gessneri, Ceriodaphnia silvestrii, Bosmina longirostris, Bosmina tubicen and Chydorus pubescens. The highest densities of C. pubescens with abnormalities were observed at sampling stations which had littoral characteristics and influences of sewage release. For C. pubescens, abnormalities were observed and classified into two types. The type 1 abnormality was considered an increase of length of intestine and size of its intestinal loop, whereas for type 2 was considered the occurrence of an intestine prolapse. The morphological abnormalities in cladocerans were described and compared to the ones described in the literature. From the results, it may observe that the abnormalities were probably resulting from continuous eutrophication process which has been occurring in the reservoir due to anthropogenic activities around the reservoir and a decrease in the water volume of the reservoir, caused by an unusual dry weather period in this region in the last years.", "labels": [4, 29]}
{"id": "2790", "token": "Industrial manufacturers are required to adopt water conservation and pollution control technologies because of increasingly serious water scarcity and water pollution, especially in textile industry. An effective performance evaluation tool for these technologies is greatly needed for textile manufacturers. However, the existing tools for textile industry can only evaluate on plant level and ignore pollution effect of water consumption. In order to help textile manufacturers know about water conservation and pollution control performance of technologies more systematically and comprehensively, we developed a process-level water conservation and pollution control performance evaluation tool of cleaner production technology in textile industry. The new tool includes three indicators: water withdrawal reduction, water consumption reduction and water assimilation reduction. Comparison between the new tool and old ones by evaluating the low-pollution-concentration effluent reuse technology in a polyester flannel fabric dyeing and printing plant demonstrates that the new tool can help textile manufacturers to not only understand operation mechanism of a technology on specific processes and then take specific improvement measures on different processes to optimize water conservation and pollution control performance, but also find out indiscoverable disadvantages of a technology and then adopt complementary technologies to reduce negative effect of the technology. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [4, 29]}
{"id": "2886", "token": "In many areas of the world, leaching of phosphorus in the soil causes serious water pollution. The purpose of this research was to decrease the phosphorus loss in soil by the adsorption behavior of biochars with special structural characteristics. In this study, a series of analysis methods including scanning electron microscopy, infrared spectroscopy, elemental composition, thermogravimetric, and X-ray diffractometer analysis have been used to investigate the properties and structures of different sources of biochars. The adsorption of phosphorus by maize-straw biochar, rice-hull biochar, and pine biochar was quantified by the balance method in this research. The results show that pine biochar has more structural and thermal stability than maize-straw biochar and rice-hull biochar. Different sources of biochar have significantly different phosphate adsorption capabilities. Pine biochar has the best phosphorus adsorption capacity; the actual maximum adsorption capacity was 13.898mgg(-1); however, the phosphorus adsorption capacity of maize-straw biochar was minimum, the actual maximum adsorption capacity was 8.809mgg(-1). The volume of phosphorus adsorption on biochars increases with increasing concentration of phosphorus added to the solution, but the rate of increase gradually decreases. The phosphorus adsorption curve agreed well with the Langmuir isotherm equation.", "labels": [4, 29]}
{"id": "2989", "token": "Nitrogen (N) runoff from paddy fields serves as one of the main sources of water pollution. Our aim was to reduce N runoff from paddy fields by fertilizer management and inoculation with arbuscular mycorrhizal fungi (AMF). In northeast China, Shuangcheng city in Heilongjiang province, a field experiment was conducted, using rice provided with 0%, 20%, 40%, 60%, 80%, and 100% of the local norm of fertilization (including N, phosphorus and potassium), with or without inoculation with Glomus mosseae. The volume, concentrations of total N (TN), dissolved N (DN) and particulate N (PN) of runoff water were measured. We found that the local norm of fertilization led to 18.9 kg/ha of N runoff during rice growing season, with DN accounting for 60%-70%. We also found that reduction in fertilization by 20% cut down TN runoff by 8.2% while AMF inoculation decreased N runoff at each fertilizer level and this effect was inhibited by high fertilization. The combination of inoculation with AMF and 80% of the local norm of fertilization was observed to reduce N runoff by 27.2%. Conclusively, we suggested that the contribution of AMF inoculation combined with decreasing fertilization should get more attention to slow down water eutrophication by reducing N runoff from paddy fields. (C) 2016 The Research Center for Eco-Environmental Sciences, Chinese Academy of Sciences. Published by Elsevier B.V.", "labels": [4, 29]}
{"id": "3079", "token": "In this review paper, the ill effects of pharmaceuticals (PhAs) on the environment and their adsorption on graphene oxide (GO) and graphene oxide-based (GO-based) nanomaterials have been summarised and discussed. The adsorption of prominent PhAs discussed herein includes beta-blockers (atenolol and propranolol), antibiotics (tetracycline, ciprofloxacin and sulfamethoxazole), pharmaceutically active compounds (carbamazepine) and analgesics such as diclofenac. The adsorption of PhAs strictly depends upon the experimental conditions such as pH, adsorbent and adsorbate concentrations, temperature, ionic strength, etc. To understand the adsorption mechanism and feasibility of the adsorption process, the adsorption isotherms, thermodynamics and kinetic studies were also considered. Except for some cases, GO and its derivatives show excellent adsorption capacities for PhAs, which is crucial for their applications in the environmental pollution cleanup.", "labels": [4, 29]}
{"id": "3207", "token": "To achieve influence of underwater windmill's flow parameters and structure parameters-related changes with the hydrodynamic characteristics, an underwater windmill's additional contraction device is devised. According to the orthogonal experimental design, flow velocity, shrinking angle, locating range and outlet diameter are selected as four factors to carry out an 4 L-9 (3(4)) orthogonal experiment in this paper. The results of numerical simulation show that the influences of output torque and axial force on hydrodynamic performance of underwater windmill are flow velocity, locating range, outlet diameter and shrinking angle by turns. And the influence of flow velocity and locating range on output torque and axial force of underwater windmill is more evident, while the shrinking angle has small influence on it. As the output torque increases, the inhomogeneity of hydrofoils' surface pressure distribution is much more in evidence. No obvious flow separation phenomenon is occurred on hydrofoils' surface. It indicates that hydrofoil design is reasonable to some extent. In the upper edge of hydrofoil's pressure value are much lower, namely, this position may exist cavitations region. With the increase of the radius, the cavitation region moves to the trailing edge gradually. Mechanics analysis results also show that the assumption of rigidity hydrofoil is reasonable in the process of numerical simulation. Above research conclusions will provide significative reference for more hydrodynamic performance research of underwater windmill.", "labels": [4, 29]}
{"id": "3314", "token": "Water erosion causes soil degradation and nonpoint pollution. Pollutants are primarily transported on the surfaces of fine soil and sediment particles. Several soil loss models and empirical equations have been developed for the size distribution estimation of the sediment leaving the field, including the physically-based models and empirical equations. Usually, physically-based models require a large amount of data, sometimes exceeding the amount of available data in the modeled area. Conversely, empirical equations do not always predict the sediment composition associated with individual events and may require data that are not always available. Therefore, the objective of this study was to develop a model to predict the particle size distribution (PSD) of eroded soil. A total of 41 erosion events from 21 soils were used. These data were compiled from previous studies. Correlation and multiple regression analyses were used to identify the main variables controlling sediment PSD. These variables were the particle size distribution in the soil matrix, the antecedent soil moisture condition, soil erodibility, and hillslope geometry. With these variables, an artificial neural network was calibrated using data from 29 events (r(2) = 0.98, 0.97, and 0.86; for sand, silt, and clay in the sediment, respectively) and then validated and tested on 12 events (r(2) = 0.74, 0.85, and 0.75; for sand, silt, and clay in the sediment, respectively). The artificial neural network was compared with three empirical models. The network presented better performance in predicting sediment PSD and differentiating rain-runoff events in the same soil. In addition to the quality of the particle distribution estimates, this model requires a small number of easily obtained variables, providing a convenient routine for predicting PSD in eroded sediment in other pollutant transport models. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [4, 29]}
{"id": "3476", "token": "The purpose of the paper is to assess the groundwater quality near the landfill sites using landfill water pollution index (LWPI). In order to investigate the scale of groundwater contamination, three landfills (E, H and S) in different stages of their operation were taken into analysis. Samples of groundwater in the vicinity of studied landfills were collected four times each year in the period from 2004 to 2014. A total of over 300 groundwater samples were analysed for pH, EC, PAH, TOC, Cr, Hg, Zn, Pb, Cd, Cu, as required by the UE legal acts for landfill monitoring system. The calculated values of the LWPI allowed the quantification of the overall water quality near the landfill sites. The obtained results indicated that the most negative impact on groundwater quality is observed near the old Landfill H. Improper location of piezometer at the Landfill S favoured infiltration of run-off from road pavement into the soil-water environment. Deep deposition of the groundwater level at Landfill S area reduced the landfill impact on the water quality. Conducted analyses revealed that the LWPI can be used for evaluation of water pollution near a landfill, for assessment of the variability of water pollution with time and for comparison of water quality from different piezometers, landfills or time periods. The applied WQI (Water Quality Index) can also be an important information tool for landfill policy makers and the public about the groundwater pollution threat from landfill.", "labels": [4, 29]}
{"id": "67", "token": "Canine influenza is a contagious respiratory disease in dogs caused by two subtypes (H3N2 and H3N8) of canine influenza virus (CIV). Currently, only inactivated influenza vaccines (ITVs) are available for the prevention of CIVs. Historically, live-attenuated influenza vaccines (LAIVs) have been shown to produce better immunogenicity and protection efficacy than IIVs. Here, we have engineered a CIV H3N2 LAW by using the internal genes of a previously described CIV H3N8 LAW as a master donor virus (MDV) and the surface HA and NA genes of a circulating CIV H3N2 strain. Our findings show that CIV H3N2 LAW replicates efficiently at low temperature but its replication is impaired at higher temperatures. The CIV H3N2 LAIV was attenuated in vivo but induced better protection efficacy in mice against challenge with wild-type CIV H3N2 than a commercial CIV H3N2 IIV. This is the first description of a LAIV for the prevention of CIV H3N2 in dogs.", "labels": [6, 39]}
{"id": "104", "token": "There are common aspects and mechanisms between different types of autoimmune diseases such as multiple sclerosis (MS), neuromyelitis optica spectrum disorders (NMOSDs), and autoimmune encephalitis (AE) as well as paraneoplastic inflammatory disorders of the central nervous system. To our present knowledge, depending on the disease, T and B cells as well as antibodies contribute to various aspects of the pathogenesis. Possibly the events leading to the breaking of tolerance between the different diseases are of great similarity and so far, only partially understood. Beside endogenous factors (genetics, genomics, epigenetics, malignancy) also exogenous factors (vitamin D, sun light exposure, smoking, gut microbiome, viral infections) contribute to susceptibility in such diseases. What differs between these disorders are the target molecules of the immune attack. For T cells, these target molecules are presented on major histocompatibility complex (MHC) molecules as MHC-bound ligands. B cells have an important role by amplifying the immune response of T cells by capturing antigen with their surface immunoglobulin and presenting it to T cells. Antibodies secreted by plasma cells that have differentiated from B cells are highly structure specific and can have important effector functions leading to functional impairment or/and lesion evolvement. In MS, the target molecules are mainly myelin-and neuron/axon-derived proteins; in NMOSD, mainly aquaporin-4 expressed on astrocytes; and in AE, various proteins that are expressed by neurons and axons.", "labels": [6, 39]}
{"id": "259", "token": "This study aimed at investigating the genetic diversity of a panel of Candida africana strains recovered from vaginal samples in different countries. All fungal strains were heterozygous at the mating-type-like locus and belonged to the genotype A of Candida albicans. Moreover, all examined C. africana strains lack N-acetylglucosamine assimilation and sequence analysis of the HXK1 gene showed a distinctive polymorphism that impair the utilization of this amino sugar in this yeast. Multi-locus sequencing of seven housekeeping genes revealed a substantial genetic homogeneity among the strains, except for the CaMPIb, SYA1 and VPS13 loci which contributed significantly to the classification of our set of C. africana strains into six existing diploid sequence types. Amplified fragment length polymorphism fingerprint analysis yielded greater genotypic heterogeneity among the C. africana strains. Overall the data reported here show that in C. africana genetic diversity occurs and the existence of this intriguing group of C. albicans strains with specific phenotypes associated could be useful for future comparative studies in order to better understand the genetics and evolution of this important human pathogen.", "labels": [6, 39]}
{"id": "317", "token": "The migratory phenomenon in Portugal has become one of the main factors for the genetic variability. In the last few years, a new class of autosomal insertion/deletion markers-InDel-has attracted interest in forensic genetics. Since there is no data for InDel markers of Portuguese-speaking African countries (PALOP) immigrants living in Lisboa, our aim is the characterization of those groups of individuals by typing them with at least 30 InDel markers and to compare different groups of individuals/populations. We studied 454 bloodstain samples belonging to immigrant individuals from Angola, Guinea-Bissau, and Mozambique. DNA extraction was performed with the Chelex (R) 100 method. After extraction, all samples were typed with the Investigator (R) DIPplex method. Through the obtained results, allelic frequencies show that all markers are at Hardy-Weinberg equilibrium, and we can confirm that those populations show significant genetic distances between themselves, between them, and the host Lisboa population. Because of this, they introduce genetic variability in Lisboa population.", "labels": [6, 39]}
{"id": "550", "token": "The viral supergroup includes the entire collection of known and unknown viruses that roam our planet and infect life forms. The supergroup is remarkably diverse both in its genetics and morphology and has historically remained difficult to study and classify. The accumulation of protein structure data in the past few years now provides an excellent opportunity to re-examine the classification and evolution of viruses. Here we scan completely sequenced viral proteomes from all genome types and identify protein folds involved in the formation of viral capsids and virion architectures. Viruses encoding similar capsid/coat related folds were pooled into lineages, after benchmarking against published literature. Remarkably, the in silico exercise reproduced all previously described members of known structure-based viral lineages, along with several proposals for new additions, suggesting it could be a useful supplement to experimental approaches and to aid qualitative assessment of viral diversity in metagenome samples.", "labels": [6, 39]}
{"id": "588", "token": "Invasive species that successfully establish, persist, and expand within an area of introduction, in spite of demographic bottlenecks that reduce their genetic diversity, represent a paradox. Bottlenecks should inhibit population growth and invasive expansion, as a decrease in genetic diversity should result in inbreeding depression, increased fixation of deleterious mutations by genetic drift (drift load), and reduced evolutionary potential to respond to novel selection pressures. Here, we focus on the problems of inbreeding depression and drift load in introduced populations as key components of the Genetic Paradox of Invasions (GPI). We briefly review published explanations for the GPI, which are based on various mechanisms (invasion history events, reproductive traits, genetic characteristics) that mediate the avoidance of inbreeding depression and drift load. We find that there is still a substantial lack of explanation and empirical evidence for explaining the GPI for strongly bottlenecked invasions, or for during critical invasion phases (e.g. initial colonization, leading edges of range expansion) where strong genetic depletion, inbreeding depression and drift load occurs. Accordingly, we suggest that discussion of the GPI should be revived to find additional mechanisms applicable to explaining invasion success for such species and invasion phases. Based on a synthesis of the literature on the population genetics of invaders and the ecology of invaded habitats, we propose that inbreeding x environment (IxE) interactions are one such mechanism that may have strong explanatory power to address the GPI. Specifically, we suggest that a temporary or permanent release from stress in invaded habitats may alleviate the negative effects of genetic depletion on fitness via IxE interactions, and present published empirical evidence supporting this hypothesis. We additionally discuss that IxE interactions can result in rapid evolutionary changes, and may even contribute to adaptation of invaders in the absence of high genetic variation. With a view to encouraging further empirical research, we propose an experimental approach to investigate the occurrence of IxE interactions in ongoing invasions. Revived research on the GPI should provide new fundamental insights into eco-evolutionary invasion biology, and more generally into the evolutionary consequences of the interactions between inbreeding and environment.", "labels": [6, 39]}
{"id": "673", "token": "The Bay of Bengal is one of the most productive ecosystems in the northern Indian Ocean and it harbours a rich community of cetaceans, including Indo-Pacific bottlenose (Tursiops aduncus) and humpback (Sousa spp.) dolphins. The taxonomy of these genera has been controversial, but within the Indian Ocean both seem to be divided into phylogenetically discrete units that range from the east to the west. Within the Sousa genus, S. plumbea is distributed in the western Indian Ocean while S. chinensis is distributed in the eastern Indian and western Pacific Ocean. T. aduncus has a discontinuous distribution throughout the Indo-Pacific Ocean and two different phylogenetic units are known to exist, one along the eastern African coast and another one in the eastern Indian and west Pacific Ocean. In this study we investigate the phylogeography of Indo-Pacific humpback and bottlenose dolphins in the northern Bay of Bengal. We sequenced the mitochondrial DNA control region for 17 bottlenose and 15 humpback dolphins and compared the results with previously published sequences within each genus. In both cases, we found that Bangladesh dolphins are genetically different from neighbouring populations. While the Bangladesh T. aduncus seem to be more closely related to the African T. aduncus form than the Pacific form, Sousa spp. seem to be more closely related to individuals from Australia. The genetic uniqueness of these populations has important evolutionary implications, due to their isolation, coastal distribution in a geographic cul-de-sac characterized by an extreme infusion, redistribution and recycling of biological productivity, and conservation implications since their survival is threatened in particular by fatal interactions with fisheries. We suggest that the particular and extreme oceanographic conditions found in the Bay of Bengal may be driving speciation in these dolphins and other marine megafauna.", "labels": [6, 39]}
{"id": "708", "token": "Quantitative genetics theory predicts adaptive evolution to be constrained along evolutionary lines of least resistance. In theory, hybridization and subsequent interspecific gene flow may, however, rapidly change the evolutionary constraints of a population and eventually change its evolutionary potential, but empirical evidence is still scarce. Using closely related species pairs of Lake Victoria cichlids sampled from four different islands with different levels of interspecific gene flow, we tested for potential effects of introgressive hybridization on phenotypic evolution in wild populations. We found that these effects differed among our study species. Constraints measured as the eccentricity of phenotypic variance-covariance matrices declined significantly with increasing gene flow in the less abundant species for matrices that have a diverged line of least resistance. In contrast, we find no such decline for the more abundant species. Overall our results suggest that hybridization can change the underlying phenotypic variance-covariance matrix, potentially increasing the adaptive potential of such populations.", "labels": [6, 39]}
{"id": "1026", "token": "Genetic analyses can provide information about human evolutionary history that cannot always be gleaned from other sources. We evaluated evidence of selective pressure due to introduced infectious diseases in the genomes of two indigenous southern African San groups-the double dagger Khomani who had abundant contact with other people migrating into the region and the more isolated Ju vertical bar'hoansi. We used a dual approach to test for increased selection on immune genes compared with the rest of the genome in these groups. First, we calculated summary values of statistics that measure genomic signatures of adaptation to contrast selection signatures in immune genes and all genes. Second, we located regions of the genome with extreme values of three selection statistics and examined these regions for enrichment of immune genes. We found stronger and more abundant signals of selection in immune genes in the double dagger Khomani than in the Ju vertical bar'hoansi. We confirm this finding within each population to avoid effects of different demographic histories of the two populations. We identified eight immune genes that have potentially been targets of strong selection in the double dagger Khomani, whereas in the Juj'hoansi, no immune genes were found in the genomic regions with the strongest signals of selection. We suggest that the more abundant signatures of selection at immune genes in the double dagger Khomani could be explained by their more frequent contact with immigrant groups, which likely led to increased exposure and adaptation to introduced infectious diseases.", "labels": [6, 39]}
{"id": "1103", "token": "A black fly species of the Simulium feuerborni species-group of Simulium (Nevermannia) from Cameron Highland, Peninsular Malaysia, previously regarded as S. feuerborni Edwards, originally described from East Java, is described as Simulium pairoti sp. nov. based on complete life stages. High intraspecific variations in the arrangement of the six pupal gill filaments, length of the stalk of the ventral paired filaments, and length of the anterodorsal projection of the cocoon, are noted in this species. This new species is readily distinguished from its congeners by having the characters of male genitalia with simple lamellate ventral plate, short inwardly-twisted styles, several parameral hooks, and a simple narrow median sclerite. Morphological data reported herein plus the chromosomal and molecular data presented elsewhere support S. pairoti as a novel pseudocryptic species. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [6, 39]}
{"id": "1257", "token": "Background: The assessment of affective temperaments has provided useful insights for the psychopathological understanding of affective disorders and for the conceptualization of bipolar spectrum disorders. The Temperament in Memphis Pisa and San Diego (TEMPS) instrument has been widely used in research, yet its psychometric properties and optimal factor structure are unclear. Methods: The PubMed/MEDLINE, PsycINFO, and EMBASE electronic databases were searched from inception until March 15th, 2016. Validation peer-reviewed studies of different versions of the TEMPS performed in adult samples were considered for inclusion. Results: Twenty-seven studies (N=20,787) met inclusion criteria. Several versions of the TEMPS have been validated in 14 languages across 15 countries. The 110-item self-reported version of the TEMPS has been the most studied version. Most studies (50%) supported a five factor solution although few studies performed confirmatory factor analyses. A five-factor solution has consistently been reported for the 39-item version of the TEMPS-A. Overall, evidence indicates that different versions of the TEMPS have adequate internal consistency reliability, while the TEMPS-A-110 version has acceptable test-retest reliability. The methodological quality of included studies varied. Limitations: A meta-analysis could not be performed due to the heterogeneity of settings and versions of the TEMPS utilized. Conclusions: Different versions of the TEMPS have been validated across different cultures. The short 39-item version of the TEMPS-A holds promise and merits further investigation. Culture-bound factors may influence the expression and/or assessment of affective temperaments with the TEMPS.", "labels": [6, 39]}
{"id": "1496", "token": "Metabolomic analysis of feces can provide useful insight on the metabolic status, the health/disease state of the human/animal and the symbiosis with the gut microbiome. As a result, recently there is increased interest on the application of holistic analysis of feces for biomarker discovery. For metabolomics applications, the sample preparation process used prior to the analysis of fecal samples is of high importance, as it greatly affects the obtained metabolic profile, especially since feces, as matrix are diversifying in their physicochemical characteristics and molecular content. However there is still little information in the literature and lack of a universal approach on sample treatment for fecal metabolic profiling. The scope of the present work was to study the conditions for sample preparation of rat feces with the ultimate goal of the acquisition of comprehensive metabolic profiles either untargeted by NMR spectroscopy and GC MS or targeted by HILIC-MS/MS. A fecal sample pooled from male and female Wistar rats was extracted under various conditions by modifying the pH value, the nature of the organic solvent and the sample weight to solvent volume ratio. It was found that the 1/2 (wt./vs) ratio provided the highest number of metabolites under neutral and basic conditions in both untargeted profiling techniques. Concerning LC MS profiles, neutral acetonitrile and propanol provided higher signals and wide metabolite coverage, though extraction efficiency is metabolite dependent. (C) 2016 Elsevier B.V. All rights reserved.", "labels": [6, 39]}
{"id": "1649", "token": "Barley (Hordeum vulgare L.) is among the most stress-tolerant crops; however, not much is known about the genetic and environmental control of metabolic adaptation of barley to abiotic stresses. We have subjected a genetically diverse set of 81 barley accessions, consisting of Mediterranean landrace genotypes and German elite breeding lines, to drought and combined heat and drought stress at anthesis. Our aim was to (i) investigate potential differences in morphological, physiological, and metabolic adaptation to the two stress scenarios between the Mediterranean and German barley genotypes and (ii) identify metabolic quantitative trait loci (mQTLs). To this end, we have genotyped the investigated barley lines with an Illumina iSelect 9K array and analyzed a set of 57 metabolites from the primary C and N as well as antioxidant metabolism in flag leaves under control and stress conditions. We found that drought-adapted genotypes attenuate leaf carbon metabolism much more strongly than elite lines during drought stress adaptation. Furthermore, we identified mQTLs for flag leaf gamma-tocopherol, glutathione, and succinate content by association genetics that co-localize with genes encoding enzymes of the pathways producing these antioxidant metabolites. Our results provide the molecular basis for breeding barley cultivars with improved abiotic stress tolerance.", "labels": [6, 39]}
{"id": "1766", "token": "Spatial structure can decisively influence the way evolutionary processes unfold. To date, several methods have been used to study evolution in spatial systems, including population genetics, quantitative genetics, moment-closure approximations, and individual-based models. Here we extend the study of spatial evolutionary dynamics to eco-evolutionary models based on reaction-diffusion equations and adaptive dynamics. Specifically, we derive expressions for the strength of directional and stabilizing/disruptive selection that apply both in continuous space and to metacommunities with symmetrical dispersal between patches. For directional selection on a quantitative trait, this yields a way to integrate local directional selection across space and determine whether the trait value will increase or decrease. The robustness of this prediction is validated against quantitative genetics. For stabilizing/disruptive selection, we show that spatial heterogeneity always contributes to disruptive selection and hence always promotes evolutionary branching. The expression for directional selection is numerically very efficient and hence lends itself to simulation studies of evolutionary community assembly. We illustrate the application and utility of the expressions for this purpose with two examples of the evolution of resource utilization. Finally, we outline the domain of applicability of reaction-diffusion equations as a modeling framework and discuss their limitations.", "labels": [6, 39]}
{"id": "1838", "token": "Peroxisomes are thought to have played a key role in the evolution of metabolic networks of photosynthetic organisms by connecting oxidative and biosynthetic routes operating in different compartments. While the various oxidative pathways operating in the peroxisomes of higher plants are fairly well characterized, the reactions present in the primitive peroxisomes ( microbodies) of algae are poorly understood. Screening of a Chlamydomonas insertional mutant library identified a strain strongly impaired in oil remobilization and defective in Cre05.g232002 (CrACX2), a gene encoding a member of the acyl-CoA oxidase/dehydrogenase superfamily. The purified recombinant CrACX2 expressed in Escherichia coli catalyzed the oxidation of fatty acyl-CoAs into trans-2-enoyl-CoA and produced H2O2. This result demonstrated that CrACX2 is a genuine acyl-CoA oxidase, which is responsible for the first step of the peroxisomal fatty acid ( FA) beta-oxidation spiral. A fluorescent protein-tagging study pointed to a peroxisomal location of CrACX2. The importance of peroxisomal FA beta-oxidation in algal physiology was shown by the impact of the mutation on FA turnover during day/night cycles. Moreover, under nitrogen depletion the mutant accumulated 20% more oil than the wild type, illustrating the potential of beta-oxidation mutants for algal biotechnology. This study provides experimental evidence that a plant-type FA beta-oxidation involving H2O2- producing acyl-CoA oxidation activity has already evolved in the microbodies of the unicellular green alga Chlamydomonas reinhardtii.", "labels": [6, 39]}
{"id": "2055", "token": "Background: Inferring the ancestry of each region of admixed individuals' genomes is useful in studies ranging from disease gene mapping to speciation genetics. Current methods require high-coverage genotype data and phased reference panels, and are therefore inappropriate for many data sets. We present a software application, AD-LIBS, that uses a hidden Markov model to infer ancestry across hybrid genomes without requiring variant calling or phasing. This approach is useful for non-model organisms and in cases of low-coverage data, such as ancient DNA. Results: We demonstrate the utility of AD-LIBS with synthetic data. We then use AD-LIBS to infer ancestry in two published data sets: European human genomes with Neanderthal ancestry and brown bear genomes with polar bear ancestry. AD-LIBS correctly infers 87-91% of ancestry in simulations and produces ancestry maps that agree with published results and global ancestry estimates in humans. In brown bears, we find more polar bear ancestry than has been published previously, using both AD-LIBS and an existing software application for local ancestry inference, HAPMIX. We validate AD-LIBS polar bear ancestry maps by recovering a geographic signal within bears that mirrors what is seen in SNP data. Finally, we demonstrate that AD-LIBS is more effective than HAPMIX at inferring ancestry when preexisting phased reference data are unavailable and genomes are sequenced to low coverage. Conclusions: AD-LIBS is an effective tool for ancestry inference that can be used even when few individuals are available for comparison or when genomes are sequenced to low coverage. AD-LIBS is therefore likely to be useful in studies of non-model or ancient organisms that lack large amounts of genomic DNA. AD-LIBS can therefore expand the range of studies in which admixture mapping is a viable tool.", "labels": [6, 39]}
{"id": "2130", "token": "Hypertension (high blood pressure) is a major public health problem affecting more than a billion people worldwide with complications, including stroke, heart failure and kidney failure. The regulation of blood pressure is multifactorial reflecting genetic susceptibility, in utero environment and external factors such as obesity and salt intake. In keeping with Arthur Guyton's hypothesis, the kidney plays a key role in blood pressure control and data from clinical studies; physiology and genetics have shown that hypertension is driven a failure of the kidney to excrete excess salt at normal levels of blood pressure. There is a number of rare Mendelian blood pressure syndromes, which have shed light on the molecular mechanisms involved in dysregulated ion transport in the distal kidney. One in particular is Familial hyperkalemic hypertension (FHHt), an autosomal dominant monogenic form of hypertension characterised by high blood pressure, hyperkalemia, hyperchloremic metabolic acidosis, and hypercalciuria. The clinical signs of FHHt are treated by low doses of thiazide diuretic, and it mirrors Gitelman syndrome which features the inverse phenotype of hypotension, hypokalemic metabolic alkalosis, and hypocalciuria. Gitelman syndrome is caused by loss of function mutations in the thiazide-sensitive Na/Cl cotransporter (NCC); however, FHHt patients do not have mutations in the SCL12A3 locus encoding NCC. Instead, mutations have been identified in genes that have revealed a key signalling pathway that regulates NCC and several other key transporters and ion channels in the kidney that are critical for BP regulation. This is the WNK kinase signalling pathway that is the subject of this review.", "labels": [6, 39]}
{"id": "2186", "token": "This paper reveals that nearly 25 years after the National Academy of Sciences (NAS), Biological Effects of Ionizing Radiation (BEIR) I Committee (1972) used Russell's dose-rate data to support the adoption of the linear-no-threshold (LNT) dose response model for genetic and cancer risk assessment, Russell acknowledged a significant under-reporting of the mutation rate of the historical control group. This error, which was unknown to BEIR I, had profound implications, leading it to incorrectly adopt the LNT model, which was a decision that profoundly changed the course of risk assessment for radiation and chemicals to the present.", "labels": [6, 39]}
{"id": "2357", "token": "Artificial insemination with cryopreserved semen enables affordable, large-scale dissemination of gametes with superior genetics. However, cryopreservation can cause functional and structural damage to spermatozoa that is associated with reactive oxygen species (ROS) production, impairment of sperm motility and decreased fertilizing potential, but little attention has been paid to protein changes. The goal of this study was to investigate the oxidative modifications (measured as carbonylation level changes) of bull spermatozoa proteins triggered by the cryopreservation process. Flow cytometry and computer assisted sperm analysis were used to evaluate changes in viability, ROS level and motility of spermatozoa. Western blotting, in conjunction with two-dimensional electrophoresis (2D-oxyblot) and matrix assisted laser desorption/ionization time-of-flight/time-of-flight spectrometry, was employed to identify and quantify the specifically carbonylated spermatozoa proteins. Cryopreservation decreased motility and viability but increased the number of ROS-positive cells. We identified 11 proteins (ropporin-1, outer dense fiber protein 2, glutathione S-transferase, triosephosphate isomerase, capping protein beta 3 isoform, actin-related protein Ml, actin-related protein T2, NADH dehydrogenase, isocitrate dehydrogenase, cilia- and flagella-associated protein 161, phosphatidylethanolamine-binding protein 4) showing differences in protein carbonylation in response to cryopreservation. The identified proteins are associated with cytoskeleton and flagella organization, detoxification and energy metabolism. Moreover, almost all of the identified carbonylated proteins are involved in capacitation. Our results indicate for the first time that cryopreservation induces oxidation of selected sperm proteins via carbonylation. We suggest that carbonylation of sperm proteins could be a direct result of oxidative stress and potentially lead to disturbances of capacitation-involved proteins or could indicate cryopreservation-induced premature capacitation. (C) 2017 Published by Elsevier Inc.", "labels": [6, 39]}
{"id": "2499", "token": "In order to assess how the last sea level rise affected the Aegean archipelago, we quantified the magnitude and rate of geographic change for the Aegean islands during the last sea-level-rise episode (21 kyr BP-present) with a spatially explicit geophysical model. An island-specific Area-Distance-Change (ADC) typology was constructed, with higher ADC values representing a higher degree of change. The highest fragmentation rates of the Aegean archipelago occurred in tandem with the largest rates of sea-level-rise occurring between 17 kyr and 7 kyr ago. Sea-level rise resulted in an area loss for the Aegean archipelago of approximately 70%. Spatiotemporal differences in sea-level changes across the Aegean Sea and irregular bathymetry produced a variety of island surface-area loss responses, with area losses ranging from 20% to >90% per island. In addition, sea-level rise led to increased island isolation, increasing distances of islands to continents to >200% for some islands. We discuss how rates of area contractions and distance increases may have affected biotas, their evolutionary history and genetics. Five testable hypotheses are proposed to guide future research. We hypothesize that islands with higher ADC-values will exhibit higher degrees of community hyper-saturation, more local extinctions, larger genetic bottlenecks, higher genetic diversity within species pools, more endemics and shared species on continental fragments and higher z-values of the power-law species-area relationship. The developed typology and the quantified geographic response to sea-level rise of continental islands, as in the Aegean Sea, present an ideal research framework to test biogeographic and evolutionary hypotheses assessing the role of rates of area and distance change affecting biota. (C) 2017 Elsevier B.V. All rights reserved.", "labels": [6, 39]}
{"id": "2663", "token": "Purpose of review The task of cataloging human genetic variation and its relation to disease is rapidly approaching completion. The new challenge is to discover the function of disease-associated genes and to understand the pathways that lead to human disease. We propose that achieving this new level of understanding will increasingly rely on the use of model organisms. We discuss the advantages of the mouse as a model organism to our understanding of human disease. Recent findings The collection of available mouse strains represents as much genetic and phenotypic variation as is found in the human population. However, unlike humans, mice can be subjected to experimental breeding protocols and the availability of tissues allows for a far greater and deeper level of phenotyping. New methods for gene editing make it relatively easy to create mouse models of known human mutations. The distinction between genetic and epigenetic inheritance can be studied in great detail. Various experimental protocols enable the exploration of the role of the microbiome in physiology and disease. Summary We propose that there will be an interdependence between human and model organism research. Technological advances and new genetic screening platforms in the mouse have greatly improved the path to gene discovery and mechanistic studies of gene function.", "labels": [6, 39]}
{"id": "2699", "token": "This paper assesses the discovery of the dose-rate effect in radiation genetics and how it challenged fundamental tenets of the linear non-threshold (LNT) dose response model, including the assumptions that all mutational damage is cumulative and irreversible and that the dose-response is linear at low doses. Newly uncovered historical information also describes how a key 1964 report by the International Commission for Radiological Protection (ICRP) addressed the effects of dose rate in the assessment of genetic risk. This unique story involves assessments by two leading radiation geneticists, Hermann J. Muller and William L. Russell, who independently argued that the report's Genetic Summary Section on dose rate was incorrect while simultaneously offering vastly different views as to what the report's summary should have contained. This paper reveals occurrences of scientific disagreements, how conflicts were resolved, which view(s) prevailed and why. During this process the Nobel Laureate, Muller, provided incorrect information to the ICRP in what appears to have been an attempt to manipulate the decision-making process and to prevent the dose-rate concept from being adopted into risk assessment practices.", "labels": [6, 39]}
{"id": "2769", "token": "BACKGROUND CONTEXT: There is limited research investigating educational attainment as a risk factor for low back pain (LBP), with the influence of gender commonly being neglected. Furthermore, genetics and early shared environment explain a substantial proportion of LBP cases and need to be controlled for when investigating risk factors for LBP. PURPOSE: To investigate whether educational attainment affects the prevalence and risk of LBP differently in men and women while controlling for the influence of genetics and early shared environment. STUDY DESIGN: This is a cross-sectional and prospective twin case-control study. PATIENT SAMPLE: Adult monozygotic (MZ) and dizygotic (DZ) twins from the Murcia Twin Registry, with available data on educational attainment, formed the base sample for this study. The prevalence analysis considered twins with available data on LBP in 2013 (n=1,580). The longitudinal analysis considered twins free of LBP at baseline (2009-2011), with available data on LBP at follow-up (2013) (n=1,077). OUTCOME MEASURES: Data on the lifetime prevalence of activity limiting LBP (outcome) and educational attainment (risk factor) were self-reported. METHODS: The prevalence analysis investigated the cross-sectional association between educational attainment and LBP, whereas the longitudinal analysis investigated whether educational attainment increased the risk of developing LBP. Both analyses were performed in the following sequence. First, a total sample analysis was performed on all twins (considering them as individuals), adjusting for confounding variables selected by the data. Second, to control for the influence of genetics and early shared environment, a within-pair case-control analysis (stratified by zygosity) was performed on complete twin pairs discordant for LBP (ie, one twin had LBP, whereas the co-twin did not). All analyses were stratified for gender where possible, with an interaction term determining whether gender was a significant moderator of the association between educational attainment and LBP. RESULTS: Women with either general secondary or university education were less likely to experience (prevalence analysis) or to develop LBP (longitudinal analysis). Educational attainment did not affect the risk of LBP in men. When controlling for the effects of genetics and early shared environment, the relationship between educational status and LBP in women was no longer statistically significant. CONCLUSIONS: Educational attainment affects LBP differently in men and women, with higher levels of education only decreasing the risk of developing LBP in women. After adjusting for genetics and early shared environment, the relationship between educational attainment and LBP in women disappears. This suggests that genetics and early shared environment are confounding the relationship between educational attainment and LBP in women. (C) 2016 Elsevier Inc. All rights reserved.", "labels": [6, 39]}
{"id": "2832", "token": "Hybrids are generally less fit than their parental species, and the mechanisms underlying their fitness reductions can manifest through different traits. For example, hybrids can have physiological, behavioral, or ecological defects, and these defects can generate reproductive isolation between their parental species. However, the rate that mechanisms of postzygotic isolation other than hybrid sterility and inviability evolve has remained largely uninvestigated, despite isolated studies showing that behavioral defects in hybrids are not only possible but might be widespread. Here, we study a fundamental animal-behavior the ability of individuals to find food-and test the rate at which it breaks down in hybrids. We measured the ability of hybrids from 94 pairs of Drosophila species to find food and show that this ability decreases with increasing genetic divergence between the parental species and that male hybrids are more strongly (and negatively) affected than females. Our findings quantify the rate that hybrid dysfunction evolves across the diverse radiation of Drosophila and highlights the need for future investigations of the genetic and neurological mechanisms that affect a hybrid's ability to find a suitable substrate on which to feed and breed.", "labels": [6, 39]}
{"id": "2882", "token": "Acacias (Mimosoideae) represent a major woody group in arid and subarid habitats of all tropical and subtropical regions. The genetic diversity and population dynamic of African species are still poorly investigated, in particular due to ploidy variation among and within species. Here, we aim to investigate the diversity of the plastid genome (or plastome) of Central Saharan mimosoids, in order to assess its potential utility for phylogenetic and population genetic analyses. We first used a genome skimming strategy to assemble the complete plastome plus the nuclear ribosomal DNA cluster of six species belonging to three genera (Vachellia, Senegalia, and Faidherbia). Phylogenetic relationships based on these data confirm the existence of three main evolutionary lineages in the Hoggar range (southern Algeria). An analysis of the plastome structure reveals an extension of the inverted repeat (IR) in Faidherbia albida as recently reported in two other genera of the same lineage (Inga and Acacia s. s.). Higher substitution rates are detected in this lineage, and our species sampling allows revealing genes (particularly accD, clpP, rps2, rps3, ycf1, ycf2, and ycf4) under positive selection following the IR extension. The reasons for this evolutionary transition need to be unraveled. We then develop 21 plastid microsatellites to be used on a large panel of mimosoid species. At a local scale, 18 of these loci reveal intra-specific polymorphism in at least one species. These markers may be useful to assess the genetic diversity of the plastome for comparative phylogeographies or population genetic studies.", "labels": [6, 39]}
{"id": "3041", "token": "The care and prevention of congenital disorders (CDs) is an emerging but unprioritised health need in South Africa (SA). Inadequate empirical data and underreporting conceal the true burden of CDs while medical genetic services to confront the problem have regressed. Positive epidemiological transition in the country now demands these services are improved to significantly further reduce child mortality. Current sector capacity in SA is inadequate and required personnel targets will not be reached quickly enough to meet the growing health need even if relevant posts are designated. Historically, genetic-trained nurses played a defined role in primary healthcare (PHC) by recognising and diagnosing common CDs and counselling patients and their families, while referring complex matters to the limited tertiary medical genetic services available. Policy changes to redress past inequalities and other healthcare priorities resulted in genetic services being incorporated into PHC, with few genetic nurses retaining their genetic services role. While the medium- to long-term aim for SA would be to develop medical genetic services with appropriate capacity at all levels of healthcare, there is an urgent short-term need to provide basic medical genetic services in PHC. Central to achieving this is the upgrading and re-implementation of the previously successful Medical Genetics Education Programme (MGEP). This post-graduate distance learning, education programme is implemented with the Congenital Disorders Course Book, a distance education tool promoting independent, home-based learning. Together, these tools offer an approach to swiftly build up a nursing work-force with improved knowledge and skills in medical genetics.", "labels": [6, 39]}
{"id": "3156", "token": "Platelet activation in response to stimulation of the Protease Activated Receptor 4 (PAR4) receptor differs by race. One factor that contributes to this difference is the expression level of Phosphatidylcholine Transfer Protein (PCTP), a regulator of platelet PAR4 function. We have conducted an expression Quantitative Trait Locus (eQTL) analysis that identifies single nucleotide polymorphisms (SNPs) linked to the expression level of platelet genes. This analysis revealed 26 SNPs associated with the expression level of PCTP at genome-wide significance (p < 5x10-8). Using annotation from ENCODE and other public data we prioritised one of these SNPs, rs2912553, for functional testing. The allelic frequency of rs2912553 is racially-dimorphic, in concordance with the racially differential expression of PCTP. Reporter gene assays confirmed that the single nucleotide change caused by rs2912553 altered the transcriptional potency of the surrounding genomic locus. Electromobility shift assays, luciferase assays, and overexpression studies indicated a role for the megakaryocytic transcription factor GATA1. In summary, we have integrated multi-omic data to identify and functionalise an eQTL. This, along with the previously described relationship between PCTP and PAR4 function, allows us to characterise a genotype- phenotype relationship through the mechanism of gene expression.", "labels": [6, 39]}
{"id": "3280", "token": "Background: Rare conditions can be catastrophic for families and the implications for public health can be substantial. Our study compared basic surveillance through active medical record review with a linked administrative data file to assess the number of cases of two rare conditions, fragile X syndrome (FXS) and muscular dystrophy (MD) in a population. Methods: Two methods of data collection were used to collect information from five counties comprising two standard metropolitan statistical areas of South Carolina. The passive system relied mostly on health claims data using ICD-9 CM diagnostic codes. The active system relied on a nurse abstracting records from a list of all licensed physicians with specialties in neurology, orthopedics, and genetics. Results: There were 141 FXS cases and 348 MD cases that met the case definitions using active surveillance. Additional cases were found for both conditions but they were determined to not be true cases. After linking the actively collected MD and FXS cases to passive datasets, we found that the estimated total numbers of cases were similar to using capture-recapture analysis; the positive predictive values for cases identified in the passive system were 56.6% for MD and 75.7% for FXS. Conclusions: Applying capture-recapture methods to passively collected surveillance data for rare health conditions produced an estimate of the number of true cases that was similar to that obtained through active data collection.", "labels": [6, 39]}
{"id": "3352", "token": "Giardia duodenalis is a flagellated intestinal protozoan responsible for infections in various hosts including humans and several wild and domestic animals. Few studies have correlated environmental contamination and clinical infections in the same region. The aim of this study was to compare groups of Giardia duodenalis from clinical and environmental sources through population genetic analyses to verify haplotype sharing and the degree of genetic similarity among populations from clinical and environmental sources in the metropolitan region of Campinas. The results showed high diversity of haplotypes and substantial genetic similarity between clinical and environmental groups of G.duodenalis. We demonstrated sharing of Giardia genotypes among the different populations studied. The comparison between veterinary and human sequences led us to identify new zoonotic genotypes, including human isolates from genetic assemblage C. The application of a population genetic analysis in epidemiological studies allows quantification of the degree of genetic similarity among populations of Giardia duodenalis from different sources of contamination. The genetic similarity of Giardia isolates among human, veterinary, and environmental groups reinforced the correlation between clinical and environmental isolates in this region, which is of great importance for public health.", "labels": [6, 39]}
{"id": "3427", "token": "Aims/hypothesis MODY can be wrongly diagnosed as type 1 diabetes in children. We aimed to find the prevalence of MODY in a nationwide population-based registry of childhood diabetes. Methods Using next-generation sequencing, we screened the HNF1A, HNF4A, HNF1B, GCK and INS genes in all 469 children (12.1%) negative for both GAD and IA-2 autoantibodies and 469 antibody-positive matched controls selected from the Norwegian Childhood Diabetes Registry (3882 children). Variants were classified using clinical diagnostic criteria for pathogenicity ranging from class 1 (neutral) to class 5 (pathogenic). Results We identified 58 rare exonic and splice variants in cases and controls. Among antibody-negative patients, 6.5% had genetic variants of classes 3-5 (vs 2.4% in controls; p = 0.002). For the stricter classification (classes 4 and 5), the corresponding number was 4.1% (vs 0.2% in controls; p= 1.6x10-5). HNF1A showed the strongest enrichment of class 3-5 variants, with 3.9% among antibody-negative patients (vs 0.4% in controls; p = 0.0002). Antibody-negative carriers of variants in class 3 had a similar phenotype to those carrying variants in classes 4 and 5. Conclusions/interpretation This is the first study screening for MODY in all antibody-negative children in a nationwide population-based registry. Our results suggest that the prevalence of MODY in antibody-negative childhood diabetes may reach 6.5%. One-third of these MODY cases had not been recognised by clinicians. Since a precise diagnosis is important for treatment and genetic counselling, molecular screening of all antibody-negative children should be considered in routine diagnostics.", "labels": [6, 39]}
{"id": "82", "token": "The pillars of Computer Science and Engineering (CSE) curriculum are Data Structures, Database management systems, languages, operating systems and algorithms. This article explains the relationship and connectivity of these core courses. Authors follow the pedagogy technique to teach the Data Structures (DS) by considering its evolution. The article focus on the method of providing connectivity between the building blocks of DS like Data Containers, Container Iterators, Algorithms and Functors. Each data structure is explained by considering its property, iterations, problems and applications. The three fold method is followed to teach DS, which includes think, build and discuss phases. The pedagogy techniques practiced by authors are revealed many mysteries, which are not discussed in most of the DS text books.", "labels": [0, 11]}
{"id": "329", "token": "Owing to the ubiquity of web applications in modern computing, the server software that delivers these applications is an attractive attack vector for would-be malicious actors in cyberspace. Recently, Moving Target Defense (MTD) strategies have grown in popularity in the computer security community because of their ability to enhance resilience and force attackers into uncharacteristic behavior. The MTD prototype discussed in this paper acts as a proactive defense strategy that offers increased protection against an attacker's ability to probe for and exploit vulnerable web server software. The testing shows that web server diversity in an MTD reduces the ability to exploit vulnerabilities in a web server, reduces impacts of successfully exploited vulnerabilities, and increases the resilience of the protected application.", "labels": [0, 11]}
{"id": "465", "token": "GeoWeb 2.0, laying the foundations of Volunteered Geographic Information (VGI) systems, has led to platforms where users can contribute to the geographic knowledge that is open to access. Moreover, as a result of the advancements in 3D visualization, virtual globes able to visualize geographic data even on browsers emerged. However the integration of VGI systems and virtual globes has not been fully realized. The study presented aims to visualize volunteered data in 3D, considering also the ease of use aspects for general public, using Free and Open Source Software (FOSS). The new Application Programming Interface (API) of NASA, Web World Wind, written in JavaScript and based on Web Graphics Library (WebGL) is cross-platform and cross-browser, so that the virtual globe created using this API can be accessible through any WebGL supported browser on different operating systems and devices, as a result not requiring any installation or configuration on the client-side, making the collected data more usable to users, which is not the case with the World Wind for Java as installation and configuration of the Java Virtual Machine (JVM) is required. Furthermore, the data collected through various VGI platforms might be in different formats, stored in a traditional relational database or in a NoSQL database. The project developed aims to visualize and query data collected through Open Data Kit (ODK) platform and a cross-platform application, where data is stored in a relational PostgreSQL and NoSQL CouchDB databases respectively.", "labels": [0, 11]}
{"id": "560", "token": "The Secure Shell Protocol (SSH) is a well-known standard protocol, mainly used for remotely accessing shell accounts on Unix-like operating systems to perform administrative tasks. As a result, the SSH service has been an appealing target for attackers, aiming to guess root passwords performing dictionary attacks or to directly exploit the service itself. To identify such situations, this article addresses the detection of SSH anomalous connections from an intrusion detection perspective. The main idea is to compare several strategies and approaches for a better detection of SSH-based attacks. To test the classification performance of different classifiers and combinations of them, SSH data coming from a real-world honeynet are gathered and analysed. For comparison purposes and to draw conclusions about data collection, both packet-based and flow data are analysed. A wide range of classifiers and ensembles are applied to these data, as well as different validation schemes for better analysis of the obtained results. The high-rate classification results lead to positive conclusions about the identification of malicious SSH connections.", "labels": [0, 11]}
{"id": "670", "token": "In this work we present the functional specifications, architecture and implementation of the HERMOPHILOS web-based system developed to auto-mate and accelerate the accessible eTextbooks' production, workflow management, and delivery in an a higher education environment. We describe the redesign of the relative manual procedures and we show how HERMOPHILOS makes things easier and faster for the print-disabled students, as well as for the personnel involved. The web services of HERMOPHILOS include user sign up, user authentication, user rights management, students' accessible textbooks re-quests, digital textbook requests to publishers, requests' progress monitoring, original digital textbook copy submission, scanning, OCR, version and archive management, copyright protection, distribution, and digital content usage statistics. Implementation specifications included support for all browsers, operating systems, and mobile devices, accessible user interfaces (WCAG 2.0 AA), and advanced encryption and security policies. The HERMOPHILOS system sup-ports multiple formats for eTextbooks: plain text (.txt), rich text (.rtf), accessible markup (.xml, .xhtml, and .html), large print (.doc), audio books (.mp3), DAISY 2&3 (text only or full text - full audio), Braille (.brf or .brl), MS-Word (.docx), portable document format (.pdf) and LaTex (.tex). Paperwork was dramatically reduced, and the need for students' visits to the accessibility office was eliminated. The results show that, compared to the traditional procedure, the HERMOPHILOS workflow management system reduced the overall production and delivery time by 47 %.", "labels": [0, 11]}
{"id": "743", "token": "Mindful Gnats is a computer game and App that introduces mindfulness and relaxation skills to young people aged nine years and older. In this paper the authors describe their model for using technology to support children with the development of psychological skills. This model combines a computer game to introduce and practice psychological skills played in the presence of an adult, with an App that assists young people as they practise and transfer those skills into their everyday life at home, at school and in the community. The Mindful Gnats computer game comprises a six level 3-D game world and is available on iOS and Windows. The Mindful Gnats App is available for both iOS and Android operating systems. This paper describes the background research that informed the design of Mindful Gnats as well as the specific mindfulness and relaxation contents of the programme. The authors' on-going research to evaluate the effectiveness of Mindful Gnats with regular children and those with clinical difficulties is described, along with the key lessons the authors have learnt from their experience in the design of mental health promoting technology.", "labels": [0, 11]}
{"id": "783", "token": "Programmable Network like SDN allows administrators to program network infrastructure according to service demand and custom-defined policies. Network policies are interpreted by the centralized controller to define actions and rules to process the network traffic on devices that belong to a single domain. However, actual networks are multi-domain where several domains are interconnected. Then, because SDN controllers in a domain cannot define nor monitor policies in other domains, network administrators cannot ensure that their own policies, origin policies are being enforced by the domains not directly managed by them (i.e. foreign domains). We present AudiT, a multi-domain SDN policy verifier that identifies whether an origin policy is enforced by foreign domains. AudiT comprises (1) model for network topology, policies, and flows, (2) an Audit protocol to gather information about the actions performed by network devices to carry the flows of interest, and (3) a validation engine that takes that information and detects security policy violations, and (4) an extension to the OpenFlow protocol to enable external auditing. This paper presents our approach and illustrates its application using an example considering multiple SDN networks.", "labels": [0, 11]}
{"id": "832", "token": "Since April 2014 the Artemis/ECSEL project EMC2 is running and provides significant results. EMC2 stands for Embedded Multi-Core Systems for Mixed Criticality Applications in Dynamic and Changeable Real-Time Environments. In this paper we report recent progress on technical work in the different workpackages and use cases. We highlight progress in the research on system architecture, design methodology, platform and operating systems, and in qualification and certification. Application cases in the fields of automotive, avionics, health care, and industry are presented exploiting the technical results achieved.", "labels": [0, 11]}
{"id": "967", "token": "Geographic Object-Based Image Analysis (GEOBIA) mostly uses proprietary software, but the interest in Free and Open-Source Software (FOSS) for GEOBIA is growing. This interest stems not only from cost savings, but also from benefits concerning reproducibility and collaboration. Technical challenges hamper practical reproducibility, especially when multiple software packages are required to conduct an analysis. In this study, we use containerization to package a GEOBIA workflow in a well-defined FOSS environment. We explore the approach using two software stacks to perform an exemplary analysis detecting destruction of buildings in bi-temporal images of a conflict area. The analysis combines feature extraction techniques with segmentation and object-based analysis to detect changes using automatically-defined local reference values and to distinguish disappeared buildings from non-target structures. The resulting workflow is published as FOSS comprising both the model and data in a ready to use Docker image and a user interface for interaction with the containerized workflow. The presented solution advances GEOBIA in the following aspects: higher transparency of methodology; easier reuse and adaption of workflows; better transferability between operating systems; complete description of the software environment; and easy application of workflows by image analysis experts and non-experts. As a result, it promotes not only the reproducibility of GEOBIA, but also its practical adoption.", "labels": [0, 11]}
{"id": "1054", "token": "We present BILL2D, a modern and efficient C++ package for classical simulations of two-dimensional Hamiltonian systems. BILL2D can be used for various billiard and diffusion problems with one or more charged particles with interactions, different external potentials, an external magnetic field, periodic and open boundaries, etc. The software package can also calculate many key quantities in complex systems such as Poincare sections, survival probabilities, and diffusion coefficients. While aiming at a large class of applicable systems, the code also strives for ease-of-use, efficiency, and modularity for the implementation of additional features. The package comes along with a user guide, a developer's manual, and a documentation of the application program interface (API). Program summary Program title: Bill2d Catalogue identifier: AEYLv1_0 Program summary URL: http://cpc.cs.qub.ac.uk/summaries/AEYLv1_0.html Program obtainable from: CPC Program Library, Queen's University, Belfast, N. Ireland Licensing provisions: GNU General Public License, version 3 No. of lines in distributed program, including test data, etc.: 37098 No. of bytes in distributed program, including test data, etc.: 1155037 Distribution format: tar.gz Programming language: C++(14). Computer: Tested on x86 and x86 64 architectures. Operating systems: Tested on Linux, and OS X versions 10.9-10.11. Has the code been vectorized or parallelized?: Shared memory parallelization when simulating ensembles of systems. Vectorization of operations with R-2 vectors. RAM: Simulation dependent: kilobytes to gigabytes Classification: 4.3, 7.8, 7.9, 7.10, 16.9. External routines: Boost, CMake, GSL, HDF5; and optionally Google-Mock, GoogleTest, and Doxygen Nature of problem: Numerical propagation of classical two-dimensional single and many-body systems, possibly in a magnetic field, and calculation of relevant quantities such as Poincare sections, survival probabilities, diffusion co-efficients, etc. Solution method: Symplectic numerical integration of Hamilton's equations of motion in Cartesian coordinates, or solution of Newton's equations of motion if in a magnetic field. The program implements several well-established algorithms. Restrictions: Pointlike particles with equal masses and charges, although the latter restrictions are easy to lift. Unusual features: Program is efficient, extremely modular and easy to extend, and allows arbitrary particle-particle interactions. Additional comments: The source code is also available at https://bitbucicet.orgisolanpaa/bill2d. See README for locations of user guide, developer manual, and API docs. Running time: From milliseconds to days, depends on type of simulation. (C) 2015 Elsevier B.V. All rights reserved.", "labels": [0, 11]}
{"id": "1189", "token": "The invasive computing paradigm offers applications the possibility to dynamically spread their computation in a multicore/multiprocessor system in a resource-aware way. If applications are assumed to act maliciously, many security problems arise. In this acticle, we discuss different ways to deal with security problems in a resource-aware way. We first formalize the attacker model and the different security requirements that applications may have in multi-core systems. We then survey different hardware and software security mechanisms that can be dynamically configured to guarantee security on demand for invasive applications.", "labels": [0, 11]}
{"id": "1273", "token": "In recent years smart mobile devices have bolstered new interaction scenarios that require more sophisticated human-machine interfaces. The leading developers of operating systems for these devices now provide APIs (Application Programming Interface) for developers to implement their own applications, including different solutions for developing graphical interfaces, control sensors and providing oral interaction. Despite the usefulness of these resources, defined strategies are still needed for developing multimodal interfaces to take greater advantage of these devices for identifying and meeting the needs of users. Currently, these applications are typically ad-hoc and facilitate oral communication only through simple commands. In this paper we propose the practical application of context-sensitive multimodal conversational agents to provide advanced library services that dynamically consider specific user needs and preferences, as well as the specific characteristics of the environment in which the interaction occurs. Such agents would improve and customize the service provided by a mobile device with Internet access. Our proposal integrates features of Android APIs on a modular architecture emphasizing the management of interactions and context awareness in order to create robust applications that can be easily updated and adapted to the user.", "labels": [0, 11]}
{"id": "1376", "token": "Latency jitter is a pressing problem in Virtual Reality (VR) applications. This paper analyzes latency jitter caused by typical interprocess communication (IPC) techniques commonly found in today's computer systems used for VR. Test programs measure the seal ability and latencies for various IPC techniques, where increasing number of threads are performing the same task concurrently. We use four different implementations on a vanilla Linux kernel as well as on a real-time (RT) Linux kernel to further assess if a RT variant of a multiuser multiprocess operating system can prevent latency spikes and how this behavior would apply to different programming languages and IPC techniques. We found that Linux RT can limit the latency jitter at the cost of throughput for certain implementations. Further, coarse grained concurrency should be employed to avoid adding up of scheduler latencies, especially for native system space IPC, while actor systems are found to support a higher degree of concurrency granularity and a higher level of abstraction.", "labels": [0, 11]}
{"id": "1519", "token": "This study aims to analyze the users' form of interaction and problems in terms of interface design considering the people's constant interaction with mobile devices which has an important place in their daily life. For this purpose, the location of interface design elements and the changes caused in this development process of mobile communication technology are addressed. Because it is directly associated with the topics, required literature reviews has been done, descriptions and opinions related to the interface design have been given place. In addition to this, the notion of usability, interface usability, user-oriented interface design and the importance interface in the human-computer interaction are tried to be explained. Due to this the most widely used operating systems of Android and IOS, interface design of these operating systems it was analyzed by considering the basic graphic design principles. In order to measure the usability of these interfaces, one of interrogation methods based on information collected from the focus groups. At the end of the study, results of design analysis of the participants were compared and situation evaluation has been done.", "labels": [0, 11]}
{"id": "1650", "token": "Configuration options are widely used for customizing the behavior and initial settings of software applications, server processes, and operating systems. Their distinctive property is that each option is processed, defined, and described in different parts of a software project - namely in code, in configuration file, and in documentation. This creates a challenge for maintaining project consistency as it evolves. It also promotes inconsistencies leading to misconfiguration issues in production scenarios. We propose an approach for detection of inconsistencies between source code and documentation based on static analysis. Our approach automatically identifies source code locations where options are read, and for each such location retrieves the name of the option. Inconsistencies are then detected by comparing the results against the option names listed in documentation. We evaluated our approach on multiple components of Apache Hadoop, a complex framework with more than 800 options. Our tool ORPLocator was able to successfully locate at least one read point for 93% to 96% of documented options within four Hadoop components. A comparison with a previous state-of-the-art technique shows that our tool produces more accurate results. Moreover, our evaluation has uncovered 4 previously unknown, real-world inconsistencies between documented options and source code.", "labels": [0, 11]}
{"id": "1890", "token": "Aluminum/graphite (Al/Gr) composites have been used as self-lubricating materials due to the superior lubricating effect of graphite during sliding. This paper summarizes various tribological aspects of self-lubricating aluminum composites. The influence of various factors such as (a) material factors, graphite size and volume fraction, and (b) mechanical factors, applied load and sliding speed on the tribological properties of self-lubricating aluminum composites, is discussed. Furthermore, the tribological properties of self-lubricating composites as a function of these parameters and the active wear mechanism involved in various systems are discussed. Bringing self-lubricating composites into different operating systems is a solution to reduce the use of external toxic petroleum-based lubricants in sliding contacts in a way to help the environment and reduce energy dissipation in industrial components for strategies toward sustainability and energy efficiency.", "labels": [0, 11]}
{"id": "2041", "token": "Experiments in the computer teaching process often need to use a number of operating systems, which often destroys the computer room in common operating system. Maintenance of the engine room has brought some difficulties. If the traditional experiments build a virtual experimental platform to complete on the basis of virtual machine technology, it cannot only improve the use of the engine room, but also can release the administrator from the tedious maintenance work. Therefore, it has important practical value.", "labels": [0, 11]}
{"id": "2113", "token": "The work reported here focuses on the controllability expressions in the mathematical modeling of dehydration process of food concentrates in producing powder using spray-DIC (spray-Detente Instantanee Controlee or spray-instant controlled pressure drop). This paper presents the second-order partial differential equations for mathematical modeling of moisture and heat transfer in spray-DIC process. This paper proposes the enhancement in the simple model of DIC technique with controllability expression to be used in the spray-DIC. The controllability expression in the drying process models gives better results when compared to the models without the controllability expression. The results were computed and shown by MATLAB 2013 with Windows 8 operating systems. The controllability expression in dehydration process model using the spray-DIC drier manage to succesfully control the dehydration process.", "labels": [0, 11]}
{"id": "2293", "token": "PartitionFinder 2 is a program for automatically selecting best-fit partitioning schemes and models of evolution for phylogenetic analyses. PartitionFinder 2 is substantially faster and more efficient than version 1, and incorporates many new methods and features. These include the ability to analyze morphological datasets, new methods to analyze genome-scale datasets, new output formats to facilitate interoperability with downstream software, and many new models of molecular evolution. PartitionFinder 2 is freely available under an open source license and works on Windows, OSX, and Linux operating systems. It can be downloaded from www.robertlanfear.com/partitionfinder. The source code is available at https://github.com/brettc/partitionfinder.", "labels": [0, 11]}
{"id": "2316", "token": "Automotive systems are widely used in industry and our daily life. As the reliability of automotive systems is becoming a greater challenge in our community, increasingly more automotive companies are interested in applying formal methods to improve the reliability of automotive systems. We focus on automotive operating systems conforming to the OSEK/VDX standard. Such operating systems are considered as important components to ensure the reliability of the automotive systems. In previous work, we proposed a framework to verify the design models of reactive systems against their specifications. This framework allows us to check whether the design model conforms to the specification based on a simulation relation. This paper shows a case study in which the framework is applied to a real design of the OSEK/VDX operating system. As a result, we found that we were able to check several important properties of the design model. We show the effectiveness and practicality of the framework based on the results of the case study.", "labels": [0, 11]}
{"id": "2572", "token": "Transition of the precision engineering and instrumentation to the widespread use of nanoscale structures and thin layers requires improved localization methods for measuring the depth of the material. Unified standards and the generally accepted methods for measuring the wear resistance and friction coefficient are not currently available. The aim of this work was the development of a universal friction machine with the simplified requirements for the preparation and the geometric shape of the sample and the opposing disc. An important requirement for the equipment and the method of measurement is the ability to measure the friction coefficient and the determination of the wear resistance of coatings and hardened layers of micron and submicron thicknesses. Another important requirement is modeling in the experiment of acyclic friction process, as close as possible to the real operating conditions of components and parts. Both of these conditions are successfully realized by using the method of disc on plate. Implementation of disk on plate method was used to simplify and improve the rapid measurement, and to minimize load on the friction assembly, reduce friction pair temperature, increase the sensitivity and improve the resistive bridge thermal stabilization. The complex for the study of friction and wear processes of various materials pairs in conditions close to operational was manufactured and tested. The measuring console with a low value of the parasitic load on the measuring cell was designed. A computerized hardware and software system for the registration of the friction parameters of the process was developed. The software for processing and storage of experiment results was developed. The software is compatible with modern Windows operating systems. The file format for measurement results storage is compatible with the conventional graphic editors and could be processed by means of Excel. The main principles of the analysis and processing of the results are consequentially described. Typical results of usage of the developed machine for friction coefficient measurements and the determination of the wear resistance of massive, homogeneous surface-hardened materials and alloys with coatings are shown. The high efficiency of the created equipment complex during investigation of coatings, optimization of coating depositing processes and the modification of the surface layers are shown in the study. The efficiency of the complex was confirmed by the study of the modified layers and micron thickness coatings. It was found that the friction coefficient and wear resistance of construction materials, modified thin microcrystalline layers and nanostructured coatings was effectively controlled by using of the created complex.", "labels": [0, 11]}
{"id": "2828", "token": "As a next generation networking protocol, OpenFlow enhances network performance by separating the control plane from data plane. It can be implemented for quality of service: users desiring network resources or with higher priorities defined by the system are allocated with adequate resources. Besides the communication protocol, another two elements are required to complete the OpenFlowsystem: the switch, either physical or virtual, which supports OpenFlow, and the controller, which sends setting packets to control the switch flow table. With OpenFlow, users are not restricted to functions provided by the specific switch, since by a standard application programming interface (API) users can define wanted functions instead of predefined ones bundled in operating systems. This paper aims to create an OpenFlow switch monitoring system, which oversees traffic pass through switches under the controller, and provides a convenient webpage for network administrators to modify flow priorities and effectively manage the network.", "labels": [0, 11]}
{"id": "2912", "token": "This paper develops an Internet-of-Things data highway embracing end sensors, sensor nodes, databases, big data processors, web connections, and high-end statistics engines. It is aiming at automatic, pseudo real-time, and integrative sensor stream processing, fully benefitting from the capability of sophisticated statistics packages supporting a variety of artificial intelligence and data mining libraries. Specifically, Raspberry Pi nodes capture signals from attached sensors via GPIO interfaces and insert into a remote MySQL database table using its connector utility. In the Linux machine, the table entry is purged at each fixed time and dumped to a text file for a later batch analysis using Hadoop. The R package running in a Windows PC periodically downloads the sensor stream from the database table via the implementation of a library extension invoking relevant operating systems calls. In the R space, even a spatial analysis and visualization can be provided comprehensively.", "labels": [0, 11]}
{"id": "2931", "token": "Recent smartphone platforms based on new operating systems, such as iOS, Android, or Windows Phone, have been a huge success in recent years and open up many new opportunities. Unfortunately, 2011 also showed us that the new technologies and the privacy-related data on smartphones are also increasingly interesting for attackers. Especially, the Android platform has been the favorite target for malware, mainly because of the openness of the platform, the ability to install applications from other sources than the Android Market, and the significant gains in market share. Although the processes of detecting and analyzing malware are well known from the PC world, where the arms race between attackers and defenders has continued for the past 15years, they cannot be directly applied to smartphone platforms because of differences in the hardware and software architectures. In this paper, we first give an overview of the current malware situation on smartphone platforms with a special focus on Android and explain relevant malware detection and analysis methods. It turns out that most of the current malware relies on the installation by the user, who represents the last line of defense in malware detection. With these conclusions, we then present a new malware detection method that focuses on the information that the user is able to see prior to the installation of an applicationthe metadata within the platform's software market. Depending on the platform, this includes the application's description, its permissions, the ratings, or information about the developer. To analyze these data, we use sophisticated knowledge discovery processes and lean statistical methods. By presenting a wide range of examples based on real application metadata extracted from the Android Market, we show the possibilities of the new method. With the possibilities, we argue that it should be an essential part of a complete malware analysis/detection chain that includes other well-known methods such as network traffic analysis, or static, or dynamic code inspection. Copyright (c) 2013 John Wiley & Sons, Ltd.", "labels": [0, 11]}
{"id": "3108", "token": "In this paper, we introduce Software Asset Analyzer (SAA), a system that monitors and detects potentially vulnerable software asset modifications in end devices, and can be used to guide patch management. Software patching is a complex and failure-prone process that, on enterprise networks, requires triage. Accurate inventories of software (applications and operating systems) improve patching efficiency, which is a significant concern for security analysts. By generating asset baselines, the SAA identifies and reports abnormal deviations in individual end-devices, which allows security analysts to identify vulnerable devices and further enforce security patching. This system is also suited for detecting vulnerable software installs and remediation process verification. SAA is a low-cost and efficient method that yields accurate and complete inventories of assets on end-devices, reducing the potential loss from new vulnerabilities.", "labels": [0, 11]}
{"id": "3192", "token": "In recent years, the development of network information for the reform and development of education has played a great role in promoting. At present, the mobile Internet, becoming the number one choice of access to information and communication way, the development of mobile Internet information technology for the development of the education sector to provide more opportunities for mobile, fragmented, individualized education, socializing, features a new mobile Internet era of education. Young students as a mainstream mobile Internet user base, but also the direct object of English teaching, the traditional English teaching model can not meet the needs of young students, how to mobile Internet applications to English teaching is currently facing a major college English teaching problem. In this paper, the efficiency of learning in the mobile Internet era, the reform of college English teaching on how to improve college English outside the classroom in depth discussion and research, and put forward the corresponding strategies and methods of reform. First, recognize that the mobile Internet Mobile Internet, mobile communications and the Internet is to combine the two into one. Open and highlight the 4G era of mobile terminal equipment will inject huge amounts of energy for the development of mobile Internet, mobile Internet industry in 2014 will bring an unprecedented leap. Mobile Internet is a smart mobile terminal by using a mobile wireless communications services to obtain business and emerging business, including terminals, software and applications at three levels. Terminal layer including smart phones, tablet PCs, e-books, MID, etc; software including operating systems, middleware, database and security software. Application layer including casual entertainment, media-tools, business finance, culture and education etc. Different applications and services. As of January 2014, the total number of China's mobile Internet users reached 838 million, in the mobile phone user penetration rate of 67.8%; the scale of mobile phone users reached 500 million, more than eighty percent of the total number of Internet users, the phone maintains the first big Internet terminal status. Development of China's mobile Internet era into the universal. According to the Chinese mobile Internet users Research Reports statistics, more than 800 million mobile Internet users, groups of students are the main force, accounting for up to 80% ratio.", "labels": [0, 11]}
{"id": "3292", "token": "In the era of cloud computing and big data, virtualization is gaining great popularity in storage systems. Since multiple guest virtual machines (DomUs) are running on a single physical device, disk I/O fairness among DomUs and aggregated throughput remain the challenges in virtualized environments. Although several methods have been developed for disk I/O performance virtualization among multiple DomUs, most of them suffer from one or more of the following drawbacks. (1) A fair scheduling mechanism is missing when requests converge together from multiple queues. (2) Existing methods rely on better performance of the underlying storage system such as solid state drive (SSD). (3) Throughput and latency are not considered simultaneously. To address these disadvantages, this paper presents a virtual multi-channel of disk I/O (VMCD) method that can be built on top of an ordinary storage utility, which mitigates the interference among multiple DomUs by using separated virtual channel (V-Channel) and an I/O request queue for each DomU. In our VMCD, several mechanisms are employed to enhance the I/O performance, including a credit allocation mechanism, a global monitoring strategy, and a virtual multi-channel fair scheduling algorithm. The proposed techniques are implemented on the Xen virtual disk and evaluated on Linux guest operating systems. Experiments results show that VMCD increases fairness by 70 percent approximately compared with CFQ and Anticipatory schedulers, by 30 percent approximately compared with Deadline scheduler; and enhances bandwidth utilization by 28 percent approximately compared with CFQ and Anticipatory schedulers, by 37 percent compared with Deadline in the case of three or more virtual DomUs running on the same physical host.", "labels": [0, 11]}
{"id": "3420", "token": "Mobile devices including popular smartphone contributes to efficiency improvement of on-site data processing. Mobile environment for real-time data processing needs some additional aspects besides desktop ones, as the style of mobile app, mobile web and mobile web app. Generally, mobile app provides internal storage service so that offline data processing is possible. But mobile app needs separate development according to different types of devices or operating systems, even to different sizes of display panel of mobile devices. Geo-based data are composed of vector and raster formats from complex structure, compared to other data sets including image data and multimedia data. Hence, even though mobile applications development for geo-based data is more complicated than other ones, users' demands with respect to geo-based data processing functionalities on mobile environment are increasing in these days. Mobile web supported by technical basis of HyperText Markup Language5 (HTML5) is regarded as useful service type combining geo-based data processing modules and mobile environments, because it does not require user' downloading or installation of programs and just needs web browsers. Indexed DB Application Programming Interface (API) within this international web standard provides offline data storage functions on mobile environment. Using this API, data sets can be permanently stored into mobile devices, not cache memory. Among numerous geo-data functionalities, visualization topic is basically and commonly used in most mobile services. This study presents an implementation case of mobile web app with geobased data visualization processing on online and offline mode. Types of geo-based data sets are base map of Open Street Map (OSM), OSM vector layers with Extensible Markup Language (XML) contents and high resolution satellite images of optical sensor. It is thought that the result of this implementation can play a role to create intelligent mobile application fields using both geo-based data sets and earth observation satellite image sets.", "labels": [0, 11]}
{"id": "3471", "token": "A next generation B factory and the detector counterpart, SuperKEKB and Belle II, are being built in Japan, as the upgrades of KEKB and Belle, respectively. The new collider will start its commissioning in 2015. This is an ambitious project. The luminosity of the e(+) e(-) collider will be upgraded by a factor of 40, which will create a 50 times larger data set compared to the Belle sample. Both the background and the triggered event rates will be increased by a factor of at least 10. The Belle II software system is designed to accommodate these challenges and to run on grid, cloud, and local resources around the world. Various external software packages are employed to enhance the user interface. The software system, basf2, is structured as a framework built with dynamic module loading and the ability of parallel processing. The system is written in C++ with Python steering scripts, compatible with common Linux operating systems. A full detector simulation library is created based on Geant4. In this paper, we will explain the design of the Belle II software structure and the current status of the software development.", "labels": [0, 11]}
{"id": "3525", "token": "Information leakage and memory disclosures are significant threats to the security of modern operating systems. If an attacker is able to obtain the binary-code of a program, it is then possible to reverse engineer its source code, uncover vulnerabilities, craft exploits, and subsequently patch together code-segments to form code-reuse attacks. These activities are particularly concerning when the program is a device driver or the operating system kernel, since these facilitate privilege-escalation and the ability to persist and hide. While execute-only code is a way to inhibit memory disclosures, the current x86-64 bit virtual memory implementation does not provide the capability to enforce execute only access permissions. The authors present their implementation of ExOShim: a novel, 325-line, lightweight shim hypervisor layer employing Intel's commodity virtualization features that can be dynamically inserted beneath a running kernel to prevent memory disclosures by marking its code execute-only. Unlike alternative approaches that operate only on user level applications, ExOShim utilizes self-protection and hiding techniques that guarantee its integrity even in the event that the attacker is able to gain root-level access. The technology can be combined with fine grained compile- and load-time diversity to mitigate the additional threat of indirect memory disclosures. These concepts have been integrated within an experimental MINIX-like 64-bit microkernel. While the concepts are general and could be applied to other operating systems, their implementation is subtle and requires a detailed understanding of the kernels interaction with its virtual memory layer and consideration at boot -time to load kernel code and kernel data on distinct pages of memory. Early evaluations quantify ExOShim's code size and complexity, run time performance cost, and effectiveness in thwarting information leakage. ExOShim provides complete MULTIC-like execute only protection for kernel code at a runtime- performance overhead of only 0.86% due to the advanced modern caching techniques in the x86 architecture. Overall, this paper contributes the presentation, implementation, and evaluation of a lightweight tool for enforcing execute only access control permissions on kernel code using the virtualization features of the modern x86-64 architecture.", "labels": [0, 11]}
{"id": "124", "token": "The internal quality of intact persimmon cv. 'Rojo Brillante' was assessed trough visible and near infrared hyperspectral imaging. Fruits at three stages of commercial maturity were exposed to different treatments with CO2 to obtain fruit with different ripeness and level of astringency (soluble tannin content). Spectral and spatial information were used for building classification models to predict ripeness and astringency trough multivariate analysis techniques like linear and quadratic discriminant analysis (LDA and QDA) and support vector machine (SVM). Additionally, flesh firmness was predicted by partial least square regression (PLSR). The full spectrum was used to determine the internal properties and later principal component analysis (PCA) was used to select optimal wavelengths (580, 680 and 1050 nm). The correct classification was above 92% for the three classifiers in the case of ripeness and 95% for QDA in the case of astringency. A value of R-2 = 0.80 and a ratio of prediction deviation (RPD) of 1.86 were obtained with the selected wavelengths for the prediction of firmness which demonstrated the potential of hyperspectral imaging as a non-destructive tool in the assessment of the firmness, ripeness state and astringency level of 'Rojo Brillante' persimmon. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [0, 7]}
{"id": "175", "token": "Image segmentation is an important processing in many applications such as image retrieval and computer vision. One of the most successful models for image segmentation is the level set methods which are based on local context. The methods, though comparatively effective in segmenting images with inhomogeneous intensity, are considerably computation-intensive and at the risk of falling into local minima in the convergence of the active contour energy function. To address the issues, we propose a region-based level set method, called KL-MLBF, which is based on the multi-scale local binary fitting (MLBF) and the Kullback-Leibler (KL) divergence. We first apply the multi-scale theory to the local binary fitting model to build MLBF. Then the energy term measured by KL divergence between regions to be segmented is incorporated into the energy function of MLBF. KL-MLBF utilizes the between-cluster distance and the adaptive kernel function selection strategy to formulate the energy function. Being more robust to the initial location of the contour than the classical segmentation models, KL-MLBF can deal with blurry boundaries and noise problems. The results of experiments on synthetic and real images have shown that KL-MLBF can improve the effectiveness of segmentation while ensuring the accuracy by accelerating the minimization of the energy function.", "labels": [0, 7]}
{"id": "313", "token": "This study examined the effects of display curvature (400, 600, 1200 mm, and flat), display zone (5 zones), and task duration (15 and 30 min) on legibility and visual fatigue. Each participant completed two 15-min visual search task sets at each curvature setting. The 600-mm and 1200-mm settings yielded better results than the flat setting in terms of legibility and perceived visual fatigue. Relative to the corresponding centre zone, the outermost zones of the 1200-mm and flat settings showed a decrease of 8%-37% in legibility, whereas those of the flat setting showed an increase of 26%-45% in perceived visual fatigue. Across curvatures, legibility decreased by 2%-8%, whereas perceived visual fatigue increased by 22% during the second task set. The two task sets induced an increase of 102% in the eye complaint score and a decrease of 0.3 Hz in the critical fusion frequency, both of which indicated an increase in visual fatigue. In summary, a curvature of around 600 mm, central display zones, and frequent breaks are recommended to improve legibility and reduce visual fatigue. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [0, 7]}
{"id": "397", "token": "Appropriately merging visual words are an effective dimension reduction method for the bag-of-visual-words model in image classification. The approach of hierarchically merging visual words has been extensively employed, because it gives a fully determined merging hierarchy. Existing supervised hierarchical merging methods take different approaches and realize the merging process with various formulations. In this paper, we propose a unified hierarchical merging approach built upon the graph-embedding framework. Our approach is able to merge visual words for any scenario, where a preferred structure and an undesired structure are defined, and, therefore, can effectively attend to all kinds of requirements for the word-merging process. In terms of computational efficiency, we show that our algorithm can seamlessly integrate a fast search strategy developed in our previous work and, thus, well maintain the state-of-the-art merging speed. To the best of our survey, the proposed approach is the first one that addresses the hierarchical visual word mergence in such a flexible and unified manner. As demonstrated, it can maintain excellent image classification performance even after a significant dimension reduction, and outperform all the existing comparable visual word-merging methods. In a broad sense, our work provides an open platform for applying, evaluating, and developing new criteria for hierarchical word-merging tasks.", "labels": [0, 7]}
{"id": "545", "token": "The study aimed to determine if computer vision techniques rooted in deep learning can use a small set of radiographs to perform clinically relevant image classification with high fidelity. One thousand eight hundred eighty-five chest radiographs on 909 patients obtained between January 2013 and July 2015 at our institution were retrieved and anonymized. The source images were manually annotated as frontal or lateral and randomly divided into training, validation, and test sets. Training and validation sets were augmented to over 150,000 images using standard image manipulations. We then pre-trained a series of deep convolutional networks based on the open-source GoogLeNet with various transformations of the open-source ImageNet (non-radiology) images. These trained networks were then fine-tuned using the original and augmented radiology images. The model with highest validation accuracy was applied to our institutional test set and a publicly available set. Accuracy was assessed by using the Youden Index to set a binary cutoff for frontal or lateral classification. This retrospective study was IRB approved prior to initiation. A network pre-trained on 1.2 million greyscale ImageNet images and fine-tuned on augmented radiographs was chosen. The binary classification method correctly classified 100 % (95 % CI 99.73-100 %) of both our test set and the publicly available images. Classification was rapid, at 38 images per second. A deep convolutional neural network created using non-radiological images, and an augmented set of radiographs is effective in highly accurate classification of chest radiograph view type and is a feasible, rapid method for high-throughput annotation.", "labels": [0, 7]}
{"id": "709", "token": "Human action recognition (HAR) is a core technology for human-computer interaction and video understanding, attracting significant research and development attention in the field of computer vision. However, in uncontrolled environments, achieving effective HAR is still challenging, due to the widely varying nature of video content. In previous research efforts, trajectory-based video representations have been widely used for HAR. Although these approaches show state-of-the-art HAR performance for various datasets, issues like a high computational complexity and the presence of redundant trajectories still need to be addressed in order to solve the problem of real-world HAR. In this paper, we propose a novel method for HAR, integrating a technique for rejecting redundant trajectories that are mainly originating from camera movement, without degrading the effectiveness of HAR. Furthermore, in order to facilitate efficient optical flow estimation prior to trajectory extraction, we integrate a technique for dynamic frame skipping. As a result, we only make use of a small subset of the frames present in a video clip for optical flow estimation. Comparative experiments with five publicly available human action datasets show that the proposed method outperforms state-of-the-art HAR approaches in terms of effectiveness, while simultaneously mitigating the computational complexity. (C) 2016 Elsevier B.V. All rights reserved.", "labels": [0, 7]}
{"id": "859", "token": "The seasonality of fruits and vegetables makes it impossible to consume and use them throughout the year, thus numerous processing efforts have been made to offer an alternative to their fresh consumption and application. To prolong their availability on the market, drying has received special attention as currently this method is considered one of the most common ways for obtaining food and pharmaceutical products from natural sources. This paper demonstrates the weakness of common drying methods applied for fruits and vegetables and the possible ways to improve the quality using different drying techniques or their combination with an emphasis on the microwave energy. Particular attention has been drawn to the combined drying with the assistance of vacuum-microwaves. The quality of the dried products was ascribed by chemical properties including the content of polyphenols, antioxidant capacity and volatiles as well as physical parameters such as color, shrinkage, porosity and texture. Both these fields of quality classification were considered taking into account sensory attributes and energy aspects in the perspective of possible industrial applications. In conclusion, the most promising way for improving the quality of dried fruit and vegetable products is hybrid drying consisting of osmotic dehydration in concentrated fruit juices followed by heat pump drying and vacuum-microwave finish drying.", "labels": [0, 7]}
{"id": "1058", "token": "Underwater exploration has become an active research area over the past few decades. The image enhancement is one of the challenges for those computer vision based underwater researches because of the degradation of the images in the underwater environment. The scattering and absorption are the main causes in the underwater environment to make the images decrease their visibility, for example, blurry, low contrast, and reducing visual ranges. To tackle aforementioned problems, this paper presents a novel method for underwater image enhancement inspired by the Retinex framework, which simulates the human visual system. The term Retinex is created by the combinations of Retina and Cortex. The proposed method, namely LAB-MSR, is achieved by modifying the original Retinex algorithm. It utilizes the combination of the bilateral filter and trilateral filter on the three channels of the image in CIELAB color space according to the characteristics of each channel. With real world data, experiments are carried out to demonstrate both the degradation characteristics of the underwater images in different turbidities, and the competitive performance of the proposed method. (C) 2017 The Authors. Published by Elsevier B.V.", "labels": [0, 7]}
{"id": "1086", "token": "The qualities of color images captured by digital imaging devices are vulnerable to the scene illumination settings of a given environment. The colors of captured objects may not be accurately reproduced when the illumination settings are uncontrollable or not known a priori. This undesirable property can inevitably degrade the qualities of captured images and lead to difficulties in subsequent image-processing stages. Considering that the task of controlling scene illumination is nontrivial, color correction has emerged as a plausible post-processing procedure to efficiently restore the scene chromatics of a given image. In this study, a new color correction technique called the Saturation Avoidance Color Correction (SACC) algorithm is proposed to remove the undesirable effect of scene illuminants. Unlike most well-established color correction algorithms, the proposed SACC comprises a nonlinear pixel adjustment mechanism to avoid the saturation effect during the color manipulation process. A collection of color images including indoor, outdoor, and underwater images are used to verify the capability of SACC. Extensive experimental studies reveal that the proposed algorithm is preferable to some existing techniques because the former has a high capability to mitigate the color saturation issue and is able to produce corrected images with more pleasant visualization.", "labels": [0, 7]}
{"id": "1237", "token": "Background and objective: The preoperative planning of bone fractures using information from CT scans increases the probability of obtaining satisfactory results, since specialists are provided with additional information before surgery. The reduction of complex bone fractures requires solving a 3D puzzle in order to place each fragment into its correct position. Computer-assisted solutions may aid in this process by identifying the number of fragments and their location, by calculating the fracture zones or even by computing the correct position of each fragment. The main goal of this paper is the development of an automatic method to calculate contact zones between fragments and thus to ease the computation of bone fracture reduction. Methods: In this paper, an automatic method to calculate the contact zone between two bone fragments is presented. In a previous step, bone fragments are segmented and labelled from CT images and a point cloud is generated for each bone fragment. The calculated contact zones enable the automatic reduction of complex fractures. To that end, an automatic method to match bone fragments in complex fractures is also presented. Results: The proposed method has been successfully applied in the calculation of the contact zone of 4 different bones from the ankle area. The calculated fracture zones enabled the reduction of all the tested cases using the presented matching algorithm. The performed tests show that the reduction of these fractures using the proposed methods leaded to a small overlapping between fragments. Conclusions: The presented method makes the application of puzzle-solving strategies easier, since it does not obtain the entire fracture zone but the contact area between each pair of fragments. Therefore, it is not necessary to find correspondences between fracture zones and fragments may be aligned two by two. The developed algorithms have been successfully applied in different fracture cases in the ankle area. The small overlapping error obtained in the performed tests demonstrates the absence of visual overlapping in the figures. (C) 2016 Elsevier Ireland Ltd. All rights reserved.", "labels": [0, 7]}
{"id": "1339", "token": "Image registration deals with establishing correspondences between images of the same scene or object. An image registration algorithm should handle the variations introduced by the imaging system capturing the scene. Scale Invariant Feature Transform (SIFT) is an image registration algorithm based on local features in an image. Compared to the previous registration algorithms, SIFT is more robust to variations caused by changes in size, illumination, rotation, and viewpoint of the images. Owing to its performance, the algorithm is widely studied, modified, and successfully applied in many image and video based applications, in the domains such as medicine, industry, and defense. This paper is an outcome of extensive study on the state-of-art image registration algorithms based on SIFT. Around 20 algorithms based on the SIFT algorithm is discussed. A classification is made based on the objective with which the basic algorithm is modified. A comparative study on the performance, methodology of each technique is presented along with their applicability to various image processing applications and domains.", "labels": [0, 7]}
{"id": "1539", "token": "This paper presents a computer vision-based algorithm that automatically detects the components of an interior partition and infers its current state using 2D digital images. The algorithm relies on four integrated shape and color-based modules, which detect studs, insulation, electrical outlets, and three states for drywall sheets (installed, plastered, and painted). Based on the results of the four modules, images are classified into five states. The proposed method was validated using three image databases of indoor construction sites captured by a quadcopter (a type of unmanned aerial vehicle), a smartphone, and collected from publically available sources on the internet The method's high accuracy rates, its fast performance, and applicability to different contexts such as automated robotic inspection are indicative of its promising performance. The visual detection results can potentially provide situational awareness for construction trades, provide future progress tracking systems with information on actual state, and help leverage the use of image processing at indoor sites. (C) 2016 Elsevier B.V. All rights reserved.", "labels": [0, 7]}
{"id": "1572", "token": "In order to reduce the security risk of commercial aircraft, passengers are not allowed to take certain items in their carry-on baggage. For this reason, human operators are trained to detect prohibited items using a manually-controlled baggage screening process. In this paper, the use of an automated method based on multiple X-ray views is proposed to recognise certain regular objects with highly-defined shapes and sizes. The method consists of two steps: 'monocular analysis', to obtain possible detections in each view of a sequence, and 'multiple view analysis', to recognise the objects of interest using matching in all views. The search for matching candidates is efficiently performed using a look-up table that is computed offline. In order to illustrate the effectiveness of the proposed method, experimental results on recognising regular objects (clips, springs and razor blades) in pencil cases are shown achieving high precision and recall (P-r = 95.7%, R-e = 92.5%) for 120 objects. We believe that it would be possible to design an automated aid in a target detection task using the proposed algorithm.", "labels": [0, 7]}
{"id": "1765", "token": "The main objective of this study was to configure the acquisition and analysis of low-field magnetic resonance imaging (MRI) to predict physico-chemical characteristics of Iberian loin, evaluating the use of different MRI sequences (spin echo, SE; gradient echo, GE; turbo 3D, T3D), computational texture feature methods (GLCM, NGLDM, GLRLM, GLCM + NGLDM + GLRLM), and data mining techniques (multiple linear regression, MLR; isotonic regression, IR). Moderate to very good correlation coefficients and low mean absolute error were found when applying MLR or IR on any method of computational texture features from MRI acquired with SE or GE. For T3D sequence, accurate results are only obtained by applying IR on GLCM or GLCM + NGLDM + GLRLM methods. Considering not only the accuracy of the methodology but also consumed time and required resources, the use of SE sequences for MRI acquisition, GLCM method for MRI texture analysis, and MLR could be indicated for prediction physico-chemical characteristics of loin.", "labels": [0, 7]}
{"id": "1833", "token": "Switched systems theory is used to analyze the stability of image-based observers for three-dimensional localization of objects in a scene in the presence of intermittent measurements due to occlusions, feature tracking losses, or a limited camera field of view, for example. Generally, observers or filters that are exponentially stable under persistent measurement availability may have unbounded error growth under intermittent measurement loss, even while providing seemingly accurate state estimates. By constructing a framework that utilizes a state predictor during periods when measurements are not available, a class of image-based observers is shown to be exponentially convergent in the presence of intermittent measurements if an average dwell time, and a total unmeasurability time, condition is satisfied. The conditions are developed in a general form, applicable to any observer that is exponentially convergent assuming persistent visibility, and utilizes object motion knowledge to reduce the amount of time measurements must be available to maintain convergence guarantees. Based on the stability results, simulations are provided to show improved performance compared to a zero-order hold approach, where state estimates are held constant when measurements are not available. Experimental results are also included to verify the theoretical results, to demonstrate applicability of the developed observer and predictor design, and to compare against a typical approach using an extended Kalman filter.", "labels": [0, 7]}
{"id": "1970", "token": "Deep learning is a thing of tomorrow which is causing a complete drift from shallow architecture to deep architecture and an estimate shows that by 2017 about 10 % of computers will be learning rather than processing. Deep learning has fast growing effects in the area of pattern recognition, computer vision, speech recognition, feature extraction, language processing, bioinformatics, and statistical classification. To make a system learn, deep learning makes use of a wide horizon of machine learning algorithms. Gene expression data is uncertain and imprecise. In this paper, we discuss supervised and unsupervised algorithms applied to gene expression dataset. There are intermediate algorithms classified as semi-supervised and self taught which also play an important role to improve the prediction accuracy in diagnosis of cancer. We discuss deep learning algorithms which provide better analysis of hidden patterns in the dataset, thus improving the prediction accuracy.", "labels": [0, 7]}
{"id": "2032", "token": "An effective method based on measuring the fiber orientation of yarn floats with two-dimensional Fourier transform (2-D FFT) is proposed to recognize the weave pattern of yarn-dyed fabric in the high-resolution image. The recognition process consists of four main steps: 1. High-resolution image reduction, 2.Fabric image skew correction, 3.Yarn floats localization, 4. Yarn floats classification. Firstly, the high-resolution image is reduced by the nearest interpolation algorithm. Secondly, the skew of the fabric image is corrected based on Hough transform. Thirdly, the yarn floats in the fabric image is localized by the yarns segmentation method based on the mathematical statistics of sub-images. Fourthly, the high-resolution image is corrected and its yarns are segmented successively according to the inspection information of the reduced image. The fiber orientations are detected by 2-D FFT, and the yarn floats are classified by k-means clustering algorithm. Experimental results and discussions demonstrate that, by measuring the fiber orientation of yarn floats, the proposed method is effective to recognize the yarn floats and the weave pattern for yarn-dyed, solid color, and gray fabrics.", "labels": [0, 7]}
{"id": "2104", "token": "Building oscillator-based computing systems with emerging nano-device technologies has become a promising solution for unconventional computing tasks like computer vision and pattern recognition. However, simulation and analysis of these computing systems is both time and compute intensive due to the nonlin-earity of new devices and the complex behavior of coupled oscillators. In order to speed up the simulation of coupled oscillator systems, we propose a simplified phasemodel to perform phase and frequency synchroniza-tion prediction based on a synthesis of earlier models. Our model can predict the frequency-locking behavior with several orders of magnitude speedup compared to direct evaluation, enabling the effective and efficient simulation of the large numbers of oscillators required for practical computing systems. We demonstrate the oscillator-based computing paradigm with three applications, pattern matching, convolution, and image segmentation. The simulation with these models are respectively sped up by factors of 780, 300, and 1120 in our tests.", "labels": [0, 7]}
{"id": "2236", "token": "A set of algorithms for simultaneous localization and mapping in industrial television systems is discussed. A probabilistic model of this problem is described with the FastSLAM algorithm as an example. The possibility of using a sigma-point Kalman filter for estimating the movement of spatial landmarks, a key feature of images characterized by stable detection and recognition within the video stream, is considered. A general model of the camera motion and a method for evaluating its spatial position using a particle filter are presented.", "labels": [0, 7]}
{"id": "2333", "token": "Recently, many researchers have attempted to classify Facial Attributes (FAs) by representing characteristics of FAs such as attractiveness, age, smiling and so on. In this context, recent studies have demonstrated that visual FAs are a strong background for many applications such as face verification, face search and so on. However, Facial Attribute Classification (FAC) in a wide range of attributes based on the regression representation-predicting of FAs as real-valued labels- is still a significant challenge in computer vision and psychology. In this paper, a regression model formulation is proposed for FAC in a wide range of FAs (e.g. 73 FAs). The proposed method accommodates real-valued scores to the probability of what percentage of the given FAs is present in the input image. To this end, two simultaneous dictionary learning methods are proposed to learn the regression and identity feature dictionaries simultaneously. Accordingly, a multi-level feature extraction is proposed for FAC. Then, four regression classification methods are proposed using a regression model formulated based on dictionary learning, SRC and CRC. Convincing results are acquired to handle a wide range of FAs and represent the probability of FAs on the PubFig, LFW, Groups and 10k US Adult Faces databases compared to several state-of-the-art methods. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [0, 7]}
{"id": "2424", "token": "Small satellites have limited payload and their attitudes are sometimes difficult to determine from the limited onboard sensors alone. Wrong attitudes lead to inaccurate map projections and measurements that require post-processing correction. In this study, we propose an automated and robust scheme that derives the satellite attitude from its observation images and known satellite position by matching land features from an observed image and from well-registered base-map images. The scheme combines computer vision algorithms (i.e., feature detection, and robust optimization) and geometrical constraints of the satellite observation. Applying the proposed method to UNIFORM-1 observations, which is a 50 kg class small satellite, satellite attitudes were determined with an accuracy of 0.02 degrees, comparable to that of star trackers, if the satellite position is accurately determined. Map-projected images can be generated based on the accurate attitudes. Errors in the satellite position can add systematic errors to derived attitudes. The proposed scheme focuses on determining satellite attitude with feature detection algorithms applying to raw satellite images, unlike image registration studies which register already map-projected images. By delivering accurate attitude determination and map projection, the proposed method can improve the image geometries of small satellites, and thus reveal fine-scale information about the Earth.", "labels": [0, 7]}
{"id": "2533", "token": "Efficiently and effectively detecting shell-like structures of particular shapes is an important task in computer vision and image processing. This paper presents a generalized possibilistic c-means algorithm (PCM) for shell clustering based on the diversity index of degree-lambda proposed by Patil and Taillie [Diversity as a concept and its measurement. J Amer Statist Assoc. 1982;77:548-561]. Experiments on various data sets in Wang [Possibilistic shell clustering of template-based shapes. IEEE Trans Fuzzy Syst. 2009;17:777-793] show that the the proposed generalized PCM performs better than Wang's [Possibilistic shell clustering of template-based shapes. IEEE Trans Fuzzy Syst. 2009;17:777-793] possibilistic shell clustering method according two two criteria: (i) the 'grade of detection' g(d) for each target cluster; (ii) the amount of computation, denoted as k(c), required to attain a given g(d).", "labels": [0, 7]}
{"id": "2614", "token": "Shape alignment or estimation under occlusion is one of the most challenging tasks in computer vision field. Most previous works treat occlusion as noises or part models, which usually lead to low accuracy or inefficiencies. This paper proposes an efficient and accurate regression-based algorithm for face alignment. In this framework, local and global regressions are iteratively used to train a series of random forests in a cascaded manner. In training and testing process, each step consists of two layers. In the first layer, a set of highly discriminative local features are extracted from local regions according to locality principle. The regression forests are trained for each facial landmark independently using those local features. Then the leaf node of the regression tree is encoded by histogram statistic method and the final shape is estimated by a linear regression matrix. In the second layer, our proposed global features are generated. Then we use those features to train a random fern to keep the global shape constraints. Experiments show that our method has a high speed, but same or slightly lower accuracy than state of the art methods under occlusion condition. In order to gain a higher accuracy we use multi-random shape for initialization, which may slightly reduce the calculation efficiency as a trade-off.", "labels": [0, 7]}
{"id": "2725", "token": "Active Contour Models (ACM) have been widely used for segmentation in many computer vision applications. These models are defined by an energy functional attached to an initial curve that evolves under some constraints to extract desired objects in the image. New models are proposed, and existing techniques are investigated and improved in different domains. Among these ACM, Balloon ACM is an edge-based model that adds a normal force as constraint making the curve to have more dynamic behaviors and more effectiveness in detecting objects boundary. However, some problems have been pointed out including segmentation of complex shape and high runtime processing. In this paper, we develop a new method -called Fast Adaptive Balloon (FAB)-sufficient to segment complex shape with lower computational complexity. The proposed definition for balloon force achieves satisfactory segmentation performance compared with other ACMs using both synthetic and medical images in two dimension. The results demonstrate the accuracy and effectiveness in segmentation besides the convergence speed.", "labels": [0, 7]}
{"id": "2850", "token": "In recent years, sparse representation theory has attracted the attention of many researchers in the signal processing, pattern recognition and computer vision communities. The choice of dictionary matrix plays a key role in the sparse representation based methods. It can be a pre-defined dictionary or can be learned via an optimization procedure. Furthermore, the dictionary learning process can be extended to a non-linear setting using an appropriate kernel function in order to handle non-linear structured data. In this framework, the choice of kernel function is also a key step. Multiple kernel learning is an appealing strategy for dealing with this problem. In this paper, within the framework of kernel sparse representation based classification, we propose an iterative algorithm for coincident learning of the dictionary matrix and multiple kernel function. The weighted sum of a set of basis functions is considered as the multiple kernel function where the weights are optimized such that the reconstruction error of the sparse coded data is minimized. In our proposed algorithm, the sparse coding, dictionary learning and multiple kernel learning processes are performed in three steps. The optimization process is performed considering two different structures namely distributive and collective for the sparse representation based classifier. Our experimental results show that the proposed algorithm outperforms the other existing sparse coding based approaches. These results also confirm that the collective setting leads to better results when the number of training examples is limited. On the other hand, the distributive setting is more appropriate when there are enough training samples.", "labels": [0, 7]}
{"id": "3018", "token": "For more flexibility of environmental perception by artificial intelligence it is needed to exist the supporting software modules, which will be able to automate the creation of specific language syntax and to make a further analysis for relevant decisions based on semantic functions. According of our proposed approach, of which implementation it is possible to create the couples of formal rules of given sentences (in case of natural languages) or statements (in case of special languages) by helping of computer vision, speech recognition or editable text conversion system for further automatic improvement. In other words, we have developed an approach, by which it can be achieved to significantly improve the training process automation of artificial intelligence, which as a result will give us a higher level of self-developing skills independently from us (from users). At the base of our approach we have developed a software demo version, which includes the algorithm and software code for the entire above mentioned component's implementation (computer vision, speech recognition and editable text conversion system). The program has the ability to work in a multi - stream mode and simultaneously create a syntax based on receiving information from several sources.", "labels": [0, 7]}
{"id": "3099", "token": "Saliency detection has been widely studied to predict human fixations, with various applications in computer vision and image processing. For saliency detection, we argue in this paper that the state-of-the-art High Efficiency Video Coding (HEVC) standard can be used to generate the useful features in compressed domain. Therefore, this paper proposes to learn the video saliency model, with regard to HEVC features. First, we establish an eye tracking database for video saliency detection, which can be downloaded from https://github. com/remega/video database. Through the statistical analysis on our eye tracking database, we find out that human fixations tend to fall into the regions with large-valued HEVC features on splitting depth, bit allocation, and motion vector (MV). In addition, three observations are obtained with the further analysis on our eye tracking database. Accordingly, several features in HEVC domain are proposed on the basis of splitting depth, bit allocation, and MV. Next, a kind of support vector machine is learned to integrate those HEVC features together, for video saliency detection. Since almost all video data are stored in the compressed form, our method is able to avoid both the computational cost on decoding and the storage cost on raw data. More importantly, experimental results show that the proposed method is superior to other stateof- the-art saliency detection methods, either in compressed or uncompressed domain.", "labels": [0, 7]}
{"id": "3183", "token": "Automated computer vision-based fire detection has gained popularity in recent years, as every fire detection needs to be fast and accurate. In this paper, a new fire detection method using image processing techniques is proposed. We explore how to create a fire flame-based colour space via a linear multiplication of a conversion matrix and colour features of a sample image. We show how the matrix multiplication can result in a differentiating colour space, in which the fire part is highlighted and the non-fire part is dimmed. Particle Swarm Optimization (PSO) and sample pixels from an image are used to obtain the weights of the colour-differentiating conversion matrix, and K-medoids provides a fitness metric for the PSO procedure. The obtained conversion matrix can be used for fire detection on different fire images without performing the PSO procedure. This allows a fast and easy implementable fire detection system. The empirical results indicate that the proposed method provides both qualitatively and quantitatively better results when compared to some of the conventional and state-of-the-art algorithms. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [0, 7]}
{"id": "3334", "token": "Effectively exploring and browsing document collections is a fundamental problem in visualization. Traditionally, document visualization is based on a data model that represents each document as the set of its comprised words, effectively characterizing what the document is. In this paper we take an alternative perspective: motivated by the manner in which users search documents in the research process, we aim to visualize documents via their usage, or how documents tend to be used. We present a new visualization scheme - cite2vec - that allows the user to dynamically explore and browse documents via how other documents use them, information that we capture through citation contexts in a document collection. Starting from a usage-oriented word-document 2D projection, the user can dynamically steer document projections by prescribing semantic concepts, both in the form of phrase/ document compositions and document: phrase analogies, enabling the exploration and comparison of documents by their use. The user interactions are enabled by a joint representation of words and documents in a common high-dimensional embedding space where user-specified concepts correspond to linear operations of word and document vectors. Our case studies, centered around a large document corpus of computer vision research papers, highlight the potential for usage-based document visualization.", "labels": [0, 7]}
{"id": "3399", "token": "Recently, skin detection has been employed in multifarious applications of computer vision including face detection, gesture recognition, etc. This is mainly due to the appealing characteristics of skin color and its potency to segment objects. However, there are certain challenges involved in utilizing human complexion as a feature to detect faces, and they have led to the inefficiency of many methods. In order to counteract these factors, in this paper, a skin segmentation method which exploits a multi step diffusion algorithm to detect skin regions is presented. The method starts with conservative extraction of skin seeds in each frame which is accomplished by using fusion of ternary-based human motion detection, modified Bayesian classifier, and a feedback mechanism. Subsequently, these candidate skin pixels are utilized in a 2-stage diffusion scheme to detect other skin pixels. Both quantitative and qualitative results demonstrate the effectiveness of the proposed system in comparison with other works.", "labels": [0, 7]}
{"id": "130", "token": "The production of renewable bioenergy will be necessary to meet rising global fossil fuel demands. Members of the marine microalgae genus Nannochloropsis produce large quantities of oils (triacylglycerols; TAGs), and this genus is regarded as one of the most promising for biodiesel production. Recent genome sequencing and transcriptomic studies on Nannochloropsis have provided a foundation for understanding its oleaginous trait, but the mechanism underlying oil accumulation remains to be clarified. Here we report Nannochloropsis knock-out strains of four extraplastidic lysophosphatidic acid acyltransferases (LPAT1-LPAT4) that catalyze a major de novo biosynthetic step of TAGs and membrane lipids. We found that the four LPATs are differently involved in lipid metabolic flow in Nannochloropsis. Double knock-outs among the LPATs revealed the pivotal LPATs for TAG biosynthesis, and localization analysis indicated that the stramenopile-specific LPATs (LPAT3 and LPAT4) associated with TAG synthesis reside at the perimeter of lipid droplets. No homologous region has been found with other lipid droplet-associated proteins, however. Lipid droplets are an organelle found in nearly all organisms, and recently they were shown to play important roles in cellular metabolism and signaling. Our results provide direct evidence for the importance of the perimeter of lipid droplet in TAG synthesis in addition to its known role in maintaining TAG stability, and these findings suggest that the oleaginous trait of Nannochloropsis is enabled by the acquisition of LPATs at the perimeter of lipid droplets.", "labels": [6, 36]}
{"id": "177", "token": "Background: Relatively few attempts have been made to set up an assay that allows the measurement of lymphatic endothelial cells (LECs) motility. Nowadays, the most widely used methods involve adaptation of the Boyden chamber method or the wound scratch assay, both of them showing some limitations due to long and expensive setup and high variability. Methods and Results: We propose a new, economic, and easy to setup LEC Motility ( ELM) assay that will contribute to the study of lymphangiogenesis. The experimental setup consists of extending the coating of the flask with extracellular matrix (ECM) proteins also at the area opposite to the cap, where the LECs will be initially seeded at various densities. The day after, the flasks will be inclined at an angle of about 20 degrees to cover the entire coated surface. Twenty-four hours later, flasks will be moved to the standard position, and the motility of the cells will be easily observed. Using the ELM assay, we were able to compare the motility rate of LECs isolated from different origins, or seeded on different substrates. Conclusion: We propose the use of a new method to evaluate the motility of LECs: the ELM assay. This costeffective analysis has several advantages: It can be easily set up in any cell biology laboratory, can be carried out rapidly, and allows the monitoring of cellular motility for a long period.", "labels": [6, 36]}
{"id": "321", "token": "Nicotinamide adenine dinucleotide (NAD(+)) is an essential coenzyme for various physiological processes including energy metabolism, DNA repair, cell growth, and cell death. Many of these pathways are typically dysregulated in cancer cells, making NAD(+) an intriguing target for cancer therapeutics. NAD(+) is mainly synthesized by the NAD(+) salvage pathway in cancer cells, and not surprisingly, the pharmacological targeting of the NAD(+) salvage pathway causes cancer cell cytotoxicity in vitro and in vivo. Several studies have described the precise consequences of NAD(+) depletion on cancer biology, and have demonstrated that NAD(+) depletion results in depletion of energy levels through lowered rates of glycolysis, reduced citric acid cycle activity, and decreased oxidative phosphorylation. Additionally, depletion of NAD(+) causes sensitization of cancer cells to oxidative damage by disruption of the anti-oxidant defense system, decreased cell proliferation, and initiation of cell death through manipulation of cell signaling pathways (e.g., SIRT1 and p53). Recently, studies have explored the effect of well-known cancer therapeutics in combination with pharmacological depletion of NAD(+) levels, and found in many cases a synergistic effect on cancer cell cytotoxicity. In this context, we will discuss the effects of NAD(+) salvage pathway inhibition on cancer cell biology and provide insight on this pathway as a novel anti-cancer therapeutic target. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [6, 36]}
{"id": "489", "token": "Ataxia telangiectasia (A-T) is a rare incurable neurodegenerative disease caused by biallelic mutations in the gene for ataxia-telangiectasia mutated (ATM). The lack of a functional ATM kinase leads to a pleiotropic phenotype, and oxidative stress is considered to have a crucial role in the complex physiopathology. Recently, steroids have been shown to reduce the neurological symptoms of the disease, although the molecular mechanism of this effect is largely unknown. In the present study, we have demonstrated that dexamethasone treatment of A-T lymphoblastoid cells increases the content of two of the most abundant antioxidants [glutathione (GSH) and NADPH] by up to 30%. Dexamethasone promoted the nuclear accumulation of the transcription factor nuclear factor (erythroid-derived 2)-like 2 to drive expression of antioxidant pathways involved in GSH synthesis and NADPH production. The latter effect was via glucose 6-phosphate dehydrogenase activation, as confirmed by increased enzyme activity and enhancement of the pentose phosphate pathway rate. This evidence indicates that glucocorticoids are able to potentiate antioxidant defenses to counteract oxidative stress in ataxia telangiectasia, and also reveals an unexpected role for dexamethasone in redox homeostasis and cellular antioxidant activity.", "labels": [6, 36]}
{"id": "627", "token": "Purpose: The major problem in producing artificial livers is that primary hepatocytes cannot be cultured for many days. Recently, 3-dimensional (3D) printing technology draws attention and this technology regarded as a useful tool for current cell biology. By using the 3D bio-printing, these problems can be resolved. Methods: To generate 3D bio-printed structures (25 mm x 25 mm), cells-alginate constructs were fabricated by 3D bio-printing system. Mouse primary hepatocytes were isolated from the livers of 6-8 weeks old mice by a 2-step collagenase method. Samples of 4 x 10(7) hepatocytes with 80%-90% viability were printed with 3% alginate solution, and cultured with well-defined culture medium for primary hepatocytes. To confirm functional ability of hepatocytes cultured on 3D alginate scaffold, we conducted quantitative real-time polymerase chain reaction and immunofluorescence with hepatic marker genes. Results: Isolated primary hepatocytes were printed with alginate. The 3D printed hepatocytes remained alive for 14 days. Gene expression levels of Albumin, HNF-4 alpha and Foxa3 were gradually increased in the 3D structures. Immunofluorescence analysis showed that the primary hepatocytes produced hepatic-specific proteins over the same period of time. Conclusion: Our research indicates that 3D bio-printing technique can be used for long-term culture of primary hepatocytes. It can therefore be used for drug screening and as a potential method of producing artificial livers.", "labels": [6, 36]}
{"id": "698", "token": "Mitochondrial complex II or succinate dehydrogenase (SDH) is at the crossroads of oxidative phosphorylation and the tricarboxylic acid cycle. It has been shown that Sdh5 (SDHAF2/SDH5 in mammals) is required for flavination of the subunit Sdh1 (SDHA in human cells) in yeast. Here we demonstrate that in human breast cancer cells, SDHAF2/SDH5 is dispensable for SDHA flavination. In contrast to yeast, CRISPR-Cas9 nickase-mediated SDHAF2 KO breast cancer cells feature flavinated SDHA and retain fully assembled and functional complex II, as well as normal mitochondrial respiration. Our data show that SDHA flavination is independent of SDHAF2 in breast cancer cells, employing an alternative mechanism.", "labels": [6, 36]}
{"id": "808", "token": "The molecular basis for control of the cytoskeleton by the Arf GTPase-activating protein AGAP1 has not been characterized. AGAP1 is composed of G-protein-like (GLD), pleckstrin homology (PH), Arf GAP, and ankyrin repeat domains. Kif2A was identified in screens for proteins that bind to AGAP1. The GLD and PH domains of AGAP1 bound the motor domain of Kif2A. Kif2A increased GAP activity of AGAP1, and a protein composed of the GLD and PH domains of AGAP1 increased ATPase activity of Kif2A. Knockdown (KD) of Kif2A or AGAP1 slowed cell migration and accelerated cell spreading. The effect of Kif2A KD on spreading could be rescued by expression of Kif2A-GFP or FLAG-AGAP1, but not by Kif2C-GFP. The effect of AGAP1 KD could be rescued by FLAG-AGAP1, but not by an AGAP1 mutant that did not bind Kif2A efficiently, ArfGAP1-HA or Kif2A-GFP. Taken together, the results support the hypothesis that the Kif2AAGAP1 complex contributes to control of cytoskeleton remodeling involved in cell movement.", "labels": [6, 36]}
{"id": "943", "token": "Systems cell biology understanding of development requires characterization of all the molecules produced in the biological system. Decades of research and new-generation sequencing provided functional information on key genes and transcripts. However, there is less information available on how differential gene expression translates into the domains of functionally important proteins, peptides, and metabolites, and how changes in these molecules impact development. Mass spectrometry (MS) is the current technology of choice for the detection and quantification of large numbers of proteins and metabolites, because it requires no use of antibodies, functional probes, or a priori knowledge of molecules produced in the system. This review focuses on recent technologies that have improved MS sensitivity for proteins and metabolites and enabled new functionalities to assess their temporal and spatial changes during vertebrate embryonic development. This review highlights case studies, in which new-generation MS tools have enabled the study of hundreds-to-thousands of proteins and metabolites in tissues, cell populations, and single cells in model systems of vertebrate development, particularly the frog (Xenopus), zebrafish, and mouse. New-generation MS expands the toolbox of cell and developmental studies, raising exciting potentials to advance basic and translational research in the life sciences.", "labels": [6, 36]}
{"id": "1108", "token": "Many pathological processes including neurogenic bladder and malignancy necessitate bladder reconstruction, which is currently performed using intestinal tissue. The use of intestinal tissue, however, subjects patients to metabolic abnormalities, bladder stones, and other long-term sequelae, raising the need for a source of safe and reliable bladder tissue. Advancements in stem cell biology have catapulted stem cells to the center of many current tissue regeneration and bioengineering strategies. This review presents the recent advancements in the use of stem cells in bladder tissue bioengineering.", "labels": [6, 36]}
{"id": "1218", "token": "In the field of cell biology, particle counting in intracellular images is important for investigating the cause of diseases. However, particles are manually counted by human observers now. Such manually counting takes a lot of time, and counting result becomes subjective. If an automatic counting method by computer is realized, we can treat a large number of images and it can obtain many objective data. The development of an automatic counting method much contributes to understand the case of disease. However, particle counting in intracellular images by a computer is new research field, and conventional methods are little. Thus, we propose counting method based on regression analysis. We use partial least squares regression and auto-correlation between two different types of features using mask patterns for higher-order local autocorrelation feature. The proposed method gives higher accuracy than counting by principal component regression, support vector regression and ImageJ. In experiment, the proposed method can count with small error in comparison with human counting. The effectiveness of our method is shown by experiments. (C) 2016 Wiley Periodicals, Inc.", "labels": [6, 36]}
{"id": "1495", "token": "Background: Recent experiments regarding Ndc80/Hec1 in force generation at kinetochores for chromosome motions have prompted speculation about possible models for interactions between positively charged molecules at kinetochores and negative charge at and near the plus ends of microtubules. Discussion: A clear picture of how kinetochores and centrosomes establish and maintain a dynamic coupling to microtubules for force generation during the complex motions of mitosis remains elusive. The current paradigm of molecular cell biology requires that specific molecules, or molecular geometries, for force generation be identified. However, it is possible to explain several different mitotic motions-including poleward force production at kinetochores-within a classical electrostatics approach in terms of experimentally known charge distributions, modeled as surface and volume bound charges interacting over nanometer distances. Conclusion: We propose here that implicating Ndc80/Hec1 as a bound volume positive charge distribution in electrostatic generation of poleward force at kinetochores is most consistent with a wide range of experimental observations on mitotic motions, including polar production of poleward force and chromosome congression.", "labels": [6, 36]}
{"id": "1625", "token": "Chronic myeloid leukemia (CML) is a myeloproliferative disease with a characteristic BCR-ABL tyrosine kinase (TK) fusion protein. Despite the clinical efficacy accomplished by TKIs therapies, disease progression may affect patient response rate to these inhibitors due to a multitude of factors that could lead to development of a mechanism known as multidrug resistance (MDR). 7-Ketocholesterol (7KC) is an oxidized cholesterol derivative that has been extensively reported to cause cell death in a variety of cancer models. In this study, we showed the in vitro efficacy of 7KC against MDR leukemia cell line, Lucena. 7KC treatment induced reduction in cell viability, together with apoptosis-mediated cell death. Moreover, downregulation of MDR protein caused intracellular drug accumulation and 7KC co-incubation with either Daunorubicin or Vincristine reduced cell viability compared to the use of each drug alone. Additionally, quantitative label-free mass spectrometry-based protein quantification showed alteration of different molecular pathways involved in cell cycle arrest, induction of apoptosis and misfolded protein response. Conclusively, this study highlights the effect of 7KC as a sensitizing agent of multi drug resistance CML and elucidates its molecular mechanisms. Significance: CML patients treated with tyrosine kinase inhibitors (TKIs) have showed a 5-year estimated overall survival of 89%, with cumulative complete cytogenetic response of 87%. However, development of drug resistance is a common feature of the disease progression. This study aimed at showing the effect of 7KC as a cytotoxic and sensitizing agent of multidrug resistance CML cell lines. The cellular and molecular basis of this compound were elucidated using a comprehensive strategy based on quantitative proteomic and cell biology assays. We showed that 7KC induced cell death and overcomes drug resistance in CML through mechanisms that go beyond the classical MDR1 pathways. (C) 2016 Elsevier B.V. All rights reserved.", "labels": [6, 36]}
{"id": "1717", "token": "Extracellular vesicles or exosomes constitute an evolutionarily conserved mechanism of intercellular signaling. Exosomes are gaining an increasing amount of attention due to their role in pathologies, including malignancy, their importance as prognostic and diagnostic markers, and their potential as a therapeutic tool. Merkel cell carcinoma (MCC) is an aggressive form of skin cancer with a poor prognosis. Because an effective systemic treatment for this cancer type is currently not available, an exosome-based therapy was proposed. However, comprehensive secretome profiling has not been performed for MCC. To help unveil the putative contribution of exosomes in MCC, we studied the protein content of MCC-derived exosomes. Since approximately 80% of all MCC cases contain Merkel cell polyomavirus (MCPyV), the secretomes of two MCPyV-negative and two MCPyV-positive MCC cell lines were compared. We identified with high confidence 164 exosome-derived proteins common for all four cell lines that were annotated in ExoCarta and Vesiclepedia databases. These include proteins implicated in motility, metastasis and tumor progression, such as integrins and tetraspanins, intracellular signaling molecules, chaperones, proteasomal proteins, and translation factors. Additional virus-negative and virus-positive MCC cell lines should be examined to identify highly representative exosomal proteins that may provide reliable prognostic and diagnostic biomarkers, as well as targets for treatment in the future. Data are available via ProteomeXchange with identifier PXD004198.", "labels": [6, 36]}
{"id": "1778", "token": "Kruppel-like factors (KLFs) are a family of zinc-finger transcription factors that are found in many species. Recent studies have shown that KLFs play a fundamental role in regulating diverse biological processes such as cell proliferation, differentiation, development and regeneration. Of note, several KLFs are also crucial for maintaining pluripotency and, hence, have been linked to reprogramming and regenerative medicine approaches. Here, we review the crucial functions of KLFs in mammalian embryogenesis, stem cell biology and regeneration, as revealed by studies of animal models. We also highlight how KLFs have been implicated in human diseases and outline potential avenues for future research.", "labels": [6, 36]}
{"id": "1845", "token": "CD4(+)CD25(high)FOXP3(+) regulatory T cells (Tregs) are involved in graft-specific tolerance after solid organ transplantation. However, adoptive transfer of polyspecific Tregs alone is insufficient to prevent graft rejection even in rodent models, indicating that graft-specific Tregs are required. We developed a highly specific chimeric antigen receptor that recognizes the HLA molecule A*02 (referred to as A2-CAR). Transduction into natural regulatory T cells (nTregs) changes the specificity of the nTregs without alteration of their regulatory phenotype and epigenetic stability. Activation of nTregs via the A2-CAR induced proliferation and enhanced the suppressor function of modified nTregs. Compared with nTregs, A2-CAR Tregs exhibited superior control of strong allospecific immune responses in vitro and in humanized mouse models. A2-CAR Tregs completely prevented rejection of allogeneic target cells and tissues in immune reconstituted humanized mice in the absence of any immunosuppression. Therefore, these modified cells have great potential for incorporation into clinical trials of Treg-supported weaning after allogeneic transplantation.", "labels": [6, 36]}
{"id": "1873", "token": "In current practice, human immunodeficiency virus-infected (HIV+) candidates with CD4 >200 cells/mm(3) are eligible for kidney transplantation; however, the optimal pretransplant CD4 count above this threshold remains to be defined. We evaluated clinical outcomes in patients with baseline CD4 >350 and <350 cells/mm(3) among 38 anti-thymocyte globulin (ATG)-treated HIV-negative to HIV+ kidney transplants performed at our center between 2006 and 2013. Median follow-up was 2.6 years. Rates of acute rejection and patient and graft survival were not different between groups. Occurrence of severe CD4 lymphopenia (<200 cells/mm(3)), however, was more common among patients with a baseline CD4 count 200-349 cells/mm(3) compared with those transplanted at higher counts (75% vs. 30% at 4 weeks [p = 0.04] and 71% vs. 5% at 52 weeks [p = 0.001], respectively, after transplant). After adjusting for age, baseline CD4 count of 200-349 cells/mm(3) was an independent predictor of severe CD4 lymphopenia at 4 weeks (relative risk [RR] 2.6; 95% confidence interval [CI] 1.3-5.1) and 52 weeks (RR 14.3; 95% CI 2-100.4) after transplant. Patients with CD4 <200 cells/mm(3) at 4 weeks had higher probability of serious infections during first 6 months after transplant (19% vs. 50%; log-rank p = 0.05). These findings suggest that ATG must be used with caution in HIV+ kidney allograft recipients with a pretransplant CD4 count <350 cells/mm(3). In this single-center retrospective cohort study, the authors show that anti-thymocyte globulin-treated HIV-positive kidney transplant recipients with a baseline CD4 count <350 cells/mm(3) have a higher risk of severe lymphopenia (CD4 <200 cells/mm(3)), and associated nonopportunistic infections.", "labels": [6, 36]}
{"id": "2016", "token": "The existence of a local renin-angiotensin system (RAS) specific to the hematopoietic bone marrow (BM) microenvironment had been proposed two decades ago. Most of the RAS molecules including ACE, ACE2, AGT, AGTR1, AGTR2, AKR1C4, AKR1D1, ANPEP, ATP6AP2, CMA1, CPA3, CTSA, CTSD, CTSG, CYP11A1, CYP11B1, CYP11B2, CYP17A1, CYP21A2, DPP3, EGFR, ENPEP, GPER, HSD11B1, HSD11B2, IGF2R, KLK1, LNPEP, MAS1, MME, NR3C1, NR3C2, PREP, REN, RNPEP, and THOP1 are locally present in the BM microenvironment. Local BM RAS peptides control the hematopoietic niche, myelopoiesis, erythropoiesis, thrombopoiesis and the development of other cellular lineages. Local BM RAS is important in hematopoietic stem cell biology and microenvironment. Angiotensin II regulates the proliferation, differentiation, and engraftment of hematopoietic stem cells. Activation of Mas receptor or ACE2 promotes proliferation of CD34+ cells. BM contains a progenitor that expresses renin throughout development. Angiotensin II attenuates the migration and proliferation of CD34+ Cells and promotes the adhesion of both MNCs and CD34+ cells. Renin cells in hematopoietic organs are precursor B cells. The renin cell requires RBP-J to differentiate. Mutant renin-expressing hematopoietic precursors can cause leukemia. Deletion of RBP-J in the renin-expressing progenitors enriches the precursor B-cell gene programme. Mutant cells undergo a neoplastic transformation, and mice develop a highly penetrant B-cell leukemia with multi-organ infiltration and early death. Many biological conditions during the development and function of blood cells are mediated by RAS, such as apoptosis, cellular proliferation, intracellular signaling, mobilization, angiogenesis, and fibrosis. The aim of this paper is to review recent developments regarding the actions of local BM RAS in the genesis of leukemia and other malignancies molecules.", "labels": [6, 36]}
{"id": "2092", "token": "Aging is the main risk factor for many degenerative diseases and declining health. Senescent cells are part of the underlying mechanism for time-dependent tissue dysfunction. These cells can negatively affect neighbouring cells through an altered secretory phenotype: the senescence-associated secretory phenotype (SASP). The SASP induces senescence in healthy cells, promotes tumour formation and progression, and contributes to other age-related diseases such as atherosclerosis, immune-senescence and neurodegeneration. Removal of senescent cells was recently demonstrated to delay age-related degeneration and extend lifespan. To better understand cell aging and to reap the benefits of senescent cell removal, it is necessary to have a reliable biomarker to identify these cells. Following an introduction to cellular senescence, we discuss several classes of biomarkers in the context of their utility in identifying and/or removing senescent cells from tissues. Although senescence can be induced by a variety of stimuli, senescent cells share some characteristics that enable their identification both in vitro and in vivo. Nevertheless, it may prove difficult to identify a single biomarker capable of distinguishing senescence in all cell types. Therefore, this will not be a comprehensive review of all senescence biomarkers but rather an outlook on technologies and markers that are most suitable to identify and isolate senescent cells. Crown Copyright (C) 2016 Published by Elsevier B.V. All rights reserved.", "labels": [6, 36]}
{"id": "2155", "token": "There is a consensus in the cardiac stem cell biology field that human embryonic stem cell derived-cardiomyocytes (hESC-CMs) are immature and do not resemble human adult cardiomyocytes, either phenotypically or transcriptionally. One striking difference between hESC-CMs and mature adult cardiomyocytes is their morphology. hESC-CMs grown in vitro are pleomorphic in shape and have no clear sarcomere organization; conversely, adult cardiomyocytes are rod-shaped with an average length-to-width (aspect) ratio of 7:1 and display a highly organized internal cytoskeletal structure. By combining multiple cues, i.e. substrate stiffness and topographical features, it may be possible to create a more physiologically-relevant model that better recapitulates the architecture of the native human heart which will aid in regenerative medicine therapies, disease modeling, drug testing, developmental and cardiotoxicity studies. Prior work in our lab used microcontact printing on glass slides to control the cell shape to improve the maturation of hESC-CMs. Since then, new work has focused on patterning methods on more compliant substrates using both microcontact printing, as well as a sacrificial polyvinyl alcohol (PVA) film. In this proceeding, the advantages and disadvantages of the above methods will be discussed in relationship to hESC-CM maturation.", "labels": [6, 36]}
{"id": "2309", "token": "Predicting the location where a protein resides within a cell is important in cell biology. Computational approaches to this issue have attracted more and more attentions from the community of biomedicine. Among the protein features used to predict the subcellular localization of proteins, the feature derived from Gene Ontology (GO) has been shown to be superior to others. However, most of the sights in this field are set on the presence or absence of some predefined GO terms. We proposed a method to derive information from the intrinsic structure of the GO graph. The feature vector was constructed with each element in it representing the information content of the GO term annotating to a protein investigated, and the support vector machines was used as classifier to test our extracted features. Evaluation experiments were conducted on three protein datasets and the results show that our method can enhance eukaryotic and human subcellular location prediction accuracy by up to 1.1% better than previous studies that also used GO-based features. Especially in the scenario where the cellular component annotation is absent, our method can achieved satisfied results with an overall accuracy of more than 87%. (C) 2016 Elsevier Ltd. All rights reserved.", "labels": [6, 36]}
{"id": "2453", "token": "Renin is the initiator and rate-limiting factor in the renin-angiotensin blood pressure regulation system. Although renin is not exclusively produced in the kidney, in nonmurine species the synthesis and secretion of the active circulatory enzyme is confined almost exclusively to the dense core granules of juxtaglomerular (JG) cells, where prorenin is processed and stored for release via a regulated pathway. Despite its importance, the structural organization and regulation of granules within these cells is not well understood, in part due to the difficulty in culturing primary JG cells in vitro and the lack of appropriate cell lines. We have streamlined the isolation and culture of primary renin-expressing cells suitable for high-speed, high-resolution live imaging using a Percoll gradient-based procedure to purify cells from RenGFP(+) transgenic mice. Fibronectin-coated glass coverslips proved optimal for the adhesion of renin-expressing cells and facilitated live cell imaging at the plasma membrane of primary renin cells using total internal reflection fluorescence microscopy (TIRFM). To obtain quantitative data on intracellular function, we stained mixed granule and lysosome populations with Lysotracker Red and stimulated cells using 100 nM isoproterenol. Analysis of membrane-proximal acidic granular organelle dynamics and behavior within renin-expressing cells revealed the existence of two populations of granular organelles with distinct functional responses following isoproterenol stimulation. The application of high-resolution techniques for imaging JG and other specialized kidney cells provides new opportunities for investigating renal cell biology.", "labels": [6, 36]}
{"id": "2656", "token": "Angioimmunoblastic T cell lymphoma (AITL) originates from follicular helper T-cells and is characterised by a polymorphic infiltrate with the neoplastic T-cells forming small clusters around the follicle and high endothelial venules. Despite the recent advances in its phenotypic characterisation, the genetics and molecular mechanisms underlying AITL are not fully understood. In the present study, we performed whole exome sequencing in 9 cases of AITL from Taiwan (n = 6) and U. K. (n = 3). We confirmed frequent mutations in TET2 (9/9), DNMT3A (3/9), IDH2 (3/9), RHOA (3/9) and PLCG1 (2/9) as recently reported by others. More importantly, we identified mutations in TNFRSF21 (1/9), CCND3 (1/9) and SAMSN1 (1/9), which are not yet seen or strongly implicated in the pathogenesis of AITL. Among the pathogenic mutations identified in AITL, mutations in DNA methylation regulators TET2 and DNMT3A occur early in hematopoietic stem cells as shown by previous studies, and these genetic events enhance the self-renewal of hematopoietic stem cells, but are unlikely to have any major impact on T-cell differentiation. Mutations in RHOA, PLCG1 and TNFRSF21 (DR6), which encode proteins critical for T-cell biology, most likely promote T-cell differentiation and malignant transformation, consequently generating the malignant phenotype. Our findings extend the molecular insights into the multistage development of AITL.", "labels": [6, 36]}
{"id": "2713", "token": "The behavior of cells and how they react to stimuli is critically important for drug development, drug delivery, and understanding the molecular basis of many diseases. However, we still lack a comprehensive understanding of these interactions, particularly in relation to drug delivery from nanoparticles. This Sensors Issues article discusses the importance of quantifying these interactions and highlights some key areas where advances in sensor technology have the potential to transform our understanding of drug delivery and cell biology.", "labels": [6, 36]}
{"id": "2728", "token": "Stem cells are one of the key components in tissue engineering (TE) for tissue repair and regeneration. However, further studies are necessary in order to provide a suitable microenvironment for stem cells to differentiate and thereby regenerate tissues. Carbon-based nanomaterials (i.e., carbon nanotubes (CNTs) and graphene) have recently attracted much significant attention as tools for investigating and controlling stem cell biology and fate due to their remarkable characteristics, including unique mechanical properties, tunable surface chemistry, and high electrical conductivity. In this review paper, we describe applications of CNTs and graphene in stem cell differentiation and consequently tissue formation in both in vitro and in vivo conditions. Cytotoxicity of CNTs and graphene is also addressed. Finally, we discuss potential challenges and future directions for applications of CNTs and graphene in the stem cell culture and differentiation.", "labels": [6, 36]}
{"id": "2896", "token": "Better memory for positive information compared to negative and neutral information has been repeatedly associated with successful aging. The main psychological explanations for this so-called positivity effect in memory principally rely on emotional, motivational, and cognitive mechanisms that make older adults' cognition highly sensitive to positive information according to ultimate goals of well-being. However, emerging evidence also delineates a genetic profile for positivity effects in memory, which may render some older adults more prone than others to encoding and remembering positive memories. First, we present a brief overview of behavioral and neuroimaging studies about the positivity effect in aging. Subsequently, we report studies on candidate genes associated with positive memories. In particular, we review work to date on several candidate genes that are sensitive to stimulus valence such as ADRA2B, COMT, and 5HTTLPR. Finally, we propose that the future approach to the study of genetic correlates of positivity effects in memory should also include mitochondrial functioning (TOMM40). Altogether, the study of genetics and cell biology of positivity effects in memory can help us to reveal the underlying bottom-up pathways to positive affect in healthy aging. (C) 2016 Elsevier Inc. All rights reserved.", "labels": [6, 36]}
{"id": "2965", "token": "Cell division is a fascinating and fundamental process that sustains life. By this process, unicellular organisms reproduce and multicellular organisms sustain development, growth, and tissue repair. Division of a mother cell gives rise to two daughter cells according to an ordered set of events within four successive phases called G1 (gap1), S (DNA S ynthesis), G2 (gap2), and M (Mitosis) phase. How these different phases are orchestrated to ensure the physical separation of the two daughter cells is a tightly regulated process. Indeed, inappropriate cell division could lead to uncontrolled cell proliferation and ultimately to cancer. Saccharomyces cerevisiae is an excellent model system for unraveling the secrets of cell division. A large community of researchers has chosen budding yeast as a model because of its advantages: rapid growth in simple and economical media, tractable genetics, powerful biochemistry, cell biology, and proteomics approaches. Furthermore, the cell cycle mechanisms, as elucidated in yeast, are conserved in higher eukaryotes. The ability to synchronize and get large numbers of cells in a particular stage of the cell cycle is crucial to properly explore the mechanisms of the cell cycle. An overview of the most common yeast synchronization techniques has been compiled in this chapter.", "labels": [6, 36]}
{"id": "3048", "token": "Mass-spectrometry-based proteomics is continuing to make major contributions to the discovery of fundamental biological processes and, more recently, has also developed into an assay platform capable of measuring hundreds to thousands of proteins in any biological system. The field has progressed at an amazing rate over the past five years in terms of technology as well as the breadth and depth of applications in all areas of the life sciences. Some of the technical approaches that were at an experimental stage back then are considered the gold standard today, and the community is learning to come to grips with the volume and complexity of the data generated. The revolution in DNA/RNA sequencing technology extends the reach of proteomic research to practically any species, and the notion that mass spectrometry has the potential to eventually retire the western blot is no longer in the realm of science fiction. In this review, we focus on the major technical and conceptual developments since 2007 and illustrate these by important recent applications.", "labels": [6, 36]}
{"id": "3257", "token": "Microfluidic flow cells provide excellent control over the formation of microemulsions, which are widely applied as templates for the fabrication of hydrogel microparticles and vesicles with defined physicochemical properties. In recent years, bio-orthogonal synthesis schemes of macromolecular building blocks as well as their microfluidic processing under mild reaction conditions have greatly extended microfluidics-based vesicle and hydrogel design beyond material sciences. In particular, in synthetic and cell biology, tissue engineering as well as cell-free biotechnology, microgels and vesicles as experimental platforms with known parameter space allow for mimicking, studying and manipulating key aspects of cellular life in vitro in a tailored fashion. This article provides insights in recent advances to fabricate vesicles and microgels by microfluidic jets and droplets with tailored volume, shape and internal structure, and presents developments in applying these materials as artificial extracellular matrices as well as simple cell mimics designed by microfluidics.", "labels": [6, 36]}
{"id": "3315", "token": "Atomic Force microscopy (AFM) is becoming a prevalent tool in cell biology and biomedical studies, especially those focusing on the mechanical properties of cells and tissues. The newest generation of bio-AFMs combine ease of use and seamless integration with live-cell epifluorescence or more advanced optical microscopies. As a unique feature with respect to other bionanotools, AFM provides nanometer-resolution maps for cell topography, stiffness, viscoelasticity, and adhesion, often overlaid with matching optical images of the probed cells. This review is intended for those about to embark in the use of bio-AFMs, and aims to assist them in designing an experiment to measure the mechanical properties of adherent cells. In addition to describing the main steps in a typical cell mechanics protocol and explaining how data is analysed, this review will also discuss some of the relevant contact mechanics models available and how they have been used to characterize specific features of cellular and biological samples.", "labels": [6, 36]}
{"id": "3493", "token": "The planar cell polarity (PCP) pathway is best known for its role in polarizing epithelial cells within the plane of a tissue but it also plays a role in a range of cell migration events during development. The mechanism by which the PCP pathway polarizes stationary epithelial cells is well characterized, but how PCP signaling functions to regulate more dynamic cell behaviors during directed cell migration is much less understood. Here, we review recent discoveries regarding the localization of PCP proteins in migrating cells and their impact on the cell biology of collective and individual cell migratory behaviors.", "labels": [6, 36]}
{"id": "26", "token": "Tauopathies encompass a broad range of neurodegenerative diseases featuring extensive neuronal death and cognitive decline. However, research over the past 30 years has failed to significantly advance our understanding of how tau causes dementia, limiting the design of rational therapeutics. It has become evident that we need to expand our understanding of tau in physiology, in order to delineate how tau may contribute to pathology. This review discusses recent evidence that has uncovered a novel aspect of tau function, based on its previously uncharacterized localization to the synapse. Here, multiple streams of evidence support a critical role for synaptic tau in the regulation of synapse physiology. In particular, long-term depression, a form of synaptic weakening, is dependent on the presence of tau in hippocampal neurons. The regulation of tau by specific phosphorylation events downstream of GSK-3 beta activation appears to be integral to this signaling role. We also describe how the regulation of synapse physiology by tau and its phosphorylation may inform our understanding of tauopathies and comorbid diseases. This work should provide a platform for future tau biology research in addition to therapeutic design.", "labels": [5, 32]}
{"id": "78", "token": "Ultrasonic ranging (UR) technology has being used widely in many industries around the world. This paper aims to design and manufacture an ultrasonic distance measuring system with lower price and higher accuracy. Based on the deep study of principle of ultrasonic ranging, we designed the general plan and detailed electrical circuits for the ultrasonic distance measuring system based on single chip microprocessor of AT89S52, including the transmitter module of ultrasonic wave, receiving module of ultrasonic wave, display module etc. Then, we compiled the relative driven programs for all modules. After that, we debugged the combined system of hardware and software system. At last, the experimental results show that the cost is about 300RMB for 3 prototypes, measuring rang is 0.16 similar to 1.5m with the accuracy of 0.001mm, which means the ranging system meets the design requirements of lower price and higher accuracy.", "labels": [1, 13]}
{"id": "12", "token": "From a geoinformation science perspective real estate portals apply non-spatial methods to analyse and visualise rental price data. Their approach shows considerable shortcomings. Portal operators neglect real estate agents' mantra that exactly three things are important in real estates: location, location and location (Stroisch, 2010). Although real estate portals retacord the spatial reference of their listed apartments, geocoded address data is used insufficiently for analyses and visualisation, and in many cases the data is just used to pin map the listings. To date geoinformation science, spatial statistics and geovisualization play a minor role for real estate portals in analysing and visualising their housing data. This contribution discusses the analytical and geovisual status quo of real estate portals and addresses the most serious deficits of the employed non-spatial methods. Alternative analysing approaches from geostatistics, machine learning and geovisualization demonstrate potentials to optimise real estate portals' analysing and visualisation capacities.", "labels": [0, 8]}
{"id": "47", "token": "1. Host-parasitoid systems are characterized by a continuous development of new defence strategies in hosts and counter-defence mechanisms in parasitoids. This co-evolutionary arms race makes host-parasitoid systems excellent for understanding trade-offs in host use caused by evolutionary changes in host immune responses and parasitoid virulence. However, knowledge obtained from natural host-parasitoid systems on such trade-offs is still limited. 2. In this study, the aim was to examine trade-offs in parasitoid virulence in Asecodes parviclava (Hymenoptera: Eulophidae) when attacking three closely related beetles: Galerucella pusilla, Galerucella calmariensis and Galerucella tenella (Coleoptera: Chrysomelidae). A second aim was to examine whether geographic variation in parasitoid infectivity or host immune response could explain differences in parasitism rate between northern and southern sites. 3. More specifically, we wanted to examine whether the capacity to infect host larvae differed depending on the previous host species of the parasitoids and if such differences were connected to differences in the induction of host immune systems. This was achieved by combining controlled parasitism experiments with cytological studies of infected larvae. 4. Our results reveal that parasitism success in A. parviclava differs both depending on previous and current host species, with a higher virulence when attacking larvae of the same species as the previous host. Virulence was in general high for parasitoids from G. pusilla and low for parasitoids from G. calmariensis. At the same time, G. pusilla larvae had the strongest immune response and G. calmariensis the weakest. These observations were linked to changes in the larval hemocyte composition, showing changes in cell types important for the encapsulation process in individuals infected by more or less virulent parasitoids. 5. These findings suggest ongoing evolution in parasitoid virulence and host immune response, making the system a strong candidate for further studies on host race formation and speciation.", "labels": [6, 38]}
{"id": "55", "token": "This paper designs and implements an embedded security gateway based on double-homed structure which composed of software and hardware parts. The core of hardware platform is based on two S3C6410 processors and one EP1C18F4620 FPGA. The software is based on reduced Linux kernel 3.0.1. The gateway uses Net-filter/IP-tables firewall, IPSec VPN and Network isolation technologies. And it can effectively reduce the risk of transmitting information by public network and improve the defensive capability. So it can be applied to the business with high security level.", "labels": [0, 9]}
{"id": "15", "token": "This paper proposes a general architecture for testing, validating and verifying Ambient Intelligence (AmI) environments: AmISim. The development of AmI is a very complex task because this technology must often adapt to contextual information as well as unpredictable behaviours and environmental features. The architecture presented deals with AmI applications in order to cover the different components of these kinds of systems: environment, users, context and adaptation. This architecture is the first one that is able to cover all these features, which are needed in a full AmI system. The paper shows that AmISim is able to cover a complete AmI system and to provide a framework which can test scenarios that would be impossible to test in real environments or even with previous simulation approaches. Simulated and real elements coexist in AmISim for a robust testing, validation and verification of the AmI systems, which provide an easier and less costly deployment.", "labels": [4, 25]}
{"id": "20", "token": "When we conserve energy resources from any systems, our environment can enjoy cleaner air and a healthier, and we can help protect the climate by reducing heating due to more energy consumption. Energy Efficient medical equipment design is the latest research in medical science. Now, scientists are focus and shifting toward energy efficient medical system design. ECG machine is the most commonly used in medical equipments. If any equipment consuming less power than the environment, climate and whole medical regions will be move to greener, pollution-less and energy efficient. Finally, it reduces the cost of medical treatment and save energy consumptions. In this work, we are going to design and implement energy efficient ECG machine using LVDCI (Low Voltage Digitally Control Impedance), SSTL (Stub Series Terminated Logic) and HSTL (High Speed Transistor Logic) I/O standard.", "labels": [3, 23]}
{"id": "69", "token": "Typically-developing (TD) children frequently refer to objects uniquely in gesture. Parents translate these gestures into words, facilitating children's acquisition of these words (Goldin-Meadow et al. in Dev Sci 10(6):778-785, 2007). We ask whether this pattern holds for children with autism (AU) and with Down syndrome (DS) who show delayed vocabulary development. We observed 23 children with AU, 23 with DS, and 23 TD children with their parents over a year. Children used gestures to indicate objects before labeling them and parents translated their gestures into words. Importantly, children benefited from this input, acquiring more words for the translated gestures than the not translated ones. Results highlight the role contingent parental input to child gesture plays in language development of children with developmental disorders.", "labels": [2, 18]}
{"id": "34", "token": "People unconsciously and unintentionally make inferences about others' personality traits based on their behaviours. In this study, a classic memory phenomenon - proactive interference (PI) - is for the first time used to detect spontaneous trait inferences. PI should occur when lists of behaviour descriptions, all implying the same trait, are to be remembered. Switching to a new trait should produce release' from proactive interference (or RPI). Results from two experiments supported these predictions. PI and RPI effects are consistent with an interactive activation and competition model of person perception (e.g., McNeill & Burton, 2002, J. Exp. Psychol., 55A, 1141), which predicts categorical organization of social behaviours based on personality traits. Advantages of this model are discussed.", "labels": [2, 17]}
{"id": "10", "token": "Geosynthetics have been commonly used as reinforcement layers to bridge over underground cavities, sinkholes, and trenches to support upper soil mass. In such applications, the geosynthetics, acting as tensioned membranes plus the effect of soil arching, maintain the stability and mitigate the subsidence of the overlying soil. This study, including a two-dimensional experimental testing and subsequent numerical simulations, investigates the subsidence of the soil mass and deformation of the geosynthetics over a roadway subdrain. The experimental study was performed in a fabricated container with 7 trapdoors (125 mm each) at the bottom. One of the trapdoors was lowered to mimic a trench for subdrain. Cylindrical aluminum bars were used as soil in the experimental testing to imitate the two-dimensional (2D) situations. A layer of geotextile was placed underneath the soil fill to serve as the reinforcement. Following the experimental test, a numerical simulation was carried out, using Discrete Element Method, PFC2D, to extend the scope of the experimental study. The results indicated that (1) the deformed shape of the geosynthetic layer is approximately parabolic, (2) the subsidence was decreased hyperbolically in the vertical direction and the lateral influence range appeared to be bounded by two lines inclined at (45 degrees + phi/2), and (3) the friction angle showed significant influence on subsidence and tension in geosynthetic. (C) 2015 Elsevier Ltd. All rights reserved.", "labels": [4, 26]}
